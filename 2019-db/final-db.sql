-- MySQL dump 10.13  Distrib 5.6.33, for debian-linux-gnu (x86_64)
--
-- Host: localhost    Database: wp_halfway
-- ------------------------------------------------------
-- Server version	5.6.33-0ubuntu0.14.04.1

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `bolt_authtoken`
--

DROP TABLE IF EXISTS `bolt_authtoken`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_authtoken` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` int(11) DEFAULT NULL,
  `username` varchar(32) COLLATE utf8_unicode_ci DEFAULT NULL,
  `token` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `salt` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `lastseen` datetime DEFAULT NULL,
  `ip` varchar(45) COLLATE utf8_unicode_ci DEFAULT NULL,
  `useragent` varchar(128) COLLATE utf8_unicode_ci DEFAULT NULL,
  `validity` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_740AC52FA76ED395` (`user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=232 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_authtoken`
--

LOCK TABLES `bolt_authtoken` WRITE;
/*!40000 ALTER TABLE `bolt_authtoken` DISABLE KEYS */;
/*!40000 ALTER TABLE `bolt_authtoken` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_blocks`
--

DROP TABLE IF EXISTS `bolt_blocks`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_blocks` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `slug` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `datecreated` datetime NOT NULL,
  `datechanged` datetime NOT NULL,
  `datepublish` datetime DEFAULT NULL,
  `datedepublish` datetime DEFAULT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `templatefields` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `content` longtext COLLATE utf8_unicode_ci,
  `contentlink` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `image` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `show_in_sidebar` tinyint(1) NOT NULL DEFAULT '0',
  `contentlink_text` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `contentlink_title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `sidebar_ordering` int(11) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `IDX_7B2C81B7989D9B62` (`slug`),
  KEY `IDX_7B2C81B7AFBA6FD8` (`datecreated`),
  KEY `IDX_7B2C81B7BE74E59A` (`datechanged`),
  KEY `IDX_7B2C81B7A5131421` (`datepublish`),
  KEY `IDX_7B2C81B7B7805520` (`datedepublish`),
  KEY `IDX_7B2C81B77B00651C` (`status`)
) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_blocks`
--

LOCK TABLES `bolt_blocks` WRITE;
/*!40000 ALTER TABLE `bolt_blocks` DISABLE KEYS */;
INSERT INTO `bolt_blocks` VALUES (2,'footer','2019-02-26 16:57:05','2019-06-24 11:43:23','2019-02-26 16:56:42',NULL,1,'published','[]','Footer','© Halfway to the Future 2019.\r\n\r\nRead our [Privacy Policy](/privacy-policy \"HttF Privacy Policy\").\r\n\r\nFollow us on [Twitter](https://twitter.com/httfsymposium \"@httfsymposium on Twitter\").\r\n\r\n<hr>\r\n\r\nPowered by [Bolt CMS](https://bolt.cm \"Bolt CMS\"). \r\n\r\nDesigned by [Martin Porcheron](https://www.porcheron.uk/ \"Martin Porcheron\").\r\n',NULL,NULL,0,NULL,NULL,0),(3,'sponsors-light','2019-02-26 17:00:09','2019-10-15 11:40:17','2019-02-26 16:59:54',NULL,1,'published','[]','Sponsors (Light Theme)','**With thanks to our sponsors:**\r\n\r\n[![University of Nottingham logo](/files/2019-06/partner-uon-black.png)](https://www.nottingham.ac.uk/ \"University of Nottingham\")\r\n\r\n[![SIGCHI logo](/files/2019-06/sponsor-sigchi-black.png)](https://sigchi.org/ \"ACM SIGCHI\")\r\n\r\n\r\n[![Microsoft logo](/files/2019-10/sponsor-microsoft-black.png)](https://www.microsoft.com/en-us/research/ \"Microsoft Research\")',NULL,NULL,0,NULL,NULL,9),(4,'sigchi-student-rate','2019-06-23 15:12:51','2019-07-05 18:15:17','2019-06-23 15:11:41',NULL,1,'held','[]','SIGCHI Student Rate','Details on the student discount from SIGCHI are [now available](/sigchi-student-subsidy \"SIGCHI student discount\"). Please apply early for your discount, as discount codes are limited.\r\n',NULL,NULL,1,NULL,NULL,1),(5,'programme','2019-06-23 19:59:09','2019-11-20 16:21:05','2019-06-23 19:58:55',NULL,1,'published','[]','Programme','The symposium programme, with details of all keynotes, talks, posters, panels, and demos is online now. ','/programme',NULL,1,'Programme','Browse the programme',1),(6,'sponsors-dark','2019-06-24 23:34:47','2019-10-15 11:40:35','2019-06-24 23:33:34',NULL,1,'published','[]','Sponsors (Dark Theme)','**With thanks to our sponsors:**\r\n\r\n[![University of Nottingham logo](/files/2019-06/partner-uon-white.png)](https://www.nottingham.ac.uk/ \"University of Nottingham\")\r\n\r\n[![SIGCHI logo](/files/2019-06/sponsor-sigchi-white.png)](https://sigchi.org/ \"ACM SIGCHI\")\r\n\r\n[![Microsoft logo](/files/2019-10/sponsor-microsoft-white.png)](https://www.microsoft.com/en-us/research/ \"Microsoft Research\")',NULL,NULL,0,NULL,NULL,0),(7,'registration-now-open','2019-07-05 18:14:45','2019-11-18 17:12:39','2019-07-05 18:13:31',NULL,1,'held','[]','Registration','Online registration will close today by midday. [Please register online now](/registration \"Registration for HttF\"), or in person at the venue.','https://www.halfwaytothefuture.org/registration',NULL,1,'Register here','Start online registration now',0);
/*!40000 ALTER TABLE `bolt_blocks` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_cron`
--

DROP TABLE IF EXISTS `bolt_cron`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_cron` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `interim` varchar(16) COLLATE utf8_unicode_ci NOT NULL,
  `lastrun` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_CD38E123615F8869` (`interim`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_cron`
--

LOCK TABLES `bolt_cron` WRITE;
/*!40000 ALTER TABLE `bolt_cron` DISABLE KEYS */;
/*!40000 ALTER TABLE `bolt_cron` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_field_value`
--

DROP TABLE IF EXISTS `bolt_field_value`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_field_value` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `contenttype` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `content_id` int(11) NOT NULL,
  `name` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `grouping` int(11) NOT NULL DEFAULT '0',
  `block` varchar(64) COLLATE utf8_unicode_ci DEFAULT NULL,
  `fieldname` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `fieldtype` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  `value_string` varchar(255) COLLATE utf8_unicode_ci DEFAULT NULL,
  `value_text` longtext COLLATE utf8_unicode_ci,
  `value_integer` int(11) DEFAULT NULL,
  `value_float` double DEFAULT NULL,
  `value_decimal` decimal(18,9) DEFAULT NULL,
  `value_date` date DEFAULT NULL,
  `value_datetime` datetime DEFAULT NULL,
  `value_json_array` longtext COLLATE utf8_unicode_ci NOT NULL COMMENT '(DC2Type:json)',
  `value_boolean` tinyint(1) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `IDX_8B31D78784A0A3ED745E1826` (`content_id`,`contenttype`)
) ENGINE=InnoDB AUTO_INCREMENT=738 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_field_value`
--

LOCK TABLES `bolt_field_value` WRITE;
/*!40000 ALTER TABLE `bolt_field_value` DISABLE KEYS */;
INSERT INTO `bolt_field_value` VALUES (3,'homepage',1,'body',0,'parablock','text','markdown',NULL,'**Halfway to the Future** is a two-day symposium in the city of Nottingham, UK exploring the past, present, and future of HCI and design-based research.  The symposium will take place on the **19th and 20th November 2019** at the **Albert Hall Conference Centre**.',NULL,NULL,NULL,NULL,NULL,'[]',0),(6,'homepage',1,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(36,'pages',1,'body',4,'parablock','text','markdown',NULL,'## Important Dates\r\n**Submission deadline (extended)**: Wednesday 26th June, 23:59 BST (GMT+1)<br>\r\n**Notification**: Friday 26th July<br>\r\n**Deadline for confirmation of attendance (for panellists)**: Friday 23rd August<br>\r\n**Early bird registration closes**: Friday 27th September<br>\r\n**Registration closes**: Monday 18th November',NULL,NULL,NULL,NULL,NULL,'[]',0),(37,'pages',1,'body',4,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(38,'pages',1,'body',5,'parablock','text','markdown',NULL,'Halfway to the Future is co-organised by the [Mixed Reality Lab](http://www.mrl.nott.ac.uk/ \"The Mixed Reality Laboratory at the University of Nottingham\") at the University of Nottingham as part of celebrations of its 20-year anniversary. Keynote speakers and respective panel themes have been chosen for their formative and ongoing influence on the lab’s work across two decades.',NULL,NULL,NULL,NULL,NULL,'[]',0),(39,'pages',1,'body',5,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(40,'pages',1,'body',6,'parablock','text','markdown',NULL,'<br>\r\nIf you have any questions, please contact the [Programme Chairs](mailto:programme@halfwaytothefuture.org \"Email the HttF Programme Chairs\"), Joel Fischer and Jocelyn Spence. \r\n  ',NULL,NULL,NULL,NULL,NULL,'[]',0),(41,'pages',1,'body',6,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(60,'pages',4,'body',5,'parablock','text','markdown',NULL,'**Steve Benford** is a Professor in the Mixed Reality Lab at the University of Nottingham where he leads the \'Smart Products\' beacon and directs the Horizon ‘Creating Our Lives in Data\' Centre for Doctoral Training. He previously held an EPSRC Dream Fellowship, has been a Visiting Professor at the BBC and was elected to the CHI Academy in 2012. \r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(61,'pages',4,'body',5,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(80,'pages',6,'body',0,'dualparablock','textleft','markdown',NULL,'**Tuesday 19th**\r\n* **08:30 — 09:30** Registration\r\n* **09:30 — 10:00** Welcome and opening address\r\n* **10:00 — 12:00** Mixed Reality\r\n* **12:00 — 13:00** Lunch (provided)\r\n* **13:00 — 15:00** Public & Private Spaces\r\n* **15:00 — 15:30** Break\r\n* **15:30 — 17:30** Artificial Intelligence, Humans & Machines\r\n* **17:30 — 19:00** Posters session\r\n* **19:30** (Additional Fee) [Symposium dinner](/session/symposium-dinner \"Read about the symposium dinner\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(81,'pages',6,'body',0,'dualparablock','textright','markdown',NULL,'**Wednesday 20th**\r\n* **09:00 — 11:00** Ubiquitous Computing\r\n* **11:00 — 11:30** Break\r\n* **11:30 — 12:15** Arts & Design-led Approaches (keynote only)\r\n* **12:15 — 13:15** Lunch (provided)\r\n* **13:15 — 14:30** Arts & Design-led Approaches (cont\'d)\r\n* **14:30 — 15:00** Break\r\n* **15:00 — 17:00** New Approaches to Research & Design\r\n* **17:00** Symposium closes',NULL,NULL,NULL,NULL,NULL,'[]',0),(82,'pages',6,'body',0,'dualparablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(83,'pages',6,'body',1,'parablock','text','markdown',NULL,'This agenda will be replaced by an interactive programme closer to the time of the symposium',NULL,NULL,NULL,NULL,NULL,'[]',0),(84,'pages',6,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(86,'pages',5,'body',0,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/alberthall.jpg\"}',0),(87,'pages',5,'body',0,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(88,'pages',5,'body',0,'imageblock','alt','text',NULL,'Albert Hall Conference Centre, Nottingham',NULL,NULL,NULL,NULL,NULL,'[]',0),(89,'pages',5,'body',0,'imageblock','caption','markdown',NULL,'Albert Hall Conference Centre, Nottingham.',NULL,NULL,NULL,NULL,NULL,'[]',0),(90,'pages',5,'body',1,'parablock','text','markdown',NULL,'The Albert Hall main entrance is located on **North Circus Street**, opposite St. Barnabas Cathedral and adjacent to the Nottingham Playhouse in the city centre of Nottingham. The main entrance **has stairs**.\r\n\r\n* Satellite navigation postcodes: NG1 5AA or NG1 5AE\r\n* Main (non-accessible) entrance on [Google Maps](https://goo.gl/maps/EJo8tKkwr5S2  \"The Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?address=North%20Circus%20Street\\,%20Nottingham\\,%20NG1%205AA\\,%20England&auid=12125193638640445003&ll=52.954342\\,-1.156263&lsp=9902&q=Albert%20Hall%20Conference%20Centre&_ext=ChoKBQgEEOEBCgQIBRADCgUIBhDfAQoECAoQABImKQQv6rSReUpAMZApjnHmoPK/OYIEEBG4ekpAQZYP7CfTY/K/UAQ%3D \"The Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\nThe **accessible entrance**, used also for deliveries, is on the opposite side of the building, on Maid Marian Way. We ask you to not use this entrance unless you need it as it is smaller.\r\n \r\n* Accessible entrance on [Google Maps](https://goo.gl/maps/mvsggnjntbhV7VBh8 \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?q=52.954293,-1.155787&sll=52.954293,-1.155787&sspn=0.001193,0.002492&t=h \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(91,'pages',5,'body',1,'parablock','class','text',NULL,'outline',NULL,NULL,NULL,NULL,NULL,'[]',0),(108,'pages',8,'body',0,'parablock','text','markdown',NULL,'This website only directly logs minimal information (such as page requests, system errors, IP addresses etc.). This log data is automatically stored on servers in the EU and is never shared or published.\r\n\r\nThis website **does not set any cookies for visitors**.\r\n\r\nThis website **does not use any externally hosted or managed services**.\r\n\r\nThere is **no advertising on this website or monetisation of traffic**.',NULL,NULL,NULL,NULL,NULL,'[]',0),(109,'pages',8,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(110,'pages',8,'body',1,'parablock','text','markdown',NULL,'## University of Nottingham Privacy Policy\r\nIn addition to the above information, your use of this website is also covered by the [University of Nottingham Privacy Poilcy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham\'s Privacy Poilcy\"). This policy includes information such as the University\'s Data Protection Officer, whom you should contact if you have any questions, concerns, or wish to request access to any data we store about you. Please note that we are entitled to, and do, charge a fee for providing this information.',NULL,NULL,NULL,NULL,NULL,'[]',0),(111,'pages',8,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(112,'pages',8,'body',2,'parablock','text','markdown',NULL,'## Further Information and Contact\r\nIf you would like any further information about this website, please email the [Communications Chair](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\"). If you wish to make a Subject Access Request for your data, you should contact the University\'s Data Protection Officer, details for which are in the [University of Nottingham Privacy Poilcy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham\'s Privacy Poilcy\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(113,'pages',8,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(114,'pages',8,'body',3,'parablock','text','markdown',NULL,'*Last Updated: 13th February 2019*',NULL,NULL,NULL,NULL,NULL,'[]',0),(115,'pages',8,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(120,'pages',4,'body',13,'parablock','text','markdown',NULL,'**Bill Gaver** is Professor of Design and co-director of the Interaction Research Studio at Goldsmiths, University of London. His research on design-led methodologies and innovative technologies for everyday life led him to develop an internationally recognised studio bringing the skills of designers together with expertise in ubiquitous computing and sociology.\r\n<br>\r\n<br>\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(121,'pages',4,'body',13,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(128,'pages',2,'body',1,'dualparablock','textleft','markdown',NULL,'**Programme Chairs**<br>\r\n[Joel E. Fischer](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/joel.fischer \"Joel\'s profile on the University of Nottingham website\")<br>\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")<br>\r\n[Jocelyn Spence](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/jocelyn.spence \"Jocelyn\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email both Programme Chairs\")*\r\n\r\n**Communications & Marketing Chair**<br>\r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [comms@halfwaytothefuture.org](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\")*\r\n\r\n**Sponsorship Chair**<br>\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email the Sponsorship Chair\")*\r\n\r\n**Local Arrangements Chair**<br>\r\n[Sarah Martindale](https://www.nottingham.ac.uk/clas/departments/culturalmediaandvisualstudies/people/sarah.martindale \"Sarah\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [local@halfwaytothefuture.org](mailto:local@halfwaytothefuture.org \"Email the Local Arragenments Chair\")*\r\n\r\n**Equality, Diversity, and Inclusion Chair**<br>\r\n[Pepita Barnard Stringer](https://www.horizon.ac.uk/researchers/ \"Pepita is a member of the Horizon Digital Economy Research Institute at the University of Nottingham\")\r\n\r\n*Email: [edi@halfwaytothefuture.org](mailto:edi@halfwaytothefuture.org \"Email the Equality, Diversity, and Inclusion Chair\")*\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(129,'pages',2,'body',1,'dualparablock','textright','markdown',NULL,'**Keynote Chair**<br>\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [keynote@halfwaytothefuture.org](mailto:keynote@halfwaytothefuture.org \"Email the Keynote CHair\")*\r\n\r\n**Demos Chair**<br>\r\n[Edgar Bodiaj](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/edgar.bodiaj \"Edgar\'s profile on the University of Nottingham website\")<br>\r\n[Paul Tennent](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/paul.tennent \"Paul\'s profile on the University of Nottingham website\")<br>\r\nJoe Marshall (Paternity Leave)\r\n\r\n*Email: [demos@halfwaytothefuture.org](mailto:technical@halfwaytothefuture.org \"Email the Demos Chair\")*\r\n\r\n**Technical Chair**<br>\r\n[Adrian Hazzard](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/adrian.hazzard \"Adrian\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [technical@halfwaytothefuture.org](mailto:technical@halfwaytothefuture.org \"Email the Techincal Chair\")*\r\n\r\n**Treasurer & Registration Chair**<br>\r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [treasurer@halfwaytothefuture.org](mailto:treasurer@halfwaytothefuture.org \"Email the Treasurer and Registration Chair\")*\r\n\r\n**Communications & Marketing Assistant**<br>\r\n[Velvet Spors](https://highlights.cdt.horizon.ac.uk/students/psxavsp \"Velvet is a student in the Horizon Centre for Doctoral Training at the University of Nottingham\")\r\n\r\n**Administrative Assistants**<br>\r\n[Lindsay Norman](https://www.nottingham.ac.uk/computerscience/people/lindsay.norman \"Lindsay\'s profile on the University of Nottingham website\")<br>\r\n[Felicia Black](https://www.nottingham.ac.uk/computerscience/people/felicia.black \"Felicia\'s profile on the University of Nottingham website\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(130,'pages',2,'body',1,'dualparablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(135,'pages',4,'body',5,'parablock','label','text',NULL,'Steve Benford biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(139,'pages',4,'body',13,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(144,'pages',4,'body',13,'parablock','label','text',NULL,'Bill Gaver biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(149,'pages',4,'body',16,'parablock','text','markdown',NULL,'**Christian Heath** is Professor of Work and Organisation at King’s College London. He specialises in fine grained, video-based studies of social interaction drawing on ethnomethodology and conversation analysis. He is currently undertaking research in areas that include health care, markets and economic behaviour, and museums and galleries. He is a Fellow of the Academy of the Social Sciences (FAcSS), a Freeman of the Worship Company of Art Scholars and was recently received the EUSSET-IISI Lifetime Achievement Award for his contribution to the fields of Computing and Informatics. His publications include: *The Dynamics of Auction: Social Interaction and the Sale of Fine Art and Antiques* (Cambridge: ISCA Best Book Award), *Video and Qualitative Research: Analysing Social Interaction in Everyday* (Sage with Jon Hindmarsh and Paul Luff) and *Technology in Action* (Cambridge, with Paul Luff).\r\n<br>\r\n<br>',NULL,NULL,NULL,NULL,NULL,'[]',0),(150,'pages',4,'body',16,'parablock','label','text',NULL,'Christian Heath biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(151,'pages',4,'body',16,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(159,'pages',4,'body',2,'parablock','text','markdown',NULL,'**Yvonne Rogers** is the director of the Interaction Centre at UCL (UCLIC), and a deputy head of the Computer Science department. She is interested in how technology transforms what it means to be human. Much of her work is situated in the wild - concerned with informing, building and evaluating novel user experiences through creating and assembling a diversity of technologies (e.g. tangibles, AR, IoT) that augment everyday, learning, community engagement and collaborative work activities. She has been instrumental in promulgating new theories (e.g., external cognition), alternative methodologies (e.g., in the wild studies) and far-reaching research agendas (e.g., “Being Human: HCI in 2020” manifesto), and has pioneered an approach to innovation and ubiquitous learning. She has also published over 300 articles, including two monographs “HCI Theory: Classical, Modern and Contemporary” and \"Research in the Wild\". She is a fellow of the ACM, BCS and the ACM CHI Academy.',NULL,NULL,NULL,NULL,NULL,'[]',0),(160,'pages',4,'body',2,'parablock','label','text',NULL,'Yvonne Rogers biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(161,'pages',4,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(169,'pages',4,'body',8,'parablock','text','markdown',NULL,'**Lucy Suchman** holds a Chair in the Anthropology of Science and Technology at Lancaster University in the UK. Before taking up her present post she was a Principal Scientist at Xerox’s Palo Alto Research Center (PARC), where she spent twenty years as a researcher. Suchman’s current research extends her longstanding engagement with the field of human-computer interaction to the domain of contemporary war fighting. She is focused more specifically on the knowledge that informs immersive military training simulations, and on problems of ‘situational awareness’ in remotely-controlled and automated weapon systems. She is the author of Human-Machine Reconfigurations (2007) and Plans and Situated Actions: the problem of human-machine communication (1987), both published by Cambridge University Press. In 2010 she received the ACM SIGCHI Lifetime Research Award, and in 2014 the Society for Social Studies of Science (4S) Bernal Prize for Contributions to the Field. \r\n<br>',NULL,NULL,NULL,NULL,NULL,'[]',0),(170,'pages',4,'body',8,'parablock','label','text',NULL,'Lucy Suchman biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(171,'pages',4,'body',8,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(172,'pages',4,'body',9,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/alextaylor.jpg\"}',0),(173,'pages',4,'body',9,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(174,'pages',4,'body',9,'imageblock','alt','text',NULL,'Alex Taylor',NULL,NULL,NULL,NULL,NULL,'[]',0),(175,'pages',4,'body',9,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(176,'pages',4,'body',10,'parablock','text','markdown',NULL,'**Alex Taylor** is a sociologist working in the Centre for Human Centred Design, at City, University of London. Showing a broad fasciation for the entanglements between social life and machines, his research ranges from empirical studies of technology in everyday life to speculative design interventions—both large and small. Across these realms, he draws on a feminist technoscience to ask questions about the co-constitutive roles human-machine composites play in forms of knowing and being, and how they might open up possibilities for fundamental transformations in society. Most recently, he’s begun to wonder about the abilities of humans and non-humans, together, and to speculate on hybrid compositions that enlarge capacity and offer the chance of something different-than, something more-than.\r\n<br>\r\n<br>',NULL,NULL,NULL,NULL,NULL,'[]',0),(177,'pages',4,'body',10,'parablock','label','text',NULL,'Alex Taylor biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(178,'pages',4,'body',10,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(200,'pages',1,'body',4,'parablock','label','text',NULL,'Important Dates',NULL,NULL,NULL,NULL,NULL,'[]',0),(201,'pages',1,'body',5,'parablock','label','text',NULL,'MRL@20',NULL,NULL,NULL,NULL,NULL,'[]',0),(202,'pages',1,'body',6,'parablock','label','text',NULL,'Contact the Programme Chairs',NULL,NULL,NULL,NULL,NULL,'[]',0),(204,'homepage',1,'body',0,'parablock','label','text',NULL,'About the event',NULL,NULL,NULL,NULL,NULL,'[]',0),(216,'pages',2,'body',1,'dualparablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(217,'pages',5,'body',1,'parablock','label','text',NULL,'Main Entrance',NULL,NULL,NULL,NULL,NULL,'[]',0),(218,'pages',5,'body',2,'parablock','text','markdown',NULL,'For more information, please see the following pages:\r\n\r\n* [Travel to the venue](/travel \"Information on travelling to the venue via car, train, bus, tram, or aeroplane\")\r\n* [Venue accessibility](/accessibility \"Information on venue accessibility\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(219,'pages',5,'body',2,'parablock','label','text',NULL,'Links',NULL,NULL,NULL,NULL,NULL,'[]',0),(220,'pages',5,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(263,'pages',1,'body',2,'parablock','text','markdown',NULL,'## Submission Information \r\nWe invite **papers of up to 6,000 words** (not including references) addressing current work relating to the themes above, especially those building on or responding to the influential works to be discussed.\r\n\r\nWe also invite **short papers of up to 2,000 words** (not including references) looking towards the future of these themes. Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. Accepted papers not chosen for panels will be invited to be presented in poster format. We will publish an edited volume of panel papers and online adjunct proceedings of papers selected for poster presentation.\r\n\r\nFor information on preparing a submission, including the templates to use, please read the [submission guidance](/submission-guidance \"Submission guidance for HttF\") webpage. All submissions will be reviewed by at least two experts in the field and the process will be double-blind. All accepted papers will be published in the Halfway to the Future Proceedings in the **ACM Digital Library**, as part of the ACM International Conference Proceedings Series (ICPS).',NULL,NULL,NULL,NULL,NULL,'[]',0),(264,'pages',1,'body',2,'parablock','label','text',NULL,'Submission information',NULL,NULL,NULL,NULL,NULL,'[]',0),(265,'pages',1,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(270,'pages',1,'body',1,'parablock','text','markdown',NULL,'The keynotes will be followed by presentations, drawn from submitted papers, of current related work and short future-oriented provocations and a panel discussion/Q&A seeking to shape the agenda of that research area in the years to come. The event will also incorporate an exhibition of interactive works and a poster session.',NULL,NULL,NULL,NULL,NULL,'[]',0),(271,'pages',1,'body',1,'parablock','label','text',NULL,'About the sessions',NULL,NULL,NULL,NULL,NULL,'[]',0),(272,'pages',1,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(273,'pages',6,'body',0,'dualparablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(274,'pages',6,'body',1,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(282,'pages',8,'body',0,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(283,'pages',8,'body',1,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(284,'pages',8,'body',2,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(285,'pages',8,'body',3,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(286,'pages',11,'body',0,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/tb-404.png\"}',0),(287,'pages',11,'body',0,'imageblock','imagestyle','select',NULL,'inline',NULL,NULL,NULL,NULL,NULL,'[]',0),(288,'pages',11,'body',0,'imageblock','alt','text',NULL,'404 Not Found',NULL,NULL,NULL,NULL,NULL,'[]',0),(289,'pages',11,'body',0,'imageblock','caption','markdown',NULL,'Tumbeasts by [Matthew Inman](https://theoatmeal.com/comics/state_web_summer \"The source for the Tumbeasts graphic\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(290,'pages',3,'body',0,'dualparablock','textleft','markdown',NULL,'Oliver Bates (Lancaster University)<br>\r\nBen Bedwell (University of Nottingham)<br>\r\nBarry Brown (Stockholm University)<br>\r\nKo-Le Chen (Newcastle University)<br>\r\nLuigina Ciolfi (Sheffield Hallam University)<br>\r\nEnrico Costanza (University College London)<br>\r\nDimitrios Darzentas (University of Nottingham)<br>\r\nAbigail Durrant (Northumbria University)<br>\r\nEva Eriksson (Chalmers University of Technology)<br>\r\nMike Fraser (University of Bristol)<br>\r\nGabriella  Giannachi (University of Exeter)<br>\r\nLone Koefoed Hansen (Aarhus University)<br>\r\nBen Kirman (University of York)<br>\r\nHyosun Kwon (Loughborough University)<br>\r\nAiri Lampinen (Stockholm University)<br>\r\nShaun Lawson (Northumbria University)<br>\r\nConor Linehan (University College Cork)<br>\r\nAnders Løvlie (IT University of Copenhagen)<br>\r\nPaul Marshall (University of Bristol)<br>\r\nJuan Pablo Martínez Ávila (University of Nottingham)<br>\r\nDonald McMillan (Stockholm University)<br>\r\nBettina Nissen (University of Edinburgh)<br>',NULL,NULL,NULL,NULL,NULL,'[]',0),(291,'pages',3,'body',0,'dualparablock','textright','markdown',NULL,'Leif Oppermann (Fraunhofer FIT)<br>\r\nMark Perry (Brunel University)<br>\r\nMartin Porcheron (University of Nottingham)<br>\r\nChiara Rossitto (Stockholm University)<br>\r\nAsreen Rostami (Stockholm University)<br>\r\nAnne Roudaut (University of Bristol)<br>\r\nMaria Roussou (National and Kapodistrian University of Athens)<br>\r\nAnna Ståhl (RISESICS)<br>\r\nDanaë Stanton Fraser (University of Bath)<br>\r\nRobyn Taylor (Newcastle University)<br>\r\nPaul Tennent (University of Nottingham)<br>\r\nPeter Tolmie (University of Siegen)<br>\r\nZ Toups (New Mexico State University)<br>\r\nVasiliki Tsaknaki (KTH Royal Institute of Technology)<br>\r\nLachlan Urquhart (The University of Edinburgh)<br>\r\nNervo Verdezoto (Cardiff University)<br>\r\nJohn Vines (Newcastle University)<br>\r\nAnnika Waern (Uppsala University)<br>\r\nHelena Webb (University of Oxford)<br>\r\nJulie Williamson (University of Glasgow)<br>\r\nDan Xu (Amsterdam University of Applied Sciences)',NULL,NULL,NULL,NULL,NULL,'[]',0),(292,'pages',3,'body',0,'dualparablock','label','text',NULL,'List',NULL,NULL,NULL,NULL,NULL,'[]',0),(293,'pages',3,'body',0,'dualparablock','class','text',NULL,'nogap',NULL,NULL,NULL,NULL,NULL,'[]',0),(297,'pages',15,'body',0,'parablock','text','markdown',NULL,'* [15th February 2019](/email-2019-02-15 \"An email sent to subscribers on the 15th February 2019\")\r\n* [1st April 2019](/email-2019-04-01 \"An email sent to subscribers on the 1st April 2019\")\r\n* [7th June 2019](/email-2019-06-07 \"An email sent to subscribers on the 7th June 2019\")\r\n* [18th June 2019](/email-2019-06-18 \"An email sent to subscribers on the 18th June 2019\")\r\n* [8th July 2019](/email-2019-07-08 \"An email sent to subscribers on the 8th July 2019\")\r\n* [11th September 2019](/email-2019-09-11 \"An email sent to subscribers on the 11th September 2019\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(298,'pages',15,'body',0,'parablock','label','text',NULL,'List',NULL,NULL,NULL,NULL,NULL,'[]',0),(299,'pages',15,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(300,'pages',15,'body',1,'parablock','text','markdown',NULL,'All details of subscribers has since been deleted.',NULL,NULL,NULL,NULL,NULL,'[]',0),(301,'pages',15,'body',1,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(302,'pages',15,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(309,'pages',17,'body',2,'parablock','text','markdown',NULL,'## Where to submit\r\n\r\nSubmission to the symposium is made using the [EasyChair system](/submission \"The HttF submission system\"). You must create an account and submit to the HttF2019 conference. Submissions will not be accepted by other means. We have extended the submission deadline until Wednesday, 26 June 2019, 23:59 BST (GMT+1).',NULL,NULL,NULL,NULL,NULL,'[]',0),(310,'pages',17,'body',2,'parablock','label','text',NULL,'Submission information',NULL,NULL,NULL,NULL,NULL,'[]',0),(311,'pages',17,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(315,'pages',17,'body',3,'parablock','text','markdown',NULL,'## Preparing an accepted submission\r\nAuthors will be notified of acceptance or rejection by **Friday 26th July 2019**. Selected authors will be asked take part in one of the six panels at the symposium. All accepted authors who are not invited to present their work within one of the symposium panels will be invited to produce a poster to be displayed during the symposium as well as being included in the Halfway to the Future Proceedings.\r\n\r\nPlease follow the specific guide on [preparing an accepted submission](/accepted-submission-guidance \"Accepted submission guidance\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(316,'pages',17,'body',3,'parablock','label','text',NULL,'Preparing an accepted submission',NULL,NULL,NULL,NULL,NULL,'[]',0),(317,'pages',17,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(318,'pages',17,'body',4,'parablock','text','markdown',NULL,'## Additional questions or help\r\nIf you have any questions regarding preparing your paper for submission, please contact the [Programme Chairs](mailto:programme@halfwaytothefuture.org \"Please email the HttF Programme Chairs if you have any questions\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(319,'pages',17,'body',4,'parablock','label','text',NULL,'Contact the Programme Chairs',NULL,NULL,NULL,NULL,NULL,'[]',0),(320,'pages',17,'body',4,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(359,'pages',4,'body',17,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-05/paulluff.jpg\"}',0),(360,'pages',4,'body',17,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(361,'pages',4,'body',17,'imageblock','alt','text',NULL,'Paul Luff',NULL,NULL,NULL,NULL,NULL,'[]',0),(362,'pages',4,'body',17,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(363,'pages',4,'body',18,'parablock','text','markdown',NULL,'**Paul Luff** is Professor of Organisations and Technology at King’s College. He has undertaken detailed video-based studies of diverse settings including control rooms, trading rooms, surveillance centres, surgery, general practice consultations, design and architectural practices. In most of these projects he has worked with computer scientists and engineers developing human-robot interaction, ubiquitous technologies and advanced collaboration systems. Contributions of these studies have been to inform the identification of user requirements, aspects of the design of the technology and ways these might be evaluated and assessed. He is the co-author with Christian Heath of ‘Technology in Action’ (Cambridge University Press) and with Christian Heath and Jon Hindmarsh) of ‘Video in Qualitative Research’ (Sage).',NULL,NULL,NULL,NULL,NULL,'[]',0),(364,'pages',4,'body',18,'parablock','label','text',NULL,'Paul Luff Biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(365,'pages',4,'body',18,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(366,'pages',18,'body',0,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/alberthall.jpg\"}',0),(367,'pages',18,'body',0,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(368,'pages',18,'body',0,'imageblock','alt','text',NULL,'Albert Hall Conference Centre, Nottingham',NULL,NULL,NULL,NULL,NULL,'[]',0),(369,'pages',18,'body',0,'imageblock','caption','markdown',NULL,'Albert Hall Conference Centre, Nottingham.',NULL,NULL,NULL,NULL,NULL,'[]',0),(370,'pages',18,'body',1,'parablock','text','markdown',NULL,'The Albert Hall main entrance is located on **North Circus Street**, opposite St. Barnabas Cathedral and adjacent to the Nottingham Playhouse in the city centre of Nottingham. The main entrance **has stairs**.\r\n\r\n* Satellite navigation postcodes: NG1 5AA or NG1 5AE\r\n* Main (non-accessible) entrance on [Google Maps](https://goo.gl/maps/EJo8tKkwr5S2  \"The Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?address=North%20Circus%20Street\\,%20Nottingham\\,%20NG1%205AA\\,%20England&auid=12125193638640445003&ll=52.954342\\,-1.156263&lsp=9902&q=Albert%20Hall%20Conference%20Centre&_ext=ChoKBQgEEOEBCgQIBRADCgUIBhDfAQoECAoQABImKQQv6rSReUpAMZApjnHmoPK/OYIEEBG4ekpAQZYP7CfTY/K/UAQ%3D \"The Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\nThe **accessible entrance**, used also for deliveries, is on the opposite side of the building, on Maid Marian Way. We ask you to not use this entrance unless you need it as it is smaller.\r\n \r\n* Accessible entrance on [Google Maps](https://goo.gl/maps/mvsggnjntbhV7VBh8 \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?q=52.954293,-1.155787&sll=52.954293,-1.155787&sspn=0.001193,0.002492&t=h \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(371,'pages',18,'body',1,'parablock','label','text',NULL,'Main Entrance',NULL,NULL,NULL,NULL,NULL,'[]',0),(372,'pages',18,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(373,'pages',18,'body',2,'parablock','text','markdown',NULL,'## Travel by public transport\r\nIf you are travelling by rail, Nottingham has a single central railway station that is a 15-minute walk from the venue, through the centre of the city. You can either walk from the station, catch a tram from the station to the nearby **Royal Centre** tram stop (see below for details of discounted tram travel), or alternatively catch a taxi from the adjacent taxi rank.\r\n\r\nDue to construction work as part of the [Nottingham Southside Regeneration Project](https://southside.nottinghamcity.gov.uk/ \"Nottingham City Council Southside Rengeration Project information\"), the city\'s southern bus station, Broadmarsh, is currently closed. \r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(374,'pages',18,'body',2,'parablock','label','text',NULL,'Public Transport',NULL,NULL,NULL,NULL,NULL,'[]',0),(375,'pages',18,'body',2,'parablock','class','text',NULL,'clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(383,'pages',18,'body',5,'parablock','text','markdown',NULL,'## Travel by car\r\nIf you wish to travel by car, there are a couple of nearby public carparks you can use. At the carpark you will receive a ticket that can then be validated on your arrival at the Albert Hall reception.\r\n\r\n* NCP Nottingham City on Mount Street (NG1 6HG)\r\n* NCP St. James Street (NG1 6EY)\r\n\r\nAlternatively, you can park at one of the [9 free Park and Ride](https://robinhoodnetwork.co.uk/information/park-ride-bus-tram.html \"Robin Hood Network park and ride sites in Nottingham\") sites that are part of the Robin Hood Network. The route to the main (non-accessible) and accessible entrance is the same from each car park.',NULL,NULL,NULL,NULL,NULL,'[]',0),(384,'pages',18,'body',5,'parablock','label','text',NULL,'Car',NULL,NULL,NULL,NULL,NULL,'[]',0),(385,'pages',18,'body',5,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(386,'pages',18,'body',6,'parablock','text','markdown',NULL,'## Travel by taxi\r\nIf travelling by taxi, give the details of the venue (as above). Most taxi drivers are likely to be familiar with the venue, and certainly with the cathedral on Derby Road.\r\n\r\nIf you need the accessible entrance, you may also direct the taxi driver to the Central Police Station on Maid Marian Way (this is adjacent to the accessible entrance).',NULL,NULL,NULL,NULL,NULL,'[]',0),(387,'pages',18,'body',6,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(388,'pages',18,'body',6,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(396,'pages',19,'body',1,'parablock','text','markdown',NULL,'### The Park Plaza\r\nThe **preferred hotel for guests**, [The Park Plaza](/hotel \"Information about the symposium hotel, the Park Plaza\"), is fully accessible. Guests should contact the hotel in advance to receive specific advice. The hotel is a short distance (by pavement) from the Albert Hall Conference Centre. There is a small gradient on this hill between the Albert Hall Conference Centre and the hotel.\r\n\r\nThe **symposium dinner** will also take place in  Park Plaza. Although the dinner will take place on the 11th floor, the nearest **gender-neutral accessible toilet is by lift to the ground floor**.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(397,'pages',19,'body',1,'parablock','label','text',NULL,'The Park Plaza',NULL,NULL,NULL,NULL,NULL,'[]',0),(398,'pages',19,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(399,'pages',19,'body',2,'parablock','text','markdown',NULL,'### Nottingham Contemporary\r\nThe **Welcome Reception** will take place at the Nottingham Contemporary art gallery, in the café/bar. This is fully wheelchair accessible with **gendered and gender-neutral accessible toilets conveniently located next to the café**. The café is accessible by lift from the ground floor/entrance of the gallery. ',NULL,NULL,NULL,NULL,NULL,'[]',0),(400,'pages',19,'body',2,'parablock','label','text',NULL,'Nottingham Contemporary',NULL,NULL,NULL,NULL,NULL,'[]',0),(401,'pages',19,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(408,'pages',19,'body',0,'parablock','text','markdown',NULL,'## Symposium venues\r\nHalfway to the Future will be held across three different venues in Nottingham.\r\n\r\n### Albert Hall Conference Centre\r\nThe main symposium activities will take place in the [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk/ \"The Albert Hall Conference Centre Nottingham website\"), Nottingham, UK. The venue is conveniently located in the city centre of Nottingham near to multiple hotels. We will occupy the entirety of the venue throughout the symposium.\r\n\r\nWe are aware of comments online that there are parts of the venue which are not accessible by wheelchair. The Albert Hall Conference Centre has since **installed an additional stairlift to access to the floor of The Great Hall** (the room in which the main symposium sessions will take place).\r\n\r\nThe Albert Hall Conference Centre has an **accessible gender-neutral toilet on the ground floor** and there will be **non-accessible gender-neutral toilets accessible from The Great Hall**. The non-accessible toilets on the ground floor will remain gendered at the request of the venue.\r\n\r\nAll speakers in The Great Hall will have microphones connected to a PA system that includes **an induction loop**. \r\n\r\nThe **Main Entrance to the Albert Hall Conference Centre is not accessible**, but there is an alternative accessible entrance on Maid Marian Way, next to the Central Police Station. We access that, where possible, for attendees use the main entrance to keep this entrance clear for those that need it. ',NULL,NULL,NULL,NULL,NULL,'[]',0),(409,'pages',19,'body',0,'parablock','label','text',NULL,'Albert Hall Conference Centre',NULL,NULL,NULL,NULL,NULL,'[]',0),(410,'pages',19,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(411,'pages',20,'body',0,'parablock','text','markdown',NULL,'## Visa application support letters\r\n\r\nThe University of Nottingham is able to issue Visa support letters, which may be used to support a visa application to visit the UK for the symposium. We can include details of any submission you have made on the letter. We are not able to provide specific advice or support for visa applications, however.\r\n\r\nTo request a letter, you **must** initially have registered for the symposium, and then [complete this online form](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUNFBEV1BVQ0k3Q0hTMDZTSU1KSUZVSkFYWCQlQCN0PWcu \"Visa support letter request form\"). We will issue the letter once we have confirmed you have registered.\r\n\r\nIf you need further help, please email [visa-support@halfwaytothefuture.org](mailto:visa-support@halfwaytothefuture.org \"Visa support letter email address\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(412,'pages',20,'body',0,'parablock','label','text',NULL,'Visa application support letters',NULL,NULL,NULL,NULL,NULL,'[]',0),(413,'pages',20,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(414,'pages',20,'body',1,'parablock','text','markdown',NULL,'## Visiting the UK after Brexit\r\n\r\nThe following guidance was prepared for CHI 2019 in the UK—we have updated it for Halfway to the Future. We will update this page with further information once it is known.\r\n\r\n**If you are a non-EU citizen travelling from outside of the EU**, then there are likely to be no differences to normal travel to the UK. Visa rules etc. will not be changed in the short term. Go ahead and book your travel and accommodation as you would for a normal trip to the UK.\r\n\r\n**For EU citizens travelling from an EU country**, things may change a little. The UK Government and European Commission say flights between the UK and the EU will continue after 31st October 2019, no matter what happens after Brexit (this will apply to sea, coach, rail or Eurotunnel shuttle too). The European Commission has also said that there will be no difference to travel and holidaymakers won’t need a Visa during the ‘transition period’ (where the UK has left the EU but still follows EU rules while the new arrangements are made). This may change if there is a no-deal Brexit; we will keep this page updated with more information as we have it.\r\n\r\nYou may still need to check your passport is valid for at least six months after the date you plan to travel. For EU citizens, you might want to take out travel insurance rather than relying on EHIC, as rules for that may change is there is a no-deal Brexit.\r\n\r\nPlease also read the [GOV.UK EU exit guidance on transport](https://www.gov.uk/prepare-eu-exit/all?parent=&keywords=&any_part_of_taxonomy_tree%5B%5D=a4038b29-b332-4f13-98b1-1c9709e216bc&order=updated-newest \"HM Government on transport after the UK\'s exit from the European Union\").\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(415,'pages',20,'body',1,'parablock','label','text',NULL,'Brexit',NULL,NULL,NULL,NULL,NULL,'[]',0),(416,'pages',20,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(420,'pages',21,'body',1,'parablock','text','markdown',NULL,'## Hotel rates\r\n**Monday 18th November** (i.e. checking in the day before the symposium):<br>\r\n£99 for single occupancy (£109 for double occupancy)<br>\r\n\r\n**Tuesday 19th November** (i.e. checking out on Wednesday 20th):<br>\r\n£120 for single occupancy (£130 for double occupancy)\r\n\r\n* All rates include breakfast and Wi-Fi\r\n* All rates are inclusive of VAT at 20%\r\n* A £25.00 per room, per night security deposit may be required on check in\r\n* Check in is at 2pm and check out is at midday\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(421,'pages',21,'body',1,'parablock','label','text',NULL,'Hotel rates',NULL,NULL,NULL,NULL,NULL,'[]',0),(422,'pages',21,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(427,'pages',21,'body',0,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-05/parkplaza.jpg\"}',0),(428,'pages',21,'body',0,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(429,'pages',21,'body',0,'imageblock','alt','text',NULL,'The Park Plaza entrance',NULL,NULL,NULL,NULL,NULL,'[]',0),(430,'pages',21,'body',0,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(431,'pages',21,'body',2,'parablock','text','markdown',NULL,'## Booking details\r\nTo receive these special rates, you must book *before* the 19th September 2019. To make the booking, please telephone the Park Plaza on +44 (0) 115 947 7200 and quote the block code *15308496*.',NULL,NULL,NULL,NULL,NULL,'[]',0),(432,'pages',21,'body',2,'parablock','label','text',NULL,'Booking details',NULL,NULL,NULL,NULL,NULL,'[]',0),(433,'pages',21,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(438,'pages',4,'body',22,'parablock','text','markdown',NULL,'We thank each of the keynote speakers for agreeing to present and reflect upon their work during the symposium.',NULL,NULL,NULL,NULL,NULL,'[]',0),(439,'pages',4,'body',22,'parablock','label','text',NULL,'Thanks',NULL,NULL,NULL,NULL,NULL,'[]',0),(440,'pages',4,'body',22,'parablock','class','text',NULL,'clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(445,'pages',4,'body',21,'parablock','text','markdown',NULL,'**Susanne Bødker** is Professor at the Department of Computer Science at Aarhus University in Denmark. She co-manages the interdisciplinary Center for Participatory IT, and heads the recently started ERC project on Common Interactive Objects. She does participatory design, computer supported collaborative work and activity theory. Email: bodker@cs.au.dk',NULL,NULL,NULL,NULL,NULL,'[]',0),(446,'pages',4,'body',21,'parablock','label','text',NULL,'Susanne Bødker biography',NULL,NULL,NULL,NULL,NULL,'[]',0),(447,'pages',4,'body',21,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(448,'pages',22,'body',0,'parablock','text','markdown',NULL,'At this event we uphold the following values:\r\n\r\n* Committing to empowering each other\r\n* Listening to others\' views and communicating respectfully\r\n* Being aware of our biases and prejudices\r\n* Respecting our environment and the people around us, in person and online\r\n* Respecting people’s choice of gender pronouns, personal space, and right to engage/disengage in any conversation\r\n* Respecting participants wishes not to be photographed or videoed\r\n\r\nHowever, to represent ourselves and our research to our very best ability, we will not tolerate any abuse, violence, discrimination or harassment. Harassment includes but is not limited to:\r\n\r\n* offensive verbal or written comments and visual imagery related to gender, age, sexual orientation and activity, disability, physical appearance, body size, race, ethnicity, religion, \r\n* sustained disruption of talks or other events, harassing photography, including capturing or sharing visual images of individuals wearing orange lanyards \r\n* deliberate intimidation or threats, including violent language and images, stalking, following, inappropriate physical contact, and unwelcome sexual attention\r\n\r\nAbsolutely everyone involved with our activities, including participants, members, sponsors, guests, volunteers, organisers, and our committee members, are subject to our Code of Conduct. \r\n\r\nIf what you’re doing is making someone feel uncomfortable, that counts as harassment and is enough reason to stop doing it.\r\n\r\n**Attendees asked to stop any inappropriate behaviour are expected to comply immediately. **\r\n\r\nIf a person engages in any unacceptable behaviour, as highlighted above, we may take any action we deem appropriate, including but not limited to warnings, expulsion, and banning, with no eligibility for reimbursement or refund of any type.   We may also withdraw any associated publication that you have had accepted into the symposium proceedings.\r\n\r\nOur decisions regarding the Code of Conduct may be escalated to the General Chairs as a committee, or the organising committee as a whole. The decision to take action is non-negotiable once it has been made.\r\n\r\n**If you are being harassed, or are aware of any inappropriate behaviour, or have any other concerns, please contact the general chairs using the contacts below or approach one of our volunteers. The general chairs will make a mobile phone number (for SMS and WhatsApp) available during the symposium.**\r\n\r\nIn addition to the above, we are following the [ACM Policy Against Harassment](https://www.acm.org/special-interest-groups/volunteer-resources/officers-manual/policy-against-discrimination-and-harassment \"Read the ACM Policy Against Discrimination and Harassment\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(449,'pages',22,'body',0,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(450,'pages',22,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(451,'pages',22,'body',1,'parablock','text','markdown',NULL,'## Contact Details\r\nPlease email us at: [edi@halfwaytothefuture.org](mailto:edi@halfwaytothefuture.org \"Email the quality, Diversity, and Inclusion Chair\") (Pepita Stringer; Equality, Diversity, and Inclusion Chair) or [comms@halfwaytothefuture.org](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\") (Martin Porcheron; Communications Chair). You may also call or send WhatsApp and SMS messages to the Communications Chair on ‭+44 7394 212757‬ during the symposium.\r\n\r\nAlternatively, you may send a [report via our website](/report \"Report a concern/contact the EDI and Communications Chairs\"), and choose whether or not to identify yourself.\r\n\r\nThis event complies with the [University of Nottingham’s Events guidance](https://www.nottingham.ac.uk/safety/policies-and-guidance/events/events.aspx \"The University of Nottingham\'s guidance and policy on events\").\r\n\r\n## Credits\r\nThis Code of Conduct was adapted from *Hacksmiths Code of Conduct* and the *CSCW 2019 Code of Conduct*.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(452,'pages',22,'body',1,'parablock','label','text',NULL,'Contact details',NULL,NULL,NULL,NULL,NULL,'[]',0),(453,'pages',22,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(457,'pages',25,'body',0,'parablock','text','markdown',NULL,'## Registration discount codes\r\n\r\nThe discount is administered through the form of discount codes being issued to those who apply. These are then used during online registration to unlock the discounted rate.\r\n\r\nYou should request a registration discount code using [this online form](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUMDhVM0pCNDdJOUxXVjlKU0E4MzBBTjJJOCQlQCN0PWcu \"Register for a SIGCHI student subsidy\"). This form will stay open even after we have exceeded 80 allocated discount codes, so that we can reallocate discount codes given to students who later decide not to attend. We will let you know if you are on the waiting list and will inform you right away if and when a code becomes available. \r\n\r\nWe will send the discount codes to the people who have requested a code, **giving priority to those who have had a paper accepted**. Remaining discount codes will be given on a first-come, first-served basis to **those who have submitted, but were not accepted**. After this, any remaining codes will be allocated on a first-come, first-served basis to those interested in attending.\r\n\r\nYou will be emailed instructions on how to **complete registration within two weeks of the discount code being sent to you**. \r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(458,'pages',25,'body',0,'parablock','label','text',NULL,'Registration discount codes',NULL,NULL,NULL,NULL,NULL,'[]',0),(459,'pages',25,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(463,'pages',25,'body',2,'parablock','text','markdown',NULL,'If you have any questions, please contact our [Sponsorship Chair](mailto:sponsorship@halfwaytothefuture.org \"Email the Sponsorship Chair with questions regarding this subsidy\").\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(464,'pages',25,'body',2,'parablock','label','text',NULL,'Qestions',NULL,NULL,NULL,NULL,NULL,'[]',0),(465,'pages',25,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(469,'pages',23,'body',0,'parablock','text','markdown',NULL,'## Code of Conduct\r\nAs an attendee of the event, you are required to consent to and abide by the Halfway to the Future Code of Conduct. Please do read this code of conduct. We are also applying the [ACM’s Policy Against Discrimination and Harassment for Members and Event Attendees](https://www.acm.org/special-interest-groups/volunteer-resources/officers-manual/policy-against-discrimination-and-harassment \"ACM Policy Against Harassment at ACM Activities\").\r\n\r\nAttendees asked to stop any inappropriate behaviour, as defined by but not limited to what is covered by the code of conduct, are expected to comply immediately.\r\n\r\nIf a person engages in any inappropriate behaviour, we may take any action we deem appropriate, including (but not limited to) warnings, expulsion, and banning, with no eligibility for reimbursement or refund of any type. We may also withdraw any associated publication that you have had accepted into the symposium proceedings.\r\n\r\nInappropriate behaviour outside of the event venues, or online, between or by attendees, or to members of the public or staff supporting the event, including venue employees, may be covered by this policy.\r\n\r\nOur decisions regarding the Code of Conduct may be escalated to the General Chairs as a committee, or the organising committee as a whole. The decision to take action is non-negotiable once it has been made.',NULL,NULL,NULL,NULL,NULL,'[]',0),(470,'pages',23,'body',0,'parablock','label','text',NULL,'Code of Conduct',NULL,NULL,NULL,NULL,NULL,'[]',0),(471,'pages',23,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(472,'pages',23,'body',1,'parablock','text','markdown',NULL,'## Minors and children\r\nAll children under 18 must accompanied by a parent or guardian at all times. We do not have any childcare facilities and are not able to provide supervision for children. Children are, at all times, the responsibility of the parent or guardian, and we cannot accept any liability or responsibility for them.\r\n\r\nPlease contact the organisers in advance if you intend to bring children as we will need to manage the cost of their attendance.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(473,'pages',23,'body',1,'parablock','label','text',NULL,'Minors and children',NULL,NULL,NULL,NULL,NULL,'[]',0),(474,'pages',23,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(475,'pages',23,'body',2,'parablock','text','markdown',NULL,'## Photography and videography\r\nWe will be documenting the event in a number of ways, including roving photography in areas where people can enter without restriction (including at the symposium dinner) and static videography of the sessions. This will be managed according to the University of Nottingham Photography and Videography policies: [Privacy Information for Subjects of Photography](https://www.nottingham.ac.uk/utilities/privacy/privacy-information-for-the-subjects-of-photography.aspx \"Privacy Information for the Subjects of Photography\"), [Photography privacy notices](https://www.nottingham.ac.uk/brand/services/photography-guidance/photography-privacy-notices.aspx \"Photography privacy notices\"), [Filming guidance and privacy notices](https://www.nottingham.ac.uk/brand/services/video/video-privacy-notices.aspx \"Filming guidance and privacy notices\"), [Privacy Information for Subjects of Videography](https://www.nottingham.ac.uk/utilities/privacy/privacy-information-for-the-subjects-of-videography.aspx \"Privacy Information for the Subjects of Videography\"), and [GDPR video guidance](https://www.nottingham.ac.uk/brand/services/video/video-gdpr.aspx \"GDPR video guidance\").\r\n\r\nThe copyright for all photography and videography will, in the first place, remain with the University of Nottingham. Any attendee reserves the right to withdraw consent at any time for inclusion in future photography or videography and we will do our best to honour this where reasonably possible. If you wish for imagery that includes you to not be used in any documentation of the event, please contact the organising committee and we will not include it in any future documentation.\r\n\r\n### Attendees\r\n\r\nWe will be video recording the sessions including panel discussions. If you wish to ask a question during these sessions, your voice will be recorded. In these cases, it is assumed that you are informed of this and are consenting, including assignment of copyright of your contribution. We will issue privacy notices before and during the event, as well as verbal reminders of on-going videography and audio recording. However, you can opt to ask a question by providing it in writing, so that an organiser or volunteer can ask the question on your behalf. \r\n\r\nWe will be documenting the event through photography in the symposium venues. If you prefer to not be included, we will supply—for free—different coloured lanyards that indicate your preference not to be included in such photography. This choice will be made during online registration, although you are free to request to any organiser or volunteer such a lanyard at any time during the event.\r\n\r\nYou will not be the feature and focus of a photograph, unless you have been asked to provide additional written consent.\r\n\r\n### Panel members\r\nIf you are selected to be on a panel, we will ask you to complete additional consent and privacy waivers in relation to photography and videography. \r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(476,'pages',23,'body',2,'parablock','label','text',NULL,'Photography and videography',NULL,NULL,NULL,NULL,NULL,'[]',0),(477,'pages',23,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(478,'pages',23,'body',3,'parablock','text','markdown',NULL,'## Privacy Policy\r\nThis event is being organised by employees of the University of Nottingham, and as such the event, and all attendees, are bound by the [University of Nottingham Privacy Policy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham Privacy Policy\"). You should read the specific policy that covers [the Halfway to the Future website](https://www.halfwaytothefuture.org/privacy-policy \"The Halfway to the Future website Privacy Policy\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(479,'pages',23,'body',3,'parablock','label','text',NULL,'Privacy Policy',NULL,NULL,NULL,NULL,NULL,'[]',0),(480,'pages',23,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(481,'pages',23,'body',4,'parablock','text','markdown',NULL,'### SIGCHI subsidy\r\n\r\nThrough sponsorship with ACM SIGCHI, we are able to offer a number of subsidised student places on a first-come, first-served basis. We will distribute codes that can be used during registration to discount the registration. Our decisions on allocation codes are final.\r\n\r\nTo receive this sponsorship, ACM stipulates that you must have both ACM and ACM SIGCHI memberships ($19 each)—you must sign up from the [ACM SIGCHI website](https://campus2.acm.org/public/qj/login_gensigqj.cfm?rdr=promo=QJSIG&offering=026&form_type=SIG \"Apply for SIGCHI membership on the ACM website\"). You do not need to register for ACM SIGCHI membership until we contact you.\r\n\r\nEven those registering for the symposium using the SIGCHI-sponsored rate must provide details of their student status to the Halfway to the Future organising committee, as above.\r\n\r\nAs organisers, we are issuing the subsidy to students, and claiming this back from ACM on your behalf. As a result, we will contact you should ACM alert us that you are not a member at the time of symposium. In such a case, we will ask you to either register for ACM and SIGCHI or pay the subsidy to Halfway to the Future (£100). If this is not done, we will cancel your registration without reimbursement or refund. As we are claiming this subsidy from ACM on your behalf, ACM requires us to collect either a tax identification number or passport number, where possible, as well as your country of residence. This data will be transferred to ACM in accordance with their policies.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(482,'pages',23,'body',4,'parablock','label','text',NULL,'Student subsidy',NULL,NULL,NULL,NULL,NULL,'[]',0),(483,'pages',23,'body',4,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(484,'pages',23,'body',5,'parablock','text','markdown',NULL,'## Refunds and cancellations\r\nA full refund will be available for cancellations up to Monday 16th September 2019 (UTC/GMT), minus a £25 administration fee. Thereafter no refunds are available. If you need to cancel, please email [registration@halfwaytothefuture.org](mailto:registration@halfwaytothefuture.org \"Email the Registration Chairs\") before this date.\r\n\r\nAs above, if your behaviour is deemed inappropriate and against our code of conduct, we reserve the right to cancel your registration and expel you from the symposium without a refund. This includes any harassment or comments posted digitally before, during or after the symposium.\r\n\r\nIf, for any reason, the organisers have to cancel the event due to any extenuating or unforeseen circumstances beyond the control of the organisers (force majeure), we reserve the right to not issue any refunds for registration or for additional packages such as the symposium dinner. However, we will endeavour to return any unspent money to attendees in proportion to the cost incurred.\r\n\r\nWe are mindful of the complicated visa situation, especially in the context of Brexit, and can provide letters to support any application for a visa. Please see our [Visas and Brexit webpage](/visas-and-brexit \"Halfway to the Future Visas and Brexit information\") to apply for a letter or for more information. If you experience any foreseen immigration problems beyond your control, subsequent to registration, you should contact the organisers on [registration@halfwaytothefuture.org](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\") or +44 (0) 115 95 14227 and we will try to assist you wherever possible.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(485,'pages',23,'body',5,'parablock','label','text',NULL,'Refunds and cancellations',NULL,NULL,NULL,NULL,NULL,'[]',0),(486,'pages',23,'body',5,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(487,'pages',23,'body',6,'parablock','text','markdown',NULL,'## Additional questions/information\r\nShould you have any additional questions or would like further information on any of the points above, please contact the [Local Arrangements Chair by email](local@halfwaytothefuture.org \"Email the Local Arragements Chair\") or by telephoning +44 (0) 115 82 32556.',NULL,NULL,NULL,NULL,NULL,'[]',0),(488,'pages',23,'body',6,'parablock','label','text',NULL,'Additional questions/information',NULL,NULL,NULL,NULL,NULL,'[]',0),(489,'pages',23,'body',6,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(515,'homepage',1,'body',3,'parablock','text','markdown',NULL,'We would like to thank the University of Nottingham [Faculty of Science](https://www.nottingham.ac.uk/science/home.aspx \"The University of Nottingham Faculty of Science website\"), [Creative and Digital Interdisciplinary Research Cluster](https://www.nottingham.ac.uk/research/research-areas/creative-and-digital/index.aspx \"University of Nottingham Creative and Digital IRC website\"), and [Smart Products Beacon](https://www.nottingham.ac.uk/research/beacons-of-excellence/smart-products/index.aspx \"The University of Nottingham Smart Products Beacon website\"); [ACM SIGCHI](https://sigchi.org/ \"The ACM Special Interest Group in Human-Computer Interaction website\"), and [Microsoft](https://www.microsoft.com/en-us/research/ \"The Microsoft Research website\") for generously sponsoring the symposium. ',NULL,NULL,NULL,NULL,NULL,'[]',0),(516,'homepage',1,'body',3,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(517,'homepage',1,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(518,'pages',1,'body',3,'cardblock','text','markdown',NULL,'Please read the [submission guidance on how to format and submit your papers](/submission-guidance \"Submission guidance for HttF\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(519,'pages',1,'body',3,'cardblock','label','text',NULL,'Submission Link',NULL,NULL,NULL,NULL,NULL,'[]',0),(520,'pages',1,'body',3,'cardblock','title','text',NULL,'Preparing your submission…',NULL,NULL,NULL,NULL,NULL,'[]',0),(521,'pages',1,'body',3,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(529,'pages',17,'body',0,'cardblock','text','markdown',NULL,'* [Word submission template](https://www.acm.org/binaries/content/assets/publications/taps/acm_submission_template.docx \"The Microsoft Word submission template for HttF papers\")\r\n* [LaTeX master template](https://www.acm.org/binaries/content/assets/publications/consolidated-tex-template/acmart-master.zip \"The ACM master template, including the sigconf option for HttF papers\") using the *sigconf* option (or create an ACM Conference Proceedings project using [Overleaf](https://www.overleaf.com/gallery/tagged/acm-official#.WOuOk2e1taQ))\r\n\r\nMore information and resources are available on the [ACM website](https://www.acm.org/publications/taps/word-template-workflow \"The ACM workflow for submitting papers written in Microsoft Word\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(530,'pages',17,'body',0,'cardblock','label','text',NULL,'Submission template downloads',NULL,NULL,NULL,NULL,NULL,'[]',0),(531,'pages',17,'body',0,'cardblock','title','text',NULL,'Submission template downloads',NULL,NULL,NULL,NULL,NULL,'[]',0),(532,'pages',17,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(533,'pages',17,'body',1,'parablock','text','markdown',NULL,'## Guidance on preparing your submission\r\n\r\nPlease read the following points carefully.\r\n\r\n* Your submission must be aligned with one of the [symposium themes](/themes \"HttF symposium themes\").\r\n\r\nMost importantly, \r\n\r\n* **all submissions must be anonymised**, with author details redacted in the paper **and** in the file metadata. Do **not** anonymise any references to your previous work, but **do** refer to your own publications in the third person. If your paper is not correctly anonymised, it may be desk rejected. Please direct any questions about anonymisation to [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the HttF Programme Chairs with questions about anonymisation\")\r\n\r\nThere\'s a word limit:\r\n\r\n* papers must either be *no more than 6,000 words* addressing current work relating to the [symposium theme](/themes \"HttF symposium themes\") you have chosen (and preferably referring in some way to the paper listed for that [theme](/themes \"HttF symspoium themes\"), or *no more than 2,000 words* looking towards the future of one of the [panel themes](/themes \"HttF symspoium themes\"). We encourage thought-provoking and/or unorthodox content, especially for the future-oriented work.\r\n* References, title, authors, abstract, and other frontmatter (e.g., keywords, CCS concepts, copyright notice etc.) **do not** count towards the word limit for either type of paper submission. \r\n* Tip for wordcount if you\'re working in Overleaf / LaTeX editors, etc. it may be easiest to copy-paste the PDF output into Word (the LaTeX word count may not cope well with comments, etc. in your bibtex source).  \r\n* FAQ: How \"hard\" is the word limit? **We won\'t raise an eyebrow as long as you\'re within 10% of the limit for your submission type**. Any more though, and we\'re going to have to desk reject the submission. Please count carefully! \r\n\r\nFurthermore,\r\n\r\n* all submissions will be reviewed by at least two experts in the field, and the entire review process will be double-blind.\r\n* Selected accepted authors will be offered the opportunity to take part in the panel discussion with the panel’s keynote speaker and other accepted authors. This selection process will be juried based on acceptances *after* double-blind peer review. \r\n* All papers are expected to be ready for publication; we do not offer the opportunity for substantial revisions or second reviews. Correction of minor errors can be made when preparing accepted papers for publication.\r\n* Submissions prepared in Microsoft Word **will** look significantly different to submissions prepared in LaTeX because they are in the \"submission\" template, authors will have to follow [these ACM instructions](hhttps://www.acm.org/binaries/content/assets/publications/taps/acm_master_article_template_instructions.pdf \"ACM Instructions for Applying the Master Article Template\") to make their paper look correct should they be accepted.\r\n* **No submission will be penalised or receive special treatment as a result of the template inconsistencies.**\r\n\r\nBy submitting to the symposium, you are agreeing to the following ACM policies:\r\n\r\n* Please follow the [ACM’s in-text citation style and reference formats](https://www.acm.org/publications/authors/reference-formatting \"The ACM guinelines on citing and references\"). This is best done at the submission stage and absolutely required upon submission of accepted papers.\r\n* Submissions must adhere to the ACM’s policies on [copyright](https://www.acm.org/publications/policies/copyright-policy \"The ACM policy on copyright\") and [plagiarism](https://www.acm.org/publications/policies/plagiarism \"The ACM policy on plagiarism\"). \r\n* Authors and reviewers will be asked to indicate their understanding and acceptance of the [ACM Policy on Conflict of Interest in Publication](https://www.acm.org/publications/policies/conflict-of-interest \"The ACM policy on conflict of interest\") when items are submitted and reviewed.\r\n* Papers submitted to this symposium cannot be under consideration for any other conference or publication (no simultaneous submissions) and cannot be previously published without undergoing substantial revision. See the [ACM Policy on Prior Publication and Simultaneous Submissions](https://www.acm.org/publications/policies/simultaneous-submissions \"The ACM policy on Prior Publication and Simultaneous Submissions\"). ',NULL,NULL,NULL,NULL,NULL,'[]',0),(534,'pages',17,'body',1,'parablock','label','text',NULL,'Submission Preparation',NULL,NULL,NULL,NULL,NULL,'[]',0),(535,'pages',17,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(536,'pages',18,'body',0,'imageblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(538,'pages',25,'body',1,'cardblock','text','markdown',NULL,'Please [pre-apply](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUMDhVM0pCNDdJOUxXVjlKU0E4MzBBTjJJOCQlQCN0PWcu \"Register for a student subsidy\") to receive the discount. We will start issuing codes once decisions have been made on papers.\r\n\r\nYou **do not** need to be a member of ACM SIGCHI until completing your online registration.',NULL,NULL,NULL,NULL,NULL,'[]',0),(539,'pages',25,'body',1,'cardblock','label','text',NULL,'Pre-apply to receive the discount',NULL,NULL,NULL,NULL,NULL,'[]',0),(540,'pages',25,'body',1,'cardblock','title','text',NULL,'Pre-apply to receive the discount',NULL,NULL,NULL,NULL,NULL,'[]',0),(541,'pages',25,'body',1,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(545,'pages',4,'body',9,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(548,'pages',4,'body',17,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(550,'pages',4,'body',0,'parablock','text','markdown',NULL,'## Ubiquitous Computing\r\n**A keynote by Yvonne Roggers (UCL)**<br>\r\n[Moving on from Weiser’s Vision of Calm Computing: Engaging UbiComp Experiences](/programme/rogers-moving-on-from-weiser-s-vision-of-calm-computing-engaging-ubicomp-experiences \"Read about this paper and download a PDF of it\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(551,'pages',4,'body',0,'parablock','label','text',NULL,'Ubiquitous Computing',NULL,NULL,NULL,NULL,NULL,'[]',0),(552,'pages',4,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(553,'pages',4,'body',1,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/yvonnerogers.png\"}',0),(554,'pages',4,'body',1,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(555,'pages',4,'body',1,'imageblock','alt','text',NULL,'Yvonne Rogers',NULL,NULL,NULL,NULL,NULL,'[]',0),(556,'pages',4,'body',1,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(557,'pages',4,'body',1,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(558,'pages',4,'body',3,'parablock','text','markdown',NULL,'## Mixed Reality\r\n**A keynote by Steve Benford (University of Nottingham)**<br>\r\n[Orchestrating a Mixed Reality Performance](/programme/koleva-orchestrating-a-mixed-reality-performance \"Read about this paper and download a PDF of it\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(559,'pages',4,'body',3,'parablock','label','text',NULL,'Mixed Reality',NULL,NULL,NULL,NULL,NULL,'[]',0),(560,'pages',4,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(561,'pages',4,'body',4,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/stevebenford.jpg\"}',0),(562,'pages',4,'body',4,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(563,'pages',4,'body',4,'imageblock','alt','text',NULL,'Steve Benford',NULL,NULL,NULL,NULL,NULL,'[]',0),(564,'pages',4,'body',4,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(565,'pages',4,'body',4,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(566,'pages',4,'body',6,'parablock','text','markdown',NULL,'## Artificial Intelligence, Humans & Machines\r\n**A conversation between Lucy Suchman (Lancaster University) and Alex Taylor (City, University of London), in which Lucy will be attending remotely**<br>\r\n[Human-Machine Reconfigurations: Plans and Situated Actions](/programme/suchman-human-machine-reconfigurations-plans-and-situated-actions \"Read about this book\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(567,'pages',4,'body',6,'parablock','label','text',NULL,'Artificial Intelligence, Humans & Machines',NULL,NULL,NULL,NULL,NULL,'[]',0),(568,'pages',4,'body',6,'parablock','class','text',NULL,'clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(569,'pages',4,'body',7,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/lucysuchman.jpg\"}',0),(570,'pages',4,'body',7,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(571,'pages',4,'body',7,'imageblock','alt','text',NULL,'Lucy Suchman',NULL,NULL,NULL,NULL,NULL,'[]',0),(572,'pages',4,'body',7,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(573,'pages',4,'body',7,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(574,'pages',4,'body',11,'parablock','text','markdown',NULL,'## Arts & Design-led Approaches\r\n**A keynote by Bill Gaver (Goldsmiths, University of London)**<br>\r\n[Ambiguity as a Resource for Design](/programme/gaver-ambiguity-as-a-resource-for-design \"Read about this paper and download a PDF of it\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(575,'pages',4,'body',11,'parablock','label','text',NULL,'Arts & Design-led Approaches',NULL,NULL,NULL,NULL,NULL,'[]',0),(576,'pages',4,'body',11,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(577,'pages',4,'body',12,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-03/billgaver.jpg\"}',0),(578,'pages',4,'body',12,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(579,'pages',4,'body',12,'imageblock','alt','text',NULL,'Bill Gaver',NULL,NULL,NULL,NULL,NULL,'[]',0),(580,'pages',4,'body',12,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(581,'pages',4,'body',12,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(582,'pages',4,'body',14,'parablock','text','markdown',NULL,'## Public & Private Spaces\r\n**A keynote by Christian Heath and Paul Luff (King\'s College London)**<br>\r\n[Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms](/programme/heath-collaboration-and-control-crisis-management-and-multimedia-technology-in-london-underground-line-control-rooms \"Read about this paper and download a PDF of it\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(583,'pages',4,'body',14,'parablock','label','text',NULL,'Public & Private Spaces',NULL,NULL,NULL,NULL,NULL,'[]',0),(584,'pages',4,'body',14,'parablock','class','text',NULL,'clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(585,'pages',4,'body',15,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-03/christianheath.jpg\"}',0),(586,'pages',4,'body',15,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(587,'pages',4,'body',15,'imageblock','alt','text',NULL,'Christian Heath',NULL,NULL,NULL,NULL,NULL,'[]',0),(588,'pages',4,'body',15,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(589,'pages',4,'body',15,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(590,'pages',4,'body',19,'parablock','text','markdown',NULL,'## New Approaches to Research & Design\r\n**A keynote by Susanne Bødker (Aarhus University)**<br>\r\n[When second wave HCI meets third wave challenges](/programme/bodker-when-second-wave-hci-meets-third-wave-challenges \"Read about this paper and download a PDF of it\")',NULL,NULL,NULL,NULL,NULL,'[]',0),(591,'pages',4,'body',19,'parablock','label','text',NULL,'New Approaches to Research & Design',NULL,NULL,NULL,NULL,NULL,'[]',0),(592,'pages',4,'body',19,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(593,'pages',4,'body',20,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/susannebodker.jpg\"}',0),(594,'pages',4,'body',20,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(595,'pages',4,'body',20,'imageblock','alt','text',NULL,'Susanne Bødker',NULL,NULL,NULL,NULL,NULL,'[]',0),(596,'pages',4,'body',20,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(597,'pages',4,'body',20,'imageblock','class','text',NULL,'shadow rounded small-image clear',NULL,NULL,NULL,NULL,NULL,'[]',0),(603,'pages',9,'body',0,'programmeblock','detail','select',NULL,'themes',NULL,NULL,NULL,NULL,NULL,'[]',0),(604,'pages',9,'body',1,'cardblock','text','markdown',NULL,'Please read the [submission guidance](/submission-guidance \"Guidance on preparing a paper to submit to HttF\") before submitting your papers. This guidance also includes the templates you should use to prepare your submission.',NULL,NULL,NULL,NULL,NULL,'[]',0),(605,'pages',9,'body',1,'cardblock','label','text',NULL,'Submission guidance',NULL,NULL,NULL,NULL,NULL,'[]',0),(606,'pages',9,'body',1,'cardblock','title','text',NULL,'Submission guidance',NULL,NULL,NULL,NULL,NULL,'[]',0),(607,'pages',9,'body',1,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(608,'pages',2,'body',0,'cardblock','text','markdown',NULL,'[Joel E. Fischer](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/joel.fischer \"Joel\'s profile on the University of Nottingham website\"), \r\n[Sarah Martindale](https://www.nottingham.ac.uk/clas/departments/culturalmediaandvisualstudies/people/sarah.martindale \"Sarah\'s profile on the University of Nottingham website\"), \r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\"),\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\"), and \r\n[Jocelyn Spence](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/jocelyn.spence \"Jocelyn\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [general-chairs@halfwaytothefuture.org](mailto:general-chairs@halfwaytothefuture.org \"Email all five General Chairs\")*\r\n\r\n**Administration Manager**<br>\r\n[Lindsay Norman](https://www.nottingham.ac.uk/computerscience/people/lindsay.norman \"Lindsay\'s profile on the University of Nottingham website\")\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(609,'pages',2,'body',0,'cardblock','label','text',NULL,'General Chairs',NULL,NULL,NULL,NULL,NULL,'[]',0),(610,'pages',2,'body',0,'cardblock','title','text',NULL,'General Chairs',NULL,NULL,NULL,NULL,NULL,'[]',0),(611,'pages',2,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(613,'pages',11,'body',0,'imageblock','class','text',NULL,'transparent',NULL,NULL,NULL,NULL,NULL,'[]',0),(614,'pages',1,'body',0,'programmeblock','detail','select',NULL,'keynotes',NULL,NULL,NULL,NULL,NULL,'[]',0),(619,'pages',14,'body',0,'cardblock','text','markdown',NULL,'Thank you for expressing your interest in the Halfway to the Future symposium, due to take place on the 19th and 20th November 2019 in Nottingham, UK. I\'m delighted to say the committee have been working hard behind the scenes, and we are now ready to send out further details.\r\n\r\nAdditionally, we have launched our website, [www.halfwaytothefuture.org](https://www.halfwaytothefuture.org \"The Halfway to the Future website\"), and our Twitter account, [@httfsymposium](https://twitter.com/httfsymposium \"The Halfway to the Future Twiter account\"). I will, of course, also keep you in the loop with periodic updates on the symposium. We are also now able to confirm the venue — the fabulous [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk \"The Albert Hall Conference Centre Nottingham website\") in the centre of Nottingham. \r\nFinally, the Programme Chairs have put together the [Call for Papers](https://www.halfwaytothefuture.org/cfp \"The Halfway to the Future Call for Papers\"), which I have pasted below. We look forward to your submissions to the symposium!\r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair)<br>\r\n &nbsp;on behalf of the organising committee (Joel Fischer, Sarah Martindale, Martin Porcheron, Stuart Reeves, Jocelyn Spence)\r\n\r\n—\r\n\r\nHalfway to the Future symposium<br>\r\n19-20 November 2019, Nottingham, UK<br>\r\n[www.halfwaytothefuture.org](https://www.halfwaytothefuture.org  \"The Halfway to the Future website\")<br>\r\nTwitter: [@httfsymposium](http://twitter.com/httfsymposium \"The Halfway to the Future Twiter account\")\r\n\r\nThe Halfway to the Future symposium explores the past, present, and future of themes driving key research in HCI and design. Each theme will be addressed by a dedicated panel anchored by a confirmed keynote speaker discussing one of their influential papers in light of subsequent developments:\r\n * **Ubiquitous Computing** – YVONNE ROGERS (UCL) – \"Moving on from Weiser\'s vision of calm computing\" \r\n * **Mixed Reality** – STEVE BENFORD (University of Nottingham) – \"Orchestrating a mixed reality performance\" \r\n * **Artificial Intelligence, Humans & Machines** – LUCY SUCHMAN (Lancaster University) and ALEX TAYLOR (City, University of London) – \"Human-Machine Reconfigurations: Plans and Situated Actions\" \r\n * **Arts & Design-Led Approaches** – BILL GAVER (Goldsmiths, University of London) – \"Ambiguity as a resource for design\" \r\n * **Public & Private Spaces** – CHRISTIAN HEATH (Kings College London) – \"Collaboration and control: Crisis management and multimedia technology in London Underground Line Control Rooms\" \r\n * **New Approaches to Research & Design** – SUSANNE BØDKER (Aarhus University) – \"When second wave HCI meets third wave challenges\" \r\n\r\nThe keynotes will be followed by presentations, drawn from submitted papers, of current related work and short future-oriented provocations, followed by a panel discussion/Q&A seeking to shape the agenda of that research area in the years to come. The event will also incorporate an exhibition of interactive works and a poster session. \r\n\r\nWe invite papers of up to 6,000 words (not including references, format TBC) addressing current work relating to the themes above, especially those building on or responding to the influential works to be discussed. We also invite short papers of up to 2,000 words (not including references) looking towards the future of these themes. Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. Accepted papers not chosen for panels will be invited to be presented in poster format. We will publish an edited volume of panel papers and an online adjunct proceedings of papers selected for poster presentation.\r\n\r\nPlease register your interest in submitting to and/or attending this symposium in order to receive updates ([bit.ly/httf2019eoi](https://bit.ly/httf2019eoi \"Join our Expression of Interest mailing list to receive updates on the symposium\")). Further information about the symposium and a link to the submission form can be found at [www.halfwaytothefuture.org](https://www.halfwaytothefuture.org \"The Halfway to the Future website\").\r\nHalfway to the Future is co-organised by the Mixed Reality Lab, University of Nottingham, as part of celebrations of its 20-year anniversary. Keynote speakers and respective panel themes have been chosen for their formative and ongoing influence on the lab’s work across two decades.\r\n\r\n**Important Dates**<br>\r\nSubmission deadline: Friday 21st June<br>\r\nNotification: Friday 26th July<br>\r\nDeadline for confirmation of attendance (for panellists): Friday 23rd August<br>\r\nEarly bird registration closes: Friday 13th September<br>\r\nRegistration closes: Friday 11th October<br>\r\nEvent dates: Tuesday 19th – Wednesday 20th November 2019\r\n\r\nJoel Fischer and Jocelyn Spence, Programme Chairs<br>\r\nProgramme Committee, TBC',NULL,NULL,NULL,NULL,NULL,'[]',0),(620,'pages',14,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(621,'pages',14,'body',0,'cardblock','title','text',NULL,'Halfway to the Future',NULL,NULL,NULL,NULL,NULL,'[]',0),(622,'pages',14,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(623,'pages',16,'body',0,'cardblock','text','markdown',NULL,'The **Halfway to the Future** committee have been working hard on the organisation of the symposium over the last couple of months and we now have a few updates to share with you.\r\n\r\nWe are delighted to confirm that all accepted papers will be published as part the ACM International Conference Proceedings and will be included in the **ACM Digital Library**! As part of this, all submitted papers will be peer reviewed through a double-blind process. This means we are now able to distribute the [templates you should use to draft your papers](/submission-guidance \"Guidance and templates for submitting papers to HttF\").\r\n\r\nAll accepted authors who are not invited to present their work within one of the symposium panels will be invited to produce a poster to be displayed during the symposium as well as being included in the ACM conference proceedings. Selected authors from accepted submissions will offered the opportunity to take part in one of our six symposium panels (this process will be juried to curate provocative and engaging debate). We have clarified this information on our [submission guidance webpage](/submission-guidance \"Guidance and templates for submitting papers to HttF\").\r\n\r\nSubmissions are due on the **21st June**!\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the Programme Chairs with any questions you have\").\r\n\r\nFinally, just a quick note to say we are currently working on finalising the details of conference registration and will be making these details public in the coming weeks. \r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair)\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(624,'pages',16,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(625,'pages',16,'body',0,'cardblock','title','text',NULL,'EoI Update #2: Accepted papers will appear in the ACM Digital Library!',NULL,NULL,NULL,NULL,NULL,'[]',0),(626,'pages',16,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(627,'pages',26,'body',0,'cardblock','text','markdown',NULL,'We can\'t believe how the time has flown by since we announced the symposium in February. \r\n\r\n**Submissions are due 21st June**<br>\r\nThere is now just two weeks until the **Halfway to the Future** submission deadline. A reminder that we have two paper types:\r\n\r\n* 6,000-word papers addressing current work relating to [a symposium theme](https://www.halfwaytothefuture.org/themes \"HttF symposium themes\"), especially those building on or responding to the influential works to be discussed.\r\n* 2,000-word papers looking towards the future of [our themes](https://www.halfwaytothefuture.org/themes \"HttF symposium themes\"). Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. \r\n\r\nWhile we know many of you will be familiar with the CHI style of writing—which is certainly acceptable—we are also very open to more theoretical, exploratory, or otherwise non-traditional styles of paper.\r\n\r\nAll accepted papers will go into the ACM International Conference Proceedings Series for Halfway to the Future and will be included in the **ACM Digital Library**! As part of this, all submitted papers will be peer reviewed through a double-blind process. [The templates you should use to draft your papers can be downloaded from our website](https://www.halfwaytothefuture.org/submission-guidance \"The HttF submission guidance\").\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the Programme Chairs with any questions\").\r\n\r\n**Discounted student registration - £25**<br>\r\nWe are also delighted to announce that we are being sponsored by ACM SIGCHI, who are subsidising 80 student registrations! The **student registration cost for ACM SIGCHI members is just £25** (a 90% discount on full registration). For non-members, student registration costs £125. However, as ACM SIGCHI membership only costs $38, we would encourage you to join and take advantage of this very generous subsidy.\r\n\r\nTo receive this subsidy, students simply need to [apply for a discount code from our website](https://www.halfwaytothefuture.org/sigchi-student-subsidy \"Apply for a discount code for your registration now\"). You can apply for a discount code now and register later once your paper is accepted (we\'d encourage this as places are limited). Details on registering for ACM and ACM SIGCHI are [on our website too](https://www.halfwaytothefuture.org/sigchi-student-subsidy \"Details for the SIGCHI student discount are available now\").\r\n\r\nWe will send the discount codes to the people who have requested a code, **giving priority to those who have had a paper accepted**. Remaining discount codes will be given on a first-come, first-served basis to **those who have submitted, but were not accepted**. After this, any remaining codes will be allocated on a first-come, first-served basis to those interested in attending.\r\n\r\nPlease contact Stuart, our Sponsorship Chair, if you have any questions regarding the subsidy using the email address [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email our Sponsorship Chair with any questions\").\r\n\r\nWe will be opening registration in the next few weeks and I will send another email regarding this. Good luck with preparing your papers, and we look forward to seeing you in November!\r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair)<br>\r\non behalf of [the organising committee](https://www.halfwaytothefuture.org/organising-committee \"The Halfway to the Future Organising Committee\")\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(628,'pages',26,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(629,'pages',26,'body',0,'cardblock','title','text',NULL,'Halfway to the Future: Student Discount and Submission Deadline',NULL,NULL,NULL,NULL,NULL,'[]',0),(630,'pages',26,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(631,'pages',27,'body',0,'cardblock','text','markdown',NULL,'**Submission deadline extended until Wednesday 26th June**<br>\r\nApologies for another email so soon after the last one. Submissions are now coming in for the symposium, however following many requests to the Programme Chairs, we have extended the submission deadline until **Wednesday 26th June 2019** (at 23:59 BST/UTC+1).\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email any questions to the Programme Chairs\").\r\n\r\nMore details are on our [Call for Papers](/cfp \"HttF Call for Papers\").\r\n\r\n**Discounted student registration - £25**<br>\r\nIf you are or have students who are planning to submit or would like to attend the symposium this November, please do encourage them to apply for a student discount code as soon as possible. The number of codes is limited, and many have been requested already. The discount codes are funded by ACM SIGCHI.\r\n\r\nPlease note that ACM requires that students who receive the subsidy be members of ACM and ACM SIGCHI already. As this membership only costs $38, the discount is still substantial. We will advise students beforehand if they are successful and thus they do **not** need to apply for membership to request a code.\r\n\r\nTo receive this subsidy, students simply need to [apply for a discount code from our website](/sigchi-student-subsidy \"Apply for the SIGCHI student discount on our website\"). Details on registering for ACM and ACM SIGCHI are [on our website too](/sigchi-student-subsidy \"Details of the SIGCHI student discount are on our website\").\r\n\r\nPlease contact Stuart, our Sponsorship chair, if you have any questions regarding the subsidy using the email address [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email questions about the subsidy to our Sponsorship Chair\").\r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair)',NULL,NULL,NULL,NULL,NULL,'[]',0),(632,'pages',27,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(633,'pages',27,'body',0,'cardblock','title','text',NULL,'Halfway to the Future: Submission deadline extended until 26th June',NULL,NULL,NULL,NULL,NULL,'[]',0),(634,'pages',27,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(639,'pages',19,'body',3,'parablock','text','markdown',NULL,'## Public Transport\r\nMost **public transport** in Nottingham is fully wheelchair accessible, with all major bus operators ([NCT](https://www.nctx.co.uk/ \"Nottingham City Transport\"), [trentbarton](https://trentbarton.co.uk/ \"trentbarton\"), [CT4N](http://www.ct4n.co.uk/ \"Community Transport 4 Nottingham\"), and [Your Bus](http://catchyourbus.co.uk/ \"Your Bus\")), operating low-floor buses, with most of the buses having designated bays for wheelchair users as well as priority seats for those less-abled.\r\n\r\n[NET](https://thetram.net/ \"Nottingham Express Transit\"), the Nottingham tram system, only operates 100% low floor trams, all of which are wheelchair accessible. Some trains which stop at Nottingham Railway Station have a gap between the platform and the train—staff on the train or at the station can provide a ramp for wheelchair users.\r\n\r\nNottingham has an extensive network of taxis, many of which can carry individuals with a wheelchair. When booking a taxi, you should explain your needs to the taxi company. The major taxi operators are [DG Cars](https://dgcars.co.uk/ \"DG Cars\") and [Nottingham Cars](https://nottinghamcars.com/ \"Nottingham Cars\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(640,'pages',19,'body',3,'parablock','label','text',NULL,'Public Transport',NULL,NULL,NULL,NULL,NULL,'[]',0),(641,'pages',19,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(642,'pages',28,'body',0,'parablock','text','markdown',NULL,'You may **optionally** include your name and email address in this report and can choose whether or not you wish for us to contact you regarding your report. If you wish to remain anonymous, please enter a pseudonym (this can even be a random string of characters!).',NULL,NULL,NULL,NULL,NULL,'[]',0),(643,'pages',28,'body',0,'parablock','label','text',NULL,'Anonymous',NULL,NULL,NULL,NULL,NULL,'[]',0),(644,'pages',28,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(645,'pages',28,'body',1,'cardblock','text','markdown',NULL,'During the symposium, attendees will be able to contact **Martin Porcheron** (Communications Chair and Treasurer) using the UK mobile phone number ‭**+44 7394 212757‬** at any time either by calling, sending an SMS, or sending a WhatsApp message.',NULL,NULL,NULL,NULL,NULL,'[]',0),(646,'pages',28,'body',1,'cardblock','label','text',NULL,'Careline and WhatsApp',NULL,NULL,NULL,NULL,NULL,'[]',0),(647,'pages',28,'body',1,'cardblock','title','text',NULL,'Careline and WhatsApp',NULL,NULL,NULL,NULL,NULL,'[]',0),(648,'pages',28,'body',1,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(649,'pages',28,'body',2,'parablock','text','markdown',NULL,'## Contact form',NULL,NULL,NULL,NULL,NULL,'[]',0),(650,'pages',28,'body',2,'parablock','label','text',NULL,'Title',NULL,NULL,NULL,NULL,NULL,'[]',0),(651,'pages',28,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(659,'pages',18,'body',3,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/robinhoodnetwork.png\"}',0),(660,'pages',18,'body',3,'imageblock','imagestyle','select',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(661,'pages',18,'body',3,'imageblock','alt','text',NULL,'Robin Hood Network logo',NULL,NULL,NULL,NULL,NULL,'[]',0),(662,'pages',18,'body',3,'imageblock','caption','markdown',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(663,'pages',18,'body',3,'imageblock','class','text',NULL,'transparent d-none',NULL,NULL,NULL,NULL,NULL,'[]',0),(664,'pages',18,'body',4,'parablock','text','markdown',NULL,'The conference centre is located next to the **St. Barnabas cathedral bus stops** (leaving the city) and **Tollhouse Hill bus stops** (into the city). Nottingham is served by multiple bus operators, primarily [Nottingham City Transport](https://www.nctx.co.uk/ \"The Nottingham City Transport website\") and [trentbarton](https://www.trentbarton.co.uk/ \"The trentbarton website\"). Most of the bus companies also co-operate as part of the [Robin Hood Network](http://robinhoodnetwork.co.uk/ \"The Robin Hood Network website\") and provide all-day multi-operator tickets. If your journey starts and ends in Nottingham, you can use the [Robin Hood Network journey planner](https://robinhoodnetwork.co.uk/journey-planner.html?destinationLatLng=52.9549572912,-1.1575989576&destination=Cathedral \"The Robin Hood Network Journey Planner to the nearest bus stop for HttF\") to find your route to the venue.\r\n\r\nIf you are catching a tram, the Nottingham tram system, NET, is providing discounted tram travel for attendees, however you must print off and complete the voucher in [this PDF](https://www.halfwaytothefuture.org/files/2019-02/ahccfindus.pdf \"Nottingham Express Transit Tram discount for HttF attendees\") for each day you travel on the tram system. To buy a tram ticket, you must use a machine at any tram stop, and purchase an \"Event Ticket\". You must retain this voucher with you at all times while on the tram as failure to do so may result in a penalty fare. The nearest stop is **Royal Centre**.\r\n\r\nNET is also part of the Robin Hood Network, thus Robin Hood tickets are valid on both buses and trams (note that each Robin Hood operator sells operator-only and multi-operator tickets).',NULL,NULL,NULL,NULL,NULL,'[]',0),(665,'pages',18,'body',4,'parablock','label','text',NULL,'Public transport continued',NULL,NULL,NULL,NULL,NULL,'[]',0),(666,'pages',18,'body',4,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(667,'pages',5,'body',0,'imageblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(668,'pages',21,'body',0,'imageblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(669,'pages',7,'body',0,'cardblock','text','markdown',NULL,'All registrations are subject to our [Terms & Conditions](/registration-terms-conditions \"HttF Registration Terms & Conditions\"), and all those who register and/or attend for the symposium are bound by the [Code of Conduct](/conduct \"HttF Code of Coduct\"). If you have been/will be registered by another person (e.g. an administrator), please familiarise yourself with these before the symposium.',NULL,NULL,NULL,NULL,NULL,'[]',0),(670,'pages',7,'body',0,'cardblock','label','text',NULL,'Registration information',NULL,NULL,NULL,NULL,NULL,'[]',0),(671,'pages',7,'body',0,'cardblock','title','text',NULL,'Registration information',NULL,NULL,NULL,NULL,NULL,'[]',0),(672,'pages',7,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(673,'pages',7,'body',1,'parablock','text','markdown',NULL,'We will host a [Welcome Reception](/session/welcome-reception \"Halfway to the Future Weclome Reception\") at the Nottingham Contemporary gallery on Monday 18th November, with free drinks and nibbles, the *night before the symposium officially opens*. This will be an open and free event for all attendees, so you may wish to travel to Nottingham the *day before the symposium commences*.\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(674,'pages',7,'body',1,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(675,'pages',7,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(680,'pages',30,'body',0,'cardblock','text','markdown',NULL,'All submissions to the symposium are now under review—we received 80 in total. We will send notifications to authors by the 26th July.\r\n\r\n**Symposium registration and dinner**<br>\r\nWe have now opened up our [symposium registration](/registration \"Halfway to the Future registration\") on our website. Register before the 13th September for early bird rates. \r\n\r\nDuring registration you will also be offered the opportunity to join us for the symposium dinner on the first night of the symposium. We are also offering a choice of vegetarian, vegan, gluten free and Halal meal options—[the menu can be seen on our website](/session/symposium-dinner \"Halfway to the Future symposium dinner\"). We would love to see as many of you there as possible!\r\n\r\n**Reduced hotel rates**<br>\r\nThe Park Plaza Hotel in Nottingham has also offered reduced rates to symposium attendees. Details of these rates, which include breakfast, [are now on our website](/hotel \"The Park Plaza, Nottingham\"). These rooms are available on a first-come first-served basis.\r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair)',NULL,NULL,NULL,NULL,NULL,'[]',0),(681,'pages',30,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(682,'pages',30,'body',0,'cardblock','title','text',NULL,'Halfway to the Future: Symposium registration is open',NULL,NULL,NULL,NULL,NULL,'[]',0),(683,'pages',30,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(684,'pages',20,'body',2,'cardblock','text','markdown',NULL,'The UK will no longer leave the European Union until after Halfway to the Future. As such, there remains free movement of people on pre-existing terms until a future date. This future date may be in 2020, or mid-to-late December 2019 at the earliest.',NULL,NULL,NULL,NULL,NULL,'[]',0),(685,'pages',20,'body',2,'cardblock','label','text',NULL,'Update 16th November 2019',NULL,NULL,NULL,NULL,NULL,'[]',0),(686,'pages',20,'body',2,'cardblock','title','text',NULL,'Update 16th November 2019',NULL,NULL,NULL,NULL,NULL,'[]',0),(687,'pages',20,'body',2,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(688,'pages',31,'body',0,'parablock','text','markdown',NULL,'## Overall process\r\n\r\n1. Prepare a revised version of your work using the final template, incorporating the changes requested by reviewers. Upload this to EasyChair by **Friday 6th September 2019**\r\n2. At least one author must register before **Friday 27th September 2019**, otherwise your publication **will not** be included in the Halfway to the Future Proceedings\r\n3. The Programme Chairs will review your PDF and communicate with you as to whether the requested changes have been satisfactorily made\r\n4. Complete the ACM rights allocation and update your paper\r\n5. Submit the final versions for publication to the publishing system. This needs to be done by **early October**.',NULL,NULL,NULL,NULL,NULL,'[]',0),(689,'pages',31,'body',0,'parablock','label','text',NULL,'Overall process',NULL,NULL,NULL,NULL,NULL,'[]',0),(690,'pages',31,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(691,'pages',31,'body',1,'parablock','text','markdown',NULL,'### Step 1: Preparing your revised paper\r\nIn addition to making the requested changes, the new templates enable you to import required indexing concepts for your article from the [ACM Computing Classification System (CCS)](https://www.acm.org/publications/class-2012 \"The ACM classification system for all work in the Digital Library\") using an [indexing support tool](https://dl.acm.org/ccs/ccs.cfm? \"A tool developed by ACM to generate the classification for papers in the Digital Library\") found in the ACM Digital Library (DL) which generates the necessary TeX code once you have selected your terms (and generates XML for Word documents). The ACM **requires** the use of this tool to generate your CCS concepts before submission to the Digital Library.\r\n\r\nMicrosoft Word users will have to follow the [ACM Master Article Template workflow](https://www.acm.org/publications/taps/word-template-workflow  \"Information on preparing papers for publication that were written in Microsoft Word\") to prepare their document.\r\n\r\nWe also request that authors make their papers as accessible as possible by including alternative text for all images and tables to make more of your content available to readers with visual impairments. \r\n\r\nYou should upload the revised version of your paper to EasyChair, where the Programme Chairs will review the PDF and assess whether you have complied with the template requirements for ACM publication.\r\n\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(692,'pages',31,'body',1,'parablock','label','text',NULL,'Details',NULL,NULL,NULL,NULL,NULL,'[]',0),(693,'pages',31,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(697,'pages',32,'body',0,'cardblock','text','markdown',NULL,'Sponsorship is an ideal opportunity to demonstrate your organisation’s commitment and research collaboration in the field of HCI and design-based research, as well as raising awareness of your products or services. If you are interested in sponsoring Halfway to the Future, please email [Stuart Reeves, our Sponsorship Chair](mailto:sponsorship@halfwaytothefuture.org \"Email Stuart Reeves for more information on sponsorsing the symposium\") for details. We have multiple sponsorship tiers and can also create a bespoke sponsorship package for you.',NULL,NULL,NULL,NULL,NULL,'[]',0),(698,'pages',32,'body',0,'cardblock','label','text',NULL,'Sponsor Halfway to the Future',NULL,NULL,NULL,NULL,NULL,'[]',0),(699,'pages',32,'body',0,'cardblock','title','text',NULL,'Sponsor Halfway to the Future',NULL,NULL,NULL,NULL,NULL,'[]',0),(700,'pages',32,'body',0,'cardblock','class','text',NULL,'d-none',NULL,NULL,NULL,NULL,NULL,'[]',0),(701,'pages',32,'body',1,'parablock','text','markdown',NULL,'**Platinum Sponsors**<br>\r\n* [ACM SIGCHI](https://sigchi.org \"The Association of Computing Machinery Special Interest Group on Computer-Human Interaction website\")\r\n* [University of Nottingham Faculty of Science](https://www.nottingham.ac.uk/science \"The University of Nottingham Faculty of Science website\")\r\n* [University of Nottingham Creative and Digital Interdisciplinary Research Cluster](https://www.nottingham.ac.uk/research/research-areas/creative-and-digital/index.aspx \"The University of Nottingham Creative and Digital IRC website\")\r\n\r\n**Gold Sponsors**<br>\r\n* [Microsoft Research](https://www.microsoft.com/en-us/research/ \"The Microsoft Research website\")\r\n* [University of Nottingham Smart Products Beacon](https://www.nottingham.ac.uk/research/beacons-of-excellence/smart-products/index.aspx \"The University of Nottingham Smart Products Beacon website\")\r\n\r\n**Partners**<br>\r\n* [Mixed Reality Lab](http://www.mrl.nott.ac.uk/ \"The Mixed Reality Laboratory website\")\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(702,'pages',32,'body',1,'parablock','label','text',NULL,'Sponsors',NULL,NULL,NULL,NULL,NULL,'[]',0),(703,'pages',32,'body',1,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(704,'pages',31,'body',2,'cardblock','text','markdown',NULL,'A note to anyone attempting to use the Word template: our website contains all the information made available to us by the ACM. Word users should follow the [ACM Master Article Template workflow](https://www.acm.org/publications/taps/word-template-workflow \"ACM Master Article Template workflow\"). This means you should download the Word Master Article template from ACM, apply it to your submission (details given in the link), and follow the guide in marking up your references accordingly.\r\n\r\nNote that Mendeley users may have to convert their dynamic Mendeley references to text as the ACM macros do not seem to work with Mendeley\'s references.\r\n\r\nPapers prepared in Word **will be in single column**, LaTeX papers **should be double-column with the sigconf option in the \\documentclass**. ',NULL,NULL,NULL,NULL,NULL,'[]',0),(705,'pages',31,'body',2,'cardblock','label','text',NULL,'Update from the Programme Chairs',NULL,NULL,NULL,NULL,NULL,'[]',0),(706,'pages',31,'body',2,'cardblock','title','text',NULL,'Update from the Programme Chairs (5th September)',NULL,NULL,NULL,NULL,NULL,'[]',0),(707,'pages',31,'body',2,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(708,'pages',31,'body',3,'parablock','text','markdown',NULL,'### Step 2: Register\r\nYou can [register for the symposium online](/registration \"Halfway to the Future 2019 registration\"). All panellists **and poster presenters** must register by the early registration deadline of 27th September. Please contact us if this presents any problem for you.\r\n\r\n### Step 3: Paper finalised\r\nThe Programme Chairs will send you an email to confirm your changes were accepted and that you will receive the ACM rights email and ACM TAPS (publishing system) links shortly. Please check your spam folders for emails from acm.org.  **This will be a very quick turnaround**.\r\n\r\n### Step 4: ACM rights\r\nAccepted authors will be required to complete [a rights management form](https://www.acm.org/publications/icps-instructions/ \"About the ACM ICPS rights management process\"). We will email the correct rights text and bibliographic strip that must be placed within the paper where required in the template. Please expect an email from [rightsreview@acm.org](mailto:rightsreview@acm.org \"Emails regarding rights come from this email address at ACM\") and adjust your junk/spam settings accordingly.\r\n\r\nNo pre-publication version may be put online or otherwise distributed until all rights management, bibliographic information, and copyright information has been completed and confirmed by the Programme Chairs.\r\n\r\n### Step 5: Upload your final versions\r\nWe will input all data about papers into the ACM TAPS system, which, as authors, you will then use to upload your source documents. You will be emailed with details of how to do this closer to the time. We ask that you complete this and the rights step above as quickly as possible. **This will be sent at the same time (roughly) as the rights emails**.',NULL,NULL,NULL,NULL,NULL,'[]',0),(709,'pages',31,'body',3,'parablock','label','text',NULL,'Continued details',NULL,NULL,NULL,NULL,NULL,'[]',0),(710,'pages',31,'body',3,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(711,'pages',19,'body',4,'parablock','text','markdown',NULL,'## Questions or concerns\r\nIf you have any concerns regarding accessibility, please do not hesitate to contact the [Local Arrangements Chair](/organising-committee \"Please contact the Local Arragements Chair if you have questions regarding accessibility\"). If you wish to make the organisers aware of any accessible arrangements prior to the symposium, please also contact the [Local Arrangements Chair](/organising-committee \"Please contact the Local Arragements Chair if you wish to make the organisers aware of any specific issues\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(712,'pages',19,'body',4,'parablock','label','text',NULL,'Questions or concerns',NULL,NULL,NULL,NULL,NULL,'[]',0),(713,'pages',19,'body',4,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(714,'pages',33,'body',0,'cardblock','text','markdown',NULL,'Our [provisional programme is now online](/programme \"Halfway to the Future Provisional Programme\") which includes the details of the 29 talks and 13 posters accepted to the symposium (in addition to our 6 keynotes and panels). Information on demos as well as abstracts for the accepted papers will be coming soon. Thank you to the [Programme Committee members](/programme-committee \"Members of the Halfway to the Future Programme Committee\") for their hard work, we couldn\'t have done this without your support.\r\n\r\nWe hope that you find the programme as exciting as we do. Each session has been curated so that we can have an engaging discussion around our six symposium themes, reflecting on work that has taken place and looking towards the future of where HCI and design-based research might go. We have set the timings of each session to allow for as much audience participation as possible throughout the entirety of the two days. \r\n\r\nWe hope you choose to register, which [you can do online now on our website](/registration \"Register now for Halfway to the Future\"). We have extended the early registration deadline to the 27th September and there are a number of SIGCHI-sponsored student registrations still available (£25 registration for students). \r\n\r\nFinally, this is my final email to you as a subscriber of our Expression of Interest mailing list. After this email is sent, I will be deleting all data relating to the expression of interest from our systems. Thank you for expressing interest in the symposium (and for reading and responding to these emails), it gave us the confidence that we were doing the right thing very early on in this process.\r\n\r\nOn behalf of the [organising committee](/organising-committee \"Halfway to the Future Organising Committee\"), we look forward to meeting you in November!\r\n\r\nBest wishes,<br>\r\nMartin Porcheron (Communications Chair & Treasurer)\r\n',NULL,NULL,NULL,NULL,NULL,'[]',0),(715,'pages',33,'body',0,'cardblock','label','text',NULL,'Email Text',NULL,NULL,NULL,NULL,NULL,'[]',0),(716,'pages',33,'body',0,'cardblock','title','text',NULL,'Halfway to the Future: Provisional programme and early-bird registration',NULL,NULL,NULL,NULL,NULL,'[]',0),(717,'pages',33,'body',0,'cardblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(718,'pages',10,'body',0,'searchblock','label','text',NULL,'Search authors, institutions, and papers',NULL,NULL,NULL,NULL,NULL,'[]',0),(719,'pages',10,'body',0,'searchblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(720,'pages',10,'body',1,'programmeblock','detail','select',NULL,'full',NULL,NULL,NULL,NULL,NULL,'[]',0),(724,'pages',18,'body',7,'parablock','text','markdown',NULL,'## Travel by aeroplane\r\nThe nearest airport is **East Midlands Airport**. To reach Nottingham from the airport you need to take the [Skylink Nottingham](https://trentbarton.co.uk/services/skylinknottingham \"The trentbarton Skylink bus travels to and from East Midlands Airport\") bus to _Nottingham_ and alight at the **Friar Lane bus stop**, or catch a taxi.',NULL,NULL,NULL,NULL,NULL,'[]',0),(725,'pages',18,'body',7,'parablock','label','text',NULL,'Aeroplane',NULL,NULL,NULL,NULL,NULL,'[]',0),(726,'pages',18,'body',7,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(727,'homepage',1,'body',1,'imageblock','image','image',NULL,NULL,NULL,NULL,NULL,NULL,NULL,'{\"file\":\"2019-02/alberthall.jpg\"}',0),(728,'homepage',1,'body',1,'imageblock','imagestyle','select',NULL,'default',NULL,NULL,NULL,NULL,NULL,'[]',0),(729,'homepage',1,'body',1,'imageblock','alt','text',NULL,'Albert Hall Conference Centre, Nottingham',NULL,NULL,NULL,NULL,NULL,'[]',0),(730,'homepage',1,'body',1,'imageblock','caption','markdown',NULL,'Albert Hall Conference Centre, Nottingham',NULL,NULL,NULL,NULL,NULL,'[]',0),(731,'homepage',1,'body',1,'imageblock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(732,'homepage',1,'body',2,'parablock','text','markdown',NULL,'The symposium will address a range of key themes with dedicated single-track panels, each anchored by prominent keynote speakers reflecting upon one of their influential works in light of subsequent developments and present concerns. This will be followed by presentations of current related research, short future-oriented provocations, and a panel discussion/Q&A.\r\n\r\nThe symposium will also incorporate an exhibition of interactive works and a poster session. All papers will be peer reviewed under a double-blind process and some papers will be selected for panels while others will be invited to present their work in poster format.  ',NULL,NULL,NULL,NULL,NULL,'[]',0),(733,'homepage',1,'body',2,'parablock','label','text',NULL,'Symposium will address…',NULL,NULL,NULL,NULL,NULL,'[]',0),(734,'homepage',1,'body',2,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(735,'pages',24,'body',0,'parablock','text','markdown',NULL,'Download the [symposium feedback response](https://www.halfwaytothefuture.org/files/2020-01/feedback.pdf?9c4168861f \"Response to the feedback for the Halfway to the Future Symposium 2019\").',NULL,NULL,NULL,NULL,NULL,'[]',0),(736,'pages',24,'body',0,'parablock','label','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0),(737,'pages',24,'body',0,'parablock','class','text',NULL,'',NULL,NULL,NULL,NULL,NULL,'[]',0);
/*!40000 ALTER TABLE `bolt_field_value` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_homepage`
--

DROP TABLE IF EXISTS `bolt_homepage`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_homepage` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `slug` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `datecreated` datetime NOT NULL,
  `datechanged` datetime NOT NULL,
  `datepublish` datetime DEFAULT NULL,
  `datedepublish` datetime DEFAULT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `templatefields` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `image` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `teaser` longtext COLLATE utf8_unicode_ci,
  `content` longtext COLLATE utf8_unicode_ci,
  `contentlink` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `search` longtext COLLATE utf8_unicode_ci,
  PRIMARY KEY (`id`),
  KEY `IDX_9D9C7FD3989D9B62` (`slug`),
  KEY `IDX_9D9C7FD3AFBA6FD8` (`datecreated`),
  KEY `IDX_9D9C7FD3BE74E59A` (`datechanged`),
  KEY `IDX_9D9C7FD3A5131421` (`datepublish`),
  KEY `IDX_9D9C7FD3B7805520` (`datedepublish`),
  KEY `IDX_9D9C7FD37B00651C` (`status`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_homepage`
--

LOCK TABLES `bolt_homepage` WRITE;
/*!40000 ALTER TABLE `bolt_homepage` DISABLE KEYS */;
INSERT INTO `bolt_homepage` VALUES (1,'welcome-to-the-halfway-to-the-future-2019-website','2019-02-12 15:41:42','2019-11-20 16:21:47','2019-06-27 12:00:00',NULL,1,'published','[]','Welcome!',NULL,NULL,NULL,NULL,'**Halfway to the Future** is a two-day symposium in the city of Nottingham, UK exploring the past, present, and future of HCI and design-based research.  The symposium will take place on the **19th and 20th November 2019** at the **Albert Hall Conference Centre**. Albert Hall Conference Centre, Nottingham Albert Hall Conference Centre, Nottingham The symposium will address a range of key themes with dedicated single-track panels, each anchored by prominent keynote speakers reflecting upon one of their influential works in light of subsequent developments and present concerns. This will be followed by presentations of current related research, short future-oriented provocations, and a panel discussion/Q&A.\r\n\r\nThe symposium will also incorporate an exhibition of interactive works and a poster session. All papers will be peer reviewed under a double-blind process and some papers will be selected for panels while others will be invited to present their work in poster format.   We would like to thank the University of Nottingham [Faculty of Science](https://www.nottingham.ac.uk/science/home.aspx \"The University of Nottingham Faculty of Science website\"), [Creative and Digital Interdisciplinary Research Cluster](https://www.nottingham.ac.uk/research/research-areas/creative-and-digital/index.aspx \"University of Nottingham Creative and Digital IRC website\"), and [Smart Products Beacon](https://www.nottingham.ac.uk/research/beacons-of-excellence/smart-products/index.aspx \"The University of Nottingham Smart Products Beacon website\"); [ACM SIGCHI](https://sigchi.org/ \"The ACM Special Interest Group in Human-Computer Interaction website\"), and [Microsoft](https://www.microsoft.com/en-us/research/ \"The Microsoft Research website\") for generously sponsoring the symposium.');
/*!40000 ALTER TABLE `bolt_homepage` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_log_change`
--

DROP TABLE IF EXISTS `bolt_log_change`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_log_change` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `date` datetime NOT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `title` varchar(256) COLLATE utf8_unicode_ci NOT NULL,
  `contenttype` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `contentid` int(11) NOT NULL,
  `mutation_type` varchar(16) COLLATE utf8_unicode_ci NOT NULL,
  `diff` longtext COLLATE utf8_unicode_ci NOT NULL COMMENT '(DC2Type:json)',
  `comment` varchar(150) COLLATE utf8_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_946F972AA9E377A` (`date`),
  KEY `IDX_946F97275DAD987` (`ownerid`),
  KEY `IDX_946F972745E1826` (`contenttype`),
  KEY `IDX_946F972E625AE99` (`contentid`),
  KEY `IDX_946F972B0AEEF39` (`mutation_type`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_log_change`
--

LOCK TABLES `bolt_log_change` WRITE;
/*!40000 ALTER TABLE `bolt_log_change` DISABLE KEYS */;
/*!40000 ALTER TABLE `bolt_log_change` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_log_system`
--

DROP TABLE IF EXISTS `bolt_log_system`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_log_system` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `level` int(11) NOT NULL,
  `date` datetime NOT NULL,
  `message` varchar(1024) COLLATE utf8_unicode_ci NOT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `requesturi` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `route` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `ip` varchar(45) COLLATE utf8_unicode_ci NOT NULL,
  `context` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `source` longtext COLLATE utf8_unicode_ci NOT NULL COMMENT '(DC2Type:json)',
  PRIMARY KEY (`id`),
  KEY `IDX_805C16D99AEACC13` (`level`),
  KEY `IDX_805C16D9AA9E377A` (`date`),
  KEY `IDX_805C16D975DAD987` (`ownerid`),
  KEY `IDX_805C16D9E25D857E` (`context`)
) ENGINE=InnoDB AUTO_INCREMENT=4899 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_log_system`
--

LOCK TABLES `bolt_log_system` WRITE;
/*!40000 ALTER TABLE `bolt_log_system` DISABLE KEYS */;
/*!40000 ALTER TABLE `bolt_log_system` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_pages`
--

DROP TABLE IF EXISTS `bolt_pages`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_pages` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `slug` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `datecreated` datetime NOT NULL,
  `datechanged` datetime NOT NULL,
  `datepublish` datetime DEFAULT NULL,
  `datedepublish` datetime DEFAULT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `templatefields` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `image` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `teaser` longtext COLLATE utf8_unicode_ci,
  `search` longtext COLLATE utf8_unicode_ci,
  `template` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `redirect` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `parent_page` longtext COLLATE utf8_unicode_ci,
  PRIMARY KEY (`id`),
  KEY `IDX_31AF1BC8989D9B62` (`slug`),
  KEY `IDX_31AF1BC8AFBA6FD8` (`datecreated`),
  KEY `IDX_31AF1BC8BE74E59A` (`datechanged`),
  KEY `IDX_31AF1BC8A5131421` (`datepublish`),
  KEY `IDX_31AF1BC8B7805520` (`datedepublish`),
  KEY `IDX_31AF1BC87B00651C` (`status`)
) ENGINE=InnoDB AUTO_INCREMENT=36 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_pages`
--

LOCK TABLES `bolt_pages` WRITE;
/*!40000 ALTER TABLE `bolt_pages` DISABLE KEYS */;
INSERT INTO `bolt_pages` VALUES (1,'cfp','2019-02-12 15:04:38','2019-09-09 22:05:22','2019-02-12 15:04:00',NULL,1,'published','[]','Call for Papers',NULL,'The **Halfway to the Future symposium** explores the past, present, and future of themes driving key research in HCI and design. Each theme will be addressed by a dedicated panel anchored by a confirmed keynote speaker discussing one of their influential papers in light of subsequent developments:\r\n','The keynotes will be followed by presentations, drawn from submitted papers, of current related work and short future-oriented provocations and a panel discussion/Q&A seeking to shape the agenda of that research area in the years to come. The event will also incorporate an exhibition of interactive works and a poster session. ## Submission Information \r\nWe invite **papers of up to 6,000 words** (not including references) addressing current work relating to the themes above, especially those building on or responding to the influential works to be discussed.\r\n\r\nWe also invite **short papers of up to 2,000 words** (not including references) looking towards the future of these themes. Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. Accepted papers not chosen for panels will be invited to be presented in poster format. We will publish an edited volume of panel papers and online adjunct proceedings of papers selected for poster presentation.\r\n\r\nFor information on preparing a submission, including the templates to use, please read the [submission guidance](/submission-guidance \"Submission guidance for HttF\") webpage. All submissions will be reviewed by at least two experts in the field and the process will be double-blind. All accepted papers will be published in the Halfway to the Future Proceedings in the **ACM Digital Library**, as part of the ACM International Conference Proceedings Series (ICPS). Please read the [submission guidance on how to format and submit your papers](/submission-guidance \"Submission guidance for HttF\"). Preparing your submission… ## Important Dates\r\n**Submission deadline (extended)**: Wednesday 26th June, 23:59 BST (GMT+1)\r\n**Notification**: Friday 26th July\r\n**Deadline for confirmation of attendance (for panellists)**: Friday 23rd August\r\n**Early bird registration closes**: Friday 27th September\r\n**Registration closes**: Monday 18th November Halfway to the Future is co-organised by the [Mixed Reality Lab](http://www.mrl.nott.ac.uk/ \"The Mixed Reality Laboratory at the University of Nottingham\") at the University of Nottingham as part of celebrations of its 20-year anniversary. Keynote speakers and respective panel themes have been chosen for their formative and ongoing influence on the lab’s work across two decades. \r\nIf you have any questions, please contact the [Programme Chairs](mailto:programme@halfwaytothefuture.org \"Email the HttF Programme Chairs\"), Joel Fischer and Jocelyn Spence.',NULL,NULL,NULL),(2,'organising-committee','2019-02-12 16:33:23','2019-11-14 03:38:36','2019-02-12 16:30:05',NULL,1,'published','[]','Organising Committee',NULL,'The **Halfway to the Future symposium** has been put together by the following members of the [Mixed Reality Lab](http://www.mrl.nott.ac.uk/ \"The Mixed Reality Laboratory at the University of Nottingham\") at the University of Nottingham. If you are contacting a member of the committee regarding the symposium, please use the symposium email addresses included below as this helps to filter email in relation to the event in our inboxes!','[Joel E. Fischer](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/joel.fischer \"Joel\'s profile on the University of Nottingham website\"), \r\n[Sarah Martindale](https://www.nottingham.ac.uk/clas/departments/culturalmediaandvisualstudies/people/sarah.martindale \"Sarah\'s profile on the University of Nottingham website\"), \r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\"),\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\"), and \r\n[Jocelyn Spence](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/jocelyn.spence \"Jocelyn\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [general-chairs@halfwaytothefuture.org](mailto:general-chairs@halfwaytothefuture.org \"Email all five General Chairs\")*\r\n\r\n**Administration Manager**\r\n[Lindsay Norman](https://www.nottingham.ac.uk/computerscience/people/lindsay.norman \"Lindsay\'s profile on the University of Nottingham website\")\r\n General Chairs **Programme Chairs**\r\n[Joel E. Fischer](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/joel.fischer \"Joel\'s profile on the University of Nottingham website\")\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")\r\n[Jocelyn Spence](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/jocelyn.spence \"Jocelyn\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email both Programme Chairs\")*\r\n\r\n**Communications & Marketing Chair**\r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [comms@halfwaytothefuture.org](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\")*\r\n\r\n**Sponsorship Chair**\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email the Sponsorship Chair\")*\r\n\r\n**Local Arrangements Chair**\r\n[Sarah Martindale](https://www.nottingham.ac.uk/clas/departments/culturalmediaandvisualstudies/people/sarah.martindale \"Sarah\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [local@halfwaytothefuture.org](mailto:local@halfwaytothefuture.org \"Email the Local Arragenments Chair\")*\r\n\r\n**Equality, Diversity, and Inclusion Chair**\r\n[Pepita Barnard Stringer](https://www.horizon.ac.uk/researchers/ \"Pepita is a member of the Horizon Digital Economy Research Institute at the University of Nottingham\")\r\n\r\n*Email: [edi@halfwaytothefuture.org](mailto:edi@halfwaytothefuture.org \"Email the Equality, Diversity, and Inclusion Chair\")*\r\n\r\n **Keynote Chair**\r\n[Stuart Reeves](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/stuart.reeves \"Stuart\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [keynote@halfwaytothefuture.org](mailto:keynote@halfwaytothefuture.org \"Email the Keynote CHair\")*\r\n\r\n**Demos Chair**\r\n[Edgar Bodiaj](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/edgar.bodiaj \"Edgar\'s profile on the University of Nottingham website\")\r\n[Paul Tennent](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/paul.tennent \"Paul\'s profile on the University of Nottingham website\")\r\nJoe Marshall (Paternity Leave)\r\n\r\n*Email: [demos@halfwaytothefuture.org](mailto:technical@halfwaytothefuture.org \"Email the Demos Chair\")*\r\n\r\n**Technical Chair**\r\n[Adrian Hazzard](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/adrian.hazzard \"Adrian\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [technical@halfwaytothefuture.org](mailto:technical@halfwaytothefuture.org \"Email the Techincal Chair\")*\r\n\r\n**Treasurer & Registration Chair**\r\n[Martin Porcheron](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/people/martin.porcheron \"Martin\'s profile on the University of Nottingham website\")\r\n\r\n*Email: [treasurer@halfwaytothefuture.org](mailto:treasurer@halfwaytothefuture.org \"Email the Treasurer and Registration Chair\")*\r\n\r\n**Communications & Marketing Assistant**\r\n[Velvet Spors](https://highlights.cdt.horizon.ac.uk/students/psxavsp \"Velvet is a student in the Horizon Centre for Doctoral Training at the University of Nottingham\")\r\n\r\n**Administrative Assistants**\r\n[Lindsay Norman](https://www.nottingham.ac.uk/computerscience/people/lindsay.norman \"Lindsay\'s profile on the University of Nottingham website\")\r\n[Felicia Black](https://www.nottingham.ac.uk/computerscience/people/felicia.black \"Felicia\'s profile on the University of Nottingham website\")',NULL,NULL,NULL),(3,'programme-committee','2019-02-12 16:50:31','2019-09-09 22:05:37','2019-02-12 16:50:18',NULL,1,'published','[]','Programme Committee',NULL,'The following people are members of the **Halfway to the Future** programme committee.','Oliver Bates (Lancaster University)\r\nBen Bedwell (University of Nottingham)\r\nBarry Brown (Stockholm University)\r\nKo-Le Chen (Newcastle University)\r\nLuigina Ciolfi (Sheffield Hallam University)\r\nEnrico Costanza (University College London)\r\nDimitrios Darzentas (University of Nottingham)\r\nAbigail Durrant (Northumbria University)\r\nEva Eriksson (Chalmers University of Technology)\r\nMike Fraser (University of Bristol)\r\nGabriella  Giannachi (University of Exeter)\r\nLone Koefoed Hansen (Aarhus University)\r\nBen Kirman (University of York)\r\nHyosun Kwon (Loughborough University)\r\nAiri Lampinen (Stockholm University)\r\nShaun Lawson (Northumbria University)\r\nConor Linehan (University College Cork)\r\nAnders Løvlie (IT University of Copenhagen)\r\nPaul Marshall (University of Bristol)\r\nJuan Pablo Martínez Ávila (University of Nottingham)\r\nDonald McMillan (Stockholm University)\r\nBettina Nissen (University of Edinburgh) Leif Oppermann (Fraunhofer FIT)\r\nMark Perry (Brunel University)\r\nMartin Porcheron (University of Nottingham)\r\nChiara Rossitto (Stockholm University)\r\nAsreen Rostami (Stockholm University)\r\nAnne Roudaut (University of Bristol)\r\nMaria Roussou (National and Kapodistrian University of Athens)\r\nAnna Ståhl (RISESICS)\r\nDanaë Stanton Fraser (University of Bath)\r\nRobyn Taylor (Newcastle University)\r\nPaul Tennent (University of Nottingham)\r\nPeter Tolmie (University of Siegen)\r\nZ Toups (New Mexico State University)\r\nVasiliki Tsaknaki (KTH Royal Institute of Technology)\r\nLachlan Urquhart (The University of Edinburgh)\r\nNervo Verdezoto (Cardiff University)\r\nJohn Vines (Newcastle University)\r\nAnnika Waern (Uppsala University)\r\nHelena Webb (University of Oxford)\r\nJulie Williamson (University of Glasgow)\r\nDan Xu (Amsterdam University of Applied Sciences)',NULL,NULL,NULL),(4,'keynotes','2019-02-12 17:49:32','2019-09-09 22:06:03','2019-02-12 17:48:38',NULL,1,'published','[]','Keynote speakers',NULL,'The symposium will consist of six sessions and each session will be anchored around a theme, with a keynote led by a distinguished speaker. Each speaker will reflect upon an influential piece of work in light of subsequent developments and present concerns.\r\n\r\n','## Ubiquitous Computing\r\n**A keynote by Yvonne Roggers (UCL)**\r\n[Moving on from Weiser’s Vision of Calm Computing: Engaging UbiComp Experiences](/programme/rogers-moving-on-from-weiser-s-vision-of-calm-computing-engaging-ubicomp-experiences \"Read about this paper and download a PDF of it\") Yvonne Rogers  **Yvonne Rogers** is the director of the Interaction Centre at UCL (UCLIC), and a deputy head of the Computer Science department. She is interested in how technology transforms what it means to be human. Much of her work is situated in the wild - concerned with informing, building and evaluating novel user experiences through creating and assembling a diversity of technologies (e.g. tangibles, AR, IoT) that augment everyday, learning, community engagement and collaborative work activities. She has been instrumental in promulgating new theories (e.g., external cognition), alternative methodologies (e.g., in the wild studies) and far-reaching research agendas (e.g., “Being Human: HCI in 2020” manifesto), and has pioneered an approach to innovation and ubiquitous learning. She has also published over 300 articles, including two monographs “HCI Theory: Classical, Modern and Contemporary” and \"Research in the Wild\". She is a fellow of the ACM, BCS and the ACM CHI Academy. ## Mixed Reality\r\n**A keynote by Steve Benford (University of Nottingham)**\r\n[Orchestrating a Mixed Reality Performance](/programme/koleva-orchestrating-a-mixed-reality-performance \"Read about this paper and download a PDF of it\") Steve Benford  **Steve Benford** is a Professor in the Mixed Reality Lab at the University of Nottingham where he leads the \'Smart Products\' beacon and directs the Horizon ‘Creating Our Lives in Data\' Centre for Doctoral Training. He previously held an EPSRC Dream Fellowship, has been a Visiting Professor at the BBC and was elected to the CHI Academy in 2012. \r\n\r\n ## Artificial Intelligence, Humans & Machines\r\n**A conversation between Lucy Suchman (Lancaster University) and Alex Taylor (City, University of London), in which Lucy will be attending remotely**\r\n[Human-Machine Reconfigurations: Plans and Situated Actions](/programme/suchman-human-machine-reconfigurations-plans-and-situated-actions \"Read about this book\") Lucy Suchman  **Lucy Suchman** holds a Chair in the Anthropology of Science and Technology at Lancaster University in the UK. Before taking up her present post she was a Principal Scientist at Xerox’s Palo Alto Research Center (PARC), where she spent twenty years as a researcher. Suchman’s current research extends her longstanding engagement with the field of human-computer interaction to the domain of contemporary war fighting. She is focused more specifically on the knowledge that informs immersive military training simulations, and on problems of ‘situational awareness’ in remotely-controlled and automated weapon systems. She is the author of Human-Machine Reconfigurations (2007) and Plans and Situated Actions: the problem of human-machine communication (1987), both published by Cambridge University Press. In 2010 she received the ACM SIGCHI Lifetime Research Award, and in 2014 the Society for Social Studies of Science (4S) Bernal Prize for Contributions to the Field. \r\n Alex Taylor  **Alex Taylor** is a sociologist working in the Centre for Human Centred Design, at City, University of London. Showing a broad fasciation for the entanglements between social life and machines, his research ranges from empirical studies of technology in everyday life to speculative design interventions—both large and small. Across these realms, he draws on a feminist technoscience to ask questions about the co-constitutive roles human-machine composites play in forms of knowing and being, and how they might open up possibilities for fundamental transformations in society. Most recently, he’s begun to wonder about the abilities of humans and non-humans, together, and to speculate on hybrid compositions that enlarge capacity and offer the chance of something different-than, something more-than.\r\n\r\n ## Arts & Design-led Approaches\r\n**A keynote by Bill Gaver (Goldsmiths, University of London)**\r\n[Ambiguity as a Resource for Design](/programme/gaver-ambiguity-as-a-resource-for-design \"Read about this paper and download a PDF of it\") Bill Gaver  **Bill Gaver** is Professor of Design and co-director of the Interaction Research Studio at Goldsmiths, University of London. His research on design-led methodologies and innovative technologies for everyday life led him to develop an internationally recognised studio bringing the skills of designers together with expertise in ubiquitous computing and sociology.\r\n\r\n\r\n\r\n ## Public & Private Spaces\r\n**A keynote by Christian Heath and Paul Luff (King\'s College London)**\r\n[Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms](/programme/heath-collaboration-and-control-crisis-management-and-multimedia-technology-in-london-underground-line-control-rooms \"Read about this paper and download a PDF of it\") Christian Heath  **Christian Heath** is Professor of Work and Organisation at King’s College London. He specialises in fine grained, video-based studies of social interaction drawing on ethnomethodology and conversation analysis. He is currently undertaking research in areas that include health care, markets and economic behaviour, and museums and galleries. He is a Fellow of the Academy of the Social Sciences (FAcSS), a Freeman of the Worship Company of Art Scholars and was recently received the EUSSET-IISI Lifetime Achievement Award for his contribution to the fields of Computing and Informatics. His publications include: *The Dynamics of Auction: Social Interaction and the Sale of Fine Art and Antiques* (Cambridge: ISCA Best Book Award), *Video and Qualitative Research: Analysing Social Interaction in Everyday* (Sage with Jon Hindmarsh and Paul Luff) and *Technology in Action* (Cambridge, with Paul Luff).\r\n\r\n Paul Luff  **Paul Luff** is Professor of Organisations and Technology at King’s College. He has undertaken detailed video-based studies of diverse settings including control rooms, trading rooms, surveillance centres, surgery, general practice consultations, design and architectural practices. In most of these projects he has worked with computer scientists and engineers developing human-robot interaction, ubiquitous technologies and advanced collaboration systems. Contributions of these studies have been to inform the identification of user requirements, aspects of the design of the technology and ways these might be evaluated and assessed. He is the co-author with Christian Heath of ‘Technology in Action’ (Cambridge University Press) and with Christian Heath and Jon Hindmarsh) of ‘Video in Qualitative Research’ (Sage). ## New Approaches to Research & Design\r\n**A keynote by Susanne Bødker (Aarhus University)**\r\n[When second wave HCI meets third wave challenges](/programme/bodker-when-second-wave-hci-meets-third-wave-challenges \"Read about this paper and download a PDF of it\") Susanne Bødker  **Susanne Bødker** is Professor at the Department of Computer Science at Aarhus University in Denmark. She co-manages the interdisciplinary Center for Participatory IT, and heads the recently started ERC project on Common Interactive Objects. She does participatory design, computer supported collaborative work and activity theory. Email: bodker@cs.au.dk We thank each of the keynote speakers for agreeing to present and reflect upon their work during the symposium.',NULL,NULL,NULL),(5,'venue','2019-02-12 18:13:39','2019-09-12 20:42:14','2019-02-12 18:13:15',NULL,1,'published','[]','Venue',NULL,'**Halfway to the Future** will be held in the [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk/ \"The Albert Hall Conference Centre Nottingham website\"), Nottingham, UK. The venue is conveniently located in the city centre of Nottingham near to multiple hotels.','Albert Hall Conference Centre, Nottingham Albert Hall Conference Centre, Nottingham. The Albert Hall main entrance is located on **North Circus Street**, opposite St. Barnabas Cathedral and adjacent to the Nottingham Playhouse in the city centre of Nottingham. The main entrance **has stairs**.\r\n\r\n* Satellite navigation postcodes: NG1 5AA or NG1 5AE\r\n* Main (non-accessible) entrance on [Google Maps](https://goo.gl/maps/EJo8tKkwr5S2  \"The Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?address=North%20Circus%20Street\\,%20Nottingham\\,%20NG1%205AA\\,%20England&auid=12125193638640445003&ll=52.954342\\,-1.156263&lsp=9902&q=Albert%20Hall%20Conference%20Centre&_ext=ChoKBQgEEOEBCgQIBRADCgUIBhDfAQoECAoQABImKQQv6rSReUpAMZApjnHmoPK/OYIEEBG4ekpAQZYP7CfTY/K/UAQ%3D \"The Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\nThe **accessible entrance**, used also for deliveries, is on the opposite side of the building, on Maid Marian Way. We ask you to not use this entrance unless you need it as it is smaller.\r\n \r\n* Accessible entrance on [Google Maps](https://goo.gl/maps/mvsggnjntbhV7VBh8 \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?q=52.954293,-1.155787&sll=52.954293,-1.155787&sspn=0.001193,0.002492&t=h \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\n\r\n For more information, please see the following pages:\r\n\r\n* [Travel to the venue](/travel \"Information on travelling to the venue via car, train, bus, tram, or aeroplane\")\r\n* [Venue accessibility](/accessibility \"Information on venue accessibility\")',NULL,NULL,NULL),(6,'agenda','2019-02-12 18:13:43','2019-09-11 08:57:51','2019-02-12 18:13:15',NULL,1,'published','[]','Agenda',NULL,'This is a provisional agenda for the **Halfway to the Future symposium**. We are currently finalising details of our programme, although we have provisional timings for each session below. \r\n\r\nOn **Monday 18th**, we will host a free [Welcome Reception](/session/welcome-reception \"Halfway to the Future Weclome Reception\") at the Nottingham Contemporary gallery. Everyone is welcome!\r\n\r\n','**Tuesday 19th**\r\n* **08:30 — 09:30** Registration\r\n* **09:30 — 10:00** Welcome and opening address\r\n* **10:00 — 12:00** Mixed Reality\r\n* **12:00 — 13:00** Lunch (provided)\r\n* **13:00 — 15:00** Public & Private Spaces\r\n* **15:00 — 15:30** Break\r\n* **15:30 — 17:30** Artificial Intelligence, Humans & Machines\r\n* **17:30 — 19:00** Posters session\r\n* **19:30** (Additional Fee) [Symposium dinner](/session/symposium-dinner \"Read about the symposium dinner\") **Wednesday 20th**\r\n* **09:00 — 11:00** Ubiquitous Computing\r\n* **11:00 — 11:30** Break\r\n* **11:30 — 12:15** Arts & Design-led Approaches (keynote only)\r\n* **12:15 — 13:15** Lunch (provided)\r\n* **13:15 — 14:30** Arts & Design-led Approaches (cont\'d)\r\n* **14:30 — 15:00** Break\r\n* **15:00 — 17:00** New Approaches to Research & Design\r\n* **17:00** Symposium closes This agenda will be replaced by an interactive programme closer to the time of the symposium','redirect.twig','/programme',NULL),(7,'registration','2019-02-13 10:12:33','2019-10-25 16:37:54','2019-02-13 10:11:33',NULL,1,'published','[]','Registration',NULL,'You may [now complete online registration for the symposium here](https://store.nottingham.ac.uk/conferences-and-events/conferences/schools-and-departments/computer-science/halfway-to-the-future-symposium \"Register for the symposium here\"). The schedule of prices is: \r\n* Full registration: £320\r\n* Student registration: £160\r\n* Student registration with [SIGCHI student subsidy](/sigchi-student-subsidy \"Learn about the SIGCHI student subsidy\"): £60\r\n\r\n<!--We also invite attendees to a **[symposium dinner](/session/symposium-dinner \"Halfway to the Future symposium dinner\")** on the first night of the symposium. This will cost £36 and can be paid for during registration or separately afterwards. -->\r\n\r\nOnline registration closes the day before the symposium commences.\r\n\r\n','All registrations are subject to our [Terms & Conditions](/registration-terms-conditions \"HttF Registration Terms & Conditions\"), and all those who register and/or attend for the symposium are bound by the [Code of Conduct](/conduct \"HttF Code of Coduct\"). If you have been/will be registered by another person (e.g. an administrator), please familiarise yourself with these before the symposium. Registration information We will host a [Welcome Reception](/session/welcome-reception \"Halfway to the Future Weclome Reception\") at the Nottingham Contemporary gallery on Monday 18th November, with free drinks and nibbles, the *night before the symposium officially opens*. This will be an open and free event for all attendees, so you may wish to travel to Nottingham the *day before the symposium commences*.',NULL,NULL,NULL),(8,'privacy-policy','2019-02-13 10:38:00','2019-09-09 22:07:04','2019-02-13 10:34:32',NULL,1,'published','[]','Privacy Policy',NULL,'We are committed to protecting your privacy and respecting the confidentiality of information which you provide when you visit this website. At the same time, we want to try to ensure that you obtain full value from our website and from the services which you may want to receive via our website.','This website only directly logs minimal information (such as page requests, system errors, IP addresses etc.). This log data is automatically stored on servers in the EU and is never shared or published.\r\n\r\nThis website **does not set any cookies for visitors**.\r\n\r\nThis website **does not use any externally hosted or managed services**.\r\n\r\nThere is **no advertising on this website or monetisation of traffic**. ## University of Nottingham Privacy Policy\r\nIn addition to the above information, your use of this website is also covered by the [University of Nottingham Privacy Poilcy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham\'s Privacy Poilcy\"). This policy includes information such as the University\'s Data Protection Officer, whom you should contact if you have any questions, concerns, or wish to request access to any data we store about you. Please note that we are entitled to, and do, charge a fee for providing this information. ## Further Information and Contact\r\nIf you would like any further information about this website, please email the [Communications Chair](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\"). If you wish to make a Subject Access Request for your data, you should contact the University\'s Data Protection Officer, details for which are in the [University of Nottingham Privacy Poilcy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham\'s Privacy Poilcy\"). *Last Updated: 13th February 2019*',NULL,NULL,NULL),(9,'themes','2019-02-13 16:16:16','2019-09-09 22:06:03','2019-02-13 16:14:47',NULL,1,'published','[]','Symposium themes',NULL,'The symposium will be organised around six key themes. Each theme will have a keynote led by an invited speaker reflecting upon an influential piece of work that has impacted the design and research communities. \r\n\r\nUpon submission of a paper, you will be asked to recommend which theme your work most aligns with.\r\n\r\nBelow are the six themes, and the papers that we as a committee identified as having a profound impact on our community.','Please read the [submission guidance](/submission-guidance \"Guidance on preparing a paper to submit to HttF\") before submitting your papers. This guidance also includes the templates you should use to prepare your submission. Submission guidance',NULL,NULL,NULL),(10,'programme','2019-02-23 20:42:33','2019-11-16 15:03:22','2019-09-11 09:20:48',NULL,1,'published','[]','Programme',NULL,NULL,'',NULL,NULL,NULL),(11,'404-not-found','2019-02-23 22:02:13','2019-09-09 22:07:05','2019-02-23 22:01:36',NULL,1,'published','[]','404 Not Found',NULL,'Unfortunately the page you were looking for could not be found. Perhaps use the search function (in the navigation bar) to find the page you were looking for?','404 Not Found Tumbeasts by [Matthew Inman](https://theoatmeal.com/comics/state_web_summer \"The source for the Tumbeasts graphic\")',NULL,NULL,NULL),(12,'submission','2019-02-24 23:07:18','2019-09-09 22:05:29','2019-02-24 23:07:05',NULL,1,'published','[]','EasyChair login',NULL,'The EasyChair submission and reviewing system for the Halfway to the Future symposium submissions.','','redirect.twig','https://easychair.org/conferences/?conf=httf2019',NULL),(13,'eoi','2019-02-24 23:14:18','2019-09-09 22:06:38','2019-02-24 23:13:30',NULL,1,'published','[]','Expression of Interest',NULL,'Please register your interest in submitting to and/or attending this symposium in order to receive updates.','','redirect.twig','http://bit.ly/httf2019eoi',NULL),(14,'email-2019-02-15','2019-03-09 14:06:09','2019-09-09 22:06:53','2019-03-09 14:04:01',NULL,1,'published','[]','EoI Email: 15th February 2019',NULL,'The following email was sent on the 15th February 2019 to those who expressed interest in the Halfway to the Future symposium.','Thank you for expressing your interest in the Halfway to the Future symposium, due to take place on the 19th and 20th November 2019 in Nottingham, UK. I\'m delighted to say the committee have been working hard behind the scenes, and we are now ready to send out further details.\r\n\r\nAdditionally, we have launched our website, [www.halfwaytothefuture.org](https://www.halfwaytothefuture.org \"The Halfway to the Future website\"), and our Twitter account, [@httfsymposium](https://twitter.com/httfsymposium \"The Halfway to the Future Twiter account\"). I will, of course, also keep you in the loop with periodic updates on the symposium. We are also now able to confirm the venue — the fabulous [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk \"The Albert Hall Conference Centre Nottingham website\") in the centre of Nottingham. \r\nFinally, the Programme Chairs have put together the [Call for Papers](https://www.halfwaytothefuture.org/cfp \"The Halfway to the Future Call for Papers\"), which I have pasted below. We look forward to your submissions to the symposium!\r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair)\r\n  on behalf of the organising committee (Joel Fischer, Sarah Martindale, Martin Porcheron, Stuart Reeves, Jocelyn Spence)\r\n\r\n—\r\n\r\nHalfway to the Future symposium\r\n19-20 November 2019, Nottingham, UK\r\n[www.halfwaytothefuture.org](https://www.halfwaytothefuture.org  \"The Halfway to the Future website\")\r\nTwitter: [@httfsymposium](http://twitter.com/httfsymposium \"The Halfway to the Future Twiter account\")\r\n\r\nThe Halfway to the Future symposium explores the past, present, and future of themes driving key research in HCI and design. Each theme will be addressed by a dedicated panel anchored by a confirmed keynote speaker discussing one of their influential papers in light of subsequent developments:\r\n * **Ubiquitous Computing** – YVONNE ROGERS (UCL) – \"Moving on from Weiser\'s vision of calm computing\" \r\n * **Mixed Reality** – STEVE BENFORD (University of Nottingham) – \"Orchestrating a mixed reality performance\" \r\n * **Artificial Intelligence, Humans & Machines** – LUCY SUCHMAN (Lancaster University) and ALEX TAYLOR (City, University of London) – \"Human-Machine Reconfigurations: Plans and Situated Actions\" \r\n * **Arts & Design-Led Approaches** – BILL GAVER (Goldsmiths, University of London) – \"Ambiguity as a resource for design\" \r\n * **Public & Private Spaces** – CHRISTIAN HEATH (Kings College London) – \"Collaboration and control: Crisis management and multimedia technology in London Underground Line Control Rooms\" \r\n * **New Approaches to Research & Design** – SUSANNE BØDKER (Aarhus University) – \"When second wave HCI meets third wave challenges\" \r\n\r\nThe keynotes will be followed by presentations, drawn from submitted papers, of current related work and short future-oriented provocations, followed by a panel discussion/Q&A seeking to shape the agenda of that research area in the years to come. The event will also incorporate an exhibition of interactive works and a poster session. \r\n\r\nWe invite papers of up to 6,000 words (not including references, format TBC) addressing current work relating to the themes above, especially those building on or responding to the influential works to be discussed. We also invite short papers of up to 2,000 words (not including references) looking towards the future of these themes. Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. Accepted papers not chosen for panels will be invited to be presented in poster format. We will publish an edited volume of panel papers and an online adjunct proceedings of papers selected for poster presentation.\r\n\r\nPlease register your interest in submitting to and/or attending this symposium in order to receive updates ([bit.ly/httf2019eoi](https://bit.ly/httf2019eoi \"Join our Expression of Interest mailing list to receive updates on the symposium\")). Further information about the symposium and a link to the submission form can be found at [www.halfwaytothefuture.org](https://www.halfwaytothefuture.org \"The Halfway to the Future website\").\r\nHalfway to the Future is co-organised by the Mixed Reality Lab, University of Nottingham, as part of celebrations of its 20-year anniversary. Keynote speakers and respective panel themes have been chosen for their formative and ongoing influence on the lab’s work across two decades.\r\n\r\n**Important Dates**\r\nSubmission deadline: Friday 21st June\r\nNotification: Friday 26th July\r\nDeadline for confirmation of attendance (for panellists): Friday 23rd August\r\nEarly bird registration closes: Friday 13th September\r\nRegistration closes: Friday 11th October\r\nEvent dates: Tuesday 19th – Wednesday 20th November 2019\r\n\r\nJoel Fischer and Jocelyn Spence, Programme Chairs\r\nProgramme Committee, TBC Halfway to the Future',NULL,NULL,'emails'),(15,'emails','2019-03-09 14:16:03','2019-09-11 09:18:08','2019-03-09 14:14:38',NULL,1,'published','[]','Emails',NULL,'We infrequently sent out emails with updates during our organisation of the symposium, up until the 11th September. ','* [15th February 2019](/email-2019-02-15 \"An email sent to subscribers on the 15th February 2019\")\r\n* [1st April 2019](/email-2019-04-01 \"An email sent to subscribers on the 1st April 2019\")\r\n* [7th June 2019](/email-2019-06-07 \"An email sent to subscribers on the 7th June 2019\")\r\n* [18th June 2019](/email-2019-06-18 \"An email sent to subscribers on the 18th June 2019\")\r\n* [8th July 2019](/email-2019-07-08 \"An email sent to subscribers on the 8th July 2019\")\r\n* [11th September 2019](/email-2019-09-11 \"An email sent to subscribers on the 11th September 2019\") All details of subscribers has since been deleted.',NULL,NULL,NULL),(16,'email-2019-04-01','2019-03-19 20:08:31','2019-09-09 22:06:53','2019-03-19 20:08:15',NULL,1,'published','[]','EoI Email: 1st April 2019',NULL,'The following email was sent on the 1st April 2019 to those who expressed interest in the Halfway to the Future symposium.','The **Halfway to the Future** committee have been working hard on the organisation of the symposium over the last couple of months and we now have a few updates to share with you.\r\n\r\nWe are delighted to confirm that all accepted papers will be published as part the ACM International Conference Proceedings and will be included in the **ACM Digital Library**! As part of this, all submitted papers will be peer reviewed through a double-blind process. This means we are now able to distribute the [templates you should use to draft your papers](/submission-guidance \"Guidance and templates for submitting papers to HttF\").\r\n\r\nAll accepted authors who are not invited to present their work within one of the symposium panels will be invited to produce a poster to be displayed during the symposium as well as being included in the ACM conference proceedings. Selected authors from accepted submissions will offered the opportunity to take part in one of our six symposium panels (this process will be juried to curate provocative and engaging debate). We have clarified this information on our [submission guidance webpage](/submission-guidance \"Guidance and templates for submitting papers to HttF\").\r\n\r\nSubmissions are due on the **21st June**!\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the Programme Chairs with any questions you have\").\r\n\r\nFinally, just a quick note to say we are currently working on finalising the details of conference registration and will be making these details public in the coming weeks. \r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair)\r\n EoI Update #2: Accepted papers will appear in the ACM Digital Library!',NULL,NULL,'emails'),(17,'submission-guidance','2019-03-19 20:17:53','2019-09-09 22:05:27','2019-03-19 20:08:15',NULL,1,'published','[]','Submission guidance',NULL,'All accepted papers will be published in the Halfway to the Future Proceedings in the **ACM Digital Library**, as part of the ACM International Conference Proceedings Series (ICPS). Authors are required to submit their papers using the ACM Proceedings templates and must conform to the template for inclusion in the proceedings. ','* [Word submission template](https://www.acm.org/binaries/content/assets/publications/taps/acm_submission_template.docx \"The Microsoft Word submission template for HttF papers\")\r\n* [LaTeX master template](https://www.acm.org/binaries/content/assets/publications/consolidated-tex-template/acmart-master.zip \"The ACM master template, including the sigconf option for HttF papers\") using the *sigconf* option (or create an ACM Conference Proceedings project using [Overleaf](https://www.overleaf.com/gallery/tagged/acm-official#.WOuOk2e1taQ))\r\n\r\nMore information and resources are available on the [ACM website](https://www.acm.org/publications/taps/word-template-workflow \"The ACM workflow for submitting papers written in Microsoft Word\"). Submission template downloads ## Guidance on preparing your submission\r\n\r\nPlease read the following points carefully.\r\n\r\n* Your submission must be aligned with one of the [symposium themes](/themes \"HttF symposium themes\").\r\n\r\nMost importantly, \r\n\r\n* **all submissions must be anonymised**, with author details redacted in the paper **and** in the file metadata. Do **not** anonymise any references to your previous work, but **do** refer to your own publications in the third person. If your paper is not correctly anonymised, it may be desk rejected. Please direct any questions about anonymisation to [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the HttF Programme Chairs with questions about anonymisation\")\r\n\r\nThere\'s a word limit:\r\n\r\n* papers must either be *no more than 6,000 words* addressing current work relating to the [symposium theme](/themes \"HttF symposium themes\") you have chosen (and preferably referring in some way to the paper listed for that [theme](/themes \"HttF symspoium themes\"), or *no more than 2,000 words* looking towards the future of one of the [panel themes](/themes \"HttF symspoium themes\"). We encourage thought-provoking and/or unorthodox content, especially for the future-oriented work.\r\n* References, title, authors, abstract, and other frontmatter (e.g., keywords, CCS concepts, copyright notice etc.) **do not** count towards the word limit for either type of paper submission. \r\n* Tip for wordcount if you\'re working in Overleaf / LaTeX editors, etc. it may be easiest to copy-paste the PDF output into Word (the LaTeX word count may not cope well with comments, etc. in your bibtex source).  \r\n* FAQ: How \"hard\" is the word limit? **We won\'t raise an eyebrow as long as you\'re within 10% of the limit for your submission type**. Any more though, and we\'re going to have to desk reject the submission. Please count carefully! \r\n\r\nFurthermore,\r\n\r\n* all submissions will be reviewed by at least two experts in the field, and the entire review process will be double-blind.\r\n* Selected accepted authors will be offered the opportunity to take part in the panel discussion with the panel’s keynote speaker and other accepted authors. This selection process will be juried based on acceptances *after* double-blind peer review. \r\n* All papers are expected to be ready for publication; we do not offer the opportunity for substantial revisions or second reviews. Correction of minor errors can be made when preparing accepted papers for publication.\r\n* Submissions prepared in Microsoft Word **will** look significantly different to submissions prepared in LaTeX because they are in the \"submission\" template, authors will have to follow [these ACM instructions](hhttps://www.acm.org/binaries/content/assets/publications/taps/acm_master_article_template_instructions.pdf \"ACM Instructions for Applying the Master Article Template\") to make their paper look correct should they be accepted.\r\n* **No submission will be penalised or receive special treatment as a result of the template inconsistencies.**\r\n\r\nBy submitting to the symposium, you are agreeing to the following ACM policies:\r\n\r\n* Please follow the [ACM’s in-text citation style and reference formats](https://www.acm.org/publications/authors/reference-formatting \"The ACM guinelines on citing and references\"). This is best done at the submission stage and absolutely required upon submission of accepted papers.\r\n* Submissions must adhere to the ACM’s policies on [copyright](https://www.acm.org/publications/policies/copyright-policy \"The ACM policy on copyright\") and [plagiarism](https://www.acm.org/publications/policies/plagiarism \"The ACM policy on plagiarism\"). \r\n* Authors and reviewers will be asked to indicate their understanding and acceptance of the [ACM Policy on Conflict of Interest in Publication](https://www.acm.org/publications/policies/conflict-of-interest \"The ACM policy on conflict of interest\") when items are submitted and reviewed.\r\n* Papers submitted to this symposium cannot be under consideration for any other conference or publication (no simultaneous submissions) and cannot be previously published without undergoing substantial revision. See the [ACM Policy on Prior Publication and Simultaneous Submissions](https://www.acm.org/publications/policies/simultaneous-submissions \"The ACM policy on Prior Publication and Simultaneous Submissions\").  ## Where to submit\r\n\r\nSubmission to the symposium is made using the [EasyChair system](/submission \"The HttF submission system\"). You must create an account and submit to the HttF2019 conference. Submissions will not be accepted by other means. We have extended the submission deadline until Wednesday, 26 June 2019, 23:59 BST (GMT+1). ## Preparing an accepted submission\r\nAuthors will be notified of acceptance or rejection by **Friday 26th July 2019**. Selected authors will be asked take part in one of the six panels at the symposium. All accepted authors who are not invited to present their work within one of the symposium panels will be invited to produce a poster to be displayed during the symposium as well as being included in the Halfway to the Future Proceedings.\r\n\r\nPlease follow the specific guide on [preparing an accepted submission](/accepted-submission-guidance \"Accepted submission guidance\"). ## Additional questions or help\r\nIf you have any questions regarding preparing your paper for submission, please contact the [Programme Chairs](mailto:programme@halfwaytothefuture.org \"Please email the HttF Programme Chairs if you have any questions\").',NULL,NULL,NULL),(18,'travel','2019-05-20 15:47:04','2019-09-12 20:46:45','2019-05-20 15:46:01',NULL,1,'published','[]','Travel to the venue',NULL,'**Halfway to the Future** will be held in the [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk/ \"The Albert Hall Conference Centre Nottingham website\"), Nottingham, UK. The venue is conveniently located in the city centre of Nottingham near to multiple hotels.','Albert Hall Conference Centre, Nottingham Albert Hall Conference Centre, Nottingham. The Albert Hall main entrance is located on **North Circus Street**, opposite St. Barnabas Cathedral and adjacent to the Nottingham Playhouse in the city centre of Nottingham. The main entrance **has stairs**.\r\n\r\n* Satellite navigation postcodes: NG1 5AA or NG1 5AE\r\n* Main (non-accessible) entrance on [Google Maps](https://goo.gl/maps/EJo8tKkwr5S2  \"The Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?address=North%20Circus%20Street\\,%20Nottingham\\,%20NG1%205AA\\,%20England&auid=12125193638640445003&ll=52.954342\\,-1.156263&lsp=9902&q=Albert%20Hall%20Conference%20Centre&_ext=ChoKBQgEEOEBCgQIBRADCgUIBhDfAQoECAoQABImKQQv6rSReUpAMZApjnHmoPK/OYIEEBG4ekpAQZYP7CfTY/K/UAQ%3D \"The Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\nThe **accessible entrance**, used also for deliveries, is on the opposite side of the building, on Maid Marian Way. We ask you to not use this entrance unless you need it as it is smaller.\r\n \r\n* Accessible entrance on [Google Maps](https://goo.gl/maps/mvsggnjntbhV7VBh8 \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Google Maps\") and [Apple Maps](https://maps.apple.com/?q=52.954293,-1.155787&sll=52.954293,-1.155787&sspn=0.001193,0.002492&t=h \"Accessible entrance to the Albert Hall Conference Centre Nottingham on Apple Maps\")\r\n\r\n ## Travel by public transport\r\nIf you are travelling by rail, Nottingham has a single central railway station that is a 15-minute walk from the venue, through the centre of the city. You can either walk from the station, catch a tram from the station to the nearby **Royal Centre** tram stop (see below for details of discounted tram travel), or alternatively catch a taxi from the adjacent taxi rank.\r\n\r\nDue to construction work as part of the [Nottingham Southside Regeneration Project](https://southside.nottinghamcity.gov.uk/ \"Nottingham City Council Southside Rengeration Project information\"), the city\'s southern bus station, Broadmarsh, is currently closed. \r\n Robin Hood Network logo  The conference centre is located next to the **St. Barnabas cathedral bus stops** (leaving the city) and **Tollhouse Hill bus stops** (into the city). Nottingham is served by multiple bus operators, primarily [Nottingham City Transport](https://www.nctx.co.uk/ \"The Nottingham City Transport website\") and [trentbarton](https://www.trentbarton.co.uk/ \"The trentbarton website\"). Most of the bus companies also co-operate as part of the [Robin Hood Network](http://robinhoodnetwork.co.uk/ \"The Robin Hood Network website\") and provide all-day multi-operator tickets. If your journey starts and ends in Nottingham, you can use the [Robin Hood Network journey planner](https://robinhoodnetwork.co.uk/journey-planner.html?destinationLatLng=52.9549572912,-1.1575989576&destination=Cathedral \"The Robin Hood Network Journey Planner to the nearest bus stop for HttF\") to find your route to the venue.\r\n\r\nIf you are catching a tram, the Nottingham tram system, NET, is providing discounted tram travel for attendees, however you must print off and complete the voucher in [this PDF](https://www.halfwaytothefuture.org/files/2019-02/ahccfindus.pdf \"Nottingham Express Transit Tram discount for HttF attendees\") for each day you travel on the tram system. To buy a tram ticket, you must use a machine at any tram stop, and purchase an \"Event Ticket\". You must retain this voucher with you at all times while on the tram as failure to do so may result in a penalty fare. The nearest stop is **Royal Centre**.\r\n\r\nNET is also part of the Robin Hood Network, thus Robin Hood tickets are valid on both buses and trams (note that each Robin Hood operator sells operator-only and multi-operator tickets). ## Travel by car\r\nIf you wish to travel by car, there are a couple of nearby public carparks you can use. At the carpark you will receive a ticket that can then be validated on your arrival at the Albert Hall reception.\r\n\r\n* NCP Nottingham City on Mount Street (NG1 6HG)\r\n* NCP St. James Street (NG1 6EY)\r\n\r\nAlternatively, you can park at one of the [9 free Park and Ride](https://robinhoodnetwork.co.uk/information/park-ride-bus-tram.html \"Robin Hood Network park and ride sites in Nottingham\") sites that are part of the Robin Hood Network. The route to the main (non-accessible) and accessible entrance is the same from each car park. ## Travel by taxi\r\nIf travelling by taxi, give the details of the venue (as above). Most taxi drivers are likely to be familiar with the venue, and certainly with the cathedral on Derby Road.\r\n\r\nIf you need the accessible entrance, you may also direct the taxi driver to the Central Police Station on Maid Marian Way (this is adjacent to the accessible entrance). ## Travel by aeroplane\r\nThe nearest airport is **East Midlands Airport**. To reach Nottingham from the airport you need to take the [Skylink Nottingham](https://trentbarton.co.uk/services/skylinknottingham \"The trentbarton Skylink bus travels to and from East Midlands Airport\") bus to _Nottingham_ and alight at the **Friar Lane bus stop**, or catch a taxi.',NULL,NULL,'venue'),(19,'accessibility','2019-05-20 15:50:45','2019-09-12 20:47:51','2019-05-20 15:47:34',NULL,1,'published','[]','Accessibility',NULL,'These page details the accessibility information on the symposium venues and transport in Nottingham. \r\n','## Symposium venues\r\nHalfway to the Future will be held across three different venues in Nottingham.\r\n\r\n### Albert Hall Conference Centre\r\nThe main symposium activities will take place in the [Albert Hall Conference Centre](http://www.alberthallnottingham.co.uk/ \"The Albert Hall Conference Centre Nottingham website\"), Nottingham, UK. The venue is conveniently located in the city centre of Nottingham near to multiple hotels. We will occupy the entirety of the venue throughout the symposium.\r\n\r\nWe are aware of comments online that there are parts of the venue which are not accessible by wheelchair. The Albert Hall Conference Centre has since **installed an additional stairlift to access to the floor of The Great Hall** (the room in which the main symposium sessions will take place).\r\n\r\nThe Albert Hall Conference Centre has an **accessible gender-neutral toilet on the ground floor** and there will be **non-accessible gender-neutral toilets accessible from The Great Hall**. The non-accessible toilets on the ground floor will remain gendered at the request of the venue.\r\n\r\nAll speakers in The Great Hall will have microphones connected to a PA system that includes **an induction loop**. \r\n\r\nThe **Main Entrance to the Albert Hall Conference Centre is not accessible**, but there is an alternative accessible entrance on Maid Marian Way, next to the Central Police Station. We access that, where possible, for attendees use the main entrance to keep this entrance clear for those that need it.  ### The Park Plaza\r\nThe **preferred hotel for guests**, [The Park Plaza](/hotel \"Information about the symposium hotel, the Park Plaza\"), is fully accessible. Guests should contact the hotel in advance to receive specific advice. The hotel is a short distance (by pavement) from the Albert Hall Conference Centre. There is a small gradient on this hill between the Albert Hall Conference Centre and the hotel.\r\n\r\nThe **symposium dinner** will also take place in  Park Plaza. Although the dinner will take place on the 11th floor, the nearest **gender-neutral accessible toilet is by lift to the ground floor**.\r\n ### Nottingham Contemporary\r\nThe **Welcome Reception** will take place at the Nottingham Contemporary art gallery, in the café/bar. This is fully wheelchair accessible with **gendered and gender-neutral accessible toilets conveniently located next to the café**. The café is accessible by lift from the ground floor/entrance of the gallery.  ## Public Transport\r\nMost **public transport** in Nottingham is fully wheelchair accessible, with all major bus operators ([NCT](https://www.nctx.co.uk/ \"Nottingham City Transport\"), [trentbarton](https://trentbarton.co.uk/ \"trentbarton\"), [CT4N](http://www.ct4n.co.uk/ \"Community Transport 4 Nottingham\"), and [Your Bus](http://catchyourbus.co.uk/ \"Your Bus\")), operating low-floor buses, with most of the buses having designated bays for wheelchair users as well as priority seats for those less-abled.\r\n\r\n[NET](https://thetram.net/ \"Nottingham Express Transit\"), the Nottingham tram system, only operates 100% low floor trams, all of which are wheelchair accessible. Some trains which stop at Nottingham Railway Station have a gap between the platform and the train—staff on the train or at the station can provide a ramp for wheelchair users.\r\n\r\nNottingham has an extensive network of taxis, many of which can carry individuals with a wheelchair. When booking a taxi, you should explain your needs to the taxi company. The major taxi operators are [DG Cars](https://dgcars.co.uk/ \"DG Cars\") and [Nottingham Cars](https://nottinghamcars.com/ \"Nottingham Cars\"). ## Questions or concerns\r\nIf you have any concerns regarding accessibility, please do not hesitate to contact the [Local Arrangements Chair](/organising-committee \"Please contact the Local Arragements Chair if you have questions regarding accessibility\"). If you wish to make the organisers aware of any accessible arrangements prior to the symposium, please also contact the [Local Arrangements Chair](/organising-committee \"Please contact the Local Arragements Chair if you wish to make the organisers aware of any specific issues\").',NULL,NULL,'venue'),(20,'visas-and-brexit','2019-05-29 12:44:35','2019-11-16 14:58:43','2019-05-29 12:34:31',NULL,1,'published','[]','Visas and Brexit',NULL,'This page details our understanding of the current immigration status for the UK. We are able to issue invitation letters, stamped by the School of Computer Science at the University of Nottingham, to attendees if needed.\r\n\r\nOn the 31st October 2019, the UK is due to leave the European Union (in a process known as Brexit). Details of how immigration and traveling across borders will work after this date are, and still remain, unknown. We will update this page with further information once we know it.','## Visa application support letters\r\n\r\nThe University of Nottingham is able to issue Visa support letters, which may be used to support a visa application to visit the UK for the symposium. We can include details of any submission you have made on the letter. We are not able to provide specific advice or support for visa applications, however.\r\n\r\nTo request a letter, you **must** initially have registered for the symposium, and then [complete this online form](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUNFBEV1BVQ0k3Q0hTMDZTSU1KSUZVSkFYWCQlQCN0PWcu \"Visa support letter request form\"). We will issue the letter once we have confirmed you have registered.\r\n\r\nIf you need further help, please email [visa-support@halfwaytothefuture.org](mailto:visa-support@halfwaytothefuture.org \"Visa support letter email address\"). ## Visiting the UK after Brexit\r\n\r\nThe following guidance was prepared for CHI 2019 in the UK—we have updated it for Halfway to the Future. We will update this page with further information once it is known.\r\n\r\n**If you are a non-EU citizen travelling from outside of the EU**, then there are likely to be no differences to normal travel to the UK. Visa rules etc. will not be changed in the short term. Go ahead and book your travel and accommodation as you would for a normal trip to the UK.\r\n\r\n**For EU citizens travelling from an EU country**, things may change a little. The UK Government and European Commission say flights between the UK and the EU will continue after 31st October 2019, no matter what happens after Brexit (this will apply to sea, coach, rail or Eurotunnel shuttle too). The European Commission has also said that there will be no difference to travel and holidaymakers won’t need a Visa during the ‘transition period’ (where the UK has left the EU but still follows EU rules while the new arrangements are made). This may change if there is a no-deal Brexit; we will keep this page updated with more information as we have it.\r\n\r\nYou may still need to check your passport is valid for at least six months after the date you plan to travel. For EU citizens, you might want to take out travel insurance rather than relying on EHIC, as rules for that may change is there is a no-deal Brexit.\r\n\r\nPlease also read the [GOV.UK EU exit guidance on transport](https://www.gov.uk/prepare-eu-exit/all?parent=&keywords=&any_part_of_taxonomy_tree%5B%5D=a4038b29-b332-4f13-98b1-1c9709e216bc&order=updated-newest \"HM Government on transport after the UK\'s exit from the European Union\").\r\n\r\n The UK will no longer leave the European Union until after Halfway to the Future. As such, there remains free movement of people on pre-existing terms until a future date. This future date may be in 2020, or mid-to-late December 2019 at the earliest. Update 16th November 2019',NULL,NULL,NULL),(21,'hotel','2019-05-31 09:35:33','2019-09-09 22:06:29','2019-05-31 09:23:42',NULL,1,'published','[]','Hotel',NULL,'The symposium has secured special rates for *a limited number of rooms* at the [Park Plaza in Nottingham](https://www.parkplaza.co.uk/nottingham-hotel-gb-ng1-6gd/gbnottin \"The Park Plaza Nottingham website\") for the Monday night (before the symposium) and Tuesday night. The Park Plaza is a five-minute walk from the main symposium venue, and just a couple of minutes from the centre of Nottingham.\r\n\r\nThe hotel\'s address is *Park Plaza Nottingham, 41 Maid Marian Way, Nottingham, NG1 6GD, UK*.','The Park Plaza entrance  ## Hotel rates\r\n**Monday 18th November** (i.e. checking in the day before the symposium):\r\n£99 for single occupancy (£109 for double occupancy)\r\n\r\n**Tuesday 19th November** (i.e. checking out on Wednesday 20th):\r\n£120 for single occupancy (£130 for double occupancy)\r\n\r\n* All rates include breakfast and Wi-Fi\r\n* All rates are inclusive of VAT at 20%\r\n* A £25.00 per room, per night security deposit may be required on check in\r\n* Check in is at 2pm and check out is at midday\r\n ## Booking details\r\nTo receive these special rates, you must book *before* the 19th September 2019. To make the booking, please telephone the Park Plaza on +44 (0) 115 947 7200 and quote the block code *15308496*.',NULL,NULL,NULL),(22,'conduct','2019-05-31 10:39:17','2019-09-09 22:06:32','2019-05-31 10:38:14',NULL,1,'published','[]','Code of Conduct',NULL,'We believe that everyone has the right to be in a safe and welcoming environment when attending Halfway to the Future. We wish for Halfway to the Future to be a symposium grounded in debate, which we consider to be a natural part of social academic life and is an important part of building a community and learning from one another. **Nevertheless, we will not tolerate any inappropriate behaviour as described in this code of conduct.**','At this event we uphold the following values:\r\n\r\n* Committing to empowering each other\r\n* Listening to others\' views and communicating respectfully\r\n* Being aware of our biases and prejudices\r\n* Respecting our environment and the people around us, in person and online\r\n* Respecting people’s choice of gender pronouns, personal space, and right to engage/disengage in any conversation\r\n* Respecting participants wishes not to be photographed or videoed\r\n\r\nHowever, to represent ourselves and our research to our very best ability, we will not tolerate any abuse, violence, discrimination or harassment. Harassment includes but is not limited to:\r\n\r\n* offensive verbal or written comments and visual imagery related to gender, age, sexual orientation and activity, disability, physical appearance, body size, race, ethnicity, religion, \r\n* sustained disruption of talks or other events, harassing photography, including capturing or sharing visual images of individuals wearing orange lanyards \r\n* deliberate intimidation or threats, including violent language and images, stalking, following, inappropriate physical contact, and unwelcome sexual attention\r\n\r\nAbsolutely everyone involved with our activities, including participants, members, sponsors, guests, volunteers, organisers, and our committee members, are subject to our Code of Conduct. \r\n\r\nIf what you’re doing is making someone feel uncomfortable, that counts as harassment and is enough reason to stop doing it.\r\n\r\n**Attendees asked to stop any inappropriate behaviour are expected to comply immediately. **\r\n\r\nIf a person engages in any unacceptable behaviour, as highlighted above, we may take any action we deem appropriate, including but not limited to warnings, expulsion, and banning, with no eligibility for reimbursement or refund of any type.   We may also withdraw any associated publication that you have had accepted into the symposium proceedings.\r\n\r\nOur decisions regarding the Code of Conduct may be escalated to the General Chairs as a committee, or the organising committee as a whole. The decision to take action is non-negotiable once it has been made.\r\n\r\n**If you are being harassed, or are aware of any inappropriate behaviour, or have any other concerns, please contact the general chairs using the contacts below or approach one of our volunteers. The general chairs will make a mobile phone number (for SMS and WhatsApp) available during the symposium.**\r\n\r\nIn addition to the above, we are following the [ACM Policy Against Harassment](https://www.acm.org/special-interest-groups/volunteer-resources/officers-manual/policy-against-discrimination-and-harassment \"Read the ACM Policy Against Discrimination and Harassment\"). ## Contact Details\r\nPlease email us at: [edi@halfwaytothefuture.org](mailto:edi@halfwaytothefuture.org \"Email the quality, Diversity, and Inclusion Chair\") (Pepita Stringer; Equality, Diversity, and Inclusion Chair) or [comms@halfwaytothefuture.org](mailto:comms@halfwaytothefuture.org \"Email the Communications Chair\") (Martin Porcheron; Communications Chair). You may also call or send WhatsApp and SMS messages to the Communications Chair on ‭+44 7394 212757‬ during the symposium.\r\n\r\nAlternatively, you may send a [report via our website](/report \"Report a concern/contact the EDI and Communications Chairs\"), and choose whether or not to identify yourself.\r\n\r\nThis event complies with the [University of Nottingham’s Events guidance](https://www.nottingham.ac.uk/safety/policies-and-guidance/events/events.aspx \"The University of Nottingham\'s guidance and policy on events\").\r\n\r\n## Credits\r\nThis Code of Conduct was adapted from *Hacksmiths Code of Conduct* and the *CSCW 2019 Code of Conduct*.',NULL,NULL,NULL),(23,'registration-terms-conditions','2019-05-31 11:27:11','2019-09-09 22:06:30','2019-05-31 11:26:42',NULL,1,'published','[]','Registration Terms & Conditions',NULL,'All individuals who are registered for the event, and/or attend the event are bound by these terms and conditions. \r\n\r\nThroughout these terms and conditions, we use the term \"attendee\" as shorthand for anyone who is registered for the event, or attending the event, or both. By the term “we”, this document refers to the [General Chairs of the Halfway to the Future symposium](/organising-committee \"The HttF organising committee\"), who are all employees of the University of Nottingham. By the term “event”, “symposium”, or “conference”, we refer to the Halfway to the Future symposium event at the Albert Hall Conference Centre, Nottingham and the symposium dinner at Park Plaza Nottingham.\r\n','## Code of Conduct\r\nAs an attendee of the event, you are required to consent to and abide by the Halfway to the Future Code of Conduct. Please do read this code of conduct. We are also applying the [ACM’s Policy Against Discrimination and Harassment for Members and Event Attendees](https://www.acm.org/special-interest-groups/volunteer-resources/officers-manual/policy-against-discrimination-and-harassment \"ACM Policy Against Harassment at ACM Activities\").\r\n\r\nAttendees asked to stop any inappropriate behaviour, as defined by but not limited to what is covered by the code of conduct, are expected to comply immediately.\r\n\r\nIf a person engages in any inappropriate behaviour, we may take any action we deem appropriate, including (but not limited to) warnings, expulsion, and banning, with no eligibility for reimbursement or refund of any type. We may also withdraw any associated publication that you have had accepted into the symposium proceedings.\r\n\r\nInappropriate behaviour outside of the event venues, or online, between or by attendees, or to members of the public or staff supporting the event, including venue employees, may be covered by this policy.\r\n\r\nOur decisions regarding the Code of Conduct may be escalated to the General Chairs as a committee, or the organising committee as a whole. The decision to take action is non-negotiable once it has been made. ## Minors and children\r\nAll children under 18 must accompanied by a parent or guardian at all times. We do not have any childcare facilities and are not able to provide supervision for children. Children are, at all times, the responsibility of the parent or guardian, and we cannot accept any liability or responsibility for them.\r\n\r\nPlease contact the organisers in advance if you intend to bring children as we will need to manage the cost of their attendance.\r\n ## Photography and videography\r\nWe will be documenting the event in a number of ways, including roving photography in areas where people can enter without restriction (including at the symposium dinner) and static videography of the sessions. This will be managed according to the University of Nottingham Photography and Videography policies: [Privacy Information for Subjects of Photography](https://www.nottingham.ac.uk/utilities/privacy/privacy-information-for-the-subjects-of-photography.aspx \"Privacy Information for the Subjects of Photography\"), [Photography privacy notices](https://www.nottingham.ac.uk/brand/services/photography-guidance/photography-privacy-notices.aspx \"Photography privacy notices\"), [Filming guidance and privacy notices](https://www.nottingham.ac.uk/brand/services/video/video-privacy-notices.aspx \"Filming guidance and privacy notices\"), [Privacy Information for Subjects of Videography](https://www.nottingham.ac.uk/utilities/privacy/privacy-information-for-the-subjects-of-videography.aspx \"Privacy Information for the Subjects of Videography\"), and [GDPR video guidance](https://www.nottingham.ac.uk/brand/services/video/video-gdpr.aspx \"GDPR video guidance\").\r\n\r\nThe copyright for all photography and videography will, in the first place, remain with the University of Nottingham. Any attendee reserves the right to withdraw consent at any time for inclusion in future photography or videography and we will do our best to honour this where reasonably possible. If you wish for imagery that includes you to not be used in any documentation of the event, please contact the organising committee and we will not include it in any future documentation.\r\n\r\n### Attendees\r\n\r\nWe will be video recording the sessions including panel discussions. If you wish to ask a question during these sessions, your voice will be recorded. In these cases, it is assumed that you are informed of this and are consenting, including assignment of copyright of your contribution. We will issue privacy notices before and during the event, as well as verbal reminders of on-going videography and audio recording. However, you can opt to ask a question by providing it in writing, so that an organiser or volunteer can ask the question on your behalf. \r\n\r\nWe will be documenting the event through photography in the symposium venues. If you prefer to not be included, we will supply—for free—different coloured lanyards that indicate your preference not to be included in such photography. This choice will be made during online registration, although you are free to request to any organiser or volunteer such a lanyard at any time during the event.\r\n\r\nYou will not be the feature and focus of a photograph, unless you have been asked to provide additional written consent.\r\n\r\n### Panel members\r\nIf you are selected to be on a panel, we will ask you to complete additional consent and privacy waivers in relation to photography and videography. \r\n ## Privacy Policy\r\nThis event is being organised by employees of the University of Nottingham, and as such the event, and all attendees, are bound by the [University of Nottingham Privacy Policy](https://www.nottingham.ac.uk/utilities/privacy/privacy.aspx \"The University of Nottingham Privacy Policy\"). You should read the specific policy that covers [the Halfway to the Future website](https://www.halfwaytothefuture.org/privacy-policy \"The Halfway to the Future website Privacy Policy\"). ### SIGCHI subsidy\r\n\r\nThrough sponsorship with ACM SIGCHI, we are able to offer a number of subsidised student places on a first-come, first-served basis. We will distribute codes that can be used during registration to discount the registration. Our decisions on allocation codes are final.\r\n\r\nTo receive this sponsorship, ACM stipulates that you must have both ACM and ACM SIGCHI memberships ($19 each)—you must sign up from the [ACM SIGCHI website](https://campus2.acm.org/public/qj/login_gensigqj.cfm?rdr=promo=QJSIG&offering=026&form_type=SIG \"Apply for SIGCHI membership on the ACM website\"). You do not need to register for ACM SIGCHI membership until we contact you.\r\n\r\nEven those registering for the symposium using the SIGCHI-sponsored rate must provide details of their student status to the Halfway to the Future organising committee, as above.\r\n\r\nAs organisers, we are issuing the subsidy to students, and claiming this back from ACM on your behalf. As a result, we will contact you should ACM alert us that you are not a member at the time of symposium. In such a case, we will ask you to either register for ACM and SIGCHI or pay the subsidy to Halfway to the Future (£100). If this is not done, we will cancel your registration without reimbursement or refund. As we are claiming this subsidy from ACM on your behalf, ACM requires us to collect either a tax identification number or passport number, where possible, as well as your country of residence. This data will be transferred to ACM in accordance with their policies.\r\n ## Refunds and cancellations\r\nA full refund will be available for cancellations up to Monday 16th September 2019 (UTC/GMT), minus a £25 administration fee. Thereafter no refunds are available. If you need to cancel, please email [registration@halfwaytothefuture.org](mailto:registration@halfwaytothefuture.org \"Email the Registration Chairs\") before this date.\r\n\r\nAs above, if your behaviour is deemed inappropriate and against our code of conduct, we reserve the right to cancel your registration and expel you from the symposium without a refund. This includes any harassment or comments posted digitally before, during or after the symposium.\r\n\r\nIf, for any reason, the organisers have to cancel the event due to any extenuating or unforeseen circumstances beyond the control of the organisers (force majeure), we reserve the right to not issue any refunds for registration or for additional packages such as the symposium dinner. However, we will endeavour to return any unspent money to attendees in proportion to the cost incurred.\r\n\r\nWe are mindful of the complicated visa situation, especially in the context of Brexit, and can provide letters to support any application for a visa. Please see our [Visas and Brexit webpage](/visas-and-brexit \"Halfway to the Future Visas and Brexit information\") to apply for a letter or for more information. If you experience any foreseen immigration problems beyond your control, subsequent to registration, you should contact the organisers on [registration@halfwaytothefuture.org](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\") or +44 (0) 115 95 14227 and we will try to assist you wherever possible.\r\n ## Additional questions/information\r\nShould you have any additional questions or would like further information on any of the points above, please contact the [Local Arrangements Chair by email](local@halfwaytothefuture.org \"Email the Local Arragements Chair\") or by telephoning +44 (0) 115 82 32556.',NULL,NULL,'registration'),(24,'feedback','2019-05-31 13:23:46','2020-01-23 11:48:11','2019-05-31 13:23:05',NULL,4,'published','[]','Feedback',NULL,'As organisers we received a tremendous amount of feedback in person, on Twitter, and by email from attendees. We were delighted with how the symposium went and the feedback received seems to reflect our own experience. A number of attendees made valuable suggestions for future events. Rather than let these lie in an inbox, Martin Porcheron, as a general chair, went through this ideas and synthesised them into a short report, adding in a number of comments on the approach we took and how we might have done things differently. We hope this is of value to future event organisers.','Download the [symposium feedback response](https://www.halfwaytothefuture.org/files/2020-01/feedback.pdf?9c4168861f \"Response to the feedback for the Halfway to the Future Symposium 2019\").',NULL,NULL,NULL),(25,'sigchi-student-subsidy','2019-05-31 15:29:30','2019-09-28 15:09:28','2019-05-31 15:28:57',NULL,1,'published','[]','SIGCHI Student Rate',NULL,'Thanks to sponsorship from [ACM SIGCHI](https://sigchi.org/ \"The Association of Computing Machinery Special Interest Group on Computer-Human Interaction\"), we are able to offer **80 subsidised student places at the reduced rate of £60**. Our registration price for students without the discount is £160.\r\n\r\nTo receive this rate, ACM stipulates that **you must have both ACM and ACM SIGCHI memberships** ($19 each) at the time of registration. You must sign up from the [ACM SIGCHI website on this page](https://campus2.acm.org/public/qj/login_gensigqj.cfm?rdr=promo=QJSIG&offering=026&form_type=SIG \"Register for ACM and SIGCHI membesrhip\"). You **do not** need to register for ACM SIGCHI membership **until** we contact you.\r\n','## Registration discount codes\r\n\r\nThe discount is administered through the form of discount codes being issued to those who apply. These are then used during online registration to unlock the discounted rate.\r\n\r\nYou should request a registration discount code using [this online form](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUMDhVM0pCNDdJOUxXVjlKU0E4MzBBTjJJOCQlQCN0PWcu \"Register for a SIGCHI student subsidy\"). This form will stay open even after we have exceeded 80 allocated discount codes, so that we can reallocate discount codes given to students who later decide not to attend. We will let you know if you are on the waiting list and will inform you right away if and when a code becomes available. \r\n\r\nWe will send the discount codes to the people who have requested a code, **giving priority to those who have had a paper accepted**. Remaining discount codes will be given on a first-come, first-served basis to **those who have submitted, but were not accepted**. After this, any remaining codes will be allocated on a first-come, first-served basis to those interested in attending.\r\n\r\nYou will be emailed instructions on how to **complete registration within two weeks of the discount code being sent to you**. \r\n Please [pre-apply](https://forms.office.com/Pages/ResponsePage.aspx?id=7qe9Z4D970GskTWEGCkKHucDQcu1jTJEqYL5jrKC2HFUMDhVM0pCNDdJOUxXVjlKU0E4MzBBTjJJOCQlQCN0PWcu \"Register for a student subsidy\") to receive the discount. We will start issuing codes once decisions have been made on papers.\r\n\r\nYou **do not** need to be a member of ACM SIGCHI until completing your online registration. Pre-apply to receive the discount If you have any questions, please contact our [Sponsorship Chair](mailto:sponsorship@halfwaytothefuture.org \"Email the Sponsorship Chair with questions regarding this subsidy\").',NULL,NULL,NULL),(26,'email-2019-06-07','2019-06-07 12:45:48','2019-09-09 22:06:54','2019-06-07 12:42:18',NULL,1,'published','[]','EoI Email: 7th June 2019',NULL,'The following email was sent on the 7th June 2019 to those who expressed interest in the Halfway to the Future symposium.','We can\'t believe how the time has flown by since we announced the symposium in February. \r\n\r\n**Submissions are due 21st June**\r\nThere is now just two weeks until the **Halfway to the Future** submission deadline. A reminder that we have two paper types:\r\n\r\n* 6,000-word papers addressing current work relating to [a symposium theme](https://www.halfwaytothefuture.org/themes \"HttF symposium themes\"), especially those building on or responding to the influential works to be discussed.\r\n* 2,000-word papers looking towards the future of [our themes](https://www.halfwaytothefuture.org/themes \"HttF symposium themes\"). Papers can take the form of projected projects, design fictions, manifestos, or anything that fires your imagination. \r\n\r\nWhile we know many of you will be familiar with the CHI style of writing—which is certainly acceptable—we are also very open to more theoretical, exploratory, or otherwise non-traditional styles of paper.\r\n\r\nAll accepted papers will go into the ACM International Conference Proceedings Series for Halfway to the Future and will be included in the **ACM Digital Library**! As part of this, all submitted papers will be peer reviewed through a double-blind process. [The templates you should use to draft your papers can be downloaded from our website](https://www.halfwaytothefuture.org/submission-guidance \"The HttF submission guidance\").\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email the Programme Chairs with any questions\").\r\n\r\n**Discounted student registration - £25**\r\nWe are also delighted to announce that we are being sponsored by ACM SIGCHI, who are subsidising 80 student registrations! The **student registration cost for ACM SIGCHI members is just £25** (a 90% discount on full registration). For non-members, student registration costs £125. However, as ACM SIGCHI membership only costs $38, we would encourage you to join and take advantage of this very generous subsidy.\r\n\r\nTo receive this subsidy, students simply need to [apply for a discount code from our website](https://www.halfwaytothefuture.org/sigchi-student-subsidy \"Apply for a discount code for your registration now\"). You can apply for a discount code now and register later once your paper is accepted (we\'d encourage this as places are limited). Details on registering for ACM and ACM SIGCHI are [on our website too](https://www.halfwaytothefuture.org/sigchi-student-subsidy \"Details for the SIGCHI student discount are available now\").\r\n\r\nWe will send the discount codes to the people who have requested a code, **giving priority to those who have had a paper accepted**. Remaining discount codes will be given on a first-come, first-served basis to **those who have submitted, but were not accepted**. After this, any remaining codes will be allocated on a first-come, first-served basis to those interested in attending.\r\n\r\nPlease contact Stuart, our Sponsorship Chair, if you have any questions regarding the subsidy using the email address [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email our Sponsorship Chair with any questions\").\r\n\r\nWe will be opening registration in the next few weeks and I will send another email regarding this. Good luck with preparing your papers, and we look forward to seeing you in November!\r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair)\r\non behalf of [the organising committee](https://www.halfwaytothefuture.org/organising-committee \"The Halfway to the Future Organising Committee\")\r\n\r\n Halfway to the Future: Student Discount and Submission Deadline',NULL,NULL,'emails'),(27,'email-2019-06-18','2019-06-18 16:41:08','2019-09-09 22:06:55','2019-06-18 16:39:58',NULL,1,'published','[]','EoI Email: 18th June 2019',NULL,'The following email was sent on the 18th June 2019 to those who expressed interest in the Halfway to the Future symposium.','**Submission deadline extended until Wednesday 26th June**\r\nApologies for another email so soon after the last one. Submissions are now coming in for the symposium, however following many requests to the Programme Chairs, we have extended the submission deadline until **Wednesday 26th June 2019** (at 23:59 BST/UTC+1).\r\n\r\nIf you have any questions regarding your submission or the review process, please do not hesitate to contact Joel and Jocelyn, our Programme Chairs, using the email address [programme@halfwaytothefuture.org](mailto:programme@halfwaytothefuture.org \"Email any questions to the Programme Chairs\").\r\n\r\nMore details are on our [Call for Papers](/cfp \"HttF Call for Papers\").\r\n\r\n**Discounted student registration - £25**\r\nIf you are or have students who are planning to submit or would like to attend the symposium this November, please do encourage them to apply for a student discount code as soon as possible. The number of codes is limited, and many have been requested already. The discount codes are funded by ACM SIGCHI.\r\n\r\nPlease note that ACM requires that students who receive the subsidy be members of ACM and ACM SIGCHI already. As this membership only costs $38, the discount is still substantial. We will advise students beforehand if they are successful and thus they do **not** need to apply for membership to request a code.\r\n\r\nTo receive this subsidy, students simply need to [apply for a discount code from our website](/sigchi-student-subsidy \"Apply for the SIGCHI student discount on our website\"). Details on registering for ACM and ACM SIGCHI are [on our website too](/sigchi-student-subsidy \"Details of the SIGCHI student discount are on our website\").\r\n\r\nPlease contact Stuart, our Sponsorship chair, if you have any questions regarding the subsidy using the email address [sponsorship@halfwaytothefuture.org](mailto:sponsorship@halfwaytothefuture.org \"Email questions about the subsidy to our Sponsorship Chair\").\r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair) Halfway to the Future: Submission deadline extended until 26th June',NULL,NULL,'emails'),(28,'report','2019-06-26 21:22:39','2019-10-03 16:24:57','2019-06-26 21:21:00',NULL,1,'published','[]','Report a concern',NULL,'If you wish to report a concern regarding someone\'s behaviour at, or in relation to Halfway to the Future, you may do so using the form below. This form sends an email to **Martin Porcheron** (Communications Chair) and **Pepita Stringer** (Equality, Diversity, and Inclusion Chair).  Alternatively, you may send a personal email to any/all of the [General Chairs or the committee](/organising-committee \"Details of the Organising Committee\"), or during the symposium you may approach us in person.\r\n\r\n','You may **optionally** include your name and email address in this report and can choose whether or not you wish for us to contact you regarding your report. If you wish to remain anonymous, please enter a pseudonym (this can even be a random string of characters!). During the symposium, attendees will be able to contact **Martin Porcheron** (Communications Chair and Treasurer) using the UK mobile phone number ‭**+44 7394 212757‬** at any time either by calling, sending an SMS, or sending a WhatsApp message. Careline and WhatsApp ## Contact form','form.twig',NULL,'conduct'),(29,'program','2019-07-05 10:24:45','2019-09-09 22:06:02','2019-07-05 10:22:55',NULL,1,'published','[]','Web program',NULL,'The web complete programme for **Halfway to the Future**.','','redirect.twig','/programme',NULL),(30,'email-2019-07-08','2019-07-08 11:50:53','2019-09-09 22:06:55','2019-07-08 11:48:27',NULL,1,'published','[]','EoI Email: 8th July 2019',NULL,'The following email was sent on the 8th July 2019 to those who expressed interest in the Halfway to the Future symposium.','All submissions to the symposium are now under review—we received 80 in total. We will send notifications to authors by the 26th July.\r\n\r\n**Symposium registration and dinner**\r\nWe have now opened up our [symposium registration](/registration \"Halfway to the Future registration\") on our website. Register before the 13th September for early bird rates. \r\n\r\nDuring registration you will also be offered the opportunity to join us for the symposium dinner on the first night of the symposium. We are also offering a choice of vegetarian, vegan, gluten free and Halal meal options—[the menu can be seen on our website](/session/symposium-dinner \"Halfway to the Future symposium dinner\"). We would love to see as many of you there as possible!\r\n\r\n**Reduced hotel rates**\r\nThe Park Plaza Hotel in Nottingham has also offered reduced rates to symposium attendees. Details of these rates, which include breakfast, [are now on our website](/hotel \"The Park Plaza, Nottingham\"). These rooms are available on a first-come first-served basis.\r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair) Halfway to the Future: Symposium registration is open',NULL,NULL,'emails'),(31,'accepted-submission-guidance','2019-08-23 11:33:56','2019-09-09 22:05:29','2019-08-23 11:30:12',NULL,1,'published','[]','Accepted submission guidance',NULL,'Upon acceptance, you will be contacted by the Programme Chairs with specific information on how to prepare your document for inclusion in the ACM proceedings. Accepted authors will be asked to submit both their camera-ready PDF and the raw source (i.e. Word document/LaTeX source). This is required by the ACM in order for your paper to be included in the [ACM Digital Library](https://www.acm.org/publications/taps/word-template-workflow \"Information on preparing papers for publication that were written in Microsoft Word\").\r\n\r\n\r\nThe deadline for submission of final formatted versions is **Friday 6th of September 2019**. We ask that panellists register by the early registration deadline.\r\n\r\nThe official publication date is the date the proceedings are made available in the ACM Digital Library. This date may be up to two weeks prior to the first day of the symposium. The official publication date may affect the deadline for any patent filings related to published work.\r\n\r\n','## Overall process\r\n\r\n1. Prepare a revised version of your work using the final template, incorporating the changes requested by reviewers. Upload this to EasyChair by **Friday 6th September 2019**\r\n2. At least one author must register before **Friday 27th September 2019**, otherwise your publication **will not** be included in the Halfway to the Future Proceedings\r\n3. The Programme Chairs will review your PDF and communicate with you as to whether the requested changes have been satisfactorily made\r\n4. Complete the ACM rights allocation and update your paper\r\n5. Submit the final versions for publication to the publishing system. This needs to be done by **early October**. ### Step 1: Preparing your revised paper\r\nIn addition to making the requested changes, the new templates enable you to import required indexing concepts for your article from the [ACM Computing Classification System (CCS)](https://www.acm.org/publications/class-2012 \"The ACM classification system for all work in the Digital Library\") using an [indexing support tool](https://dl.acm.org/ccs/ccs.cfm? \"A tool developed by ACM to generate the classification for papers in the Digital Library\") found in the ACM Digital Library (DL) which generates the necessary TeX code once you have selected your terms (and generates XML for Word documents). The ACM **requires** the use of this tool to generate your CCS concepts before submission to the Digital Library.\r\n\r\nMicrosoft Word users will have to follow the [ACM Master Article Template workflow](https://www.acm.org/publications/taps/word-template-workflow  \"Information on preparing papers for publication that were written in Microsoft Word\") to prepare their document.\r\n\r\nWe also request that authors make their papers as accessible as possible by including alternative text for all images and tables to make more of your content available to readers with visual impairments. \r\n\r\nYou should upload the revised version of your paper to EasyChair, where the Programme Chairs will review the PDF and assess whether you have complied with the template requirements for ACM publication.\r\n\r\n A note to anyone attempting to use the Word template: our website contains all the information made available to us by the ACM. Word users should follow the [ACM Master Article Template workflow](https://www.acm.org/publications/taps/word-template-workflow \"ACM Master Article Template workflow\"). This means you should download the Word Master Article template from ACM, apply it to your submission (details given in the link), and follow the guide in marking up your references accordingly.\r\n\r\nNote that Mendeley users may have to convert their dynamic Mendeley references to text as the ACM macros do not seem to work with Mendeley\'s references.\r\n\r\nPapers prepared in Word **will be in single column**, LaTeX papers **should be double-column with the sigconf option in the \\documentclass**.  Update from the Programme Chairs (5th September) ### Step 2: Register\r\nYou can [register for the symposium online](/registration \"Halfway to the Future 2019 registration\"). All panellists **and poster presenters** must register by the early registration deadline of 27th September. Please contact us if this presents any problem for you.\r\n\r\n### Step 3: Paper finalised\r\nThe Programme Chairs will send you an email to confirm your changes were accepted and that you will receive the ACM rights email and ACM TAPS (publishing system) links shortly. Please check your spam folders for emails from acm.org.  **This will be a very quick turnaround**.\r\n\r\n### Step 4: ACM rights\r\nAccepted authors will be required to complete [a rights management form](https://www.acm.org/publications/icps-instructions/ \"About the ACM ICPS rights management process\"). We will email the correct rights text and bibliographic strip that must be placed within the paper where required in the template. Please expect an email from [rightsreview@acm.org](mailto:rightsreview@acm.org \"Emails regarding rights come from this email address at ACM\") and adjust your junk/spam settings accordingly.\r\n\r\nNo pre-publication version may be put online or otherwise distributed until all rights management, bibliographic information, and copyright information has been completed and confirmed by the Programme Chairs.\r\n\r\n### Step 5: Upload your final versions\r\nWe will input all data about papers into the ACM TAPS system, which, as authors, you will then use to upload your source documents. You will be emailed with details of how to do this closer to the time. We ask that you complete this and the rights step above as quickly as possible. **This will be sent at the same time (roughly) as the rights emails**.',NULL,NULL,'submission-guidance'),(32,'sponsorship','2019-09-01 22:59:58','2019-11-17 16:04:28','2019-09-01 22:58:58',NULL,1,'published','[]','Sponsors',NULL,'We are incredibly grateful to the organisations that have chosen to sponsor Halfway to the Future.','Sponsorship is an ideal opportunity to demonstrate your organisation’s commitment and research collaboration in the field of HCI and design-based research, as well as raising awareness of your products or services. If you are interested in sponsoring Halfway to the Future, please email [Stuart Reeves, our Sponsorship Chair](mailto:sponsorship@halfwaytothefuture.org \"Email Stuart Reeves for more information on sponsorsing the symposium\") for details. We have multiple sponsorship tiers and can also create a bespoke sponsorship package for you. Sponsor Halfway to the Future **Platinum Sponsors**\r\n* [ACM SIGCHI](https://sigchi.org \"The Association of Computing Machinery Special Interest Group on Computer-Human Interaction website\")\r\n* [University of Nottingham Faculty of Science](https://www.nottingham.ac.uk/science \"The University of Nottingham Faculty of Science website\")\r\n* [University of Nottingham Creative and Digital Interdisciplinary Research Cluster](https://www.nottingham.ac.uk/research/research-areas/creative-and-digital/index.aspx \"The University of Nottingham Creative and Digital IRC website\")\r\n\r\n**Gold Sponsors**\r\n* [Microsoft Research](https://www.microsoft.com/en-us/research/ \"The Microsoft Research website\")\r\n* [University of Nottingham Smart Products Beacon](https://www.nottingham.ac.uk/research/beacons-of-excellence/smart-products/index.aspx \"The University of Nottingham Smart Products Beacon website\")\r\n\r\n**Partners**\r\n* [Mixed Reality Lab](http://www.mrl.nott.ac.uk/ \"The Mixed Reality Laboratory website\")',NULL,NULL,NULL),(33,'email-2019-09-11','2019-09-10 16:41:29','2019-09-11 09:16:32',NULL,NULL,1,'published','[]','EoI Email: 11th September 2019',NULL,'The following email was sent on the 11th September 2019 to those who expressed interest in the Halfway to the Future symposium. It was the last email sent to subscribers, with the subscribers list being deleted after the email was sent.','Our [provisional programme is now online](/programme \"Halfway to the Future Provisional Programme\") which includes the details of the 29 talks and 13 posters accepted to the symposium (in addition to our 6 keynotes and panels). Information on demos as well as abstracts for the accepted papers will be coming soon. Thank you to the [Programme Committee members](/programme-committee \"Members of the Halfway to the Future Programme Committee\") for their hard work, we couldn\'t have done this without your support.\r\n\r\nWe hope that you find the programme as exciting as we do. Each session has been curated so that we can have an engaging discussion around our six symposium themes, reflecting on work that has taken place and looking towards the future of where HCI and design-based research might go. We have set the timings of each session to allow for as much audience participation as possible throughout the entirety of the two days. \r\n\r\nWe hope you choose to register, which [you can do online now on our website](/registration \"Register now for Halfway to the Future\"). We have extended the early registration deadline to the 27th September and there are a number of SIGCHI-sponsored student registrations still available (£25 registration for students). \r\n\r\nFinally, this is my final email to you as a subscriber of our Expression of Interest mailing list. After this email is sent, I will be deleting all data relating to the expression of interest from our systems. Thank you for expressing interest in the symposium (and for reading and responding to these emails), it gave us the confidence that we were doing the right thing very early on in this process.\r\n\r\nOn behalf of the [organising committee](/organising-committee \"Halfway to the Future Organising Committee\"), we look forward to meeting you in November!\r\n\r\nBest wishes,\r\nMartin Porcheron (Communications Chair & Treasurer)\r\n Halfway to the Future: Provisional programme and early-bird registration',NULL,NULL,'emails'),(34,'onsite-registration','2019-10-05 19:31:11','2019-11-15 12:34:39','2019-10-05 19:30:39',NULL,1,'published','[]','Onsite Registration',NULL,'Link to the University of Nottingham store for registration','','redirect.twig','https://store.nottingham.ac.uk/conferences-and-events/conferences/schools-and-departments/computer-science/halfway-to-the-future-symposium','registration'),(35,'dl','2019-11-17 14:12:03','2019-11-17 14:12:14','2019-11-17 14:11:17',NULL,1,'published','[]','ACM Digital Library',NULL,'Browse the Halfway to the Future proceedings in the ACM Digital Library','','redirect.twig','https://bit.ly/2KrcsH3','programme');
/*!40000 ALTER TABLE `bolt_pages` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_programme`
--

DROP TABLE IF EXISTS `bolt_programme`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_programme` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `slug` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `datecreated` datetime NOT NULL,
  `datechanged` datetime NOT NULL,
  `datepublish` datetime DEFAULT NULL,
  `datedepublish` datetime DEFAULT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `templatefields` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `teaser` longtext COLLATE utf8_unicode_ci,
  `citation` longtext COLLATE utf8_unicode_ci,
  `searchabletext` longtext COLLATE utf8_unicode_ci,
  `checked` tinyint(1) NOT NULL DEFAULT '0',
  `firstauthor` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `authors` longtext COLLATE utf8_unicode_ci,
  `authorsorganisations` longtext COLLATE utf8_unicode_ci,
  `download` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `freedownload` tinyint(1) NOT NULL DEFAULT '0',
  `doi` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `doilabel` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `doititle` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `doiactive` tinyint(1) NOT NULL DEFAULT '0',
  `template` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `sessionoffset` int(11) NOT NULL DEFAULT '0',
  `lengthmins` int(11) NOT NULL DEFAULT '0',
  `locationoverride` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `locationlinkoverride` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `poster` tinyint(1) NOT NULL DEFAULT '0',
  `procpaperid` int(11) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `IDX_65E24D44989D9B62` (`slug`),
  KEY `IDX_65E24D44AFBA6FD8` (`datecreated`),
  KEY `IDX_65E24D44BE74E59A` (`datechanged`),
  KEY `IDX_65E24D44A5131421` (`datepublish`),
  KEY `IDX_65E24D44B7805520` (`datedepublish`),
  KEY `IDX_65E24D447B00651C` (`status`)
) ENGINE=InnoDB AUTO_INCREMENT=74 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_programme`
--

LOCK TABLES `bolt_programme` WRITE;
/*!40000 ALTER TABLE `bolt_programme` DISABLE KEYS */;
INSERT INTO `bolt_programme` VALUES (1,'rogers-moving-on-from-weiser-s-vision-of-calm-computing-engaging-ubicomp-experiences','2019-02-23 20:07:48','2019-09-24 12:00:08','2019-02-23 20:06:40',NULL,1,'published','[]','Moving on from Weiser’s Vision of Calm Computing: Engaging UbiComp Experiences','A motivation behind much UbiComp research has been to make our lives convenient, comfortable and informed, following in the footsteps of Weiser’s calm computing vision. Three themes that have dominated are context awareness, ambient intelligence and monitoring/tracking. While these avenues of research have been fruitful their accomplishments do not match up to anything like Weiser’s world. This paper discusses why this is so and argues that is time for a change of direction in the field. An alternative agenda is outlined that focuses on engaging rather than calming people. Humans are very resourceful at exploiting their environments and extending their capabilities using existing strategies and tools. I describe how pervasive technologies can be added to the mix, outlining three areas of practice where there is much potential for professionals and laypeople alike to combine, adapt and use them in creative and constructive ways.','Yvonne Rogers. 2006. Moving on from weiser’s vision of calm computing: Engaging ubicomp experiences. In *Proceedings of the International Conference on Ubiquitous Computing* (UbiComp \'06). Springer, Berlin, Heidelberg. 404–421. https://doi.org/10.1007/11853565_24','Moving on from Weiser\'s Vision of Calm Computing: Engaging UbiComp Experiences\r\nYvonne Rogers\r\nSchool of Informatics, Indiana University, 901 East 10th Street, Bloomington, IN47408, USA yrogers@indiana.edu\r\nAbstract. A motivation behind much UbiComp research has been to make our lives convenient, comfortable and informed, following in the footsteps of Weiser\'s calm computing vision. Three themes that have dominated are context awareness, ambient intelligence and monitoring/tracking. While these avenues of research have been fruitful their accomplishments do not match up to anything like Weiser\'s world. This paper discusses why this is so and argues that is time for a change of direction in the field. An alternative agenda is outlined that focuses on engaging rather than calming people. Humans are very resourceful at exploiting their environments and extending their capabilities using existing strategies and tools. I describe how pervasive technologies can be added to the mix, outlining three areas of practice where there is much potential for professionals and laypeople alike to combine, adapt and use them in creative and constructive ways.\r\nKeywords: calm computing, Weiser, user experiences, engaged living, UbiComp history, pervasive technologies, proactive computing.\r\n1 Introduction\r\nMark Weiser\'s vision of ubiquitous computing has had an enormous impact on the directions that the nascent field of UbiComp has taken. A central thesis was that while \"computers for personal use have focused on the excitement of interaction...the most potentially interesting, challenging and profound change implied by the ubiquitous computing era is a focus on calm.\" [46]. Given the likelihood that computers will be everywhere, in our environments and even embedded in our bodies, he argued that they better \"stay out of the way\" and not overburden us in our everyday lives. In contrast, his picture of calm technology portrayed a world of serenity, comfort and awareness, where we are kept perpetually informed of what is happening around us, what is going to happen and what has just happened. Information would appear in the centre of our attention when needed and effortlessly disappear into the periphery of our attention when not.\r\nNow regarded as the forefather of UbiComp, Weiser has inspired governments, researchers and developers across the globe. Most prominent was the European Community\'s Disappearing Computer initiative in the late 90s and early 2000s, that funded a large number of research projects to investigate how information technology could be diffused into everyday objects and settings and to see how this could lead to\r\nP. Dourish and A. Friday (Eds.): Ubicomp 2006, LNCS 4206, pp. 404 ­ 421, 2006. © Springer-Verlag Berlin Heidelberg 2006\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 405\r\nnew ways of supporting and enhancing people\'s lives that went above and beyond what was possible using desktop machines. Other ambitious and far-reaching projects included MIT\'s Oxygen, HP\'s CoolTown, IBM\'s BlueEyes, Philips Vision of the Future and attempts by various telecom companies and academia to create the ultimate `smart home\', e.g., Orange-at-Home and Aware Home. A central aspiration running through these early efforts was that the environment, the home, and our possessions would be aware, adapt and respond to our varying comfort needs, individual moods and information requirements. We would only have to walk into a room, make a gesture or speak aloud and the environment would bend to our will and respond or react as deemed appropriate for that point in time.\r\nConsiderable effort has gone into realizing Weiser\'s vision in terms of developing frameworks, technologies and infrastructures. Proactive computing was put forward as an approach to determine how to program computers to take the initiative to act on people\'s behalf [43]. The environment has been augmented with various computational resources to provide information and services, when and where desired, with the implicit goal of \"assisting everyday life and not overwhelming it\" [1]. An assortment of sensors have been experimented with in our homes, hospitals, public buildings, physical environments and even our bodies to detect trends and anomalies, providing a dizzying array of data about our health, movements, changes in the environment and so on. Algorithms have been developed to analyze the data in order for inferences to be made about what actions to take for people. In addition, sensed data is increasingly being used to automate mundane operations and actions that we would have done in our everyday worlds using conventional knobs, buttons and other physical controls. For example, our favorite kind of music or TV show that we like to exercise to will automatically play as we enter a gym. Sensed data is also being used to remind us of things we often forget to do at salient times, such as detecting the absence of milk in the fridge and messaging us to buy a carton when passing the grocery store.\r\nBut, as advanced and impressive as these endeavors have been they still do not match up to anything like a world of calm computing. There is an enormous gap between the dream of comfortable, informed and effortless living and the accomplishments of UbiComp research. As pointed out by Greenfield [20] \"we simply don\'t do `smart\' very well yet\" because it involves solving very hard artificial intelligence problems that in many ways are more challenging than creating an artificial human [26]. A fundamental stumbling block has been harnessing the huge variability in what people do, their motives for doing it, when they do it and how they do it. Ethnographic studies of how people manage their lives ­ ranging from those suffering from Alzheimer\'s Disease to high-powered professionals ­ have revealed that the specifics of the context surrounding people\'s day-to-day living are much more subtle, fluid and idiosyncratic than theories of context have led us to believe [40]. This makes it difficult, if not impossible, to try to implement context in any practical sense and from which to make sensible predictions about what someone is feeling, wanting or needing at a given moment. Hence, while it has been possible to develop a range of simple UbiComp systems that can offer relevant information at opportune moments (e.g., reminding and recommending to us things that are considered useful and important) it is proving to be much more difficult to build truly smart systems that can understand or accurately model people\'s behaviors, moods and intentions.\r\n\r\n406 Y. Rogers\r\nThe very idea of calm computing has also raised a number of ethical and social concerns. Even if it was possible for Weiser\'s dream to be fulfilled would we want to live in such a world? In particular, is it desirable to depend on computers to take on our day-to-day decision-making and planning activities? Will our abilities to learn, remember and think for ourselves suffer if we begin to rely increasingly on the environment to do them for us? Furthermore, how do designers decide which activities should be left for humans to control and which are acceptable and valuable for the environment to take over responsibility for?\r\nIn this paper I argue that progress in UbiComp research has been hampered by intractable computational and ethical problems and that we need to begin taking stock of both the dream and developments in the field. In particular, we need to rethink the value and role of calm and proactive computing as main driving forces. It is without question that Weiser\'s enormous legacy will (and should) continue to have an impact on UbiComp developments. However, sufficient time has passed since his untimely death and it should be possible now for researchers to take a critical stance. As part of this exercise, I propose that the field needs to broaden its scope, setting and addressing other goals that are more attainable and down-to-earth. New agendas need also to be outlined that can guide, stimulate and challenge UbiComp (and other) researchers and developers, building upon the growing body of research in the field.\r\nTo this end, I propose one such alternative agenda which focuses on designing UbiComp technologies for engaging user experiences. It argues for a significant shift from proactive computing to proactive people; where UbiComp technologies are designed not to do things for people but to engage them more actively in what they currently do. Rather than calm living it promotes engaged living, where technology is designed to enable people to do what they want, need or never even considered before by acting in and upon the environment. Instead of embedding pervasive computing everywhere in the environment it considers how UbiComp technologies can be created as ensembles or ecologies of resources, that can be mobile and/or fixed, to serve specific purposes and be situated in particular places. Furthermore, it argues that people rather than computers should take the initiative to be constructive, creative and, ultimately, in control of their interactions with the world ­ in novel and extensive ways.\r\nWhile this agenda might appear to be a regressive step and even an anathema to some ardent followers of Weiser\'s vision, I argue that it (and other agendas) will turn out to be more beneficial for society than persisting with following an unrealistic goal. Current technological developments together with emerging findings from user studies, showing how human activities have been positively extended by `bounded\' (as opposed to pervasive) technologies, suggest that much can be gained from reconceptualizing UbiComp in terms of designing user experiences that creatively, excitedly, and constructively extend what people currently do. This does not mean that the main tenet of Weiser\'s vision be discarded (i.e., computers appearing when needed and disappearing when not) but rather we begin to entertain other possibilities ­ besides calmness ­ for steering UbiComp research. Examples include extending and supporting personal, cognitive and social processes such as habit-changing, problemsolving, creating, analyzing, learning or performing a skill. Ultimately, research and development should be driven by a better understanding of human activity rather than\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 407\r\nwhat has tended to happen, namely, \"daring to intervene, clumsily, in situations that already work reasonably well\" [20, p231].\r\nIn the remainder of this paper I offer a constructive critique of Weiser\'s vision and the subsequent research that has followed in its footsteps. I then outline an alternative agenda for UbiComp, highlighting pertinent questions, concerns and illustrative examples of how it can be achieved.\r\n2 Weiser\'s Vision Revisited and Early Research\r\nTo illustrate how his early vision of ubiquitous computing could work, Weiser [47] presented a detailed scenario about a day in the life of Sal, an executive single mother. The scenario describes what Sal gets up to, as she moves from her domestic world to her work place, during which she is perpetually informed of the goings on of her family, neighbors, fellow citizens and work colleagues. With this knowledge she is able to keep up-to-date, avoid obstacles, make the most of her time and conduct her work ­ all in smooth and effective ways. The scenario emphasizes coziness, comfort and effortlessness:\r\n\"Sal awakens: she smells coffee. A few minutes ago her alarm clock, alerted by her restless rolling before waking, had quietly asked \"coffee?\", and she had mumbled \"yes.\" \"Yes\" and \"no\" are the only words it knows.\r\nSal looks out her windows at her neighborhood. Sunlight and a fence are visible through one, but through others she sees electronic trails that have been kept for her of neighbors\' coming and going during the early morning. Privacy conventions and practical data rates prevent displaying video footage, but time markers electronic tracks on the neighborhood map let Sal feel cozy in her street.\"\r\nIn this small excerpt we see how the world evolves around Sal\'s assumed needs, where computers, cameras and sensors are embedded into her world to make her life super efficient, smooth and calm. It is as if she glides through life, where everything is done or laid out for her and whenever there is potential for frustration, such as a traffic jam or parking problem, the invisible computers come to her rescue and gently inform her of what to do and where to go. It is worth drawing an analogy here with the world of the landed aristocracy in Victorian England who\'s day-to-day live was supported by a raft of servants that were deemed to be invisible to them. This scenario also highlights the ethical issues that such an informed world needs to address, namely the importance of establishing appropriate levels of privacy that are considered acceptable by a community (e.g., having abstract digital trails rather than video footage to ensure anonymity).\r\nThe core topics raised in Weiser\'s seminal papers have motivated much subsequent UbiComp research. Most prominent themes are context-aware computing, ambient/ubiquitous intelligence and recording/tracking and monitoring. (N.B. It should be noted that these are not mutually exclusive but overlap in the aims and methods used.)\r\n2.1 Context-Aware Computing\r\nContext-aware computing focuses on detecting, identifying and locating people\'s movements, routines or actions with a view to using this information to provide\r\n\r\n408 Y. Rogers\r\nrelevant information that may augment or assist a person or persons. Many projects have been conducted under this heading to the extent that it has been noted that ubiquitous computing is sometimes called context-aware computing [12]. In a nutshell, context is viewed as something that can be sensed and measured using location, time, person, activity type and other dimensions. An example of an early context-sensitive application was comMotion that used location information and a speech output system to inform people when they were driving or cycling past a store to buy the groceries they needed [30].\r\nA motivation behind much context-aware computing is to find ways of compensating for limitations in human cognition, e.g., attention, memory, learning, comprehension, and decision-making, through the use of sensor-based and computational tools. For example, augmented cognition ­ originating in military research ­ seeks to develop methods \"to open bottlenecks and address the biases and deficits in human cognition\" by continually sensing the ongoing context and inferring what strategies to employ to help people in their tasks [5].\r\nKey questions in context-aware computing concern what to sense, what form and what kind of information to represent to augment ongoing activities. A number of location and tagging technologies have been developed, such as RFID, satellite, GPS and ultrasonics, to enable certain categories of information to be tracked and detected. Many of these, however, have been beset with detection and precision limitations, sometimes resulting in unreliable and inaccurate data. Recent advances in cognitive radio technology that is software defined (SDR), promises to be more powerful; wireless systems will be able to locate and link to locally unused radio frequency, based on the ability to sense and remember various factors, such as human behavior, making them more dependable and more aware of their surroundings [4]. The advocates of this new technology portray its potential for highly complex settings, such as combat war zones to help commanders from different friendly forces stay appraised of the latest situation, through voice, data and video links, thereby reducing collateral damage [4].\r\nWhile newer technological developments may enable more accurate data to be detected and collected it is questionable as to how effectively it can be used. It still involves Herculean efforts to understand, interpret and act upon in real-time and in meaningful ways. Context-aware systems that attempt to guide a person through certain activities require models of human behavior and intentionality that are based on rationality and predictability [40]. However, as already mentioned, people often behave in unpredictable and subtle ways in their day-to-day contexts. Therefore, it is likely that context-aware systems will only ever be successful in highly constrained settings.\r\n2.2 Ambient and Ubiquitous Intelligence\r\nAnother dominant theme that has emerged in the field of UbiComp is ubiquitous or ambient intelligence, i.e., computational intelligence that is part of both the physical and the digital worlds. This approach follows on from work in artificial intelligence. The phrase `right place/right time/right means\' has been sloganized with visions of smart worlds and smart things, embedded with intelligence, that will predict people\'s needs and react accordingly [25]. Instead of reaching for the remote to change the TV\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 409\r\nchannel the smart entertainment system will do it for us, instead of browsing the web the smart internet will find the information we need and so on. Just as it is becoming increasingly common place for supermarkets to automatically open their doors as we walk towards them, toilets to flush when we stand up and taps to release water as we wave our hands under them it is envisioned that information will appear on our TVs, watches, walls, and other displays as and when needed (e.g., children will be alerted of dangers and tourists will be informed of points of interest when walking through an unfamiliar city).\r\nHowever, similar to context-aware computing, ambient intelligence is proving to be a hard nut to crack. While there have been significant advances in computer vision, speech recognition and gesture-based detection, the reality of multimodal interfaces ­ that can predict and deliver with accuracy and sensitivity what is assumed people want or need ­ is a long way off. One of the most well known attempts at implementing ambient intelligence was IBM\'s BlueEyes project, that sought to develop computers that could \"see\" and \"feel\" like humans. Sensing technology was used to identify a person\'s actions and to extract key information that was then analyzed to determine the person\'s physical, emotional, or informational state. This was intended to be used to help make people \"more productive by performing expected actions or by providing expected information.\" The success of the BlueEyes project, however, was limited; an example of an achievement that is posted on its website is of a television that would turn itself on when a person in the room made eye contact with it. To turn it off, the person could `tell\' it to switch off.\r\nSuch meager accomplishments in both context-aware computing and ambient intelligence reflect just how difficult it can be to get a machine to behave like a human. But it is essential that such systems be accurate for them to be accepted by humans in their everyday context. Reading, interpreting and acting upon people\'s moods, intentions, desires, etc, at any given moment in an appropriate way is a highly developed human skill that when humans get it wrong can lead to misunderstanding. When a ubiquitous computing system gets it wrong ­ which is likely to be considerably more frequent ­ it is likely to be more frustrating and we are likely to be less forgiving. For example, when the system decides to switch on the TV because we happen momentarily to stare into space while reading a book, it is likely to be unnerving and extremely annoying, especially if `it\' persistently gets it wrong.\r\n2.3 Recording, Tracking and Monitoring\r\nThe push towards developing assistive applications through sensing and alerting has been most marked for vulnerable people; a number of UbiComp systems have been built to constantly check up on the elderly, the physically and mentally disabled [34]. The movements, habits, health and mishaps of such people are recorded, tracked and presented via remote monitors to the families, carers and other people responsible for them, who can then use the information to make decisions about whether to intervene or administer alternative forms of medical care or help. In particular, there has been a move towards developing ubiquitous computing systems to aid elderly people, who need to be cared for, by helping them take their medicines regularly, checking up on their physical health, monitoring their whereabouts and detecting when they have fallen over [e.g., 13].\r\n\r\n410 Y. Rogers\r\nA number of assisted living applications and services has also been developed to help people with loss of vision or deteriorating memory to be more independent in their lives. For example, Cyber Crumbs was designed to help people with progressive vision loss find their way around a building using a reader badge system that reads out directions and warns of obstacles, such as fire hydrants [39]. Cook\'s Collage was developed as an aid for people with memory loss. It replays a series of digital still images in a comic strip reel format depicting people\'s cooking actions in situ, intended to help them remember if they have forgotten a step (e.g., adding a particular ingredient) after being distracted [45].\r\nA reason for there being so much interest in helping the less able in UbiComp is that explicit needs and benefits can be readily identified for these user groups. Moreover, there is an assumption that pervasive technologies offer more flexibility and scope for providing solutions compared with other computing technologies since they can sense, monitor and detect people\'s movements, bodily functions, etc., in ways not possible before. There is a danger, however, that such techniques may probe too far into the lives of less able people resulting in ­ albeit unintentionally ­ `extreme\' forms of recording, tracking and monitoring that these people may have no control over. For example, consider the extent to which a group of researchers went to in order to help with the care of old people in a residential care home [6]. A variety of monitoring devices were installed in the home, including badges on the patients and the caregivers and switches on the room doors that detected when they were open or closed. Load sensors were also used to measure and monitor weight changes of people while in their beds; the primary aim was to track trends in weight gain or loss over time. But the sensors could also be used to infer how well someone was sleeping. If significant movement was detected during the night this could enable a caregiver to see whether the person was having trouble sleeping (and if there was a huge increase in weight this could be inferred as someone else getting in or on the bed).\r\nSuch panopticon developments elicit a knee-jerk reaction of horror in us. While the motives behind such projects are altruistic they can also be naïve, overlooking how vulnerable people\'s privacy and self-respect may be being violated. Not surprisingly, there has been enormous concern by the media and other social scientists about the social implications of recording, tracking and re-representing people\'s movements, conversations, actions and transactions. Inevitably, a focus has been on the negative aspects, namely a person\'s right to privacy being breached. Is it right to be videoing and sensing people when sleeping, eating, etc., especially when they are not at their best [2]? Is it right to be providing information to other family members about their granny\'s sleeping habits, especially if it can be inferred from the sensed data that she might have got into bed with another patient, which none of the vested parties might want to share or let the others know about.\r\nWhile most projects are sensitive to the privacy and ethical problems surrounding the monitoring of people, they are not easy to solve and have ended up overwhelming UbiComp research. Indeed, much of the discussion about the human aspects in the field has been primarily about the trade-offs between security and privacy, convenience and privacy, and informedness and privacy. This focus has often been at the expense of other human concerns receiving less airing, such as how recording, tracking and re-representing movements and other information can be used to facilitate social and cognitive processes.\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 411\r\nMy intention here is not to diminish the importance of awareness, ambience and monitoring to detect and inform people in their everyday lives, together with the ethical and social issues they raise. Rather, my overview of the projects in these areas has revealed how difficult it is to build calm computing systems and yet the attempts have largely dominated the field of UbiComp. Those that have tried have fallen short, resulting in prototype systems that can sometimes appear to be trivial or demeaning. Conversely, there has been less focus on other areas of research that could prove to be easier to achieve and potentially of more benefit to society. The time is ripe for other directions to take center stage in UbiComp. One such avenue promoted here is to consider how humankind\'s evolved practices of science, learning, health, work and play can be enhanced. This involves thinking about UbiComp not in terms of embedding the environment with all manner of pervasive technologies but instead as bounded ensembles of entities (e.g., tools, surfaces and lenses) that can be mobile, collaborative or remote, through which information, other people and the environment are viewed and interacted with when needed. Importantly, it argues for rethinking the nature of our relationship with the computer.\r\n3 A New Agenda for UbiComp: Engaging User Experiences\r\nI suggest here that it is highly profitable to recast UbiComp research in the context of a central motivation that computers were originally designed for, namely, as tools, devices and systems that can extend and engage people in their activities and pursuits. My reason for proposing this is based on the success of researchers who have started to take this approach. In particular, a number of user studies, exploring how UbiComp technologies are being appropriated, are revealing how the `excitement of interaction\' can be brought back in innovative ways; that is not frustrating and which is quite different from that experienced with desktop applications. For example, various mixed reality, physical-digital spaces and sensor-rich physical environments have been developed to enable people to engage and use multiple dynamic representations in novel ways: in scientific and working practices and in collaborative learning and experimental games. More extensive inquiries and decisions have been enabled in situ, e.g., determining the effects of deforestation in different continents and working out when is the best time to spray or pick grapes in a vineyard.\r\nRecently, world famous computer scientist John Seely Brown put forward his updated vision of UbiComp1 in a keynote, outlining `a common sense\' model that emphasizes how UbiComp can help to catalyze creativity [41]. He proposed that creating and learning be seen as integral to our work and leisure that are formed through recreation and appropriation activities. In a similar vein, I argue that it is timely to switch from a reactive view of people towards a more proactive one. Instead of augmenting the environment to reduce the need for humans to think for themselves about what to do, what to select, etc., and doing it for them, we should consider how UbiComp technologies can be designed to augment the human intellect so that people can perform ever greater feats, extending their ability to learn, make decisions, reason, create, solve complex problems and generate innovative ideas. Weiser\'s idea that\r\n1 John Seely Brown was a co-author of the paper written by Weiser on calm technology.\r\n\r\n412 Y. Rogers\r\ntechnologies be designed to be `so embedded, so fitting and so natural\' that we use them without thinking about them needs to be counter-balanced; we should also be designing them to be exciting, stimulating and even provocative ­ causing us to reflect upon and think about our interactions with them. While Weiser promoted the advantages of calm computing I advocate the benefits of engaging UbiComp experiences that provoke us to learn, understand and reflect more upon our interactions with technologies and each other.\r\nA central concern of the engaging UbiComp experiences agenda is to fathom out how best to represent and present information that is accessible via different surfaces, devices and tools for the activity at hand. This requires determining how to make intelligible, usable and useful, the recordings of science, medicine, etc., that are streaming from an increasing array of sensors placed throughout the world. It also entails figuring out how to integrate and replay, in meaningful and powerful ways, the masses of digital recordings that are begin gathered and archived such that professionals and researchers can perform new forms of computation and problem-solving, leading to novel insights. In addition, it involves experimenting more with creative and constructive uses of UbiComp technologies and archived digital material that will excite and even make people feel uncomfortable.\r\nIn terms of who should benefit, it is useful to think of how UbiComp technologies can be developed not for the Sal\'s of the world, but for particular domains that can be set up and customized by an individual firm or organization, such as for agriculture production, environmental restoration or retailing. At a smaller scale, it is important to consider how suitable combinations of sensors, mobile devices, shared displays, and computational devices can be assembled by non-UbiComp experts (such as scientists, teachers, doctors) that they can learn, customize and `mash\' (i.e., combine together different components to create a new use). Such toolkits should not need an army of computer scientists to set up and maintain, rather the inhabitants of ubiquitous worlds should be able to take an active part in controlling their set up, evolution and destruction. Their benefits should be clear: enabling quite different forms of information flow (i.e., ways and means of accessing information) and information management (i.e., ways of storing, recording, and re-using information) from older technologies, making it possible for non-UbiCompers to begin to see how to and subsequently develop their own systems that can make a difference to their worlds. In so doing, there should be an emphasis on providing the means by which to augment and extend existing practices of working, learning and science.\r\nAs quoted by Bruner [10] \"to assist the development of the powers of the mind is to provide amplification systems to which human beings, equipped with appropriate skills, can link themselves\" (p.53). To enable this to happen requires a better understanding of existing human practices, be it learning, working, communicating, etc. Part of this reconceptualization should be to examine the interplay between technologies and their settings in terms of practice and appropriation [15]. \"Practices develop around technologies, and technologies are adapted and incorporated into practices.\" (Dourish, 2001, p. 204). More studies are needed that examine what people do with their current tools and devices in their surrounding environments. In addition, more studies are needed of UbiComp technologies being used in situ or the wild ­ to help illuminate how people can construct, appropriate and use them [e.g., 16, 22, 23, 29].\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 413\r\nWith respect to interaction design issues, we need to consider how to represent and present data and information that will enable people to more extensively compute, analyze, integrate, inquire and make decisions; how to design appropriate kinds of interfaces and interaction styles for combinations of devices, displays and tools; and how to provide transparent systems that people can understand sufficiently to know how to control and interact with them. We also need to find ways of enabling professionals and laypeople alike to build, adapt and leverage UbiComp technologies in ways that extend and map onto their activities and identified needs.\r\nA more engaging and bounded approach to UbiComp is beginning to happen but in a scattered way. Three of the most promising areas are described below: (i) playful and learning practices, (ii) scientific practices and (iii) persuasive practices. They show how UbiComp technologies can be developed to extend or change human activities together with the pertinent issues that need to be addressed. Quite different practices are covered, reflecting how the scope of UbiComp can be broad but at the same time targeted at specific users and uses.\r\n3.1 Playful and Learning Practices\r\nOne promising approach is to develop small-scale toolkits and sandboxes, comprising interlinked tools, digital representations and physical artifacts that offer the means by which to facilitate creative authoring, designing, learning, thinking and playing. By a sandbox it is not meant the various senses it has been used in computing but more literally as a physical-digital place, kitted out with objects and tangibles to play and interact with. Importantly, these should allow different groups of people to participate in novel activities that will provoke and extend existing repertoires of technologyaugmented learning, playing, improvising and creating. An example of a promising UbiComp technology toolkit is PicoCrickets, developed at MIT Media Lab, arising from the work of Mitch Resnick and his colleagues. The toolkit comprises sensors, motors, lights, microcomputers, and other physical and electrical devices that can be easily programmed and assembled to make them react, interact and communicate, enabling \"musical sculptures, interactive jewelry, dancing creatures and other playful inventions\" to be created by children and adults alike. An advantage of such lightweight, off-the-shelf tangible toolkits is that they offer many opportunities for different user groups (e.g., educators, consultants) to assemble and appropriate in a range of settings, such as schools, waiting rooms, playgrounds, national parks, and museums.\r\nA nagging question, however, is how do the benefits of such UbiComp toolkits and sand boxes compare with those offered by more conventional ones ­ that are much cheaper and more practical to make? Is it not the case that children can be highly creative and imaginative when given simply a cardboard box to play with? If so, why go to such lengths to provide them with new tools? The debate is redolent of whether it is better for children to read a book or watch a 3D Imax movie. One is not necessarily better than the other: the two provide quite different experiences, triggering different forms of imagination, enjoyment and reflection. Likewise, UbiComp and physical toys can both provoke and stimulate, but promote different kinds of learning and collaboration among children. However, a benefit of UbiComp toolkits over physical artifacts is that they offer new opportunities to combine physical interaction, through manipulation of objects or tools or through physical body postural movement and\r\n\r\n414 Y. Rogers\r\nlocation, with new ways of interacting, through digital technology. In particular, they provide different ways of thinking about the world than interacting solely with digital representations or solely with the physical world. In turn, this can encourage or even enhance further exploration, discovery, reflection and collaboration [35].\r\nExamples of projects that have pioneered the design of novel physical-digital spaces to facilitate creativity and reflection include the Hunting of the Snark [32], Ambient Wood [36], RoomQuake [33] Savannah [17], Environmental Detectives [27], Drift Table [19] and Feeding Yoshi [7]. Each of these have experimented with the use of mobile, sensor and fixed technologies in combination with wireless infrastructures to encourage exploration, invention, and out of the box thinking.\r\nThe Hunting of the Snark adventure game provoked young children into observing, wondering, understanding, and integrating their fragmented experiences of novel physical-digital spaces that subsequently they reflected upon and shared as a narrative with each other. A combination of sensor-based, tangible, handheld and wireless technologies was used to create the physical-digital spaces, where an imaginary virtual creature was purported to be roaming around in. The children had to work out how to entice the creature to appear in them and then gather evidence about its personality, moods, etc, by walking with it, feeding it and flying with it. Similarly, Savannah was designed as a physical-digital game to encourage the development of children\'s conceptual understanding of animal behavior and interactions in an imaginary virtual world. The project used GPS and handheld computers to digitally overlay a school playing field with a virtual plain. Children took on the roles of lions, had to hunt animals in the virtual savannah and capture them to maintain energy levels. After the game, the children reflected on their experiences by interacting with a visualization on a large interactive whiteboard, that showed the trails they made in the Savannah and the sounds and images that they encountered at specific place.\r\nThe Ambient Wood project used an assortment of UbiComp technologies to encourage more self-initiation in inquiry and reflective learning. Various wireless and sensor technologies, devices and representational media were combined, designed and choreographed to appear and be used in an `ambient\' woodland. Several handcrafted listening, recording and viewing devices were created to present certain kinds of digital augmentations, such as sounds of biological processes, images of organisms, and video clips of life cycles. Some of these were triggered by the children\'s exploratory movements, others were collected by the children, while still others were aggregated and represented as composite information visualizations of their exploratory behavior. RoomQuake was designed to encourage children to practice scientific investigatory practices: an earthquake was simulated in a classroom using a combination of interconnected ambient media, string and physical styrofoam balls. The ambient media provided dynamic readings of the simulated earthquakes, which students then rerepresented as physical models using the physical artifacts. The combination of computer-based simulations and physical-based artifacts enabled the whole class to take part in the measuring, modeling, interpreting, sparking much debate and reflection among the children about the seismic events.\r\nAs part of the Equator collaboration, a number of innovative `seamful games\' have been developed. The inherent limitations of ubiquitous technologies have been deliberately exploited to provoke the players into thinking about and acting upon their significance to the ongoing activity. Two examples are Treasure in which players had\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 415\r\nto move in and out of a wireless network connectivity to collect and then deposit gold tokens and Feeding Yoshi where the players were required to feed virtual creatures scattered around a city with virtual fruits that popped up on their displays as a result of their location and activity therein.\r\nEvaluations of this emerging genre of physical-digital spaces for learning and playing have been positive, highlighting enhanced understanding and an immense sense of engagement. Children and adults have been able to step back and think about what they are doing when taking part in the game or learning experience, examining the rationale behind their choices when acting out and interacting with the UbiCompbased technologies in the space. However, many of the pioneering projects were technology, resource and researcher intensive. While guidance is now beginning to appear to help those wanting to design UbiComp-based learning and playing experiences [e.g., 9, 36] we need also to strive towards creating the next generation of physicaldigital spaces and toolkits that will be as easy, cheap and popular to construct as Lego kits once were.\r\n3.2 Scientific Practices\r\nAnother area where UbiComp has great potential for augmenting human activities is the practice of scientific inquiry and research. Currently, the sciences are going through a major transformation in terms of how they are studied and the computational tools that are used and needed. Microsoft\'s 2020 Science report ­ a comprehensive vision of science for the next 14 years written by a group of internationally distinguished scientists ­ outlines this paradigm shift [31]. It points out how new conceptual and technological tools are needed that scientists from different fields can \"understand and learn from each other\'s solutions, and ultimately for scientists to acquire a set of widely applicable complex problem solving capabilities\". These include new programming, computational, analysis and publication tools. There is much scope, too, for utilizing UbiComp technologies to enhance computation thinking, through integrating sensor-based instrumentation in the medical, environmental and chemical sciences. The ability to deliver multiple streams of dynamic data to scientists, however, needs to be matched by powerful interfaces that allow them to manipulate and share them in new ways, from any location whether in the lab or in the field.\r\nAreas where there is likely to be obvious benefits to scientists through the integration of UbiComp and computational tools are environmental science and climate change. These involve collaborative visualization of scientific data, mobile access to data and capture of data from sensors deployed in the physical world. Being able to gain a bigger, better and more accurate picture of the environmental processes may help scientists make more accurate predictions and anticipate more effectively natural disasters, such as tsunamis, volcanoes, earthquakes and flooding. However, it may not simply be a case of more is more. New ways of managing the burgeoning datasets needs to be developed, that can be largely automated, but which also allows scientists to have effective windows, lenses etc., into so that they can interpret and make intelligible inferences from them at relevant times.\r\nThe 2020 report notes how tomorrow\'s scientists will need to make sense of the masses of data by becoming more computationally literate ­ in the sense of knowing how to make inferences from the emerging patterns and anomalies that the new\r\n\r\n416 Y. Rogers\r\ngeneration of software analysis tools provide. To this end, a quite different mindset is needed in schools for how science is taught. The design of new learning experiences that utilize UbiComp technologies, both indoors and outdoors, need to be developed to seed in young children the sense of what is involved in practicing new forms of complex, computational science. An example of how this can be achieved is the embedded phenomena approach; scientific phenomena are simulated using UbiComp technologies, for long periods of time, to create opportunities for groups of students to explore `patient\' science [32]. Essentially, this involves the accumulation, analysis and representation of data collected from multiple computational devices over extended periods of observation in the classroom or other sites. In so doing, it allows students to engage in the collaborative practice of scientific investigation that requires hard computational thinking but which is also exciting, creative and authentic. A core challenge, therefore, is to find ways of designing novel science learning experiences that capitalize on the benefits of combining UbiComp and PC technologies that can be used over extended periods.\r\n3.3 Persuasive Practices\r\nThe third area where there is much potential for using UbiComp technologies to engage people is as part of self-monitoring and behavioral change programs. While a range of persuasive technologies (e.g., adverts, websites, posters) has already been developed to change people\'s attitudes and behaviors, based on models of social learning [18], UbiComp technologies provide opportunities for new techniques. Specifically, mobile devices, such as PDAs coupled with on-body sensors, can be designed to enable people to take control and change their habits or lifestyles to be healthier by taking account of and acting upon dynamically updated information provided by them. For example, Intille and his group are exploring how mobile computational tools for assessing behavioral change, based on social psychology models, can be developed to motivate physical activity and healthy eating.\r\nA key question that needs to be addressed is whether UbiComp technologies are more (or less) effective compared with other technologies in changing behavior. A diversity of media-based techniques (e.g., pop-up warning messages, reminders, prompts, personalized messages) has been previously used to draw people\'s attention to certain kinds of information to change what they do or think at a given point. In terms of helping people give up habits (e.g., smoking, excessive eating) they have had mixed results since people often relapse. It is in the long-term context that UbiComp technologies may prove to be most effective, being able to monitor certain aspects of people\'s behavior and represent this information at critically weak moments in a cajoling way. A constant but gentle `nagging\' mechanism may also be effective at persuading people to do something they might not have otherwise done or to not to do something they are tempted to do. For example, a collaborative cell phone application integrated with a pedometer was used to encourage cliques of teenage girls to monitor their levels of exercise and learn more about nutrition in the context of their everyday activities [44]. The software was designed to present the monitored process (e.g., walking) in a way that made it easy for the girls to compute and make inferences of how well they were doing in terms of the number of steps taken relative to each other. A preliminary study showed that such a collaborative self-monitoring system was\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 417\r\neffective at increasing the girl\'s awareness of their diet, level of exercise and enabling them to understand the computations involved in burning food during different kinds of exercise. But most significantly, it enabled the girls to share and discuss this information with each other in their private clique, capitalizing on both the persuasive technology and peer pressure.\r\nIncorporating fun into the interface can also be an effective strategy; for example, Nintendo\'s Pocket Pikachu with pedometer attached was designed to motivate children into being more physically active on a consistent basis. The owner of the digital pet that `lives\' in the device is required to walk, run or jump each day to keep it alive. If the owner does not exercise for a week the virtual pet becomes unhappy and eventually dies. This can be a powerful means of persuasion given that children often become emotionally attached to their virtual pets, especially when they start to care for them.\r\nUbiComp technologies can also be used to reduce bad habits through explicitly providing dynamic information that someone would not have been aware of otherwise. In so doing, it can make them actively think about their behavior and modify it accordingly. The WaterBot system was developed using a special monitoring and feedback device to reduce householder\'s usage of water in their homes ­ based on the premise that many people are simply unaware of how wasteful they are [3]. A sensorbased system was developed that provided positive auditory messages and chimes when the tap was turned off. A central idea was to encourage members of the household to talk to one another about their relative levels of water usage provided by the display and to try to out do one another in the amount of water used.\r\nBut to what extent do UbiComp technologies, designed for persuasive uses, differ from the other forms of monitoring that were critiqued earlier in the paper? A main difference is that there is more active involvement of those being monitored in attaining their desired behavior change compared with those who were being monitored and assisted in care homes. The objective is to enable people, themselves, to engage with the collected information, by monitoring, understanding, interpreting and acting upon it ­ and not the environment or others to act upon their behalf. Much of the research to date in UbiComp and healthcare has focussed on automated biomonitoring of physiological processes, such as EEGs and heart rate, which others, i.e., specialists, examine and use to monitor their patient\'s health. In contrast, persuasive technologies are intended to provide dynamic information about a behavioral process that will encourage people from doing or not doing something, by being alerted and/or made aware of the consequences of what they are about to do. Moreover, designing a device to be solely in the control of the users (and their social group) enables them to be the owners of the collected data. This circumvents the need to be centrally concerned with privacy issues, allowing the focus of the research to be more oriented towards considering how best to design dynamically updated information to support cognitive and social change. A challenge, however, in this area is for long term studies to be conducted that can convincingly show that it is the perpetual and time-sensitive nature of the sensed data and the type of feedback provided that contributes to behavioral modification.\r\n\r\n418 Y. Rogers\r\n4 Conclusions\r\nMany of the research projects that have followed in the footsteps of Weiser\'s vision of calm computing have been disappointing; their achievements being limited by the extent to which they have been able to program computers to act on behalf of humans. Just as `strong\' AI failed to achieve its goals ­ where it was assumed that \"the computer is not merely a tool in the study of the mind; rather, the appropriately programmed computer really is a mind\" [41], it appears that `strong\' UbiComp is suffering from the same fate. And just as `weak\' AI2 revived AI\'s fortunes, so, too, can `weak\' UbiComp bring success to the field. This will involve pursuing more practical goals and addressing less ambitious challenges; where ensembles of technologies are designed for specific activities to be used by people in bounded locations. To make this happen, however, requires moving from a mindset that wants to make the environment smart and proactive to one that enables people, themselves, to be smarter and proactive in their everyday and working practices. Three areas of research were suggested as to how this could be achieved; but, equally, there are others where there is much potential for enhancing and extending human activities (e.g., vineyard computing [11], firefighting [24] and sports). As part of the expansion of UbiComp, a wider range of human aspects should be considered, drawing upon alternative theory, guiding frameworks and metaphors [c.f. 8, 15]. To enable other human concerns to become more prominent, however, requires the hefty weight of privacy and other related ethical issues on UbiComp\'s shoulders to be lessoned.\r\nThe `excitement of interaction\' that Weiser suggested forsaking in the pursuit of a vision of calm living should be embraced again, enabling users, designers and researchers to participate in the creation of a new generation of user experiences that go beyond what is currently possible with our existing bricolage of tools and media. We should be provoking people in their scientific, learning, analytic, creative, playing and personal activities and pursuit. Finally, while we have been privileged to have had such a great visionary, whose legacy has done so much to help shape the field, it is timely for a new set of ideas, challenges and goals to come to the fore and open up the field.\r\nAcknowledgements\r\nThanks to Tom Rodden for his suggestions on an earlier draft and the anonymous reviewers for their constructive comments.\r\nReferences\r\n1. Abowd, G.D., Mynatt. E.D.: Charting past, present, and future research in ubiquitous computing. ACM Transactions on Computer-Human Interaction, 7 (2000) 29-58\r\n2. Anderson, K., Dourish, P.: Situated Privacies: Do you know where you mother [trucker] is? In Proceedings of the 11th International Conference on Human-Computer Interaction. Las Vegas. July 22-27, 2005\r\n2 Weak AI refers to the development of software programs to perform specific problem-solving or reasoning tasks that do not have to match the way humans do them.\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 419\r\n\r\n3. Arroyo, E., Bonnanni, L., Selker, T.: WaterBot: exploring feedback and persuasive tech-\r\n\r\nniques at the sink. In CHI Proceedings, ACM, New York, 631-639, 2005\r\n\r\n4. Ashley, S.: Cognitive Radio, Scientific American, (March 2006), 67-73\r\n\r\n5. Augmented Cognition International Society. http://www.augmentedcognition.org/, Re-\r\n\r\ntrieved on 30/03/2006\r\n\r\n6. Beckwith, R., Lederer, S.: Designing for one\'s dotage: UbiComp and Residential Care fa-\r\n\r\ncilities. Conference on the Networked Home and the Home of the Future (HOIT 2003), Ir-\r\n\r\nvine, CA: April 2003\r\n\r\n7. Bell, M., Chalmers, M., Barkhuus, L., Hall, M., Sherwood, S., Tennent, P., Brown. B.,\r\n\r\nRowland, D., Benford, S., Hampshire, A., Captra, M.: Interweaving mobile games with\r\n\r\neveryday life. In Proceedings of CHI\'06, Conference on Human Factors in Computing.\r\n\r\nACM Press, (2006) 417-426\r\n\r\n8. Bellotti, V., Back, M., Edwards, K., Grinter, R., Henderson. A., Lopes, C.: Making sense\r\n\r\nof sensing systems: five questions for designers and researchers. In Proceedings of\r\n\r\nCHI\'2002, ACM Press, (2002) 415-422\r\n\r\n9. Benford, S., Schnädelbach, H., Koleva, B., Anastasi, R., Greenhalgh, C., Rodden, T.,\r\n\r\nGreen, J., Ghali, A., Pridmore, T., Gaver, B., Boucher, A., Walker, B., Pennington, S.,\r\n\r\nSchmidt, A., Gellersen, H., Steed, A.: Expected, sensed, and desired: A framework for de-\r\n\r\nsigning sensing-based interaction. ACM Trans. Comput.-Hum. Interact. 12 (2005) 3-30\r\n\r\n10. Bruner, J.S. The Relevance of Education. Harmondsworth, Middlesex, UK. (1972)\r\n\r\n11. Burrell, J., Brooke, T., Beckwith, R.: Vineyard Computing: Sensor Networks in agricul-\r\n\r\ntural production, Pervasive Computing, 3(1) (2004) 38-45\r\n\r\n12. Chalmers, D., Chalmers, M., Crowcroft, J., Kwiatkowska, M., Milner, R., O\'Neill, E.,\r\n\r\nRodden, T., Sassone, V., Sloman, M.: Ubiquitous Computing: Experience, design and sci-\r\n\r\nence. Version 4. http://www-dse.doc.ic.ac.uk/Projects/UbiNet/GC/index.html Retrieved on\r\n\r\n30/03/2006\r\n\r\n13. Consolvo, S., Roessler, P., Shelton, B., LaMarca, A., Schilit, B., Bly, S.: Technology for\r\n\r\ncare networks for elders. Pervasive Computing 3 (2004) 22-29\r\n\r\n14. Digiens@U-City.:\r\n\r\nKorea\r\n\r\nmoves\r\n\r\ninto\r\n\r\nubiquitous\r\n\r\nmode.\r\n\r\nhttp://digiens.blogspot.com/2005/08/korea-moves-into-ubiquitous-mode.html. Retrieved\r\n\r\n30/03/2006\r\n\r\n15. Dourish, P.: Where the action is: the foundation of embodied interaction. MIT, Cambridge,\r\n\r\nMA., (2001)\r\n\r\n16. Dourish, P., Grinter, B., Delgado de la Flor, J., Joseph, M.: Security in the wild: user\r\n\r\nstrategies for managing security as an everyday, practical problem. Personal and Ubiqui-\r\n\r\ntous Computing, 8 (6) (2004) 391-401\r\n\r\n17. Facer, K., Joiner, R., Stanton, D., Reid, J., Hull, R., Kirk, D.: Savannah: mobile gaming\r\n\r\nand learning. Journal of Computer Assisted Learning, 20 (2004) 399-409\r\n\r\n18. Fogg, B.J.: Persuasive Technology: Using Computers to change what we think and do.\r\n\r\nMorgan Kaufmann Publishers, San Fransisco. (2003)\r\n\r\n19. Gaver, W. W., Bowers, J., Boucher, A., Gellersen, H., Pennington, S., Schmidt, A., Steed,\r\n\r\nA., Villars, N., Walker, B.: The drift table: designing for ludic engagement. In Proceedings\r\n\r\nof CHI Extended Abstracts (2004) 885-900.\r\n\r\n20. Greenfield, A.: Everyware: The Dawning Age of Ubiquitous Computing. New Riders,\r\n\r\nBerkeley, CA. (2006)\r\n\r\n21. Intel\r\n\r\nResearch\r\n\r\nat\r\n\r\nIntel:\r\n\r\nResearch\r\n\r\nSeattle.\r\n\r\nwww.intel.com/research/network/seattle_collab.htm. Retrieved on 20/03/2006.\r\n\r\n420 Y. Rogers\r\n22. Intille, S., Larson, K., Beaudin, J., Nawyn, J., Munguia Tapia, E., Kaushik, P.: A living laboratory for the design and evaluation of ubiquitous computing technologies. In Proceedings of CHI Extended Abstracts (2005) 1941-1944\r\n23. Intille, S.S., Bao, L., Munguia Tapia, E., Rondoni, J.: Acquiring in situ training data for context-aware ubiquitous computing applications. In Proceedings CHI (2004) 1-8\r\n24. Jiang, X., Chen, N.Y., Hong, J.I., Wang, K., Takayama, L.A., Landay, J.A.: Siren: Context-aware Computing for Firefighting. In Proceedings of Second International Conference on Pervasive Computing. Lecture Notes in Computer Science, Springer Berlin Heidelberg 87-105 (2004)\r\n25. Journal of Ubiquitous Computing and Intelligence. www.aspbs.com/juci.html Retrieved 20/03/2006/\r\n26. Kindberg, T., Fox, A.: System Software for Ubiquitous Computing. IEEE Pervasive Computing, 1 (1) (2002) 70-81\r\n27. Klopfer, E., K. Squire.: Environmental Detectives ­ The Development of an Augmented Reality Platform for Environmental Simulations. Educational Technology Research and Development. (2005)\r\n28. Krikke, J.: T-Engine: Japan\'s Ubiquitous Computing Architecture is ready for prime time. Pervasive Computing (2005) 4-9\r\n29. LaMarca, A., Chawathe, Y., Consolvo, S., Hightower, J., Smith, I., Scott, J., Sohn, T., Howard, J., Hughes, J., Potter, F., Tabert, J., Powledge, P., Borriello, G., Schilit. B.: Place Lab: Device Positioning Using Radio Beacons in the Wild, Intel Research, IRS-TR-04016, (2004) http://placelab.org/publications/pubs/IRS-TR-04-016.pdf\r\n30. Marmasse, N., Schmandt, C.: Location-aware information delivery with commotion, In HUC 2000 Proceedings, Springer-Verlag, (2000) 157-171\r\n31. Microsoft 2020 Science.: http://research.microsoft.com/towards2020science/. Retrieved 30/03/2006\r\n32. Moher, T.: Embedded Phenomena: Supporting science learning with classroom-sizeddistribution simulations. In Proceedings of CHI 2006\r\n33. Moher, T., Hussain, S., Halter, T., Kilb, D..: RoomQuake: embedding dynamic phenomena within the physical space of an elementary school classroom. Extended Abstracts, In Proceedings of CHI\'05, Conference on Human Factors in Computing Systems. ACM Press (2005) 1655-1668\r\n34. Mynatt, E., Melenhorst, A., Fisk, A.D., Rogers, W.: Aware technologies for aging in place: Understanding user needs and attitudes. Pervasive Computing (2004) 36-41\r\n35. Price, S. Rogers, Y. Let\'s get physical: the learning benefits of interacting in digitally augmented physical spaces. Journal of Computers and Education, 43 (2004) 137-151\r\n36. Rogers, Y., Muller, H.: A framework for designing sensor-based interactions to promote exploration and reflection. International Journal of Human-Computer Studies, 64 (1) (2005) 1-15\r\n37. Rogers, Y., Price, S., Fitzpatrick, G., Fleck, R., Harris, E., Smith, H., Randell, C., Muller, H., O\'Malley, C., Stanton, D., Thompson, M., Weal, M.: Ambient Wood: Designing new forms of digital augmentation for learning outdoors. In Proceedings of Interaction Design and Children, ACM (2004) 1-8\r\n38. Rogers, Y., Scaife, M., Harris, E., Phelps, T., Price, S., Smith, H., Muller, H., Randall, C., Moss, A., Taylor, I., Stanton, D., O\'Malley, C., Corke, G., Gabrielli, S.: Things aren\'t what they seem to be: innovation through technology inspiration. In Proceedings of DIS\'2002 Designing Interactive Systems, ACM Press, (2002) 373-379\r\n39. Ross, D.A.: Cyber Crumbs for successful aging with vision loss. Pervasive Computing, 3 (2004) 30-35\r\n\r\nMoving on from Weiser\'s Vision of Calm Computing 421\r\n40. Salvador, T., Anderson, K. Practical Considerations of Context for Context Based Systems: An Example from an Ethnographic Case Study of a Man Diagnosed with Early Onset Alzheimer\'s Disease. In UbiComp\'03 Proceedings, A.K. Dey et al. (Eds.), LNCS 2864, Springer-Verlag Berlin Heidelberg, 243-255, 2003\r\n41. Seely Brown, J.: Ubiquitous Computing and beyond ­ an emerging new common sense model. www.johnseelybrown.com/JSB.pdf. Retrieved 20/03/2006\r\n42. Stirling, B.: Without Vision, the People Perish. Speech Given at CRA Conference on Grand Research Challenges in Computer Science and Engineering. Airlie House, Warrenton, Virginia, June 23, 2002 www.cra.org/Activities/grand.challenges/sterling.html Retrieved 20/03/2006\r\n43. Tennenhouse, D.L. \"Proactive Computing,\" Communications of the ACM 43, No. 5, 43­ 50, 2000\r\n44. Toscos, T., Faber, A., An, S., Gandhi, M.; Chick Clique: Persuasive Technology to Motivate Teenage Girls to Exercise. In CHI\'06 Extended Abstracts on Human Factor in Computing Systems, ACM Press (2006) 1873-1878\r\n45. Tran, Q., Calcaterra, G., Mynatt, E.: Cook\'s Collage: Deja Vu Display for a Home Kitchen. In Proceedings of HOIT 2005, 15-32\r\n46. Weiser, M., Brown, J.S.: The coming age of calm technology. (1996) www.ubiq.com/hypertext/weiser/acmfuture2endnote.htm. Retrieved 20/03/2006/\r\n47. Weiser, M.: The computer for the 21st century. Scientific American (1991) 94­104\r\n\r\n',1,'Rogers','Yvonne Rogers',NULL,'http://yvonnerogers.com/wp-content/uploads/2014/07/Rogers_Ubicomp06.pdf',1,'10.1007/11853565_24','SpringerLink','Browse the entry in the Springer online library',1,NULL,0,0,NULL,NULL,0,0),(2,'koleva-orchestrating-a-mixed-reality-performance','2019-02-23 20:26:12','2019-09-24 11:58:17','2019-02-23 20:25:34',NULL,1,'published','[]','Orchestrating a Mixed Reality Performance','A study of a professional touring mixed reality performance called Desert Rain yields insights into how performers orchestrate players’ engagement in an interactive experience. Six players at a time journey through an extended physical and virtual set. Each sees a virtual world projected onto a screen made from a fine water spray. This acts as a traversable interface, supporting the illusion that performers physically pass between real and virtual worlds. Live and video-based observations of Desert Rain, coupled with interviews with players and the production team, have revealed how the performers create conditions for the willing suspension of disbelief, and how they monitor and intervene in the player’s experience without breaking their engagement. This involves carefully timed performances and “off-face” and “virtual” interventions. In turn, these are supported by the ability to monitor players’ physical and virtual activity through asymmetric interfaces.','Boriana Koleva, Ian Taylor, Steve Benford, Mike Fraser, Chris Greenhalgh, Holger Schnädelbach, Dirk vom Lehn, Christian Heath, Ju Row-Farr, and Matt Adams. 2001. Orchestrating a mixed reality performance. In *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems* (CHI \'01). ACM, New York, NY, USA, 38-45. https://doi.org/10.1145/365024.365033','Papers\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\nOrchestrating a Mixed Reality Performance\r\n\r\nBoriana Koleva, Ian Taylor, Steve Benford, Mike Fraser,\r\nChris Greenhalgh, Holger Schnädelbach School of Computer Science The University of Nottingham Nottingham NG7 2RD, UK {bnk, imt, sdb, mcf, cmg, hms}\r\n@cs.nott.ac.uk\r\n\r\nDirk vom Lehn, Christian Heath The Management Centre Kings College London Franklin-Wilkins Building London SE1 8WA, UK {dirk.vom_lehn, christian.heath}\r\n@kcl.ac.uk\r\n\r\nJu Row-Farr, Matt Adams Blast Theory Toynbee Studios 28 Commercial Street London, E1 6LS,UK blasttheory@easynet.co.uk\r\n\r\nABSTRACT A study of a professional touring mixed reality performance called Desert Rain yields insights into how performers orchestrate players\' engagement in an interactive experience. Six players at a time journey through an extended physical and virtual set. Each sees a virtual world projected onto a screen made from a fine water spray. This acts as a traversable interface, supporting the illusion that performers physically pass between real and virtual worlds. Live and video-based observations of Desert Rain, coupled with interviews with players and the production team, have revealed how the performers create conditions for the willing suspension of disbelief, and how they monitor and intervene in the player\'s experience without breaking their engagement. This involves carefully timed performances and \"off-face\" and \"virtual\" interventions. In turn, these are supported by the ability to monitor players\' physical and virtual activity through asymmetric interfaces.\r\nKeywords Mixed reality, performance, traversable interfaces\r\nINTRODUCTION The increasing use of computer technology to create engaging public experiences in galleries, museums, exploratoria and theme parks raises new challenges for HCI. How does the design of such experiences differ from that of more traditional workplace technologies? Should a new breed of HCI practitioner ­ the \"imagineer\" ­ address new aspects of human-computer interaction?\r\nThis paper explores HCI issues that have emerged from the study of a professional public experience; a touring mixed\r\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. SIGCHI\'01, March 31-April 4, 2001, Seattle, WA, USA. Copyright 2001 ACM 1-58113-327-8/01/0003...$5.00.\r\n\r\nreality performance called Desert Rain. A combination of interviews, and direct and video observations of participants have been conducted throughout the touring process. These have revealed the ways in which the production team orchestrates the participants\' experience, especially how the design of Desert Rain affords different opportunities of monitoring and subtly intervening in this experience without disrupting their engagement.\r\nAN INTRODUCTION TO DESERT RAIN Desert Rain was developed as joint venture between the performance art group Blast Theory, The University of Nottingham and Nottingham NOW Contemporary Art Festival. Desert Rain is a combination of performance, installation and computer game. Six players are sent on a mission into a virtual world to find six human targets. They explore motels, deserts and underground bunkers, communicating with each other through a live audio link. Once in the virtual world, they have twenty minutes to find their allocated targets, complete the mission, and get to the final room, where the identities of the targets are revealed. The virtual world is projected onto six rain curtains, screens made of water through which performers and players physically pass.\r\nThe artistic foundation of Desert Rain The central artistic concern of Desert Rain is virtual warfare, the blurring of the boundaries between real and virtual events, especially with regard to the portrayal of warfare on television news, in Hollywood\'s films and in computer games. Whilst remaining deeply suspicious of this kind of theoretical position, Desert Rain draws inspiration from Jean Baudrillard\'s assertion that the Gulf War did not actually take place because it was in fact a virtual event. Both the content and the form of Desert Rain are designed to provoke participants to reevaluate the boundaries between reality and fiction, and between the real and the virtual. As the players eventually discover, the targets are six people who have quite different perspectives on the Gulf war:\r\n\r\n38 Volume No. 3, Issue No. 1\r\n\r\nCHI 2001\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\n· an actor who was on holiday in Egypt at the time;\r\n· a soldier who served in the gulf war, driving a personnel carrier that collected Iraqi casualties;\r\n· a soldier who was bedridden at the time of the war and watched it on TV;\r\n· a peaceworker who helped establish a peace camp on the Iraqi-Saudi border in December 1990;\r\n· a journalist who was in Baghdad on the night the air war started;\r\n· an actor who played a soldier in a TV drama about the Gulf War.\r\nThe set for Desert Rain is a combination of the real and the virtual, each mirroring the design of the other, and connected through the permeable and physically traversable rain-curtain. Finally, it remains a puzzle for the participants what the nature of their mission is; is this a game, a drama or an interactive installation?\r\nDesert Rain from a player\'s perspective Perhaps the best way to understand Desert Rain is to follow a player\'s experience from start to finish.\r\nThe whole experience lasts for approximately forty minutes. It begins in the physical world. Players buy tickets in advance and usually gather in their groups of six at the venue, although in one location, they gathered in the city centre and were then bussed out to the venue ­ a disused warehouse on the outskirts of the city. A performer leads them into a bare physical antechamber (colour plate, figure 2) where they are asked to remove their outer clothing, deposit mobile phones and similar possessions in a box under their chair. They don a uniform, an anorak, and are briefed as to their mission. The briefing introduces the six targets by name and photograph, explains how to navigate through the virtual world, and stresses the time critical and cooperative nature of the mission. There is no opportunity for questions.\r\nNext, each player is led in turn by a performer to a fabric cubicle and is zipped inside (figure 3). There they stand on a personal footpad and put on a combined headphone/microphone headset. When all six players are in place, the water is switched on. Each player is facing their own personal rain-curtain ­ a large screen, roughly two meters tall by two and a half wide, composed of falling water, onto which is back-projected an image of a virtual motel room (figure 4). The image in the curtain has some striking aesthetic qualities: one\'s attention tends to switch between the image that appears to hang in the water, the water itself and the bright projection lamp that can be seen through the curtain (appearing like a hot sun in the desert sky). The sound of the curtain is also striking, even when wearing headphones. Behind the six curtains, unseen by the players, lurk two performers. The asymmetric nature of visibility through the rain curtain means that these\r\n\r\nPapers\r\nperformers can observe the players, without being observed in return.\r\nEach footpad acts as a giant joystick; by shifting their weight on its surface the player can move forwards and backwards or can rotate clockwise and anti-clockwise, navigating through the image of the virtual world that is projected onto their own personal rain curtain.\r\nThe action now switches to the virtual world. The six players begin their journey through this world isolated from one another, each in a separate virtual motel room. Each motel room contains a virtual TV set that plays back a short video recording of the Gulf War coverage from CNN news (as a video texture with audio). Eventually the player leaves the motel room through a door, passes into an open desert landscape beyond, and heads towards the centre of the world.\r\nAs the six players draw closer, they find that they can hear one another through the live audio link, mixed in with an ambient soundtrack. They may also hear voices (those of the performers) advising them where to go if they are lost or what to do if they are experiencing difficulties. When they meet, the players see one another represented as cube-like avatars with text labels (e.g., \"player 1\") and the texture mapped image of the relevant target for that player on the front. Each player eventually locates the virtual doorway that is labeled with the name of their target. On crossing this doorway, they find that they are standing inside a rotating white virtual cylinder, facing a sign that says \"wait here\".\r\nThe action now swaps back to the physical world. One of the performers who has been observing from behind the rain curtain, physically steps through the curtain (figure 8), slowly approaches the player on the footpad, gives them a plastic swipe-card and without speaking or otherwise acknowledging their presence, turns away and walks back through the curtain. Given that the players have been concentrating hard on the virtual world and that they are likely to be feeling somewhat disorientated, this is usually experienced as a highly dramatic, even shocking, event by the players. As a critic writing in the Sunday Times notes:\r\n\"This change from virtual to real is remarkably sudden and strangely disconcerting.\" [Sunday Times, 31st Oct, 1999]\r\nThe action now swaps back to the virtual world. The players are encouraged to find the entrance to an underground bunker. Inside they find a maze of narrow corridors, similar in style to many contemporary computer games. Together they have to find the exit before their thirty minutes are up. Once found, the exit will only open if all of the players have found their targets (the players may be encouraged to help one another to find the remaining targets). If the team passes through the open exit within the allowed thirty minutes the performers appear again to lead each player forward, passing through the rain curtain ­ the reward for success. If they fail, the water is switched off before they are led forward to the next stage.\r\n\r\nanyone. anywhere.\r\n\r\n39\r\n\r\nPapers\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\n\r\nPC operator\r\n\r\nHotel room and exit space\r\nSand dune\r\n\r\nWater performer\r\n\r\nWater performer\r\n\r\nProjectors\r\n\r\nVideo\r\n\r\nWater basin\r\n\r\nWorld server\r\n6\r\n\r\n5\r\n\r\n4\r\nWater curtain\r\n3\r\n\r\n6\r\n\r\n5\r\n\r\n4\r\n\r\n3\r\n\r\n2\r\n\r\n1\r\n\r\nCubicles and\r\n\r\n2\r\n\r\nfootpads\r\n\r\nClients 1\r\n\r\nAudio mixing\r\n\r\nMixing desk operator\r\n\r\nReturn of personal items and box of sand\r\n\r\nSwipe card reader Interview playback\r\n\r\nVirtual experience space\r\n\r\nControl centre\r\n\r\nHelper\r\n\r\nHelper Seats for participants\r\n\r\nVincennes\' text\r\n\r\nAntechamber\r\n\r\nFigure 1: Desert Rain Infrastructure\r\n\r\nFor the final time, the action swaps back to the physical world. The six players pass along a narrow corridor and climb over an enclosed ramp covered in sand (figure 9) into a physical recreation of the virtual motel room ­ but one created by pasting wallpaper sized photographs onto the walls (figure 5). Here they find a real television set. Using the swipe card given to them earlier, each player brings up a video clip containing an interview with their target. The six clips show quite different perceptions of the Gulf War, revealed through interviews with the six targets. Finally, the participants change back into their original clothing and emerge from the experience. Sometime later they find that a small bag of sand containing an estimated 100,000 grains ­ the estimated number of casualties in the Gulf War ­ has been left in their pocket.\r\nThe technical foundation of Desert Rain Technically, Desert Rain is a practical exploration of using mixed reality technology to create a coherent and engaging public experience. The specific mixed reality technology in question is that of traversable interfaces. These establish the illusion that a physical space is joined to an adjacent virtual space and that participants physically pass from one to the other (appearing to dematerialise from physical space and rematerialise in virtual space or vice versa) [5]. Early laboratory prototypes of traversable interfaces employed walk-through projection surfaces to create the illusion of physically stepping into or out of the image of a virtual world. One of these prototypes was the rain curtain, a fine water spray into which images can be back projected.\r\nDesert Rain has taken the rain-curtain technology and used it to create a full-scale public performance. The rain curtain\r\n\r\nwas chosen for its aesthetic qualities, both in terms of its striking visual image and sound, its asymmetric transparency (see below), and not least, due to the artistic association of projecting a virtual desert into a curtain of water. In fact, Desert Rain employs six rain curtains to create a shared mixed reality experience for six players that involves a journey through a combination of physical and virtual spaces and interactions with performers who appear to cross from one to the other.\r\nThe technical design of Desert Rain Desert Rain is staged on an extensive physical and virtual set that is home to a complex array of technology. The virtual world is implemented in the MASSIVE-2 system. Figure 1 provides an overview of the physical set for Desert Rain (precise positions vary according to the physical constraints of the venue). This physical set can be divided into four main areas:\r\n· The antechamber where the initial briefing takes place (figure 2).\r\n· The virtual experience space consisting of the six cubicles, each with an associated rain curtain, footpad and projector. Figure 3 shows this from the players\' side. Figure 6 shows this from the performers\' side.\r\n· The hotel room and exit space, consisting of the corridor of sand (figure 9) and the physical hotel room (figure 5).\r\n· The control centre (figure 7). This houses the computers and related networking, audio and video technology for the virtual world.\r\n\r\n40 Volume No. 3, Issue No. 1\r\n\r\nCHI 2001\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\n\r\nPapers\r\n\r\nFigure 2: The briefing room (see color plate on page 549) .\r\nThree aspects of this set-up are worth particular note as they provide the performers with different ways of monitoring and intervening in the participants\' experiences.\r\n· Six computer displays located in the control centre display the viewpoints of the six players in the virtual world (as projected onto the rain curtains). These monitors enable the performers to follow all six players as they progress through the virtual world. Using the arrow keys on the keyboards, the performers can directly influence the movements of the players\' avatars, effectively nudging them in particular directions.\r\n· Using an audio mixing desk that is also located in the control centre, the performers can listen in to the conversations of the players. They can also make additional direct audio connections between pairs of players no matter where they are in the virtual world (normally, audio connections are established according to virtual proximity). Finally, they can speak directly and privately to particular combinations of players, giving them assistance or encouragement without the others hearing.\r\n· Performers can also position themselves in the corridor behind the six rain curtains (figure 6) from where they can surreptitiously monitor the players. This is made possible by the asymmetric nature of visibility through the rain curtain. Looking back through a rain curtain, a\r\n\r\nFigure 3: the players zipped into their cubicles (see color plate on page 549).\r\nperformer can observe the physical player standing on the footpad, and can also see a (reverse) image of the player\'s view of the virtual world projected onto the player\'s body and the surrounding fabric of their cubicle.\r\n\r\nThe roles of the performers The following table summarises the typical division of responsibility between the performers.\r\n\r\nPerformer 1 (antechamber) Performers 2 and 3 (behind the rain curtains)\r\nPerformer 4 (control centre)\r\nPerformer 5 (control centre)\r\n\r\nMeet and brief the players in the antechamber\r\nLead players to cubicles and zip them in. Observe players from behind the rain curtains, Cross curtains at the correct moment and hand over swipe card. Lead players to the corridor of sand.\r\nMonitor players\' progress through the virtual world and their conversations. Talk to players over audio.\r\nRun, control and monitor software. Help steer players\' avatars using the keyboards.\r\n\r\nThese individuals communicate with one another by whispering when co-located in the control centre or in the area behind the six projectors. They also employ a simple signaling system using flashlights for communication between these two spaces ­ for example indicating how many players are present in this performance (not always the maximum possible six).\r\n\r\nFigure 4: the image of the world on the rain curtain\r\n\r\nFigure 5: the physical motel room\r\n\r\n(See color plates on page 549) .\r\n\r\nanyone. anywhere.\r\n\r\n41\r\n\r\nPapers\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\n\r\nFigure 6: the corridor behind the projectors (see color plate on page 549) .\r\nThe critics\' responses to Desert Rain Desert Rain emerged from a long period of development that began in the summer of 1997 to begin touring as a polished product in October 1999. It has since toured venues in the UK and Germany: Nottingham (October 1999), Karlsruhe (November 1999), London (May 2000), Bristol (June 2000) and Glasgow (July 2000). Early performances have generated considerable interest among art critics:\r\n\"... is possibly the most technologically ambitious art installation ever made\" and \"Sombre as its aims may be, Desert Rain is exhilarating to experience first hand.\" [The Times, May 10th 2000]\r\n\"... the experience does recreate some of the fear and disorientation that those on the ground during the Gulf War must have felt\" and \"part of a growing trend in performance and installation to blur the line between spectator and participant\" [The Guardian, May 18th 2000]\r\nHowever, our paper does not set out to debate the artistic merits of Desert Rain. Instead, it takes Desert Rain as a rare opportunity to learn from the successful professional application of mixed reality technology.\r\n\r\nFigure 7: the control area (see color plate on page 549) .\r\nISSUES RAISED BY DESERT RAIN Desert Rain has provided us with a valuable opportunity to explore the use of computer technology to create an interactive public experience. We were particularly interested in the activities the production team carries out to fashion the participants\' interactions with and in, the installation.\r\nFollowing a preliminary investigation into Desert Rain while it was being prototyped at Karlsruhe in January 1999, we employed a range of methods such as direct and videobased observation and participant interviews to collect data at five further locations where Desert Rain was actually staged and performed ­ Nottingham, Karlsruhe, London, Bristol, and Glasgow. The combinations of materials provide insights into a range of issues relevant to the design of interactive public experiences that may not be so familiar from explorations into the use of advanced technologies in the workplace.\r\nDesert Rain is not a stand-alone computer system but critically relies on a production team to support participants\' interaction with the interface and in the virtual world. We have conducted detailed observations of the production team\'s actions and interactions carried out \"behind the scenes\" that provide important information on\r\n\r\nFigure 8: crossing the curtain\r\n42 Volume No. 3, Issue No. 1\r\n\r\nFigure 9: climbing the hill of sand\r\n\r\nFigure 10: rain curtain technology (See color plates on page 550) .\r\nCHI 2001\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\nhow experiences are set and illusions are enabled. Also, we have investigated how the production team monitors and intervenes in players\' action and interaction. The observational data have been augmented by informal interviews with artists and designers.\r\nField observation of player\'s interaction with and in the installation augmented by video-recordings of two players\' viewpoints in the virtual world provide information on players\' engagement with the exhibit and the organisation of their progress from the antechamber, through the virtual world to the motel room. We have also obtained insights into players\' use of the interface, both footpad and rain curtain, and observed how they orient themselves to the virtual world and respond to the performer stepping through the curtain. Fifteen intensive interviews with participants after they have left the installation provided further information about their immediate responses to Desert Rain as well as about problems they had with the use of the interface.\r\nOrchestration - managing the players\' experience Computers have traditionally been designed as tools to be applied autonomously by users. Embedded help and tutorial facilities provide users with a means to learn how to tackle problems by themselves. Laurel has offered an alternative view, that designers should consider computers as a form of theatre rather than as tools [6]. The key issue now becomes designing the user\'s experience so that they become engaged with the content rather than with the technology. \"Behind the scenes\" activities are required to successfully engage the user and to orchestrate their experience. These have to be hidden from the user\'s view, so that their engagement with the content is not disrupted.\r\nAs an example of an actual performance involving computers, Desert Rain offers insights into these issues of orchestration and engagement, especially how they can be achieved by human performers in real-time. In the following, we will see how Blast Theory have developed a range of tacit working practices and procedures for engaging players with the content ­ setting their expectations and enabling the illusion of traversal ­ and for monitoring ongoing events and intervening if necessary, with minimal disruption to their engagement.\r\nSetting expectations and enabling illusion Our observations suggest that, to a large extent, participants believe (or rather willingly suspend disbelief) in Desert Rain. The crossing of the rain-curtain by the performer creates surprise and excitement and helps to enhance the participants\' engagement. In order to establish this illusion of traversal, Blast Theory conduct carefully designed actions that lead participants into and out of the different phases of the performance. At several points in the performance Blast Theory deliberately attempt to set the players\' expectations, encouraging them to willingly suspend disbelief.\r\n\r\nPapers\r\nIn the antechamber ­ participants are introduced to Desert Rain. As they enter the installation guided by a performer, participants are instructed to change their outer-clothing. In a command-like style they are briefed about their mission in the virtual world and engaged with the game. Before they are isolated from the rest of the group and guided one-byone to their cubicles and zipped inside, they are advised to make use of the communication facilities in the virtual world. The importance of presenting a backstory prior to an interactive experience is well understood by the imagineers who design theme-park rides [4,7]. However, Blast Theory take this a step further. It can be argued that through a range of well prepared stages, participants are gradually desocialized like an inpatient in an asylum who \"finds himself cleanly stripped of his many of his accustomed affirmations, satisfactions and defences\" [2], and are subjected to a set of discomforting experiences. As the participants normally follow the performers\' instructions quietly without showing any sign of resistance towards this desocialisation procedure, it seems that the performers\' carefully conducted actions do indeed set the players\' expectations and enable the illusion of the game.\r\nCrossing the curtain ­ the moment when a player finds her target and a performer crosses the rain-curtain is the climax of the dramatic performance. After the players have navigated the virtual world for some time they have become familiar with the game and are ready for new experiences that help to maintain their engagement in the game. Blast Theory have designed the players\' discoveries of their targets in a particular way that creates surprise and excitement and makes possible that their engagement with the game is strengthened by the crossing of the curtain. However, the crossing is a moment that is fraught with danger for the performers. The timing of their movement with the players\' actions in the virtual world is of crucial importance. When players see the rotating virtual cylinder for a long time they become disoriented and question its part in the performance. They sometimes assume that the system has crashed and wait for a continuance of the program. If the performer walks too quickly through the rain-curtain the illusion of her emergence from the virtual world does not work. If the timing of the crossing is not right, it disengages the players from the game, and they attempt to involve the performer in conversation.\r\nLeaving the cubicles ­ the virtual game ends when the players have found the exit to the virtual world and leave the cubicles. The performance, however, continues as the players are led to the motel room. This is perhaps the point in Desert Rain when it is most difficult to sustain engagement. It seems that players often assume that with the end of the virtual game the performance comes to an end as well. In early performances, they would meet their coplayers in front of the cubicles where all of them would take off their anoraks, and then discuss with each other their experiences in the virtual world. Sometimes they would\r\n\r\nanyone. anywhere.\r\n\r\n43\r\n\r\nPapers\r\nattempt to return the swipecards to the performers. Only when they were asked to climb the sandhill did the tension build up again. However, it then collapsed again only a few seconds later after they have gathered in the motel room. Their excitement about the experiences in the virtual world appeared to take over and they began discussions with each other. They disengaged from Desert Rain prematurely.\r\nIn response to these observations, Blast Theory altered their orchestration of this part of the performance. The players no longer removed their anoraks until after the final motel room. Furthermore, the performers carefully planned the order in which to take the players from their cubicles, so that the players spent the minimum possible time together before moving on up the sandhill, and also so that the performers were best positioned to shepherd them on.\r\nThis last observation shows the level of detail that has to be considered when planning and executing a performance. This is a key point. The interactions with the players are meticulously planned and repeatedly rehearsed, including dialogue, inflexions, gestures and speed of movement. Potential problems are identified in advance and responses are rehearsed, with a particular focus on how they can be woven into the experience.\r\nMonitoring and Intervening Our observations indicate that the performers largely manage to lead the participants into the installation and engage them with the game. However, to ensure that the players\' engagement with Desert Rain is maintained throughout their journey, performers continually monitor events in the virtual as well as in the real world. If the players\' engagement with the game seems to be endangered at any point performers have to hand a range of prepared actions through which they can intervene in events. The players are never really isolated in their cubicle as the design of the installation allows the performers asymmetric access to the players, both in the virtual and physical worlds (through the computer monitors in the control area and the asymmetric nature of the rain curtain respectively). Monitoring and intervening can therefore largely be accomplished without the players noticing it. We have identified three styles of intervention.\r\nOff-face Interventions are conducted by the performer at the control-centre to advise players about actions in the virtual world. Occasionally, the performer also attempts to influence the player\'s movement on the footpad. Off-face interventions are produced by means of the audio link to talk to a player and to advise her on which directions to take in the virtual world or on the use of the footpad. They cannot be conducted without the players noticing them. But performers use a specially designed, dramatic voice and almost always manage to embed the intervention within the game, thus avoiding the players from becoming distracted from their actions within the virtual world.\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\nAs with other recent digital media artworks [1], Desert Rain is designed to promote collaboration among participants. Another opportunity for off-face intervention is therefore encouraging the players to help each other, for example, suggesting that players who have already found their targets go back and help their team members who have not. Given that we found communication between the players to be an especially enjoyable and engaging aspect of Desert Rain, this provides an ideal way of intervening without breaking engagement, indeed possibly even enhancing it.\r\nVirtual Interventions are carried out from the controlcentre by virtue of the arrow keys on the computers. They are very carefully conducted so that the players do not notice them. For example, when a performer observes that a player has been circling her target for some time without crossing it, she focuses her observation on this player\'s movement in relation to her target. As the player comes very close to her target the performer presses an arrow key to push the player\'s avatar through the target and thus triggers the rotating drum. The performer makes her decision about the exact moment when she pushes the arrow key with great care so that it is neatly timed with the player\'s movement in the virtual world. She moves the avatar only a tiny bit, thus making sure the push remains unnoticed for the player. Virtual interventions are closely timed with the player\'s movement in the virtual world. They can be carried out without disengaging the player from the game. Indeed, they ensure that players do not get frustrated as they circle their target.\r\nFace-to-Face Interventions are carried out by a performer who directly approaches the player\'s cubicle to give her practical advice on using the footpad. This form of intervention is very intrusive and always results in an interruption of the player\'s engagement in the game. Therefore, it is only employed on very rare occasions. A few players have been observed who despite of having received advice through the audio-link, could still not use the footpad; in order to enable them to engage in the game a performer accessed their cubicle from behind to give them hands-on support. Face-to-face interventions were only employed when off-face interventions did not work and were normally preceded by communication between the control centre and a performer behind the rain-curtain.\r\nThese practices can be contrasted with previous approaches to orchestrating performances in virtual worlds. Out of This World (OOTW) was a television gameshow that was staged on-line in a shared virtual world with actors and members of the public controlling avatars [3]. The gameshow format demanded precisely timed and coordinated interactions, especially avatar movements, so as to fit in with the rigorous timing constraints of television production and camera work. OOTW introduced a solution to this problem in the form of dedicated management software. This allowed a member of the production crew to monitor the action in the world and dynamically introduce movement constraints ­\r\n\r\n44 Volume No. 3, Issue No. 1\r\n\r\nCHI 2001\r\n\r\nCHI 2001 · 31 MARCH ­ 5 APRIL\r\ninvisible bounding boxes with different sizes and trajectories ­ so as to limit participants\' freedom to move or shepherd them to particular locations. This interface was used extensively throughout the show. The participants were given no choice and were clearly aware when they were being controlled (their screen would flash red whenever they were being moved or pushing against a constraint). Although apparently acceptable in a gameshow context where the action is staged for the benefit of external viewers, this relatively heavyweight approach would be too overt and disruptive for Desert Rain, which instead relies on more subtle techniques.\r\nAs a further comment, it might be possible to use more sophisticated navigation techniques to gently steer participants around the world without directly taking control of them, for example force-field based navigation in virtual environments as proposed by Xiao and Hubbold [9]. However, such techniques need to be extended so that performers can define and shape them in real-time in order to improvise responses to unanticipated circumstances.\r\nCONCLUSIONS Blast Theory\'s Desert Rain takes Brenda Laurel\'s concept of `Computers as Theatre\' literally. A computer system and its use by members of the public are embedded within a dramatic performance. In order to ensure the success of Desert Rain, the performers carefully set the participants expectations and produce a range of performances and unobtrusive practices to orchestrate their experiences. Key aspects of this orchestration are:\r\n· Carefully planned and thoroughly rehearsed briefings and interventions at all stages of the performance;\r\n· The use of off-face and virtual interventions so as to sustain engagement;\r\n· Encouraging the players to help one another as a way of intervening and yet increasing engagement;\r\n· The ability to monitor action in both the physical and virtual worlds through asymmetric interfaces.\r\nWe think that these observations may have broader implications for HCI.\r\nAs the need to monitor and intervene might be seen as a downfall of the `usability\' of Desert Rain\'s interface, it is worthwhile considering that currently, more and more computer systems, such as information kiosks and touch screen devices are placed within public places. Appropriate user-support for such applications is often not available, leaving the user alone and sometimes frustrated or even embarrassed in the public eye. We suggest that the ability for technical crew to dynamically manage a participant\'s experience will be increasingly important in a range of applications.\r\nContinual and unobtrusive observations of the user\'s (inter)actions with the system and within the virtual world\r\n\r\nPapers\r\nare necessary so to be able to embed interventions within ongoing actions and experiences. This requires a repertoire of social practices supported by appropriate technical facilities. Of course, this should come as no surprise ­ traditional theatre already has well established practices and facilities for managing performances ­ lighting, sound, curtains, scenery and so forth. Similar facilities are now required for managing computer-based experiences.\r\nFinally, despite the public accessibility of computer systems as they are currently deployed in museums and galleries, they are normally developed for the use by individuals, isolating the user from her companions and the wider environment [8]. In contrast, Desert Rain indicates that participants may be willing and able to support each other, while remaining engaged in an experience. Indeed, the communication involved in mutual support might even strengthen their engagement.\r\nACKNOWLEDGMENTS We gratefully acknowledge the support of: The European i3 programme (eRENA project), EPSRC, The Nottingham NOW contemporary art festival, DA2, The ZKM and The Arts Council of England. We are especially grateful to Andrew Chetty for his support and participation.\r\nREFERENCES 1. Büscher, M., O\'Brien, J., Rodden, T., and Trevor, J., He\'s\r\nbehind you: the experience of presence in shared virtual environments, Collaborative Virtual Environments (E. Churchill, D. Snowdon & A. Munro), London 2000\r\n2. Goffman, E., Asylums. Essays on the Social Situation of Mental Patients and Other Inmates. London 1987.\r\n3. Greenhalgh, C. M., Benford, S. D., Taylor, I. M., Bowers, J. M., Walker, G. & Wyver, J., Creating a Live Broadcast from a Virtual Environment, SIGGRAPH\'99, 375-384, Los Angeles, 1999.\r\n4. Kamberg, M., Seafari: An expedition into motion base ride filmmaking, in virtual reality, Digital Illusion: entertaining the future with high technology,(Dodsworth, C.), AddisonWesley, 1998.\r\n5. Koleva, B., Schnädelbach H., Benford, S. & Greenhalgh, C., Traversable Interfaces Between Real and Virtual Worlds, CHI\'2000, 2000.\r\n6. Laurel, B., Computers as Theatre. Addison-Wesley 1992.\r\n7. Pausch, R., Snoddy, J., Taylor, R., Watson, S. & Haseltine, E., Disney\'s Aladdin: first steps towards storytelling in virtual reality, Digital Illusion: entertaining the future with high technology, (Dodsworth, C.), 357-372, Addison-Wesley, 1998.\r\n8. Vom Lehn, D., Heath, C. and Knoblauch, H., Configuring Exhibits: The interactional production of experience in museums and galleries. Verbal Art across Cultures. The Aesthetics and Proto-Aesthetics of Communication. (Kotthoff, H. & Knoblauch, H.), 281-297, Tübingen: Narr, 2000.\r\n9. Xiao, D. and Hubbold R., Navigation guided by artificial force fields, CHI\'98, 179 ­ 186, 1998.\r\n\r\nanyone. anywhere.\r\n\r\n45\r\n\r\n',1,'Koleva','Boriana Koleva, Ian Taylor, Steve Benford, Mike Fraser, Chris Greenhalgh, Holger Schnädelbach, Dirk vom Lehn, Christian Heath, Ju Row-Farr, and Matt Adams',NULL,'http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.591.9355&rep=rep1&type=pdf',1,'10.1145/365024.365033','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,NULL,NULL,0,0),(3,'suchman-human-machine-reconfigurations-plans-and-situated-actions','2019-02-23 20:28:04','2019-09-20 12:09:24','2019-02-23 20:27:26',NULL,1,'published','[]','Human-Machine Reconfigurations: Plans and Situated Actions','This 2007 book considers how agencies are currently figured at the human-machine interface, and how they might be imaginatively and materially reconfigured. Contrary to the apparent enlivening of objects promised by the sciences of the artificial, the author proposes that the rhetorics and practices of those sciences work to obscure the performative nature of both persons and things. The question then shifts from debates over the status of human-like machines, to that of how humans and machines are enacted as similar or different in practice, and with what theoretical, practical and political consequences. Drawing on scholarship across the social sciences, humanities and computing, the author argues for research aimed at tracing the differences within specific sociomaterial arrangements without resorting to essentialist divides. This requires expanding our unit of analysis, while recognizing the inevitable cuts or boundaries through which technological systems are constituted.','Lucy Suchman. 2007. Human-Machine Reconfigurations: Plans and Situated Actions (2nd. ed.). Cambridge University Press.','This page intentionally left blank\r\n\r\nHuman­Machine Reconfigurations\r\nThis book considers how agencies are currently figured at the human­ machine interface and how they might be imaginatively and materially reconfigured. Contrary to the apparent enlivening of objects promised by the sciences of the artificial, the author proposes that the rhetorics and practices of those sciences work to obscure the performative nature of both persons and things. The question then shifts from debates over the status of humanlike machines to that of how humans and machines are enacted as similar or different in practice and with what theoretical, practical, and political consequences. Drawing on recent scholarship across the social sciences, humanities, and computing, the author argues for research aimed at tracing the differences within specific sociomaterial arrangements without resorting to essentialist divides. This requires expanding our unit of analysis, while recognizing the inevitable cuts or boundaries through which technological systems are constituted.\r\nLucy Suchman is Professor of Anthropology of Science and Technology in the Sociology Department at Lancaster University. She is also the Co-Director of Lancaster\'s Centre for Science Studies. Before her post at Lancaster University, she spent twenty years as a researcher at Xerox\'s Palo Alto Research Center (PARC). Her research focused on the social and material practices that make up technical systems, which she explored through critical studies and experimental and participatory projects in new technology design. In 2002, she received the Diana Forsythe Prize for Outstanding Feminist Anthropological Research in Science, Technology and Medicine.\r\n\r\nHuman­Machine Reconfigurations\r\nPlans and Situated Actions, 2nd Edition\r\nLUCY SUCHMAN\r\nLancaster University, UK\r\n\r\ncambridge university press Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo\r\nCambridge University Press The Edinburgh Building, Cambridge cb2 2ru, UK Published in the United States of America by Cambridge University Press, New York www.cambridge.org Information on this title: www.cambridge.org/9780521858915\r\n© Cambridge University Press 2007\r\nThis publication is in copyright. Subject to statutory exception and to the provision of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press.\r\nFirst published in print format 2006\r\nisbn-13 978-0-511-25649-3 eBook (EBL) isbn-10 0-511-25649-3 eBook (EBL)\r\nisbn-13 978-0-521-85891-5 hardback isbn-10 0-521-85891-7 hardback\r\nisbn-13 978-0-521-67588-8paperback isbn-10 0-521-67588-X paperback\r\nCambridge University Press has no responsibility for the persistence or accuracy of urls for external or third-party internet websites referred to in this publication, and does not guarantee that any content on such websites is, or will remain, accurate or appropriate.\r\nAs well as the original text of Plans and Situated Actions: The Problem of Human­Machine Communication, some sections of this book have been published elsewhere in other forms. Chapter 1 takes material from two special journal issues, Cognitive Science 17(1), 1993, and the Journal of the Learning Sciences 12(2), 2003, and Chapter 12 revises text published separately under the title \"Figuring Service in Discourses of ICT: The Case of Software Agents\" (2000), in E. Wynn et al. (eds.), Global and Organizational Discourses about Information Technology, Dordrecht, The Netherlands: Kluwer, pp. 15­32.\r\n\r\nContents\r\n\r\nAcknowledgments Preface to the 2nd Edition\r\n\r\npage vii xi\r\n\r\nIntroduction\r\n\r\n1\r\n\r\n1 Readings and Responses\r\n\r\n8\r\n\r\n2 Preface to the 1st Edition\r\n\r\n24\r\n\r\n3 Introduction to the 1st Edition\r\n\r\n29\r\n\r\n4 Interactive Artifacts\r\n\r\n33\r\n\r\n5 Plans\r\n\r\n51\r\n\r\n6 Situated Actions\r\n\r\n69\r\n\r\n7 Communicative Resources\r\n\r\n85\r\n\r\n8 Case and Methods\r\n\r\n109\r\n\r\n9 Human­Machine Communication\r\n\r\n125\r\n\r\n10 Conclusion to the 1st Edition\r\n\r\n176\r\n\r\n11 Plans, Scripts, and Other Ordering Devices\r\n\r\n187\r\n\r\n12 Agencies at the Interface\r\n\r\n206\r\n\r\n13 Figuring the Human in AI and Robotics\r\n\r\n226\r\n\r\n14 Demystifications and Reenchantments of the Humanlike\r\n\r\nMachine\r\n\r\n241\r\n\r\n15 Reconfigurations\r\n\r\n259\r\n\r\nReferences\r\n\r\n287\r\n\r\nIndex\r\n\r\n309\r\n\r\nv\r\n\r\nAcknowledgments\r\nOver the past two decades, I have had the extraordinary privilege of access to many research networks. The fields with which I have affiliation as a result include human­computer interaction, interface/ interaction design, computer-supported cooperative work, participatory design, information studies/social informatics, critical management and organization studies, ethnomethodology and conversation analysis, feminist technoscience, anthropology of science and technology, science and technology studies, and new/digital media studies, to name only the most explicitly designated. Within these international networks, the friends and colleagues with whom I have worked, and from whom I have learned, number literally in the hundreds. In acknowledgment of this plenitude, I am resisting the temptation to attempt to create an exhaustive list that could name everyone. Knowing well the experiences of both gratification and disappointment that accompany the reading of such lists, it is my hope that a more collective word of thanks will be accepted. Although it is too easy to say that in reading this book you will find your place in it, I nonetheless hope that the artifact that you hold will speak at least partially on its own behalf. The list of references will work as well, I hope, to provide recognition ­ though with that said, and despite my best efforts to read and remember, I beg forgiveness in advance for the undoubtedly many sins of omission that are evident there.\r\nThere are some whose presence in this text are so central and far reaching that they need to be named. Although his position is usually reserved for the last, I start with Andrew Clement, my companion in\r\nvii\r\n\r\nviii\r\n\r\nAcknowledgments\r\n\r\nheart and mind, who tempted me to move north and obtain a maple leaf card at what turned out to be just the right time. Left behind in bodies but not spirit or cyberspace are the colleagues and friends with whom I shared a decade of exciting and generative labors under the auspices of the Work Practice and Technology research area at Xerox Palo Alto Research Center. Jeanette Blomberg and Randall Trigg have been with me since the first edition of this book, and our collaboration spans the ensuing twenty years. I have learned the things discussed in this book, and much more, with them. I thank as deeply Brigitte Jordan, David Levy, and Julian Orr, the other three members of WPT with whom I shared the pleasures, privileges, trials, and puzzlements of life at PARC beginning in the 1980s, along with our honorary members and long-time visitors, Liam Bannon, Franc¸oise Brun Cottan, Charles and Marjorie Goodwin, Finn Kensing, Cathy Marshall, Susan Newman, Elin Pedersen, and Toni Robertson. In an era of news delivered by Friday (or at least the end of the financial quarter), the opportunity to have worked in the company of these extraordinary researchers for well over a decade is a blessing, as well as a demonstration of our collective commitment to the value of the long term. Although we have now gone our multiple and somewhat separate ways, the lines of connection still resonate with the same vitality that animated our work together and that, I hope, is inscribed at least in part on the pages of this book.\r\nThe others who need to be named are my colleagues now at Lancaster University. Although the brand of \"interdisciplinarity\" is an increasingly popular one, scholarship at Lancaster crosses departmental boundaries in ways that provide a kind of intellectual cornucopia beyond my fondest dreams. Within the heterodox unit that is Sociology I thank all of the members of the department ­ staff and students ­ for their innovative scholarship and warm collegiality. Through the Centre for Science Studies (CSS) at Lancaster runs the far more extended network of those interested in critical studies of technoscience, including my co-director Maggie Mort and colleagues in the Institute for Health Research and CSS Chair Maureen McNeil, along with other members of the Institute for Women\'s Studies and the Centre for Social and Economic Aspects of Genomics. The network runs as well through the Institute for Cultural Research; the Centre for the Study of Environmental Change; the Organization, Work and Technology unit within the Management School; Computing; and the recently formed Centre for Mobilities Research. Although the distance I have\r\n\r\nAcknowledgments\r\n\r\nix\r\n\r\ntraveled across institutional as well as watery boundaries has been great, I have found myself immediately again in the midst of colleagues with whom work and friendship are woven richly together. I went to Lancaster with a desire to learn, and I have not for a moment been disappointed.\r\n\r\nPreface to the 2nd Edition\r\nI experience a heightened sense of awareness, but that awareness is not of my playing, it is my playing. Just as with speech or song, the performance embodies both intentionality and feeling. But the intention is carried forward in the activity itself, it does not consist in an internal mental representation formed in advance and lined up for instrumentally assisted, bodily execution. And the feeling, likewise, is not an index of some inner, emotional state, for it inheres in my very gestures.\r\n(Ingold 2000: 413, original emphasis)\r\nIf we want to know what words like nature and technology mean, then rather than seeking some delimited set of phenomena in the world ­ as though one could point to them and say \"There, that\'s nature!\" or \"that\'s technology!\" ­ we should be trying to discover what sorts of claims are being made with these words, and whether they are justified. In the history of modern thought these claims have been concerned, above all, with the ultimate supremacy of human reason.\r\n(Ingold 2000: 312)\r\nI bring down my finger onto the Q and turn the knob down with a whole arm twist which I continue into a whole body turn as I disengage from both knob and key. SOH brings in a low quiet sound precisely as I find myself turned to face him. We are in the valley before the finale. I turn back to the synthesiser front panel and gradually swell sound Q into the intense texture it is required to be. At maximum, I hold my right hand over the volume control and bring in my left to introduce a high frequency boost and then a modulation to the filtering. As I turn the knobs, I gradually lean towards the front panel. When the modulation is on the edge of excess, I lean back and face SOH. He looks over. I move my left hand away from the panel, leaving my right poised on the volume knob. I arch myself\r\nxi\r\n\r\nxii\r\n\r\nPreface to the 2nd Edition\r\n\r\nbackwards a little further and then project my torso down while turning the knob anticlockwise. I continue my hand through and away from the panel. SOH has also stopped playing. As the considerable reverberation dies down, we relax together, face the audience and gently bow. We have finished.\r\n(Bowers 2002: 32)\r\nThe image of improvised electro-acoustic music that I want to experiment with is one where these contingencies (of place, structure, technology and the rest) are not seen as problematic obstructions to an idealised performance but are topicalised in performance itself. Improvised electroacoustic music, on this account, precisely is that form of music where those affairs are worked through publicly and in real-time. The contingency of technology-rich music making environments is the performance thematic. The whole point is to exhibit the everyday embodied means by which flesh and blood performers engage with their machines in the production of music. The point of it all does not lie elsewhere or in addition to that. It is in our abilities to work with and display a manifold of human­machine relationships that our accountability of performance should reside.\r\n(Bowers 2002: 44)\r\nMy preface by way of an extended epigraph marks the frame of this book and introduces its themes: the irreducibility of lived practice, embodied and enacted; the value of empirical investigation over categorical debate; the displacement of reason from a position of supremacy to one among many ways of knowing in acting; the heterogeneous sociomateriality and real-time contingency of performance; and the new agencies and accountabilities effected through reconfigured relations of human and machine. That these excerpts appear as a preface reflects the contingent practicalities of the authoring process itself. Coming upon these books after having finished my own, I found them so richly consonant with its themes that they could not be left unacknowledged. They appear as an afterthought, in other words, but their position at the beginning is meant to give them pride of place. Moreover, their responsiveness each to the other, however unanticipated, sets up a resonance that seemed in turn to clarify and extend my argument in ways both familiar and new. Taken together, Ingold\'s painstaking anthropology of traditional and contemporary craftwork and Bower\'s experimental ethnomethodology of emerging future practices of improvising machines work to trace the arc of my own argument in ways that I hope will become clear in the pages that follow.\r\n\r\nIntroduction\r\nMy aim in this book is to rethink the intricate, and increasingly intimate, configurations of the human and the machine. Human­machine configurations matter not only for their central place in contemporary imaginaries but also because cultural conceptions have material effects.1 As our relations with machines elaborate and intensify, questions of the humanlike capacities of machines, and machinelike attributes of humans, arise again and again. I share with Casper (1994), moreover, the concern that the wider recognition of \"nonhuman agency\" within science and technology studies begs the question of \"how entities are configured as human and nonhuman prior to our analyses\" (ibid.: 4). Casper proposes that discussions of nonhuman agency need to be reframed from categorical debates to empirical investigations of the concrete practices through which categories of human and nonhuman are mobilized and become salient within particular fields of action. And in thinking through relations of sameness and difference more broadly,\r\n1 The word imaginary in this context is a term of art in recent cultural studies (see Braidotti 2002: 143; Marcus 1995: 4; Verran 1998). It shares with the more colloquial term imagination an evocation of both vision and fantasy. In addition, however, it references the ways in which how we see and what we imagine the world to be is shaped not only by our individual experiences but also by the specific cultural and historical resources that the world makes available to us, based on our particular location within it. And perhaps most importantly for my purposes here, cultural imaginaries are realized in material ways. My inspiration for this approach is Haraway\'s commitment to what she names \"materialized refiguration (1997: 23), a trope that I return to in Chapter 13. The particular imaginaries at stake in this text are those that circulate through and in relation to the information and communication networks of what we might call the hyperdeveloped countries of Europe and North America. 1\r\n\r\n2\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nAhmed (1998) proposes a shift from a concern with these questions as something to be settled once and for all to the occasioned inquiry of \"which differences matter, here?\" (ibid.: 4). In that spirit, the question for this book shifts from one of whether humans and machines are the same or different to how and when the categories of human or machine become relevant, how relations of sameness or difference between them are enacted on particular occasions, and with what discursive and material consequences.\r\nIn taking up these questions through this second expanded edition of Plans and Situated Actions, I rejoin a discussion in which I first participated some twenty years ago, on the question of how capacities for action are figured at the human­machine interface and how they might be imaginatively and materially reconfigured. Almost two decades after the publication of the original text, and across a plethora of subsequent projects in artificial intelligence (AI) and human­computer interaction (HCI), the questions that animated my argument are as compelling, and I believe as relevant, as ever. My starting point in this volume is a critical reflection on my previous position in the debate, in light of what has happened since. More specifically, my renewed interest in questions of machine agency is inspired by contemporary developments both in relevant areas of computing and in the discussion of human­nonhuman relations within social studies of science and technology.2 What I offer here is another attempt at working these fields together in what I hope will be a new and useful way. The newness comprises less a radical shift in where we draw the boundaries between persons and machines than a reexamination of how ­ on what bases ­ those boundaries are drawn. My interest is not to argue the question of machine agency from first principles, in other words, but rather to take as my focus the study of how the effect of machines-as-agents is generated and the latter\'s implications for theorizing the human. This includes the translations that render former objects as emergent subjects, shifting associated interests and concerns across the human­artifact boundary. We can then move on to questions of what is at stake in these particular translations-inprogress and why we might want to resist or refigure them.\r\n\r\n2 At the outset I take the term agency, most simply, to reference the capacity for action, where just what that entails delineates the question to be explored. This focus is not meant to continue the long-standing discussion within sociology on structure and agency, which I take to reiterate an unfortunate dichotomy rather than to clarify questions of the political and the personal, how it is that things become durable and compelling, and the like.\r\n\r\nIntroduction\r\n\r\n3\r\n\r\nChapter 1 of this edition provides some background on the original text and reflects on its reception, taking the opportunity so rarely available to authors to respond to readings both anticipated and unexpected.3 Chapters 2 through 10 comprise the original text as published in 1987. In each of these chapters, new footnotes provide updated references, commentaries, and clarifications, primarily on particular choices of wording that have subsequently proven problematic in ways that I did not foresee. I have made only very minor editorial changes to the text itself, on the grounds that it is important that the argument as stated remain unaltered. This is true, I believe, for two reasons. First, the original publication of the book marked an intervention at a particular historical moment into the fields of artificial intelligence and human­computer interaction, and I think that the significance of the argument is tied in important ways to that context. The second reason for my decision to maintain the original text, and perhaps the more significant one, is that I believe that the argument made at the time of publication holds equally well today, across the many developments that have occurred since. The turn to so-called situated computing notwithstanding, the basic problems identified previously ­ briefly, the ways in which prescriptive representations presuppose contingent forms of action that they cannot fully specify, and the implications of that for the design of intelligent, interactive interfaces ­ continue to haunt contemporary projects in the design of the \"smart\" machine.\r\nThe book that follows comprises a kind of object lesson as well in disciplinary affiliations and boundaries. The original text perhaps shows some peculiarities understandable only in light of my location at the time of its writing. In particular, I was engaged in doctoral research for a Ph.D. in anthropology, albeit with a supervisory committee carefully chosen for their expansive and nonprogrammatic relations to disciplinary boundaries.4 Although the field of American anthropology in the 1980s was well into the period of \"studying up,\" or investigation of institutions at \"home\" in the United States,5 my dissertation project\r\n\r\n3 Part of the discussion in Chapter 1 is drawn from opportunities provided earlier, in two discussion forums in the journals Cognitive Science 17(1), 1993, and the Journal of the Learning Sciences 12(2), 2003.\r\n4 My committee included Gerald Berreman and John Gumperz, from the Department of Anthropology, and Hubert Dreyfus, from the Department of Philosophy, all at the University of California at Berkeley.\r\n5 For a founding volume see Hymes (1974). di Leonardo (1998) offers a discussion of the enduringly controversial status of \"exotics at home\" within the discipline.\r\n\r\n4\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n(with the photocopier as its object, however enhanced by the projects of computing and cognitive science) stretched the bounds of disciplinary orthodoxy. Nonetheless, I was deeply committed to my identification as an anthropologist, as well as to satisfying the requirements of a dissertation in the field. At the same time, I had become increasingly engaged, through my interests in practices of social ordering and faceto-face human interaction, with the lively and contentious research communities of ethnomethodology and conversation analysis. It was these approaches, more than any, perhaps, that informed and shaped my own at the time. Finally, but no less crucially, my position as a Research Intern at Xerox Palo Alto Research Center (PARC) meant that my text had to speak to the fields of AI and HCI themselves.\r\nMy task consequently became one of writing across these multiple audiences, attempting to convey something of the central premises and problems of each to the other. More specifically, Chapter 4 of this volume, titled \"Interactive Artifacts,\" and Chapter 5, titled \"Plans,\" are meant as introductions to those projects for readers outside of computing disciplines. Chapter 6, \"Situated Actions,\" and Chapter 7, \"Communicative Resources,\" correspondingly, are written as introductions to some starting premises regarding action and interaction for readers outside of the social sciences. One result of this is that each audience may find the chapters that cover familiar ground to be a bit basic. My hope, however, is that together they lay the groundwork for the critique that is the book\'s central concern. These chapters are followed by an exhaustive (some might even say exhausting!) explication of a collection of very specific, but, I suggest, also generic, complications in the encounter of \"users\" with an intendedly intelligent, interactive \"expert help system.\" I attempt to explicate those encounters drawing on the resources afforded by studies in face-to-face human interaction, to shed light on the problem faced by those committed to designing conversational machines. As a kind of uncontrolled laboratory inquiry, the analysis is perhaps best understood as a close study of exercises in instructed action, rather than of the practicalities of machine operation as it occurs in ordinary work environments and in the midst of ongoing activities. With that said, my sense is that the analysis of human­machine communication presented in Chapters 8 and 9 applies equally to the most recent efforts to design conversational interfaces and identifies the defining design problem for HCI more broadly. To summarize the analysis briefly, I observe that human­machine communications take place at a very limited site of\r\n\r\nIntroduction\r\n\r\n5\r\n\r\ninterchange; that is, through actions of the user that actually change the machine\'s state. The radical asymmetries in relative access of user and machine to contingencies of the unfolding situation profoundly limit possibilities for interactivity, at least in anything like the sense that it proceeds between persons in interaction.6 Chapter 10, the conclusion to the original text, provides a gesture toward alternative directions in interface design and reaffirms the generative potential of the human­ computer interface as a site for further research.\r\nReaders familiar with the original text of P&SA may choose to pass over Chapters 2 through 10 or to focus more on the footnotes that offer further reflections, references, and clarifications. The chapters that follow the original text expand and update the arguments. Chapter 11, \"Plans, Scripts, and Other Ordering Devices,\" makes clear, I hope, that although the focus of the preceding chapters is on plans (as understood within dominant AI projects of the time), the research object is a much larger class of artifacts. In this chapter I review developments both in theorizing these artifacts in their various manifestations and in empirical investigations of their workings within culturally and historically specific locales. Chapter 12, \"Agencies at the Interface,\" takes up the question of what specific forms agency takes at the contemporary human­computer interface. I begin with a review of the rise of computer graphics and animation, and the attendant figure of the \"software agent.\" Reading across the cases of software agents, wearable, and socalled pervasive or ubiquitous computing, I explore the proposition that these new initiatives can be understood as recent manifestations of the very old dream of a perfect, invisible infrastructure; a dream that I locate now within the particular historical frame of the \"service economy.\" Chapter 13, \"Figuring the Human in AI and Robotics,\" explores more deeply the question of what conceptions of the human inform current projects in AI and robotics, drawing on critiques, cases, and theoretical resources not available to me at the time of my earlier writing. In both chapters I consider developments in relevant areas of research ­ software agents, wearable computers and \"smart\" environments, situated robotics, affective computing, and sociable machines ­ since the 1980s and reflect on their implications. Rather than a comprehensive survey,\r\n\r\n6 I should make clear at the outset that I in no way believe that human­computer interactions broadly defined, as the kinds of assemblages or configurations that I discuss in Chapters 14 and 15, are confined to this narrow point. Rather, I am attempting to be specific here about just how events register themselves from the machine\'s \"point of view.\"\r\n\r\n6\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nmy aim is to identify recurring practices and familiar imaginaries across these diverse initiatives.\r\nFinally, Chapter 14, \"Demysitifications and Reenchantments of the Humanlike Machine,\" and Chapter 15, \"Reconfigurations,\" turn to the question of how it might be otherwise, both in the staging of human­ machine encounters and through the reconfiguration of relations, practices, and projects of technology design and use. As will become clear, I see the most significant developments over the last twenty years, at least with respect to the argument of this book, as having occurred less in AI than in the area of digital media more broadly on the one hand (including graphical interfaces, animation, and sensor technologies) and science and technology studies (STS) on the other. The first set of developments has opened up new possibilities not only in the design of socalled animated interface agents but also ­ more radically I will argue ­ in mundane forms of computing and the new media arts. The further areas of relevant change are both in the field of STS, which has exploded with new conceptualizations of the sociotechnical, and also in my own intellectual and professional position. The latter has involved encounters since the 1980s with feminist science studies, recent writings on science and technology within cultural anthropology, and other forms of theorizing that have provided me with resources lacking in my earlier consideration of human­machine relations. During that same period, I have had the opportunity with colleagues at PARC to explore radical alternatives to prevailing practices of system design, informed by an international community of research colleagues. Engaging in a series of iterative attempts to enact a practice of small-scale, case-based codesign, aimed at creating new configurations of information technologies, has left me with a more concrete and embodied sense of both problems and possibilities in reconfiguring relations and practices of professional system design. I have tried in these chapters to indicate my indebtedness to these various communities and the insights that I believe they afford for innovative thinking across the interface of human and machine. Inevitably, both my discussion of new insights from science and technology studies and of new developments in computing is partial at best, drawing selectively from those projects and perspectives with which I am most familiar and that I have found most generative or compelling. Drawing on these resources, I argue for the value of research aimed at articulating the differences within particular human­machine configurations, expanding our unit of analysis to include extended networks of social and material production, and recognizing the agencies, and attendant\r\n\r\nIntroduction\r\n\r\n7\r\n\r\nresponsibilities, involved in the inevitable cuts through which bounded sociomaterial entities are made.\r\nThe expansion of the text in terms of both technologies and theoretical resources is accompanied by a commitment to writing for new audiences. In particular, the new chapters of this book attempt to engage more deeply with those working in the anthropology and sociology of technology who are, and always have been, my compass and point of reference. Somewhat ironically, my location at PARC and the marketing of the original text as a contribution in computer science have meant that the book contained in Chapters 2 through 10 of this edition received much greater visibility in computing ­ particularly HCI ­ and in cognitive science than in either anthropology or STS. Although I am deeply appreciative of that readership and the friends from whom I have learned within those communities, it is as a contribution to science and technology studies that the present volume is most deliberately designed.\r\n\r\n1\r\nReadings and Responses\r\nThis chapter provides a synopsis and some contextualization of the analysis offered in the original edition of Plans and Situated Actions (P&SA), published in 1987, followed by my reflections on the reception and readings of that text. My engagement with the question of human­machine interaction, from which the book arose, began in 1979, when I arrived at PARC as a doctoral student interested in a critical anthropology of contemporary American institutions1 and with a background as well in ethnomethodology and interaction analysis. My more specific interest in the question of interactivity at the interface began when I became intrigued by an effort among my colleagues to design an interactive interface to a particular machine. The project was initiated in response to a delegation of Xerox customer service managers, who traveled to PARC from Xerox\'s primary product development site in Rochester, New York, to report on a problem with the machine and to enlist research advice in its solution.2 The machine was a relatively large, feature-rich photocopier that had just been \"launched,\" mainly as a placeholder to establish the company\'s presence in a particular market niche that was under threat from other, competitor, companies. The machine was advertised with a figure dressed in the white lab coat of the scientist/engineer but reassuring the viewer that all that was required to activate the machine\'s extensive functionality was to \"press the green [start] button\" (see Fig. 1.1).\r\n1 A defining text of what came to be known as \"anthropology as cultural critique\" is Marcus and Fischer (1986). See also Gupta and Ferguson (1997); Marcus (1999); Strathern (1999).\r\n2 The project is discussed at length in Suchman (2005). 8\r\n\r\nReadings and Responses\r\n\r\n9\r\n\r\nfigure 1.1. \"Pressing the green button\" Advertisement for the Xerox 8200 copier, circa 1983 c Xerox Corporation.\r\nIt seemed that customers were refuting this message, however, complaining instead that the machine was, as the customer service managers reported it to us, \"too complicated.\" My interest turned to investigating just what specific experiences were glossed by that general complaint, a project that I followed up among other ways by convincing my colleagues that we should install one of the machines at PARC and invite our co-workers to try to use it. My analysis of the troubles evident in these videotaped encounters with the machine by actual scientists/engineers led me to the conclusion that its obscurity was not a function of any lack of general technological sophistication on the part of its users but rather of their lack of familiarity with this particular machine. I argued that the machine\'s complexity was tied less to its esoteric technical characteristics than to mundane difficulties of interpretation characteristic of any unfamiliar artifact. My point was that making sense of a new artifact is an inherently problematic activity. Moreover, I wanted to suggest that however improved the machine interface or instruction set might be, this would never eliminate the need for active sense-making on the part of prospective users. This in turn called into\r\n\r\n10\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nquestion the viability of marketing the machine as \"self-explanatory,\" or self-evidently easy to use.3\r\nMy colleagues, meanwhile, had set out on their own project: to design an \"intelligent, interactive\" computer-based interface to the machine that would serve as a kind of coach or expert advisor in its proper use. Their strategy was to take the planning model of human action and communication prevalent at the time within the AI research community as a basis for the design. More specifically, my colleagues were engaged with initiatives in \"knowledge representation,\" which for them involved, among other things, representing \"goals\" and \"plans\" as computationally encoded control structures. When executed, these control structures should lead an artificially intelligent machine imbued with the requisite condition­action rules to take appropriate courses of action.\r\nMy project then became a close study of a second series of videotaped encounters by various people, including eminent computer scientists, attempting to operate the copier with the help of the prototype interactive interface. I took as my focus the question of interactivity and assumptions about human conversation within the field of AI, working those against findings that were emerging in sociological studies of faceto-face human conversation. The main observation of the latter was that human conversation does not follow the kind of message-passing or exchange model that formal, mathematical theories of communication posit. Rather, humans dynamically coconstruct the mutual intelligibility of a conversation through an extraordinarily rich array of embodied interactional competencies, strongly situated in the circumstances at hand (the bounds and relevance of which are, in turn, being constituted through that same interaction). I accordingly adopted the strategy of taking the premise of interaction seriously and applying a similar kind of analysis to people\'s encounters with the machine to those being\r\n\r\n3 As Balsamo succinctly points out, \"to design an interface to be `idiot-proof\' projects a very different level of technical acumen onto the intended users than do systems that are designed to be `configurable\'\" (Balsamo in press: 29). It should be noted that this agument carried with it some substantial ­ and controversial ­ implications for technology marketing practices as well, insofar as it called into question the assertion that technology purchasers could invest in new equipment with no interruption to workers\' productivity and with no collateral costs. On the contrary, this analysis suggests that however adequate the design, long-term gains through the purchase of new technology require near-term investments in the resources that workers need to appropriate new technologies effectively into their working practices. Needless to say, this is not a message that appears widely in promotional discourses.\r\n\r\nReadings and Responses\r\n\r\n11\r\n\r\ndone in conversation analysis. The result of this analysis was a renewed appreciation for some important differences ­ more particularly asymmetries ­ between humans and machines as interactional partners and for the profound difficulty of the problem of interactive interface design.\r\nAlthough the troubles that people encountered in trying to operate the machine shifted with the use of the \"expert advisor,\" the task seemed as problematic as before. To understand those troubles better, I developed a simple transcription device for the videotapes (see Chapter 9), based in the observation that in watching them I often found myself in the position of being able to see the difficulties that people were encountering, which in turn suggested ideas of how they might be helped. If I were in the room beside them, in other words, I could see how I might have intervened. At the same time I could see that the machine appeared quite oblivious to these seemingly obvious difficulties. My question then became the following: What resources was I, as (at least for these purposes) a full-fledged intelligent observer, making use of in my analyses? And how did they compare to the resources available to the machine? The answer to this question, I quickly realized, was at least in part that the machine had access only to a very small subset of the observable actions of its users. Even setting aside for the moment the question of what it means to observe, and how observable action is rendered intelligible, the machine could only \"perceive\" that small subset of the users\' actions that actually changed its state. This included doors being opened and closed, buttons being pushed, paper trays being filled or emptied, and the like. But in addition to those actions, I found myself making use of a large range of others, including talk and various other activities taking place around and in relation to the machine, which did not actually change its state. It was as if the machine were tracking the user\'s actions through a very small keyhole and then mapping what it saw back onto a prespecified template of possible interpretations. Along with limitations on users\' access to the design script,4 in other words, I could see clearly the serious limitations on the machine\'s access to its users.\r\nMy analysis, in sum, located the problem of human­machine communication in continued and deep asymmetries between person and machine. I argued that so-called interactive programs such as the\r\n\r\n4 On scripts and their configuration of users, see Woolgar (1991) and Akrich (1992). I discuss these ideas more fully in Chapter 11.\r\n\r\n12\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nexpert system devised by my colleagues exploit certain characteristics of human conversation in ways that encourage attributions of interactivity to machines by their human interlocutors. At the same time, those attributions belie the profoundly different relations of person and machine to the unfolding situation and their associated capacities to interact within and through it. So the machine\'s users will read instructions offered by an expert help system as comments on the activity underway that should be intelligible, a strategy that proves extremely powerful for moving things along. Human interaction succeeds to the extent that it does, however, due not simply to the abilities of any one participant to construct meaningfulness but also to the possibility of mutually constituting intelligibility, in and through the interaction. This includes, crucially, the detection and repair of mis- (or different) understandings. And the latter in particular, I argued, requires a kind of presence to the unfolding situation of interaction not available to the machine.\r\nMy discussion of these problems was carefully framed not to take a position on the ultimate possibility that machines could ever be intelligent and interactive but to suggest at least that the problem of interactive interface design is a much more subtle and interesting one than what it was assumed to be by my colleagues at the time. Basically, it seemed to me, their assumption was that computational artifacts just are interactive, in roughly the same way that we are, albeit with some more and less obvious limitations. However ambitious, the problem as they saw it was a fairly straightforward task of overcoming the limitations of machines by encoding more and more of the cognitive abilities attributed to humans into them.5 My purpose in emphasizing the limits on machine interactivity was not, in other words, to argue from any a priori assumptions about essential aspects of \"human nature\" (Sack 1997: 62). As I hope will become clear in the following pages, I take the boundaries between persons and machines to be discursively and materially enacted rather than naturally effected and to be available, for better and worse and with greater and lesser resistances, for refiguring. It is precisely because the distinction between person and machine rests on the traffic back and forth between the two terms that questions of human­machine identity and difference matter. With that said, my observation continues to be that although the language of interactivity\r\n\r\n5 For closely considered arguments regarding the problems with this premise, see, for example, Dreyfus ([1972]1992); Collins (1990); Button, Coulter, Lee, and Sharrock (1995); Adam (1998).\r\n\r\nReadings and Responses\r\n\r\n13\r\n\r\nand the dynamics of computational artifacts obscure enduring asymmetries of person and machine, people inevitably rediscover those differences in practice.\r\nThe prevailing view within AI in the early to mid-1980s was that the relation of plans to actions was a determining one.6 A primary aim of the argument of P&SA was to suggest a shift in the status of plans, from cognitive control structures that universally precede and determine actions to cultural resources produced and used within the course of certain forms of human activity. A starting premise of my argument was that planning is itself a form of situated activity that results in projections that bear some interesting, and as yet unexplicated, relation to the actions that they project. In ordinary affairs, \"planning\" is an imaginative and discursive practice (now underwritten by a wide range of more and less effective technologies) through which actors project what they might do and where they might go, as well as reflect on where they are in relation to where they imagined that they might be.7\r\nHaving reopened the question of what plans are and how they work, I then suggested that we locate the answer to that question in what Garfinkel and Sacks (1970: 342) have named the \"observable-reportable\" accountability of practical reasoning and practical action. A central feature of planning in this sense is that it is among the many everyday practices that we, as participants in Euro-American cultural traditions at least, call out as a foundation for the rationality of our actions. The planned character of our actions is not, in this sense, inherent but is demonstrably achieved. It is a reflexive feature of our (inter-)actions insofar as we are able, on an ongoing basis, to indicate (to others and/or to ourselves) what we are aiming to do and to account for our actions as close enough for all practical purposes to what we had intended. Note that reflexivity as used here is not a synonym for reflection but rather as a statement that the sense of our actions is found in and through the very same methods that we employ to enact them intelligibly in the first place.\r\nAn unanticipated but welcome development in the progress of my work on the original text occurred when I discovered a resonance between my project and another underway at the time inside the AI community. In the 1980s Phil Agre and David Chapman, themselves\r\n\r\n6 The central text being Miller, Galanter, and Pribram (1960). 7 On the status of plans as prospective and retrospective resources for action, see also\r\nAgre (1997: 5­9) and Agre and Chapman (1990).\r\n\r\n14\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ndoctoral students at the Massachusetts Institute of Technology (MIT) AI Lab, were engaged in a kind of endogenous critique of prevailing assumptions and practices within the field, particularly in the area of AI planning (Agre and Chapman 1987, 1990). Brought together through the closely linked networks of PARC and MIT, we discovered an unexpected complementarity in our projects. In particular, Agre and Chapman were troubled by what they found to be a logical and, they argued, fatal flaw in the machinery of AI planning. Committed to questioning the planning paradigm on a technical basis, they were interested to find an anthropologist engaged in the same project on the basis of the framework\'s adequacy as an account of everyday practice. I, correspondingly, was delighted to find allies capable of opening up the planning framework to critical inspection on its own terms. Our connection resulted in a rich exchange, not simply of the idea that plans needed reconceptualization in AI, but of theoretical and empirical resources to aid in that project. Agre subsequently developed the implications of an ethnomethodological critique for AI, and research into computation more broadly, through his conception of a \"critical technical practice,\" one in which attention to the rhetorics and technologies through which a field constructs its research objects becomes an integral part of its research practice.8 As Agre explains:\r\nInstead of seeking foundations it would embrace the impossibility of foundations, guiding itself by a continually unfolding awareness of its own workings as a historically specific practice. It would make further inquiry into the practice of AI an integral part of the practice itself. It would accept that this reflexive inquiry places all of its concepts and methods at risk. And it would regard this risk positively, not as a threat to rationality but as the promise of better ways of doing things. (1997: 23)\r\nAlthough these more complex lines of intellectual exchange remained generally unrecognized in the wider AI community, the trope of the \"situated\" traveled through Agre to his supervisor, Rod Brooks, at MIT.9 Sengers (2004) observes that, by now, references to \"situated action\"\r\n\r\n8 Agre\'s argument, of course, has strong resonance with Harding\'s notion of a \"successor science\" (1986, 1991) and related writings in feminist science studies, in its emphasis on critical engagement with the location and limits of knowledge production as an integral part of scientific practice. For a recent discussion of the interchange between P&SA and the field of AI, read through the lens of this history and Agre\'s proposal, see Sengers (2004).\r\n9 Interview with Rod Brooks, March 20, 2003. I discuss Brooks\'s approach further, particularly with respect to notions of embodiment, in Chapter 13 of this volume.\r\n\r\nReadings and Responses\r\n\r\n15\r\n\r\nhave been incorporated into business as usual within AI research. But unlike the case of Agre\'s critical technical practice, she argues, AI researchers have for the most part failed to see the argument\'s implications for their own relations to their research objects and, relatedly, have adhered to an unreconstructed form of realism in their constitution of the \"situation.\" Brooks in particular embraces an idea of situated action as part of his campaign against representationalism in AI and within a broader argument for an evolutionarily inspired model of intelligence.10 For Brooks, situated means that creatures reflect in their design an adaptation to particular environments. Following a lineage traceable to the founding premises of cybernetics, Brooks\'s situatedness is one evacuated of sociality, at least as other than a further elaboration of an environment understood primarily in physical terms. The creature\'s \"interactions\" with the environment, similarly, comprise variations of conditioned response, however tightly coupled the mechanisms or emergent the effects.\r\nA reading of situated as nonrepresentational has led in some cases to the term\'s appropriation in support of various forms of neobehaviorism. Brooks\'s robots evidence one version of this, as does the reading put forward by Vera (2003), for whom situated comes, in an ironic twist, to mean \"predetermined,\" a sense antithetical to the orientation toward the flexible, ongoing (re-)production of intelligible action that I would take it to convey. Vera makes the interesting point that a difference between Simon\'s famous ant (1969) and the Micronesian navigator invoked in the opening of P&SA is that the former is impeded by the contingencies of the environment, whereas the latter takes advantage of them. But, remarkably, he concludes from this, \"In this sense, the ant\'s behavior seems truly situated, in the strongest theoretical sense\" (Vera 2003: 283). Although I am unsure what being situated \"in the strongest theoretical sense\" could mean, I am sure that my use of situated does not mean acting in the absence of culturally and historically constituted resources for meaning making. On the contrary, as I have reiterated (perhaps for some ad nauseum), situatedness is presupposed by such practices and the condition of possibility for their realization. Behavior is not simply \"reactive and contingent on the external world\" (ibid.: 283) but rather is reflexively constitutive of the world\'s significance, which in turn gives behavior its sense.\r\n\r\n10 For formulations of Brooks\' position written for a general reader, see Brooks (1999, 2002).\r\n\r\n16\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe unfortunate separation of planned and situated as somehow two kinds of action (of which more below) contributes to an inverse reading of situated, also very different from my own, which treats the term as synonymous with spontaneous or improvisational. Set in opposition to predetermining conditions, this leads to an interpretation of situated as involving a kind of erasure of context, as implying that action happens de novo, without reference to prior histories. This is of course antithetical to the kind of strong orientation to the circumstances of action that my use of the term was meant to support and is understandable only in the context of long-standing debates within the social sciences over how we should understand the obdurate and enduring character of normative and institutionalized social orders. More sympathetically, Gordon Wells (2003) raises the question of the relation between an orientation to the in situ achievement of social order and the problem of the durability of orders of ordinary action over time and across space. To my understanding, ethnomethodology\'s insistence on the \"just here, just now\" achievement of social order is not aimed at an erasure of history. Rather, it is a move away from the structuralist premise that prior conditions fully specify what it means to act within the prescripts that institutionalized society provides. As in the analysis of prescriptive representations more broadly, social institutions and the rules that they imply do not reproduce themselves apart from ongoing activity. And like instructions, plans, and other forms of prescriptive representation, both institutions and rules of conduct presuppose in situ forms of social action that they can never fully specify.\r\nThere is in my view no inherent conflict between an ethnomethodological approach to studies of situated action and an interest in cultural historical continuities and their effects. The commitment to situated action orients us, however, always to the question of just how, and for whom, culturally and historically recognizable formations take on their relevance to the moment at hand. With respect to the durability and reach of established social orders, the dichotomies of \"micro\" and \"macro,\" \"local\" and \"global,\" are replaced by questions of location and extent. Tropes of \"large\" and \"small,\" \"top and bottom,\" give way to analyses of the cumulative durability and force of practices and artifacts extended through repeated citation and in situ reenactment. Ethnomethodology and other poststructuralist approaches to social order propose, in sum, that it is only through their everyday enactment and reiteration that institutions are reproduced and rules of conduct realized.\r\n\r\nReadings and Responses\r\n\r\n17\r\n\r\nTwo published forums in the years 1993 and 2003 comprise the most intensive discussion of the original text of P&SA, both located at the intersection of the cognitive and social sciences.11 These discussions traversed some of the thornier underbrush in my original articulation of the argument, demonstrating weaknesses and gaps as well as some surprisingly enduring and, for me, puzzling, (mis-)readings. Along with whatever contributions I have unwittingly made to the latter, I believe that they are evidence for the multiplicity of different, sometimes antithetical, premises with which I and my interlocutors approach our subject matter. Perhaps the most direct critique of the original text came in an article by Alonso Vera and Herbert Simon (1993) titled \"Situated Action: A Symbolic Interpretation.\" Aimed more broadly at refuting the growing interest in nonsymbolic forms of AI promoted by Brooks and others, Vera and Simon discuss what they name \"the congeries of theoretical views collectively referred to as `situated action (SA).\'\"12 In their representation of my argument, Vera and Simon reiterate the (mis-) reading most frequent among those who cite it, whether sympathetic or not. In particular, they claim that I assert planning to be \"irrelevant in everyday human activity\" (ibid.: 7). I took the opportunity of responding to their article to restate that the primary agenda of my writing on the topic was not to dismiss plans as phenomena of interest but, on the contrary, to recover them as objects of investigation. My concern was that as long as plans were treated as determining of the actions projected, a theory of plans became not only necessary but also sufficient for an account of human activity. One might have to worry about cases in which for one reason or another a planned action could not be executed, but the fundamental assumption was that once you knew the plan, the action simply followed.\r\n\r\n11 See Cognitive Science 17(1), 1993; Journal of the Learning Sciences 12(2), 2003. My representation of this debate is drawn from Suchman (1993, 2003). For other careful and generative readings of the original text, see Heath and Luff (2000: Chapter 1); Dourish (2001: Chapter 3). Clancey (1997) offers an extended discussion of the sense of situated for the cognitive sciences. For a cogent analysis of appropriations of a notion of \"situatedness\" in service of general critiques of education, and the identification of an alternate programme of classroom research, see Macbeth (1996).\r\n12 I have attempted scrupulously to avoid the use of acronyms such as SA or initial capitals with the phrase \"situated action,\" hoping to forestall the introduction of a hardened theoretical object and to maintain the descriptive character of the adjective. Of course all action is situated: the adjective is meant not as a qualifier, but rather as a reminder of that fact.\r\n\r\n18\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nPerhaps in part because of their commitment to this conception of plans, Vera and Simon read my argument that plans are not determining of the actions that they project (at least not in any strong sense of the word determining) as a rejection of the notion of planning altogether.13 The main justification for this reading of my argument seemed to be the example I offered of taking a canoe through a set of rapids (see Chapter 6). Vera and Simon claimed that I had said that \"a person would plan a course down the river but this plan would serve no purpose when the rapids were finally run\" (1993: 16). As evidence for this, they cite a sentence of mine meant to point to the priority of embodied action in such an activity: \"When it really comes down to the details of responding to the currents and handling a canoe, you effectively abandon the plan and fall back on whatever skills are available to you\" (Suchman 1987: 52). Although I admit that the phrase \"effectively abandon\" was an unfortunate one and legitimately prone to such a reading, I pointed out that the sense would change in a subtle but important way had Vera and Simon included the next sentence as well: \"The purpose of the plan in this case is not to get your canoe through the rapids, but rather to orient you in such a way that you can obtain the best possible position from which to use those embodied skills on which, in the final analysis, your success depends\" (ibid.: 52). The plan, in sum, has a purpose.14 The interesting question, I proposed, is just how it fulfills that purpose. Vera and Simon argued that I did not \"appear to recognize that most plans\r\n\r\n13 Vera and Simon asserted as well that I, along with Winograd and Flores (1986), argued that \"the methods and terminology of situated action should replace current humancomputer interaction methods in psychology and AI\" and that \"we must focus on how people use [interfaces] instead of how people think, or what computers can do\" (1993: 11). I do not believe that I ever used such exclusionary language in speaking of these things. Rather, my interest had been (a) to redress a situation of disattention to human­ computer interaction as situated activity and (b) to take the idea of human­computer interaction seriously as interaction, in the sense that I understand it between people. Doing the latter actually led me to the limits of the notion that what goes on between people and machines is usefully compared to interaction between people. In any case, in no way was my approach meant to replace investigations of how people think or of what computers can do. If anything, it was meant to reframe them.\r\n14 In response to my concern with this partial citation after reading a draft of Vera and Simon\'s article, they included the following footnote in the published version: \"Elsewhere on this same page, Suchman retreated a bit from this strong language, and acknowledged that, even in this kind of situation, the plan may determine initial conditions for the behavior. However, her discussion is at best contradictory, and in general, wholly skeptical of planning\" (1987: 16). Note that the sentence in question does not propose that plans are \"initial conditions\": I would maintain that the confusion here is Vera and Simon\'s, not my own.\r\n\r\nReadings and Responses\r\n\r\n19\r\n\r\nare not specifications of fixed sequences of actions, but are strategies that determine each successive action as a function of current information about the situation\" (1993: 17). Although I wonder about terms like most plans and determine . . . as a function of, the question of just how plans relate to the actions they formulate does constitute our common interest, as well as the real point of debate.\r\nMy discussion of the canoeing example was meant to emphasize both the utility of projecting future actions and the reliance of those projections on a further horizon of activity that they do not exhaustively specify. The case of whitewater canoeing seemed to me to offer a perspicuous example of both. My choice of wording has clearly contributed to the reading of my argument as saying that the plan is irrelevant once one is in the water. This despite the fact that the surrounding text makes clear that I take both the projected course and the work done within the rapids to be crucial. Again, the interesting question is just how the activity of projecting a course has its effects in the subsequent activity of finding one in situ. It is those effects, understood as a situated achievement of the very same course of action that the plan projects, that constitute the plan\'s practical adequacy as an orienting device for action.\r\nVera and Simon come in the end to what they say is \"the central claim of hard SA: that behavior can only be understood in the context of complex real-world situations. Interpreted literally, this claim is surely wrong, since no organism, natural or artificial, ever deals with the real-world situation in its full complexity\" (ibid.: 45). Setting aside the question of just what it would mean to \"interpret literally\" this claim, I proposed a rewording that would make it closer to a claim to which I would in fact subscribe, namely \"that behavior can only be understood in its relations with real-world situations.\" There are two changes here, one subtle, one less so. The more subtle shift, from \"in the context of\" to \"in its relations with,\" is meant to get away from the container-like connotation of the term context and emphasize instead that the structuring of behavior is done not a priori, but in reflexive relation to circumstances that are themselves in the process of being generated, through the same actions that they in turn work to make comprehensible. The less subtle correction is elimination of the term complex, a term more from Vera and Simon\'s discourse than from my own. In my view the complexity or simplicity of situations is a distinction that inheres not in situations but in our characterizations of them; that is, all situations are complex under some views and simple under others. Similarly, I cannot imagine what it could mean to deal with a situation in its \"full\" complexity, because\r\n\r\n20\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsituations are not quantities of preexisting properties dealt with more and less fully. The point of the claim as reworded is just that actions are structured in relation to specific circumstances and need to be understood in those terms.\r\nTo summarize, my position then and now has been that plans are conceptual and rhetorical devices (often materialized in various ways, as texts, diagrams and the like) that are deeply consequential for the lived activities of those of us who organize our actions in their terms. Just how plans are consequential for the actions they project defined, at least potentially, a territory of mutual interest for the social and cognitive sciences. Vera and Simon\'s position, in contrast, seems based on the premise that planning ­ or more accurately plan execution ­ and situated action comprise two different, alternative forms of activity: that, as they put it, a function of a plan is that it \"minimizes the number of occasions when an emergency calling for SA will arise,\" namely, those requiring reaction to \"severe, real-time requirements\" or \"unexpected events\" (1993: 41). Planning and plan execution, in other words, are still the primary forms of activity, with what is now called \"SA\" (which in its \"pure\" form according to Vera and Simon is made up entirely of predetermined responses) coming into play only in certain cases. As I tried to make clear in my response at the time, this is not the view of situated action that I hold. Nor, I believe, is it the view that will lead us closer to an understanding of how plans might be generated within situated activity and then brought to bear on some future course of action. To reach that understanding will require an account of the relation between planning-as-activity, the artifacts of that activity, and the subsequent activities to which those artifacts (conceptual, linguistic, or otherwise) are meaningfully related.15\r\nThe publication of a Books and Ideas section in the Journal of the Learning Sciences (2003) afforded another, more recent opportunity for a response to readings of the original text of P&SA. In their generally sympathetic critique in that volume, Sharrock and Button call attention to a deeper vulnerability in my original argument. They close their commentary with a valuable clarification, by pointing to ambiguities in the verb \"to determine.\" More specifically, they point out that the sense implied by a statement like \"our position on the high seas is determined . . . by consulting a chart\" presupposes not an axiomatically causal relation, but an act by which things are brought into relation (2003: 263). Bringing\r\n\r\n15 I return to this topic in Chapter 11.\r\n\r\nReadings and Responses\r\n\r\n21\r\n\r\nthings into relation may be done more and less easily, as we become familiar with particular, recurring configurations iterated over time (for example, relations between the laws governing where one may and may not park, the signs and artifacts that mark the urban landscape, the practices of driving and parking, the documents used to indicate an infraction, the ability of drivers to read those signs and documents, and so forth). Despite the seeming automaticity of these relations, however, they do not run by themselves but must be continually reiterated and reproduced, as well as elaborated, resisted, and/or transformed. Consistent with this position, I wanted to suggest that plans are just one among many types of discursive artifacts through which we achieve the rational accountability of action. As such, they arise through activity and are incorporated into the activities that they project.\r\nIn the interest of challenging the cognitive science view of plans as determinates of action, however, I uncoupled plans and actions and reframed their relation as problematic. By implicitly suggesting that plans were somehow outside of action, this move invited just the kind of separation on which the plan versus execution dichotomy, which I was trying to displace, relies. Where I had hoped to direct attention instead was precisely to the relation between the activity of planning and the conduct of actions-according-to-plan. My aim was not to define that relation but to pose it as a question for our collective research agendas and to suggest that ethnomethodology had some crucial contributions toward an answer.\r\nViewing the plan as an artifact or tool (the hammer being the iconic case) seemed helpful in further clarifying the plan/action relation. Although the durable materiality of the hammer supports the statement that it exists before and after the moments of its use, it is nonetheless clear that its status as a hammer rests on its incorporation into the practice of some form of carpentry. By the same token, being a carpenter involves, inter alia, the competent practice of hammering. The possibility of uncoupling the hammer from its use in carpentry does not mean that the two are separable in practice. Similarly, calling out a plan as a self-standing artifact is a situated action in its own right and does not diminish the reliance of the plan for its significance on its effective incorporation into practice.\r\nMost fundamentally, I wanted to draw attention to the ways in which plans and other formulations of action open out onto a sphere of embodied action and lived experience that extends always beyond their bounds and at the same time gives them their sense and efficacy. It is this relation\r\n\r\n22\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthat forms a core topic for ethnomethodology, exemplified as Sharrock and Button remind us in the work of instruction following. The efficacy of plans, instructions, and the like ­ their generality and their \"immutable mobility\" (to use Latour\'s famous phrase; 1986: 7) ­ relies precisely on the ability of those who make use of them to find the relation of these general prescriptions to the particular occasion that faces us now. It is in this respect that instructions do not precede the work of their enactment but rather that their sense is found in and through, and only in and through, that work. As should be evident, this is an extraordinarily general phenomenon of social life, though it can only be understood in its specifics.\r\nIn his broadly generous reading of P&SA, John Carroll (2003) points to what I agree is another weak link of the original book; that is, its conclusions. He suggests that it was my use of conversation analysis as a foundation for my study that limited my ability to draw out the argument\'s design implications. Rather, I would say that it was my own fledgling relation to the fields of system design and their possibilities, the limits of my experience at the time, which constrained my ability to imagine how it could be otherwise. As Carroll takes care to point out, I have been involved in the years since in exploring the design implications of the critique through my own developing practice. More specifically, this has involved a series of initiatives aimed at practicing alternative approaches, demonstrated as cases of ethnographically based, work-oriented participatory design.16\r\nSo what would I conclude now, given the benefit of all the developments since 1987 both in my own working life and in the projects of AI and HCI? In the original project I adopted the methodological strategy of applying analytic techniques and insights from the study of human interaction to see what would happen if we took the metaphor of human­computer interaction seriously. I begin my conclusions now by reiterating the basic finding of the analysis in P&SA; namely, that\r\n\r\n16 See Blomberg, Suchman, and Trigg (1996); Suchman (1999, 2001, 2002a, 2002b); Suchman, Blomberg, Orr, and Trigg (1999); Suchman, Trigg, and Blomberg (2002); Trigg, Blomberg, and Suchman (1999). I am a bit less encouraged than Carroll at the extent to which \"ethnographic workplace studies and worker participation in design are standard engineering practices\" (2003: 278). In some respects I have the contrary sense that the spaces for this kind of design practice are closing down with the economic turns of the industry and associated retrenchments in old values of (at least apparently, in upfront costs) faster and cheaper production. I return to these problems and possibilities in Chapter 15.\r\n\r\nReadings and Responses\r\n\r\n23\r\n\r\nthere is (still) no evidence for the achievement of conversation between humans and machines in the strong sense that we know it to go on between humans. Interaction, as Emanuel Schegloff reminds us (1982), is not the stage on which the exchange of messages takes place, or the means through which intentionality and interpretation operationalize themselves. Rather, interaction is a name for the ongoing, contingent coproduction of a shared sociomaterial world. Interactivity as engaged participation with others cannot be stipulated in advance but requires an autobiography, a presence, and a projected future. In this strong sense, I would argue, we have yet to realize the creation of an interactive machine.\r\nAt the same time, given recent demonstrations within science and technology studies and the media arts of the many ways in which things do participate with us, I now emphasize the proposition that they must be allowed to do so in their own particular ways. Initial observations suggest that a more productive metaphor than conversation to describe our relations with computational artifacts may be that of writing and reading (see Grint and Woolgar 1997: 70; Chapter 11). But these are new forms of writing and reading, with new materials or media. What characterizes those new media are their unprecedented dynamics, based in their underlying computational mechanisms. More than conversation at the interface, we need the creative elaboration of the particular dynamic capacities that these new media afford and of the ways that through them humans and machines together can perform interesting new effects. These are avenues that have just begun to be explored, primarily in the fields of new media, graphics and animation, art and design. Not only do these experiments promise innovations in our thinking about machines, but they also open up the equally exciting prospect of new conceptualizations of what it means to be human, understood not as a bounded, rational entity but as an unfolding, shifting biography of culturally specific experience and relations, inflected for each of us in uniquely particular ways.\r\n\r\n2\r\nPreface to the 1st Edition\r\nThomas Gladwin (1964) has written a brilliant article contrasting the method by which the Trukese navigate the open sea, with that by which Europeans navigate. He points out that the European navigator begins with a plan ­ a course ­ which he has charted according to certain universal principles, and he carries out his voyage by relating his every move to that plan. His effort throughout his voyage is directed to remaining \"on course.\" If unexpected events occur he must first alter the plan, then respond accordingly. The Trukese navigator begins with an objective rather than a plan. He sets off toward the objective and responds to conditions as they arise in an ad hoc fashion. He utilizes information provided by the wind, the waves, the tide and current, the fauna, the stars, the clouds, the sound of the water on the side of the boat, and he steers accordingly. His effort is directed to doing whatever is necessary to reach the objective. If asked, he can point to his objective at any moment, but he cannot describe his course.\r\n(Berreman 1966: 347)\r\nThe subject of this book is the two alternative views of human intelligence and directed action represented here by the Trukese and the European navigator.1 The European navigator exemplifies the\r\n1 A comment is needed here on the poetics and problems of this quotation. In his subsequent book Gladwin (1970: 232) modified his analysis of the question of plans with respect to Micronesian navigation. In particular, he proposed that the distinctions he had initially sought between Micronesian and Western navigators, and that he had located among other places in their respective relations to planning, could not be so clearly drawn. This was the case insofar as the Micronesian navigator could also be said to have a plan in advance of his voyage, the difference being less in the existence of\r\n24\r\n\r\nPreface to the 1st Edition\r\n\r\n25\r\n\r\nprevailing cognitive science model of purposeful action, for reasons that are implicit in the final sentence of the quote above. That is to say, while the Trukese navigator is hard pressed to tell us how he actually steers his course, the comparable account for the European seems to be already in hand, in the form of the very plan that is assumed to guide his actions. Although the objective of the Trukese navigator is clear from the outset, his actual course is contingent on unique circumstances that he cannot anticipate in advance. The plan of the European, in contrast, is derived from universal principles of navigation and is essentially independent of the exigencies of his particular situation.\r\nGiven these contrasting exemplars, there are at least three, quite different, implications that we might draw for the study of purposeful action. First, we might infer that there actually are different ways of acting that are favored differently across cultures. How to act purposefully is learned and subject to cultural variation. European culture favors abstract, analytic thinking, the ideal being to reason from general principles to particular instances. The Trukese, in contrast, having no such ideological commitments, learn a cumulative range of concrete, embodied responses, guided by the wisdom of memory and experience over years of actual voyages. In the pages that follow, however, I argue that all activity, even the most analytic, is fundamentally concrete and embodied. So although there must certainly be an important relationship between ideas about action and ways of acting, this first interpretation\r\n\r\nsomething that could be called a plan than in the plan\'s specific character. Whereas the Western navigator draws up a plan for each voyage, Gladwin observes, the Micronesian effectively learns a set of navigational practices as an integral part of learning to sail, which are then available for any subsequent voyage. This difference is balanced by the common requirement ­ set out, Gladwin proposes, by the sea itself ­ for aids to navigation. This revision challenges the simple readings to which this opening epigraph was prone, while underscoring the idea developed in the text that follows that we understand plans as orienting devices whose usefulness turns on their translation to action within an uncertain horizon of contingencies. It also suggests that the moral of the story be read as emphasizing the interrelation of cultural and historical traditions within which persons act and the artifacts and practices that they produce and rely on. It is the specific and various configurations of the latter that I would now argue we need to take as our topic of investigation. My thanks go to Phil Agre for drawing this passage from Gladwin to my attention. For detailed accounts of Pacific island navigational traditions, see also Lewis (1972), Hutchins (1983), and Turnbull (1990, 2000). On the politics of the European fascination with Micronesia, of which these studies are a part, David Turnbull (1990: 6) points out that \"Micronesian navigation has been `discovered\' and revived to serve as an anthropological mirror for western knowledge at the very moment when it was about to be snuffed from existence.\"\r\n\r\n26\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nof the navigation example stands in danger of confusing theory with practice.2\r\nAlternatively, we might posit that whether our actions are ad hoc or planned depends on the nature of the activity or our degree of expertise. So we might contrast instrumental, goal-directed activities with creative or expressive activities or contrast novice with expert behavior. Dividing things up along these lines, however, seems in some important ways to violate our navigation example. Clearly the Truk is involved with instrumental action in getting from one island to another, and just as clearly the European navigator relies on his chart, regardless of his degree of expertise.3\r\nFinally, the position to be taken ­ and the one that I adopt here ­ could be that, however planned, purposeful actions are inevitably situated actions. By situated actions I mean simply actions taken in the context of particular, concrete circumstances. In this sense one could argue that we all act like the Trukese, however much some of us may talk like Europeans. We must act like the Trukese because the circumstances of our actions are never fully anticipated and are continuously changing around us. As a consequence our actions, although systematic, are never planned in the strong sense that cognitive science would have it. Rather, plans are best viewed as a weak resource for what is primarily ad hoc activity. It is only when we are pressed to account for the rationality of our actions, given the biases of European culture, that we invoke the guidance of a plan. Stated in advance, plans are necessarily vague, insofar as they must accommodate the unforeseeable contingencies of particular situations. Reconstructed in retrospect, plans systematically filter out precisely the particularity of detail that characterizes situated\r\n\r\n2 Or rather, I would say now, in a familiar parochially Western move this interpretation sets up a false opposition between theory and practice, allocating the one to the European (erasing the presence of practical specificity), the latter to the Trukese (erasing the presence of generalizing practices). More seriously, this interpretation puts us in the problematic position identified by postcolonial scholarship, defining the Trukese as second Other to the European, characterized by the absence of a privileged, albeit imaginary, rationality. For a far more nuanced and provocative treatment of these questions, see Turnbull (2000), and Verran\'s argument in favor of what she calls \"disconcertment,\" or recognition of the simultaneous sameness and incommensurable difference in culturally specific \"ontic/epistemic imaginaries,\" over either universalism or relativism (2001).\r\n3 Much has now been written about the transformations that occur in learning a practice. As a central text on learning in doing, published in parallel with my own, see Lave (1988).\r\n\r\nPreface to the 1st Edition\r\n\r\n27\r\n\r\nactions, in favor of those aspects of the actions that can be seen to accord with the plan.\r\nThis third implication, it seems, is not just a symmetric alternative to the other two but is different in kind and somewhat more serious. That is, it calls into question not just the adequacy of our distinctions along the dimensions of culture, kinds of activity, or degrees of expertise, but the very productivity of our starting premises that representations of action such as plans could be the basis for an account of actions in particular situations. Because the third implication has to do with foundations, and not because there is no truth in the other two, I take the idea that actions are primarily situated and that situated actions are essentially ad hoc as the starting point for my investigations.4\r\nThe view of action exemplified by the European navigator is now being reified in the design of intelligent machines. In this book I examine one such machine, as a way of uncovering the strengths and limitations of the general view that its design embodies. The view, that purposeful action is determined by plans, is deeply rooted in the Western human sciences as the correct model of the rational actor. The logical form of plans makes them attractive for the purpose of constructing a computational model of action, to the extent that for those fields devoted to what is now called cognitive science, the analysis and synthesis of plans effectively constitute the study of action. My own contention, however, is that as students of human action we ignore the Trukese navigator at our peril. Although an account of how the European navigates may be in hand, the essential nature of action, however planned or unplanned, is situated. It behooves us, therefore, to study and to begin to find ways to describe the \"Trukese\" system.\r\nThere is an injunction in social studies of science to eschew interest in the validity of the products of science in favor of an interest in their\r\n\r\n4 I see my choice of the term ad hoc here as an unfortunate one, particularly in light of subsequent readings of the text. The problem lies in the term\'s common connotations of things done anew, or narrowly, without reference to historically constituted or broader concerns. Perhaps a better way of phrasing this would be to say that situated actions are always, and irremediably, contingent on specific, unfolding circumstances that are themselves substantially constituted through those same actions. This is the case however much actions may also be informed by prescriptive representations, past experience, future considerations, received identities, entrenched social relations, established procedures, built environments, material contraints, and the like. To be rendered effective the significance and relevance of any of those must be reiterated, or transformed, in relation to what is happening just here and just now. For a brilliant and generative proposal for what he names a \"science of singularity,\" see de Certeau (1988).\r\n\r\n28\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nproduction.5 Although I generally agree with this injunction, my investigation of one of the prevailing models of human action in cognitive science is admittedly and unabashedly interested. That is to say, I take it that there is a reality of human action, beyond either the cognitive scientist\'s models or my own accounts, to which both are trying to do justice. In that sense, I am examining the cognitive science model not just with the dispassion of the uncommitted anthropologist of science but also in light of an alternative account of human action to which I am committed and that I attempt to clarify in the process.\r\n\r\n5 I would now take this to be an oversimplification of the so-called principle of symmetry in science studies, which argues that rather than take positions deemed \"true\" at a particular moment as explicable by nature, and only those considered \"false\" as amenable to social analysis, all scientific positions should be analyzable in the same terms. Those terms now increasingly involve attempts to come to grips with the simultaneously social/cultural and material/natural constitution of scientific practices and attendant knowledges.\r\n\r\n3\r\nIntroduction to the 1st Edition\r\nThe famous anthropological absorption with the (to us) exotic . . . is, thus, essentially a device for displacing the dulling sense of familiarity with which the mysteriousness of our own ability to relate perceptively to one another is concealed from us.\r\n(Geertz 1973: 14)\r\nThe problem of shared understanding, or mutual intelligibility, has defined the field of social studies for the past hundred years. On the one hand, interpreting the actions of others has been the social scientist\'s task; to come up with accounts of the significance of human actions is, after all, the principal charge of ethnographic anthropology. On the other hand, to understand the mutual intelligibility of action as a mundane, practical accomplishment of members of the society is, in large measure, the social scientist\'s problem or subject matter. An account of that accomplishment would constitute an account of the foundation of social order. Although studies of mutual intelligibility have been concerned exclusively with human action, we now have a technology that has brought with it the idea that rather than just using machines, we interact with them as well.1 Already, the notion of \"human­machine interaction\" pervades both technical and popular discussion of computers, whether about their design or their use. In the debate over specific problems in the design and use of interactive machines, however, no question is\r\n1 Although meant to set up the contrast with machines, this statement regrettably ignores the long-standing and still lively field of ethology (see, for example, Crist 2000, 2004). It would be more accurate to say that the social sciences have been concerned with interactions between and among animal species. 29\r\n\r\n30\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nraised about the bases for the very idea of human­machine interaction as such. And recent developments in the social sciences regarding the foundations of human interaction have had remarkably little influence on the discussion of interactive machines.2\r\nThe following chapters examine the conception of purposeful action, and consequently of interaction, informing the design of interactive machines. My central concern in the investigation is a new manifestation of an old problem in the study of mutual intelligibility; namely, the relation between observable behavior and the processes, not available to direct observation, that make behavior meaningful. For psychological studies, the crucial processes are essentially cognitive, located inside the head of the actor, and include the formation and effect of beliefs, desires, intentions, and the like. For social studies, the crucial processes are interactional and circumstantial, located in the relationships among actors and between actors and their embedding situations. In either case, the problem of meaningful action turns on the observation that behavior is inherently subject to indefinitely many ascriptions of meaning or intent, while meaning and intent are expressible through an indefinite number of possible behaviors. Whether the final arbiter of action\'s significance is taken to be private psychological processes or accountability to the public world, the question to be resolved ­ what constitutes purposeful action and how is it understood ­ is the same.\r\nThe new manifestation of this question concerning the nature of purposeful action and its interpretation arises in research on machine intelligence. Theoretically, the goal of that research is a computational model of intelligent behavior that not only, given some input, produces the right output behavior but also that does so by simulating human cognitive processes. Practically, the goal is just a machine that, given some input, produces behavior that is useful and appropriate to the situation at hand.3 In either case, insofar as rightness or appropriateness of behavior means that behavior is accountably rational in the eyes of an other, the measure of success is at bottom an interactional one.\r\nFor the moment at least, the question of theoretical versus practical criteria of adequacy for machine intelligence is rendered moot by the\r\n\r\n2 There has been some significant engagement in the years since; see, for example, the articles collected in Luff, Gilbert, and Frohlich (1990); Thomas (1995). Despite these interventions, however, I would maintain that there is remarkably little substantive effect on discourses and practices of the so-called conversational machine.\r\n3 What I characterize as a theoretical/practical distinction here maps on to some versions of what have been distinguished as \"strong\" versus \"weak\" AI.\r\n\r\nIntroduction to the 1st Edition\r\n\r\n31\r\n\r\nproblems involved in constructing a device that even appears to behave in ways that are purposeful or intelligent, at least outside of the most highly constrained domains. It may simply turn out that the resistance of meaningful action to simulation in the absence of any deep understanding will defend us against false impressions of theoretical success. In any case, my purpose here is not to resolve the question of whether artificial intelligence is possible but rather to clarify some existing troubles in the project of constructing intelligent, interactive machines, as a way of contributing to our understanding of human intelligence and interaction.\r\nEvery human tool relies on, and materializes, some underlying conception of the activity that it is designed to support. As a consequence, one way to view the artifact is as a test on the limits of the underlying conception. In this book I examine an artifact built on a planning model of human action. The model treats a plan as something located in the actor\'s head, which directs his or her behavior. In contrast, I argue that artifacts built on the planning model confuse plans with situated actions and recommend instead a view of plans as formulations of antecedent conditions and consequences of action that account for action in a plausible way. Stated in advance plans are necessarily vague, insofar as they are designed to accommodate the unforeseeable contingencies of actual situations of action. As ways of talking about action, plans as such neither determine the actual course of situated action nor adequately reconstruct it.4 Although for purposes of practical action this limitation on plans is irrelevant, for purposes of a science of practical action it is crucial.5 Specifically, if we are interested in situated action itself we need to look at how it is that actors use the resources that a particular occasion provides (including, but crucially not reducible to, formulations such as plans) to construct their action\'s developing purpose and intelligibility.\r\nBeginning with a view of interaction or communication (I use the two terms interchangeably) as the mutual intelligibility of action, I\r\n\r\n4 The sense of \"adequacy\" implied here is an anthropological/sociological one; that is, plans cannot be taken as specific, or comprehensive, or experiential descriptions of how some course of action went. For practical purposes of everyday talk, of course, an account of actions taken with reference to a plan (for example, the itinerary of a journey) may be quite sufficient.\r\n5 The notion of a \"science of practical action\" sits uncomfortably with my current appreciation for the connotations of universality and generality implied. I would say instead that we cannot simply take plans as isomorphic with actions if our interest is in recovering the latter\'s enactment in situ.\r\n\r\n32\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ninvestigate the grounds for beginning to speak of interaction between humans and machines. Chapter 4 introduces the notion of interactive artifacts and its basis in certain properties of computing machines.6 Chapter 5 examines the view of plans as the basis for action and communication held by designers of artificially intelligent, interactive machines, while Chapters 6 and 7 present an alternative view of action and communication as situated, drawn from recent developments in social science. Finally, Chapters 8 and 9 offer an analysis of encounters between novice users of a machine and a computer-based system intended to be intelligent and interactive. The aim of the case study is not to criticize the particular design but to view the design as reifying certain premises about purposeful action.7 The task is to articulate those premises, to see how they succeed as a basis for human­machine communication and how they fail, and to explore the implications of their success and failure both for the design of human­machine communication and for the broader explication of purposeful action and mutual intelligibility.\r\n\r\n6 Chapter numbers have been changed to reflect the current text. 7 The term reifying in this context seems overly fixed and might be better replaced with\r\nincorporating or materializing.\r\n\r\n4\r\nInteractive Artifacts\r\nMarginal objects, objects with no clear place, play important roles. On the lines between categories, they draw attention to how we have drawn the lines. Sometimes in doing so they incite us to reaffirm the lines, sometimes to call them into question, stimulating different distinctions.\r\n(Turkle 1984: 31)\r\nIn The Second Self (1984), Sherry Turkle describes the computer as an evocative object, one that raises new questions regarding our common sense of the distinction between artifacts and intelligent others. Her studies include an examination of the impact of computer-based artifacts on children\'s conceptions of the difference between categories such as \"alive\" versus \"not alive\" and \"machine\" versus \"person.\" In dealing with the questions that computer-based objects evoke, children make clear that the differentiation of physical from psychological entities, which as adults we largely take for granted, is the end product of a process of establishing the relationship between the observable behavior of a thing and its underlying nature.1 Children have a tendency, for example, to attribute life to physical objects on the basis of behaviors such as autonomous motion or reactivity, though they reserve humanity for entities evidencing such things as emotion, speech, and apparent thought or purposefulness. Turkle\'s observation with respect to computational artifacts is that children ascribe to them an \"almost aliveness\" and a psychology, while maintaining their distinctness from\r\n1 Though see Carey (1985, Chapter 1) for a critique of the Piagetian notion that children at first have no concept for mechanical causation apart from intentional causation. (Original footnote.) 33\r\n\r\n34\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nhuman beings: a view that, as Turkle points out, is remarkable among other things for its correspondence to the views held by those who are the artifacts\' designers.2\r\nIn this book I take as a point of departure a particular aspect of the phenomenon that Turkle identifies: namely, the apparent challenge that computational artifacts pose to the long-standing distinction between the physical and the social, in the special sense of those things that one designs, builds, and uses, on the one hand, and those things with which one communicates, on the other. Although this distinction has been relatively nonproblematic to date, now for the first time the term interaction, in a sense previously reserved for describing a uniquely interpersonal activity, seems appropriately to characterize what goes on between people and certain machines as well.3 Interaction between people and machines implies mutual intelligibility or shared understanding. What motivates my inquiry, therefore, is not only the recent question of how there could be mutual intelligibility between people and machines but also the prior question of how we account for the shared understanding or mutual intelligibility that we experience as people in our interactions with others whose essential sameness is not in question. An answer to the more recent question, theoretically at least, presupposes an answer to the earlier one.\r\nIn this chapter I relate the idea of human­machine communication to some distinctive properties of computational artifacts and to the emergence of disciplines dedicated to making those artifacts intelligent. I begin with a brief discussion of cognitive science, the interdisciplinary field devoted to modeling cognitive processes, and its role in the project\r\n\r\n2 See especially pp. 62­3; Turkle finds some cause for alarm in the fact that for children the distinction of machine and person seems to turn centrally on a separation of thought from feeling; that is, computers exhibit the former but lack the latter. This view, she argues, includes a kind of dissociation of intellect and emotion, and consequent trivialization of both, that characterizes the attitudes of many in the field of artificial intelligence. (Original footnote.)\r\n3 Actually, the term interaction has its origins in the physical sciences to describe a reciprocal action or influence. I use it here in the common sense assigned to it by social science: namely, to mean communication between persons. The migration of the term from the physical sciences to the social, and now back to some ground that stands between them, relates in intriguing ways to a general blurring of the distinction between physical and social in modern science and to the general question of whether machines are actually becoming more like people or whether, in fact, people are coming to define themselves more as machines. There is clearly a mutual influence at work. For more on this last point, see Dreyfus 1979 (Chapter 9). (Original footnote.)\r\n\r\nInteractive Artifacts\r\n\r\n35\r\n\r\nof creating intelligent artifacts.4 Along with a theoretical interest in intelligent artifacts, the computer\'s properties have inspired a practical effort at engineering interaction between people and machines. I argue that the description of computational artifacts as interactive is supported by their reactive, linguistic, and internally opaque properties. With those properties in mind, I consider the double sense in which researchers are interested in artifacts that explain themselves: on the one hand, as a solution to the long-standing problem of conveying the artifact\'s intended purpose to the user, through its design and attendant instructions and, on the other hand, as a means of establishing the intelligence, or rational accountability, of the artifact itself.\r\n\r\nautomata and cognitive science\r\nHistorically the idea of automata ­ the possibility of constructing physical devices that are self-regulating in ways that we commonly associate with living, animate beings ­ has been closely tied to the simulation of animal forms. McCorduck (1979) points out that humanlike automata have been constructed since Hellenic times: statues that moved, gestured, spoke, and generally were imbued by observers (even those well aware of the internal mechanisms that powered them) with everything from minds to souls.5 In the fourteenth century in Western Europe, \"learned men\" were commonly believed to construct talking heads made of brass, considered as both the source of their creator\'s wisdom and its manifestation. More prosaically, Jacques de Vaucanson in the eighteenth century designed a series of renowned mechanical statues, the most famous being a duck, the inner workings of which produced a variety of simple outward behaviors.\r\nAt the same time Julien de la Mettrie published Man a Machine (1748), in which he argued that the vitality characteristic of human beings was the result of their physical structure rather than either something\r\n4 For an extensive treatment, see Gardner (1985). (Original footnote.) For more recent discussions see Clancey (1997); Clark (1997, 2001); and Varela, Thompson, and Rosch (1991) and for critiques see Adam (1998); Agre (1997); Button, Coulter, Lee, and Sharrock (1995); Collins (1990); Collins and Kusch (1998); Dourish (2001); Dreyfus (1992); Gilbert and Heath (1985); and Kember (2003).\r\n5 See McCorduck (1979, Chapter 1); Churchland (1984, Chapter 6). For a further history of automata, see Cohen (1966). (Original footnote.) For more recent historical treatments see Riskin (2003a, 2003b, 2007); Schaffer (1999); Standage (2002); Wood (2002).\r\n\r\n36\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nimmanent in their material substance or some immaterial force. Cognitive scientists today maintain the basic premise of de la Mettrie with respect to mind, contending that mind is best viewed as neither substantial nor insubstantial, but as an abstractable structure implementable in any number of possible physical substrates. Intelligence, in other words, is only incidentally embodied in the neurophysiology of the human brain, and what is essential about intelligence can be abstracted from that particular, albeit highly successful, substrate and embodied in an unknown range of alternative forms. This view decouples reasoning and intelligence from things uniquely human and opens the way for the construction of intelligent artifacts.6\r\nThe preoccupation of cognitive science with mind in this abstract sense is in part a concern to restore meaning to psychological explanation (see Stich 1983, Chapter 1). At the turn of this century, the recognized method for studying human mental life was introspection and, insofar as introspection was not amenable to the emerging canons of scientific method, the study of cognition seemed doomed to be irremediably unscientific. In reaction to that prospect, the behaviorists posited that all human action should be understandable in terms of publicly observable, mechanistically describable relations between the organism and its environment. In the name of turning cognitive studies into a science, in other words, the study of cognition as the study of something apart from overt behavior was effectively abandoned in mainstream psychology.\r\nCognitive science, in this respect, was a project to bring thought back into the study of human action while preserving the commitment to scientism. Cognitive science reclaims mentalist constructs such as beliefs, desires, intentions, symbols, ideas, schemata, planning, and problem solving. Once again human purposes are the basis for cognitive psychology, but this time without the unconstrained speculation of the introspectionists. The study of cognition is to be empiricized not by a strict adherence to behaviorism but by the use of a new technology: namely, the computer.\r\nThe subfield of cognitive science most dedicated to the computer is artificial intelligence. Artificial intelligence arose as advances in computing technology were tied to developments in neurophysiological\r\n\r\n6 See Turkle (1984, Chapter 7); and McCorduck (1979, Chapter 5). Turkle\'s description of the present academic AI culture at MIT is particularly insightful. (Original footnote.) For a reconstruction of the history through which \"information lost its body,\" see Hayles (1999).\r\n\r\nInteractive Artifacts\r\n\r\n37\r\n\r\nand mathematical theories of information. The requirement of computer modeling, of an information processing psychology, seemed both to make theoretical sense and to provide the accountability that would make it possible to pursue a science of otherwise inaccessible mental phenomena. If a theory of underlying mental processes could be modeled on the computer so as to produce the right outward behavior, the theory could be viewed as having passed at least a sufficiency test of its psychological validity.\r\nThe cognitivist strategy is to interject a mental operation between environmental stimulus and behavioral response: in essence, to relocate the causes of action from the environment that impinges on the actor to processes, abstractable as computation, in the actor\'s head. The first premise of cognitive science, therefore, is that people (or \"cognizers\" of any sort) act on the basis of symbolic representations: a kind of cognitive code, instantiated physically in the brain, on which operations are performed to produce mental states such as \"the belief that p,\" which in turn produce behavior consistent with those states. The relation of environmental stimuli to those mental states, on the one hand, and of mental states to behavior, on the other, remains deeply problematic and widely debated within the field (see, for example, Fodor 1983; Pylyshyn 1974, 1984; Stich 1983). The agreement among all participants in cognitive science and its affiliated disciplines, however, is that cognition is not just potentially like computation; it literally is computational. There is no reason, in principle, why there should not be a computational account of mind, therefore, and there is no a priori reason to draw a principled boundary between people, taken as information-processors or symbol manipulators or, in George Miller\'s phrase, \"informavores\" (Pylyshyn 1984: xi) and certain computing machines.\r\nThe view that intelligence is the manipulation of symbols finds practical implementation both in so-called expert systems, which structure and process large amounts of well-formulated data, and industrial robots that perform routine, repetitive assembly and control tasks. Expert systems ­ essentially sophisticated programs that manipulate data structures to accord with rules of inference that experts are understood to use ­ have minimal sensory-motor or \"peripheral\" access to the world in which they are embedded, input being most commonly through a keyboard, by a human operator. Industrial robots ­ highly specialized, computer-controlled devices designed to perform autonomously a single repetitive physical task ­ have relatively more developed sensory-motor apparatus than do expert systems, but the\r\n\r\n38\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsuccess of robotics is still confined to specialized activities, under controlled conditions. In both cases, the systems can handle large amounts of encoded information, and syntactic relationships of great sophistication and complexity, in highly circumscribed domains. But when it comes either to direct interaction with the environment, or to the exercise of practical, everyday reasoning about the significance of events in the world, there is general agreement that the state of the art in intelligent machines has yet to attain the basic cognitive abilities of the normal five-year-old child.\r\n\r\nthe idea of human­computer interaction\r\nIn spite of the current limits on machine intelligence, the use of an intentional vocabulary is already well established in both technical and popular discussion of computers. In part the attribution of purpose to computer-based artifacts derives from the simple fact that each action by the user effects an immediate machine reaction (see Turkle 1984, Chapter 8). The technical definition of interactive computing (see, for example, Oberquelle, Kupka, and Maass 1983: 313) is simply that real-time control over the computing process is placed in the hands of the user, through immediate processing and through the availability of interrupt facilities whereby the user can override and modify the operations in progress. This definition contrasts current capabilities with earlier forms of computing, specifically batch processing, where user commands were queued and executed without any intermediate feedback. The greater reactivity of current computers, combined with the fact that, like any machine, the computer\'s reactions are not random but by design, suggest the character of the computer as a purposeful and, by association, as a social object.\r\nA more profound basis for the relative sociability of computer-based artifacts, however, is the fact that the means for controlling computing machines and the behavior that results are increasingly linguistic rather than mechanistic. That is to say, machine operation becomes less a matter of pushing buttons or pulling levers with some physical result and more a matter of specifying operations and assessing their effects through the use of a common language.7 With or without machine intelligence, this\r\n7 Notwithstanding the popular fantasy of the talking machine, the crucial element that invites a view of computers as interactive is language, not speech. Although strictly speaking buttons and keys remain the principal input devices in computing, this is\r\n\r\nInteractive Artifacts\r\n\r\n39\r\n\r\nfact has contributed to the tendency of designers, in describing what goes on between people and machines, to employ terms borrowed from the description of human interaction; that is, dialogue, conversation, and so forth: terms that carry a largely unarticulated collection of intuitions about properties common to human communication and the use of computer-based machines.\r\nAlthough for the most part the vocabulary of human interaction has been taken over by researchers in human­machine communication with little deliberation, several researchers have attempted to clarify similarities and differences between computer use and human conversation. Perhaps the most thoughtful and comprehensive of these is Hayes and Reddy (1983). They identify the central difference between existing interactive computer systems and human communication as a question of \"robustness,\" or the ability on the part of conversational participants to respond to unanticipated circumstances, and to detect and remedy troubles in communication:\r\nThe ability to interact gracefully depends on a number of relatively independent skills: skills involved in parsing elliptical, fragmented, and otherwise ungrammatical input; in ensuring that communication is robust (ensuring that the intended meaning has been conveyed); in explaining abilities and limitations, actions and the motives behind them; in keeping track of the focus of attention of a dialogue; in identifying things from descriptions, even if ambiguous or unsatisfiable; and in describing things in terms appropriate for the context. Although none of these components of graceful interaction has been entirely neglected in the literature, no single current system comes close to having most of the abilities and behaviors we describe, and many are not possessed by any current systems. (1983: 232)\r\nHayes and Reddy believe, however, that:\r\nEven though there are currently no truly gracefully interacting systems, none of our proposed components of graceful interaction appears individually to be much beyond the current state of the art, at least for suitably restricted domains of discourse. (ibid.: 232)\r\nThey then review the state of the art, including systems like LIFER (Hendrix 1977) and SCHOLAR (Carbonell 1971), which display\r\n\r\nrelatively trivial. The synthesis of speech by computers may well add to our inclination to ascribe understanding to them, but will not, in itself, contribute substantively to their sensibility. However, simulation of natural language understanding, even when the language is written rather than spoken, is proving to be a profoundly difficult problem that is inseparable from the problem of simulating intelligence as such. (Original footnote.) For a more recent consideration of the talking machine, see Jeremijenko (2004).\r\n\r\n40\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsensitivity to the user\'s expectations regarding acknowledgment of input; systems that resolve ambiguity in English input from the user through questions (Hayes 1981); systems like the GUS system (Bobrow et al. 1977), which represent limited knowledge of the domain that the interaction is about; work on the maintenance of a common focus over the course of the interaction (Grosz 1977; Sidner 1979); and Hayes and Reddy\'s own work on an automated explanation facility in a simple service domain (1983).\r\nTwo caveats on Hayes and Reddy\'s prescription for a gracefully interacting system (both of which, to their credit, they freely admit) are worth noting. First, they view the abilities cited as necessary but not sufficient for human interaction, their claim for the list being simply that \"it provides a good working basis from which to build gracefully interacting systems\" (1983: 233). And not surprisingly, the abilities that they cite constitute a list of precisely those problems currently under consideration in research on human­machine communication. There is, in other words, no independent assessment of how the problems on which researchers work relate to the nature and organization of human communication as such. Second, research on those problems that have been identified is confined to highly circumscribed domains. The consequence of working from an admittedly partial and ad hoc list of abilities, in limited domains, is that practical inroads in human­computer communication can be furthered, while the basic question of what human interaction comprises is deferred. Deferred as well is the question of why it is, beyond methodological convenience, that research in human­machine interaction has proceeded only in those limited domains that it has.\r\nMoreover, although Hayes and Reddy take the position that \"it is very important for a gracefully interacting system to conduct a dialogue in as human-like a way as possible\" (1983: 233), this assertion is a point of controversy in the research community. On the one side, there is an argument to the effect that one should acknowledge, and even exploit, the fact that people bring to computer use a tremendous range of skills and expectations from human interaction. Within research on human­computer interaction, for example, some progress has been made toward allowing people to enter commands into computers using natural language (i.e., languages like English, in contrast to programming languages). On the other side, even Hayes and Reddy admit that:\r\n\r\nthe aim of being as human-like as possible must be tempered by the limited potential for comprehension of any foreseeable computer system. Until a solution is found to the problems of organizing and using the range of world\r\n\r\nInteractive Artifacts\r\n\r\n41\r\n\r\nknowledge possessed by a human, practical systems will only be able to comprehend a small amount of input, typically within a specific domain of expertise. Graceful interaction must, therefore, supplement its simulation of human conversational ability with strategies to deal naturally and gracefully with input that is not fully understood and, if possible, to steer a conversation back to the system\'s home ground. (ibid.: 233)\r\nWhereas Hayes and Reddy would make these recovery strategies invisible to the user, they also acknowledge the \"habitability\" problem identified by Watt (1968) with respect to language: that is, the tendency of human users to assume that a computer system has sophisticated linguistic abilities after it has displayed elementary ones. This tendency is not surprising, given the fact that our only precedent for language-using entities to date has been other human beings. As soon as computational artifacts demonstrate some evidence of recognizably human abilities, we are inclined to endow them with the rest. The misconceptions that ensue, however, lead some like Fitter (1979) to argue that English or other \"natural\" languages are in fact not natural for purposes of human­computer interaction:\r\nfor the purpose of man-computer communication [sic], a natural language is one that makes explicit the knowledge and processes for which the man and computer share a common understanding . . . it becomes the responsibility of the systems designer to provide a language structure which will make apparent to the user the procedures on which it is based and will not lead him to expect from the computer unrealistic powers of inference. (1979: 340, original emphasis)\r\nIn view of our tendency to ascribe full intelligence on the basis of partial evidence, the recommendation is that designers might do best to make available to the user the ways in which the system is not like a participant in interaction.8 In this spirit, Nickerson (1976) argues that:\r\nThe model that seems appropriate for this view of person-computer interaction is that of an individual making use of a sophisticated tool and not that of one person conversing with another. The term \"user\" is, of course, often used to denote the human component in a person-computer interaction, as it has been in this paper. It is, to my taste, preferable to the term \"partner,\" not only because it seems more descriptive of the nature of the relationships that existing systems permit, and that future systems are likely to, but because it implies an asymmetry with respect to goals and objectives that \"partner\" does not. \"User\" is not a term that one would normally apply to a participant in a conversation. (1976: 111)\r\n\r\n8 In fact, Nickerson (1976) points out that there are some ways in which a computer is not like another person, which lends a certain advantage to the user, for example, interruptions can be made without concern about giving offense and responses can be delayed as long as is necessary. (Original footnote.)\r\n\r\n42\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe argument that computational processes should be revealed to the user, however, is potentially counter to the promotion of an intentional vocabulary in speaking about computer-based devices. As Dennett (1978) points out, it is in part our inability to see inside each other\'s heads, or our mutual opacity, that makes intentional explanations so powerful in the interpretation of human action. So it is in part the internal complexity and opacity of the computer that invites an intentional stance. This is the case not only because users lack technical knowledge of the computer\'s internal workings but also because, even for those who possess such knowledge, there is an \"irreducibility\" to the computer as an object that is unique among human artifacts (Turkle 1984: 272). The overall behavior of the computer is not describable, that is to say, with reference to any of the simple local events that it comprises; it is precisely the behavior of a myriad of those events in combination that constitutes the overall machine. To refer to the behavior of the machine, then, one must speak of \"its\" functionality. And once reified as an entity, the inclination to ascribe actions to the entity rather than to the parts is irresistible.\r\nIntentional explanations relieve us of the burden of understanding mechanism, insofar as one need assume only that the design is rational to call upon the full power of commonsense psychology and have, ready at hand, a basis for anticipating and construing an artifact\'s behavior. At the same time, precisely because the mechanism is in fact unknown, and, insofar as underspecification is taken to be characteristic of human beings (as evidenced by the fact that we are inclined to view something that is fully specified as less than human), the personification of the machine is reinforced by the ways in which its inner workings are a mystery, and its behavior at times surprises us.9 Insofar as the machine is somewhat predictable, in sum, and yet is also both internally opaque and liable to unanticipated behavior, we are more likely to view ourselves as engaged in interaction with it than as just performing operations on it or using it as a tool to perform operations upon the world (see MacKay 1962).\r\n\r\nself-explanatory artifacts In the preceding pages I have proposed that the reactive, linguistic, and opaque properties of the computer lead us to view it as interactive\r\n9 See the discussion of \"enchantment\" in Chapter 14.\r\n\r\nInteractive Artifacts\r\n\r\n43\r\n\r\nand to apply intentional explanations to its behavior. This tie to intentionality has both theoretical and practical implications. Practically, it suggests that, like a human actor, the computer should be able to explain itself, or the intent behind its actions, to the user. Theoretically, it suggests that the computer actually has intent, as demonstrated precisely in this ability to behave in an accountably rational, intelligible way.\r\nFor practical purposes, user interface designers10 have long held the view that machines ideally should be self-explanatory, in the broad sense that their operation should be discoverable without extensive training, from information provided on or through the machine itself. On this view, the degree to which an artifact is self-explanatory is just the extent to which someone examining the artifact is able to reconstruct the designer\'s intentions regarding its use. This basic idea, that a self-explanatory artifact is one whose intended purpose is discoverable by the user, is presumably as old as the design and use of tools. With respect to computer-based artifacts, however, the notion of a selfexplanatory artifact has taken on a second sense: namely, the idea that the artifact might actually explain itself in something more like the sense that a human being does. In this second sense the goal is that the artifact should not only be intelligible to the user as a tool but also that it should be intelligent; that is, able to understand the actions of the user and to provide for the rationality of its own.\r\nIn the remainder of this chapter, I look at these two senses of a selfexplanatory machine and at the relation between them. The first sense ­ that a tool should be decipherable by its user ­ reflects the fact that artifacts are constructed by designers for a purpose and that the user of a tool needs to know something of that design intent. Given their interactional properties, computational tools seem to offer unique capabilities for the provision of instruction to their users. The idea that instructions could be presented more effectively using the power of computation is not far from the idea that computer-based artifacts could actually instruct, that is, could interact with people in a way that approximates the behavior of an intelligent human expert or coach. And this second\r\n\r\n10 In design parlance, the term user interface refers both to the physical place at which the user issues commands to a device, finds reports of its state, or obtains the products of its operation and the procedures by which those interactions occur. (Original footnote.) For further discussion of how we might refigure \"the interface,\" see Chapters 14 and 15.\r\n\r\n44\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nidea, that the artifact could interact instructively with the user, ties the practical problem of instruction to the theoretical problem of building an intelligent, interactive machine.\r\n\r\nThe Computer as an Artifact Designed for a Purpose\r\nAt the same time that computational artifacts introduce new complexity and opacity into our encounters with machines, our reliance on computer-based technology and its proliferation throughout the society increases. One result is the somewhat paradoxical objective that increasingly complex technology should be usable with decreasing amounts of training. Rather than relying on the teachings of an experienced user, the use of computers is to be conveyed directly through the technology itself.\r\nThe inherent difficulty of conveying the use of a technology directly through its design is well known to archaeologists, who have learned that although the attribution of design intent is a requirement for an artifact\'s intelligibility, the artifact\'s design as such does not convey unequivocally either its actual or its intended use. Although this problem in construing the purpose of artifacts can be alleviated, it can never fully be resolved, and it defines the essential problem that the novice user of the tool confronts. Insofar as the goal of a tool\'s design is that use of the tool should be self-evident, therefore, the problem of deciphering an artifact defines the problem of the designer as well.11\r\nAs with any communication, instructions for the use of a tool are constrained by the general maxim that utterances should be designed for their recipients. The extent to which the maxim is observed is limited in the first instance by the resources that the medium of communication affords. Face-to-face human interaction is the paradigm case of a system for communication that, because it is organized for maximum contextsensitivity, supports a response designed for just these recipients on just this occasion. Face-to-face instruction brings that context-sensitivity to bear on problems of skill acquisition. The gifted coach, for example, draws on powers of language and observation, and uses the situation of instruction, to specialize instruction for the individual student. Where\r\n11 This observation defines the problem, and the limits, of efforts by system designers to \"configure their users\" (Woolgar 1991) and the challenges ­ and possibilities ­ implied in \"de-scripting\" an unfamilair artifact (Akrich 1992). For more on these questions, see Chapter 11.\r\n\r\nInteractive Artifacts\r\n\r\n45\r\n\r\nwritten instruction relies on generalizations about its recipient and the occasion of its use, the coach draws pedagogical strength from exploitation of the unique details of particular situations.12\r\nA consequence of the human coach\'s method is that his or her skills must be deployed anew each time. An instruction manual, in contrast, has the advantage of being durable, reusable, and replicable. In part, the strength of written text is that, in direct contrast to the pointed commentary of the coach, text allows the disassociation of the occasion of an instruction\'s production from the occasion of its use.13 For the same reason, however, text affords relatively poor resources for recipient design. The promise of interactive computer systems, in these terms, is a technology that can move instructional design away from the written manual in the direction of the human coach and the resources afforded by face-to-face interaction.\r\nEfforts at building self-explicating machines in their more sophisticated forms now adopt the metaphor of the machine as an expert and the user as a novice or student. Among the most interesting attempts to design such a computer-based \"coach\" is a system called WEST (Burton and Brown 1982). The design strategy adopted in WEST is based on the observation that the skill of a human coach lies as much in what isn\'t said as what is. Specifically, the human coach does not disrupt the student\'s engagement in an activity to ask questions but instead diagnoses a student\'s strengths and weaknesses through observation. And once the diagnosis is made, the coach interjects advice and instruction selectively in ways designed to maximize learning through discovery and experience. In that spirit, the WEST system attempts to infer the student\'s knowledge of the domain (in this case a computer game called\r\n\r\n12 Face-to-face interaction is in most cases a necessary, but of course never a sufficient, condition for successful human coaching. Coombs and Alty (1984) provide an interesting discussion of the failings of interactions between human advisors and new computer users. At the same time, they point out that the characteristics of the advisory sessions that new users found unsatisfactory show marked similarities to human interactions with most rule-based computer help systems (e.g., that the advisors provide only the recommended solutions to reported problems, while failing either to elicit the view of the user or to articulate any of their own rationale). Satisfactory sessions, in contrast, were characterized by what initially appeared to be less structure and less economy, but that on further investigation was revealed as \"well-motivated despite surface appearances, the objective not being strict problem-solving as we had assumed, but problemsolving through mutual understanding. This required sensitivity to different structural factors\" (ibid.: 24­5) (original footnote).\r\n13 What Latour has subsequently characterized as a text\'s \"immutable mobility\" (1986: 7).\r\n\r\n46\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n\"How the West Was Won,\" designed to teach the use of basic arithmetic expressions) by observing the student\'s behavior.14\r\nAlthough the project of identifying a student\'s problems directly from his or her behavior proved considerably more difficult than expected, the objectives for the WEST coach were accomplished in the prototype system to an impressive degree. Because in the case of learning to play WEST the student\'s actions take the form of input to the computer (entries on a keyboard) and therefore leave an accessible trace, and because a context for those actions (the current state of, and history of consecutive moves across, the \"board\") is defined by the system, each student turn can be compared against calculations of the move that a hypothetical expert player would make given the same conditions. Each expert move, in turn, requires a stipulated set of associated skills. Evidence that a particular skill is lacking, accumulated across some number of moves, identifies that skill as a candidate for coaching. The coach then interjects offers of advice to the student at opportune moments in the course of the play, where what constitutes an opportune moment for interjection is determined according to a set of rules of thumb regarding good tutorial strategy (for example, always coach by offering the student an alternative move that both demonstrates the relevant skill and accomplishes obviously superior results; never coach on two turns in a row, no matter what; and so forth).\r\n\r\nThe Computer as an Artifact Having Purposes\r\nAlthough the computer-based coach can be understood as a logical development in the long-standing problem of instruction, the\r\n14 The student is presented with a graphic display of a game board made up of seventy squares (representing the Western frontier), a pair of icons (representing the two players, user and computer), and three spinners. A player\'s task in each turn is to combine the three numbers that the spinners provide, using the basic operations, to produce a value that becomes the number of spaces the icon is moved along the board. To add an element of strategy, squares on the board are more and less desirable. For example, \"towns\" occur every ten spaces, and landing on one advances you to the next. The object is to be the first player to land on 70. Early observation of students playing the game revealed that they were not gaining the full benefit of the arithmetic practice, in that they tended to settle on a method for combining numbers (for example, multiply the first two numbers and add the third), and to repeat that same method at each turn. Recognizing that this might reflect either a weakness in the student\'s proficiency at constructing expressions, a failure to grasp the strategy of the game, or both, Brown and Burton saw the potential usefulness of a \"coach\" that could guide the student to an expanded repertoire of skills and a better understanding of the domain. For a description of a similarly motivated \"advisory\" system for the programming language PROLOG, see Coombs and Alty (1984). (Original footnote.)\r\n\r\nInteractive Artifacts\r\n\r\n47\r\n\r\nrequirement that it be interactive introduces a second sense of selfexplanatory machine that is more recent and is uniquely tied to the advent of computing. The new idea is that the intelligibility of artifacts is not just a matter of the availability to the user of the designer\'s intentions for the artifact but of the intentions of the artifact itself. That is to say, the designer\'s objective now is to imbue the machine with the grounds for behaving in ways that are accountably rational: that is, reasonable or intelligible to others, including, in the case of interaction, ways that are responsive to the other\'s actions.\r\nIn 1950 A. M. Turing proposed a now-famous, and still controversial, test for machine intelligence based on a view of intelligence as accountable rationality. Turing argued that if a machine could be made to respond to questions in such a way that a person asking the questions could not distinguish between the machine and another human being, the machine would have to be described as intelligent. To implement his test, Turing chose a game called the \"imitation game.\" The game was initially conceived as a test of the ability of an interrogator to distinguish which of two respondents was a man and which a woman. To eliminate the evidence of physical embodiment, the interaction was to be conducted remotely via a teleprinter. This provided the basis for Turing\'s notion that the game could easily be adapted to a test of machine intelligence, by substituting the machine for one of the two human respondents. Turing expressly dismissed as a possible objection to his proposed test the contention that, although the machine might succeed in the game, it could succeed through means that bear no resemblance to human thought. Turing\'s contention was precisely that success at performing the game, regardless of mechanism, is sufficient evidence for intelligence (Turing 1950: 435). The Turing test thereby became the canonical form of the argument that if two informationprocessors, subject to the same input stimuli, produce indistinguishable output behavior, then regardless of the identity of their internal operations one processor is essentially equivalent to the other.\r\nThe lines of the controversy raised by the Turing test were drawn over a family of programs developed by Joseph Weizenbaum in the 1960s under the name ELIZA, designed to support \"natural language conversation\" with a computer (Weizenbaum 1983: 23). Of the name ELIZA, Wiezenbaum writes:\r\n\r\nIts name was chosen to emphasize that it may be incrementally improved by its users, since its language abilities may be continually improved by a \"teacher.\" Like the Eliza of Pygmalion fame, it can be made to appear even more civilized,\r\n\r\n48\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthe relation of appearance to reality, however, remaining in the domain of the playwright. (ibid.: 23)\r\nAnecdotal reports of occasions on which people approached the teletype to one of the ELIZA programs and, believing it to be connected to a colleague, engaged in some amount of \"interaction\" without detecting the true nature of their respondent led many to believe that Weizenbaum\'s program had passed a simple form of the Turing test. Notwithstanding its apparent interactional success, however, Weizenbaum himself denied the intelligence of the program on the basis of the underlying mechanism which he described as \"a mere collection of procedures\" (ibid.: 23):\r\nThe gross procedure of the program is quite simple; the text [written by the human participant] is read and inspected for the presence of a keyword. If such a word is found, the sentence is transformed according to a rule associated with the keyword, if not a content-free remark or, under certain conditions, an earlier transformation is retrieved. The text so computed or retrieved is then printed out. (ibid.: 24, original emphasis)\r\nIn spite of Weizenbaum\'s disclaimers with respect to their intelligence, the ELIZA programs are still cited as instances of successful interaction between human and machine. The grounds for their success are clearest in DOCTOR, one of the ELIZA programs whose script equipped it to respond to the human user as if the computer were a Rogerian therapist and the user a patient. The DOCTOR program exploited the maxim that shared premises can remain unspoken: that the less we say in conversation, the more what is said is assumed to be self-evident in its meaning and implications (see Coulter 1979, Chapter 5). Conversely, the very fact that a comment is made without elaboration implies that such shared background assumptions exist. The more elaboration or justification is provided, the less the appearance of transparence or selfevidence. The less elaboration there is, the more the recipient will take it that the meaning of what is provided should be obvious.\r\nThe design of the DOCTOR program, in other words, exploited the natural inclination of people to deploy what Karl Mannheim first termed the documentary method of interpretation to find the sense of actions that are assumed to be purposeful or meaningful (Garfinkel 1967: 78). Very simply, the documentary method refers to the observation that people take appearances as evidence for, or the document of, an ascribed underlying reality, while taking the reality so ascribed as a resource for the interpretation of the appearance. In the case of DOCTOR, computer-generated responses that might otherwise seem odd were rationalized by users on\r\n\r\nInteractive Artifacts\r\n\r\n49\r\n\r\nthe grounds that there must be some psychiatric intent behind them, not immediately obvious to the user as \"patient,\" but sensible nonetheless:\r\nIf, for example, one were to tell a psychiatrist \"I went for a long boat ride\" and he responded \"Tell me about boats,\" one would not assume that he knew nothing about boats, but that he had some purpose in so directing the subsequent conversation. It is important to note that this assumption is one made by the speaker. Whether it is realistic or not is an altogether different question. In any case, it has a crucial psychological utility in that it serves the speaker to maintain his sense of being heard and understood. The speaker further defends his impression (which even in real life may be illusory) by attributing to his conversational partner all sorts of background knowledge, insights and reasoning ability. But again, these are the speaker\'s contribution to the conversation. They manifest themselves inferentially in the interpretations he makes of the offered response. (Weizenbaum 1983: 26, original emphasis)\r\nIn explicating the ELIZA programs, Weizenbaum was primarily concerned with the inclination of human users to find sense in the computer\'s output and to ascribe to it an understanding, and therefore an authority, unwarranted by the actual mechanism.15 While unmasking the intelligence of his program, however, Weizenbaum continued to describe it as \"a program which makes natural language conversation with a computer possible\" (1983: 23). Nevertheless, as part of his disclaimer regarding its intelligence, Weizenbaum points to a crucial shortcoming in the ELIZA strategy with respect to conversation:\r\nELIZA in its use so far has had as one of its principal objectives the concealment of its lack of understanding. But to encourage its conversational partner to offer inputs from which it can select remedial information, it must reveal its misunderstanding. A switch of objectives from the concealment to the revelation of misunderstanding is seen as a precondition to making an ELIZA-like program\r\n\r\n15 In this regard it is interesting to note that a great debate ensued surrounding the status of the DOCTOR program as a psychotherapeutic tool. That debate took on a humorous tone when Weizenbaum submitted a letter to the Forum of the Association for Computing Machinery, an excerpt from which follows:\r\n\"Below is a listing of a PL/1 program that causes a typewriter console to imitate the verbal behavior of an autistic patient. The \"doctor\" types his interrogatories on the console. It responds exactly as does an autistic patient ­ that is, not at all. I have validated this model following the procedure first used in commercial advertising by Carter\'s Little Liver Pills (\"Seven New York doctors say . . . \") and later used so brilliantly by Dr K. M. Colby in his simulation of paranoia [a reference to Colby, K. M. et al. 1972]; I gave N psychiatrists access to my program and asked each to say from what mental disorder it suffered. M psychiatrists (M<N) said the (expletive deleted) program was autistic. (The methodological assumption here is that if two processes have identical input/output behaviors, then one constitutes an explanation of the other.) The program has the advantage that it can be implemented on a plain typewriter not connected to a computer at all.\" (Weizenbaum 1983: 28) (Original footnote.)\r\n\r\n50\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthe basis for an effective natural language man-machine communication system. (ibid.: 27, original emphasis)\r\nMore recently the inevitability of troubles in communication, and the importance of their remedy to the accomplishment of \"graceful interaction,\" has been reintroduced into the human­machine communication effort by Hayes and Reddy (1983). They observe that:\r\nDuring the course of a conversation, it is not uncommon for people to misunderstand or fail to understand each other. Such failures in communication do not usually cause the conversation to break down; rather, the participants are able to resolve the difficulty, usually by a short clarifying sub-dialogue, and continue with the conversation from where they left off. Current computer systems are unable to take part in such clarifying dialogues, or resolve communication difficulties in any other way. As a result, when such difficulties occur, a computer dialogue system is unable to keep up its end of the conversation, and a complete breakdown is likely to result; this fragility lies in stark and unfavourable contrast to the robustness of human dialogue. (ibid.: 234)\r\nHayes and Reddy go on to recommend steps toward a remedy for the fragility of human­computer interaction based on the incorporation from human communication of conventions for the detection and repair of misunderstanding. They acknowledge, however, that their recommendations are unlikely to be sufficient for successful communication in other than the simplest encounters, for example, automated directory assistance or reservation systems. The question of why this should be so ­ of the nature of the limits on human­machine communication and the nature and extent of robustness in human interaction ­ is the subject of the following chapters.\r\n\r\n5\r\nPlans\r\nOnce the European navigator has developed his operating plan and has available the appropriate technical resources, the implementation and monitoring of his navigation can be accomplished with a minimum of thought. He has simply to perform almost mechanically the steps dictated by his training and by his initial planning synthesis.\r\n(Gladwin 1964: 175)\r\nEvery account of communication involves assumptions about action, in particular about the bases for action\'s coherence and intelligibility. This chapter and the next discuss two alternative views of action. The first, adopted by most researchers in artificial intelligence, locates the organization and significance of human action in underlying plans. At least as old as the Occidental hills, this view of purposeful action is the basis for traditional philosophies of rational action and for much of the behavioral sciences. It is hardly surprising, therefore, that it should be embraced by those newer fields concerned with intelligent artifacts, particularly cognitive science and information-processing psychology. On the planning view, plans are prerequisite to and prescribe action, at every level of detail. Mutual intelligibility is a matter of the reciprocal recognizability of our plans, enabled by common conventions for the expression of intent and shared knowledge about typical situations and appropriate actions. The alternative view, developed in Chapter 6 of this book, is that although the course of action can always be projected or reconstructed in terms of prior intentions and typical situations, the prescriptive significance of intentions for situated action is inherently\r\n51\r\n\r\n52\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nvague. The coherence of situated action is tied in essential ways not to individual predispositions or conventional rules but to local interactions contingent on the actor\'s particular circumstances.1 A consequence of action\'s situated nature is that communication must incorporate both a sensitivity to local circumstances and resources for the remedy of troubles in understanding that inevitably arise. This chapter reviews the planning model of purposeful action and shared understanding. Those who adopt the planning model as a basis for interaction between people and machines draw on three related theories about the mutual intelligibility of action: (1) the planning model itself, which takes the significance of action to be derived from plans and identifies the problem for interaction as their recognition and coordination; (2) speech act theory, which accounts for the recognizability of plans or intentions by proposing conventional rules for their expression; and (3) the idea of shared background knowledge, as the common resource that stands behind individual action and gives it social meaning. Each of these promises to solve general problems in human communication, such as the relation of observable behavior to intent, the correspondence of intended and interpreted meaning, and the stability of meaning assignments across situations, in ways that are relevant to particular problems in people\'s interaction with machines.\r\n\r\nthe planning model\r\nThe planning model in cognitive science treats a plan as a sequence of actions designed to accomplish some preconceived end. The model posits that action is a form of problem solving, where the actor\'s problem is to find a path from some initial state to a desired goal state, given\r\n1 The term circumstances of course begs a further set of questions. Most important for the purpose of this argument is recognition of the extent to which the conditions of our actions are not simply pregiven and self-evident but are themselves constituted through unfolding courses of action and interaction. This is not to say that action is constructed somehow always de novo or in a vacuum. On the contrary, human activity invariably occurs in circumstances that include more and less long-standing, obdurate, and compelling layers of culturally and historically constituted, social and material conditions. However familiar and constraining, though, the significance of those conditions, and their relevance for what is happening here and now, must be actively reenacted by participants in ways not fully specified in advance or in any strongly determinate way. For explorations of the improvisatory character of action drawn from close studies of jazz performance, see Sawyer (2003).\r\n\r\nPlans\r\n\r\n53\r\n\r\ncertain conditions along the way. Actions are described, at whatever level of detail, by their preconditions and their consequences:\r\nIn problem-solving systems, actions are described by prerequisites (i.e., what must be true to enable the action), effects (what must be true after the action has occurred), and decomposition (how the action is performed, which is typically a sequence of subactions). (Allen 1984: 126)\r\nGoals define the actor\'s relationship to the situation of action, because the situation is just those conditions that obstruct or advance the actor\'s progress toward his or her goals. Advance planning is inversely related to prior knowledge of the environment of action and of the conditions that the environment is likely to present. Unanticipated conditions will require replanning. In every case, however, whether constructed entirely in advance or completed and modified during the action\'s course, the plan is prerequisite to the action.\r\n\r\nPlan Generation and Execution Monitoring\r\nOne of the earliest attempts to implement the planning model on a machine occurred as part of a project at Stanford Research Institute, beginning in the mid-1960s. The project\'s goal was to build a robot that could navigate autonomously through a series of rooms, avoiding obstacles and moving specified objects from one room to another. The robot, named by its designers Shakey, was controlled by a problem-solving program called STRIPS, which employed a means­end analysis to determine the robot\'s path (Fikes and Nilsson 1971). The STRIPS program examined the stated goal and then determined a subset of operators, or actions available to the robot, that would produce that state. The preconditions of those actions in turn identified particular subgoal states, which could be examined in the same way. The system thus worked backward from the goal until a plan was defined from the initial state to the goal state, made up of actions that the robot could perform. Subsequent work on problem solving and plan synthesis consisted in large part in refinements to this basic means­ends strategy, toward the end of achieving greater efficiency by constraining the search through possible solution paths.2\r\nBeyond the problem of constructing plans, artificial intelligence researchers have had to address problems of what Nilsson (1973) terms\r\n\r\n2 For a review of subsequent work see Sacerdoti (1977, Chapter 3). (Original footnote.)\r\n\r\n54\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfailure and surprise in the execution of their planning programs, due to the practical exigencies of action in an unpredictable environment. The objective that Shakey should actually be able to move autonomously through a real (albeit somewhat impoverished) environment added a new class of problems to those faced by mathematical or game-playing programs operating in an abstract formal domain:\r\nfor a problem-solver in a formal domain is essentially done when it has constructed a plan for a solution; nothing can go wrong. A robot in the real world, however, must consider the execution of the plan as a major part of every task. Unexpected occurrences are not unusual, so that the use of sensory feedback and corrective action are crucial. (Raphael, cited in McCorduck 1979: 224)\r\nIn Shakey\'s case, execution of the plan generated by the STRIPS program was monitored by a second program called PLANEX. The PLANEX program monitored not the actual moves of the robot, however, but the execution of the plan. The program simply assumed that the execution of the plan meant that the robot had taken the corresponding action in the real world. The program also made the assumption that every time the robot moved there was some normally distributed margin of error that would be added to a \"model of the world\" or representation of the robot\'s location. When the cumulative error in the representation got large enough, the plan monitor initiated another part of the program that triggered a camera that could, in turn, take a reading of Shakey\'s location in the actual world.\r\nThe uncertainty to which Shakey was to respond consisted in changes made to the objects in its environment. Another order of uncertainty was introduced with Sacerdoti\'s system NOAH (an acronym for Nets of Action Hierarchies). Also developed at the Stanford Research Institute as part of the Computer-Based Consultant project, NOAH was designed to monitor and respond to the actions of a human user. With NOAH, Sacerdoti extended the techniques of problem solving and execution monitoring developed in the planning domain to the problem of interactive instruction:\r\nNOAH is an integrated problem solving and execution monitoring system. Its major goal is to provide a framework for storing expertise about the actions of a particular task domain, and to impart that expertise to a human in the cooperative achievement of nontrivial tasks. (Sacerdoti 1977: 2)\r\nThe output of the planning portion of Sacerdoti\'s program is a \"procedural net\" or hierarchy of partially ordered actions, which becomes in turn the input to the execution-monitoring portion of the system. The\r\n\r\nPlans\r\n\r\n55\r\n\r\nexecution monitor takes the topmost action in the hierarchy, provides the user with an instruction, and then queries the user regarding the action\'s completion. A principal objective of the innovations that Sacerdoti introduced for the representation of procedures in NOAH was to extend execution monitoring to include tracking and assessment of the user\'s actions in response to the instructions generated:\r\nThe system will monitor the apprentice\'s work to ensure that the operation is proceeding normally. When the system becomes aware of an unexpected event, it will alter instructions to the apprentice to deal effectively with the new situation. (ibid.: 3)\r\nA positive response from the user to the system\'s query regarding the action is taken to mean that the user understood the instruction and has successfully carried it out, whereas a negative response is taken as a request for a more detailed instruction. The system allows as well for a \"motivation response\" or query from the user as to why a certain task needs to be done (to which the system responds by listing tasks to which the current task is related) and for an \"error response\" or indication from the user that the current instruction cannot be carried out. Just as the accumulation of error in the PLANEX program required feedback from the world in order to reestablish the robot\'s location, the error response from the user in Sacerdoti\'s system requires that NOAH somehow repair its representation of the user\'s situation:\r\nPLANEX presumed that an adequate mechanism existed for accurately updating the world model. This was almost the case, since there were only a small number of actions that the robot vehicle could take, and the model of each action contained information about the uncertainty it would introduce in the world model. When uncertainties reached a threshold, the vision subsystem was used to restore the accuracy of the world model.\r\nFor the domain of the Computer-Based Consultant, or even for a richer robot domain, this approach will prove inadequate . . . NOAH cannot treat the world model as a given. It must initiate interactions with the user at appropriate points to ensure that it is accurately monitoring the course of the execution . . .\r\n[W]hen a serious error is discovered (requiring the system to be more thorough in its efforts to determine the state of the world), the system must determine what portions of its world model differ from the actual situation. (ibid.: 71­2)\r\nThe situation in which Shakey moved consisted of walls and boxes (albeit boxes that could be moved unexpectedly by a human hand). The problem in designing Shakey was to maintain consistency between the represented environment and the physical environment in which the robot moved. In introducing the actions of a user, the computer\'s\r\n\r\n56\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nenvironment becomes not only a physical but also a social one, requiring the interpretation of the user\'s actions and an assessment of the user\'s understanding of his or her situation. The difficulty of maintaining a shared understanding of a situation, as shown more clearly in Chapters 8 and 9, is not just a matter of monitoring the course of events but of establishing their significance. Nonetheless, with Sacerdoti we have at least a preliminary recognition of the place of the situation in the intelligibility of action and communication.\r\n\r\nInteraction and Plan Recognition\r\nAdherents of the planning model in artificial intelligence research have taken the requirement of interaction as an injunction to extend the planning model from a single individual to two or more individuals acting in concert. The planning model attempts to bring concerted action under the jurisdiction of the individual actor by attaching to the others in the actor\'s world sufficient description and granting to the actor sufficient knowledge that he or she is able to respond to the actions of others as just another set of environmental conditions. The problem of social interaction, consequently, becomes an extension of the problem of the individual actor. The basic view of a single, goal-directed agent, acting in response to an environment of conditions, is complicated (the conditions now include the actions of other agents) but intact.\r\nThe problem for interaction, on this view, is to recognize the actions of others as the expression of their underlying plans. The complement to plan generation and execution in artificial intelligence research, therefore, is plan recognition or the attribution of plans to others based on observation of their actions. The starting premise for a theory of plan recognition is that an observer takes some sequence of actions as evidence and then forms hypotheses about the plans that could motivate and explain those actions.\r\nOne persisting difficulty for action understanding in artificial intelligence research has been the uncertain relation between actions and intended effects. Allen (1984) illustrates this problem with the example of turning on a light:\r\nThere are few physical activities that are a necessary part of performing the action of turning on a light. Depending on the context, vastly different patterns of behavior can be classified as the same action. For example, turning on a light usually involves flipping a light switch, but in some circumstances it may involve tightening the light bulb (in the basement) or hitting the wall\r\n\r\nPlans\r\n\r\n57\r\n\r\n(in an old house). Although we have knowledge about how the action can be performed, this does not define what the action is. The key defining characteristic of turning on the light seems to be that the agent is performing some activity which will cause the light, which was off when the action started, to become on when the action ends. An important side effect of this definition is that we could recognize an observed pattern of activity as \"turning on the light\" even if we had never seen or thought about that pattern previously. (ibid.: 126)\r\nAllen\'s point is twofold. First, the \"same\" action as a matter of intended effect can be achieved in any number of ways, where the ways are contingent on circumstance rather than on definitional properties of the action. And second, although an action can be accounted for post hoc with reference to its intended effect, an action\'s course cannot be predicted from knowledge of the actor\'s intent, nor can the course be inferred from observation of the outcome. Allen identifies the indeterminate relationship of intended effect to method as a problem for planning or plan recognition systems: a problem that he attempts to resolve by constructing a logical language for action descriptions that handles the distinction between what he calls the \"causal definition\" of an action (i.e., the pre and post conditions that must hold to say that the action has occurred, independent of any method) and the action\'s characterization in terms of a particular method or procedure for its accomplishment.3\r\nWhereas Allen\'s approach to the problem of plan recognition is an attempt to reconstruct logically our vocabulary of purposeful action, a few more psychologically oriented researchers in artificial intelligence have undertaken experiments designed to reveal the process by which people bring the actions of others under the jurisdiction of an ascribed plan. Schmidt, Sridharan, and Goodson (1978) observe, for example, that plan attribution seems to require certain transformations of the sequential organization of the action described.4 They report that throughout the process of plan attribution the problem to be solved by the subject remains \"ill-formed,\" by which they mean that at any given time neither the range of possible plans that the other might be carrying out,\r\n\r\n3 Another, less problematic, uncertainty that Allen attempts to capture is the observation that while some components of an action are sequentially ordered in a necessary way (i.e., one is prerequisite to the other), other components, although necessary to the action, have no necessary sequential relationship to each other. The incorporation of unordered actions into the structure of plans, pioneered by Sacerdoti (1975), was viewed as a substantial breakthrough in early planning research. (Original footnote.)\r\n4 The empirical method of their study is unusual in artificial intelligence research, where work generally proceeds on the basis of imagination and introspection. (Original footnote.)\r\n\r\n58\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nnor the criteria for assessing just what plan is actually in effect, are clearly defined (ibid.: 80). Nonetheless, they report that their subjects are able to posit an underlying plan. Their strategy appears to be to adopt tentatively a single hypothesis about the other\'s plan rather than entertain all or even some number of logical possibilities simultaneously. The preferred hypothesis regarding the other\'s plan then affects what actions are noted and recalled in the subject\'s accounts of the action, and the temporal order of events is restructured into logical \"in order to\" or \"because\" relationships, such that relations among actions are not restricted to consecutive events in time. At the same time, the current hypothesis is always subject to elaboration or revision in light of subsequent events to the extent that subjects are often required to suspend judgment on a given hypothesis and to adopt a \"wait and see\" strategy. Wherever possible, actions that violate the structure of an attributed plan are explained away before the plan itself is reconsidered. Schmidt, Shridharan, and Goodson conclude that all of these observations \"support the generalization that action understanding is simply a process of plan recognition\" (ibid.: 50). It is worth noting, however, that although these observations clearly point to a process of plan attribution by the observer, there is no independent evidence that the process of plan attribution is a process of recognizing the plan of the actor.\r\n\r\nThe Status of Plans\r\nAssessment of the planning model is complicated by equivocation in the literature between plans as a conceptual framework for the analysis and simulation of action and plans as a psychological mechanism for its actual production. When researchers describe human action in terms of plans, the discussion generally finesses the question of just how the formulations provided by the researcher are purported to relate to the actor\'s intent. The claim is at least that people analyze each other\'s actions into goals and plans to understand each other. But the suggestion that the plan is \"recognized\" implies that it has an existence prior to and independent of the attribution and that it actually determines the action. The identification of the plan with the actor\'s intent is explicit in the writing of philosophers of action supportive of artificial intelligence research like Margaret Boden, who writes:\r\nunless an intention is thought of as an action-plan that can draw upon background knowledge and utilize it in the guidance of behavior one cannot understand how intentions function in real life. (1973: 27­8)\r\n\r\nPlans\r\n\r\n59\r\n\r\nIntentions, in other words, are realized as plans-for-action that directly guide behavior. A logical extension of Boden\'s view, particularly given an interest in rendering it more computable, is the view that plans actually are prescriptions or instructions for action. An early and seminal articulation of this view came from Miller, Galanter, and Pribram (1960), who define an intention as \"the uncompleted parts of a Plan whose execution has already begun\" (ibid.: 61). With respect to the plan itself:\r\nAny complete description of behavior should be adequate to serve as a set of instructions, that is, it should have the characteristics of a plan that could guide the action described. When we speak of a plan . . . the term will refer to a hierarchy of instructions . . . A plan is any hierarchical process in the organism that can control the order in which a sequence of operations is to be performed.\r\nA Plan is, for an organism, essentially the same as a program for a computer . . . , we regard a computer program that simulates certain features of an organism\'s behavior as a theory about the organismic Plan that generated the behavior.\r\nMoreover, we shall also use the term \"Plan\" to designate a rough sketch of some course of action . . . , as well as the completely detailed specification of every detailed operation . . . We shall say that a creature is executing a particular Plan when in fact that Plan is controlling the sequence of operations he is carrying out. (ibid.: 17, original emphasis)\r\nWith Miller, Galanter, and Pribram the view that purposeful action is planned is put forth as a psychological \"process theory\" compatible with the interest in a mechanistic, computationally tractable account of intelligent action.5 By improving on or completing our commonsense descriptions of the structure of action, the structure is now represented not only as a plausible sequence but also as a hierarchical plan. The plan reduces, moreover, to a detailed set of instructions that actually serves as the program that controls the action. At this point the plan as stipulated becomes substitutable for the action, insofar as the action is viewed as derivative from the plan. And once this substitution is done, the theory is self-sustaining: the problem of action is assumed to be solved by the planning model and the task that remains is the model\'s refinement.\r\nAlthough attributing the plan to the actor resolves the question of the plan\'s status, however, it introduces new problems with respect to what we actually mean by purposeful action. If plans are synonymous with purposeful action how do we account, on the one hand, for a prior intent to act that may never be realized and, on the other hand, for\r\n\r\n5 For a close, critical reading of Miller, Galanter, and Pribram from within the field of artificial intelligence research, see Agre (1997, Chapter 8).\r\n\r\n60\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nan intentional action for which we would ordinarily say no plan was formed ahead of time?6 And if any plan of action can be analyzed at any level of detail, what level of description represents that which we would want to call purposeful action? If every level, there is no reason in principle to distinguish, for example, between deliberate action and involuntary response, as the latter always can be ascribed to a process of planning unavailable to the actor. In fact, this is just what Boden would have us do. On her account, action can be reduced to basic units for which \"no further procedural analysis could conceivably be given.\" Those units compose \"complex procedural schemata or action-plans,\" which in turn produce \"complex intentional effects\" (1973: 36). Psychological processes at the level of intention, in other words, are reducible ultimately to bodily operations.\r\nBut although the planning model would have a statement of intent reflect an actual set of instructions for action, even casual observation indicates that our statements of intent generally do not address the question of situated action at any level of detail. In fact, because the relation of the intent to accomplish some goal to the actual course of situated action is enormously contingent, a statement of intent generally says very little about the action that follows. It is precisely because our plans are inherently vague ­ because we can state our intentions without having to describe the actual course that our actions will take ­ that an intentional vocabulary is so useful for our everyday affairs.\r\nThe confusion in the planning literature over the status of plans mirrors the fact that in our everyday action descriptions we do not normally distinguish between accounts of action provided before and after the fact and an action\'s actual course. As commonsense constructs plans are a constituent of practical action, but they are constituent as an artifact of our reasoning about action, not as the generative mechanism of action. Our imagined projections and our retrospective reconstructions are the principal means by which we catch hold of situated action and reason about it, whereas situated action itself, in contrast, is essentially transparent to us as actors.7 The planning model, however, takes over our commonsense preoccupation with the anticipation of action and the review of\r\n\r\n6 Davis (cited in Allen 1984) gives the example of a person driving who brakes when a small child runs in front of the car. See also Searle\'s distinction (1980) between \"prior intentions\" and \"intentions-in-action.\" (Original footnote.)\r\n7 One result of the transparency of situated action is that we have little vocabulary with which to talk about it, though Chapters 6 and 7 attempt to present some recent efforts from the social sciences. For a treatment of the philosophical vocabulary proposed by Heidegger, see Dreyfus (1991). (Original footnote, with updated reference.)\r\n\r\nPlans\r\n\r\n61\r\n\r\nits outcomes and attempts to systematize that reasoning as a model for\r\naction while ignoring the actual stuff, the situated action, which is the reasoning\'s object.8\r\n\r\nspeech acts\r\nA growing number of research efforts devoted to machine intelligence have as their objective, for both theoretical and practical reasons, human­machine communication using English or \"natural language\" (for example, Brady and Berwick 1983; Bruce 1981; Joshi, Webber, and Sag 1981). Researchers in natural language understanding have embraced Austin\'s observation (1962) that language is a form of action as a way of subsuming communication to the planning model. If language is a form of action, it follows that language understanding, like the interpretation of action generally, involves an analysis of a speaker\'s utterances in terms of the plans those utterances serve:\r\nLet us start with an intuitive description of what we think occurs when one agent A asks a question of another agent B which B then answers. A has some goal; s/he creates a plan (plan construction) that involves asking B a question whose answer will provide some information needed in order to achieve the goal. A then executes this plan, asking B the question. B interprets the question, and attempts to infer A\'s plan (plan inference). (Allen 1983; original emphasis)\r\nAs with the interpretation of action, plans are the substrate on which the interpretation of natural language utterances rests, insofar as \"human language behavior is part of a coherent plan of action directed toward satisfying a speaker\'s goals\" (Appelt 1985: 1). We understand language, and action more generally, when we successfully infer the other\'s goals and understand how the other\'s action furthers them. The appropriateness of a response turns on that analysis, from which in turn:\r\nThe hearer then adopts new goals (e.g., to respond to a request, to clarify the previous speaker\'s utterance or goal), and plans his own utterances to achieve those. A conversation ensues. (Cohen n.d.: 24)\r\n\r\n8 A note of clarification is in order here, particularly in light of readings of this text that have taken my argument to be either that plans do not exist or that they are \"merely\" fictions created before and after the fact of specifically situated activity. In rereading this passage I realize the contribution that I myself may have made to this misunderstanding in not emphasizing clearly enough that I take planning itself to be a form of situated action. As I have argued in Chapter 1, this is true both in the sense that plans are imaginative and discursive accounts created in anticipation of action and in the sense that they may be cited in the midst of ongoing activity, as well as afterwards. See also Chapter 11.\r\n\r\n62\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nGiven such an account of conversation, the research problem with respect to language understanding is essentially the same as that of the planning model more generally; that is, to characterize actions in terms of their preconditions and effects and to formulate a set of inference rules for mapping between actions and underlying plans. Among researchers in the natural language area of artificial intelligence research, Searle\'s speech act theory (1969) is seen to offer some initial guidelines for computational models of communication:\r\nWe hypothesize that people maintain, as part of their models of the world, symbolic descriptions of the world models of other people. Our plan-based approach will regard speech acts as operators whose effects are primarily on the models that speakers and hearers maintain of each other. (Cohen and Perrault 1979: 179)\r\nSearle\'s conditions of satisfaction for the successful performance of speech acts are read as the speech act\'s \"preconditions,\" whereas its illocutionary force is the desired \"effect\":\r\nUtterances are produced by actions (speech acts) that are excited in order to have some effect on the hearer. This effect typically involves modifying the hearer\'s beliefs or goals. A speech act, like any other action, may be observed by the hearer and may allow the hearer to infer what the speaker\'s plan is. (Allen 1983: 108)\r\nIn describing utterances by their preconditions and effects, speech acts seem to provide at least the framework within which computational mechanisms for engineering interaction between people and machines might emerge. But although Searle\'s \"conditions of satisfaction\" state conventions governing the illocutionary force of certain classes of utterance, he argues against the possibility of a rule-based semantics for construing the significance of any particular utterance. Although the maxims that speech act theory proposes (for example, the felicity condition for a directive is that S wants H to do A) tell us something about the general conditions of satisfaction for a directive, they tell us nothing further about the significance of any particular directive. With respect to the problem of interpretation, Gumperz (1982b: 326) offers the following example from an exchange between two secretaries in a small office:\r\nA: Are you going to be here for ten minutes? B: Go ahead and take your break. Take longer if you want. A: I\'ll just be outside on the porch. Call me if you need me. B: OK. Don\'t worry.\r\n\r\nPlans\r\n\r\n63\r\n\r\nGumperz points out that B\'s response to A\'s question clearly indicates that B interprets the questions as an indirect request that B stay in the office while A takes a break and, by her reply, A confirms that interpretation. B\'s interpretation accords with a categorization of A\'s question as an indirect speech act (Searle 1979), and with Grice\'s discussion of implicature (1975); that is, B assumes that A is cooperating and that her question must be relevant, and therefore B searches her mind for some possible context or interpretive frame that would make sense of the question and comes up with the break. But, Gumperz points out, this analysis begs the question of how B arrives at the right inference:\r\nWhat is it about the situation that leads her to think A is talking about taking a break? A common sociolinguistic procedure in such cases is to attempt to formulate discourse rules such as the following: \"If a secretary in an office around break time asks a co-worker a question seeking information about the co-worker\'s plans for the period usually allotted for breaks, interpret it as a request to take her break.\" Such rules are difficult to formulate and in any case are neither sufficiently general to cover a wide enough range of situations nor specific enough to predict responses. An alternative approach is to consider the pragmatics of questioning and to argue that questioning is semantically related to requesting, and that there are a number of contexts in which questions can be interpreted as requests. While such semantic processes clearly channel conversational inference, there is nothing in this type of explanation that refers to taking a break. (1982b: 326­7)\r\nThe problem that Gumperz identifies here applies equally to attempts to account for inferences such as B\'s by arguing that she recognizes A\'s plan to take a break. Clearly she does: the outstanding question is how. Although we can always construct a post hoc account that explains interpretation in terms of knowledge of typical situations and motives, it remains the case that with speech act theory, as with the planning model, neither typifications of intent nor general rules for its expression are sufficient to account for the mutual intelligibility of our situated action. In the final analysis, attempts to construct a taxonomy of intentions and rules for their recognition seem to beg the question of situated interpretation rather than answer it.\r\n\r\nbackground knowledge\r\nGumperz\'s example demonstrates a problem that any account of human action must face; namely, that an action\'s significance seems to lie as much in what it presupposes and implies about its situation as in any\r\n\r\n64\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nexplicit or observable behavior as such. Even the notion of observable behavior becomes problematic in this respect, insofar as what we do and what we understand others to be doing is so thoroughly informed by assumptions about the action\'s significance. In the interpretation of purposeful action, it is hard to know where observation leaves off and where interpretation begins. In recognition of the fact that human behavior is a figure defined by its ground, social science has largely turned from the observation of behavior to explication of the background that seems to lend behavior its sense.\r\nFor cognitive science the background of action is not the world as such, but knowledge about the world. Researchers agree that representation of knowledge about the world is a principal limiting factor on progress in machine intelligence. The prevailing strategy in representing knowledge has been to categorize the world into domains of knowledge (e.g., areas of specialization such as medicine along one dimension or propositions about physical phenomena such as liquids along another) and then to enumerate facts about the domain and relationships between them. Having carved out domains of specialized knowledge the catchall for anything not clearly assignable is \"common sense,\" which then can be spoken of as if it were yet another domain of knowledge (albeit one that is foundational to the others).\r\nAlthough some progress has been made in selected areas of specialized knowledge, the domain of commonsense knowledge so far remains intractable and unwieldy.9 One approach to bounding commonsense knowledge, exemplified by the work of Schank and Abelson (1977), is to classify the everyday world as types of situations and assign to each its own body of specialized knowledge. The claim is that our knowledge of the everyday world is organized by a \"predetermined, stereotyped sequence of actions that define a well-known situation\" or script (ibid.: 422). Needless to say, \"[s]cripts are extremely numerous. There is a restaurant script, a birthday party script, a football game script, a classroom script, and so on\" (ibid.: 423). Every situation, in other words, has its plan made up of ordered action sequences, each action producing the conditions that enable the next action to occur. Admittedly, the normative order of these action sequences can be thrown off course by any one of what Schank and Abelson term distractions, obstacles, or\r\n\r\n9 For a cogent critique of the most ambitious effort to encode \"commonsense\" knowledge as a foundation for AI, see Adam\'s account of the CYC project in Adam (1998, Chapter 3).\r\n\r\nPlans\r\n\r\n65\r\n\r\nerrors. Distractions, about which they have little to say, comprise the interruption of one script by another, whereas:\r\nAn obstacle to the normal sequence occurs when someone or something prevents a normal action from occurring or some enabling condition for the action is absent. An error occurs when the action is completed in an inappropriate manner, so that the normal consequences of the action do not come about. (ibid.: 426)\r\nNot only does the typical script proceed according to a normal sequence of actions, in other words, but each script has its typical obstacles and errors that, like the script itself, are stored in memory along with their remedies and retrieved and applied as needed.\r\nWhereas plans associate intentions with action sequences, scripts associate action sequences with typical situations. In practice, however, the stipulation of relevant background knowledge for typical situations always takes the form of a partial list, albeit one offered as if the author could complete the list given the requisite time and space:\r\nIf one intends to buy bread, for instance, the knowledge of which bakers are open and which are shut on that day of the week will enter into the generation of one\'s plan of action in a definite way; one\'s knowledge of local topography (and perhaps of map-reading) will guide one\'s locomotion to the selected shop; one\'s knowledge of linguistic grammar and of the reciprocal roles of shopkeeper and customer will be needed to generate that part of the action-plan concerned with speaking to the baker, and one\'s financial competence will guide and monitor the exchange of coins over the shop counter. (Boden 1973: 28)\r\nLike Boden\'s story of the business of buying bread, attempts in artificial intelligence research to formalize commonsense knowledge rely on an appeal to intuition that shows little sign of yielding to scientific methods. The difficulty is not just that every action presupposes a large quantity of background knowledge: though it would pose practical problems, such a difficulty would be tractable eventually. Just because \"implicit knowledge\" can in principle be enumerated indefinitely, deciding in practice about the enumeration of background knowledge remains a stubbornly ad hoc procedure, for which researchers have not succeeded in constructing rules that do not depend, in their turn, on some deeper ad hoc procedures.\r\nNevertheless, the image evoked by \"shared knowledge\" is a potentially enumerable body of implicit assumptions or presuppositions that stands behind every explicit action or utterance and from which\r\n\r\n66\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nparticipants in interaction selectively draw in understanding each other\'s actions. This image suggests that what actually does get said on any occasion must reflect the application of a principle of communicative economy, which recommends roughly that to the extent that either the premises or rationale of an action can be assumed to be shared, they can be left unspoken. That means, in turn, that speakers must have procedures for deciding the extent of the listener\'s knowledge and the commensurate requirements for explication. The listener, likewise, must make inferences regarding the speaker\'s assumptions about shared knowledge on the basis of what he or she chooses explicitly to say. What is unspoken and relevant to what is said is assumed to reside in the speaker\'s and listener\'s common stock of background knowledge, the existence of which is proven by the fact that an account of what is said always requires reference to further facts that, though unspoken, are clearly relevant.\r\nThis image of communication is challenged, however, by the results of an exercise assigned by Garfinkel to his students (1972). Garfinkel\'s aim was to press the commonsense notion that background knowledge is a body of things thought but unsaid that stands behind behavior and makes it intelligible. The request was that the students provide a complete description of what was communicated, in one particular conversation, as a matter of the participants\' shared knowledge. Students were asked to report a simple conversation by writing on the left-hand side of a piece of paper what was said and on the right-hand side what it was that they and their partners actually understood was being talked about. Garfinkel reports that when he made the assignment:\r\n\r\nmany students asked how much I wanted them to write. As I progressively imposed accuracy, clarity, and distinctness, the task became increasingly laborious. Finally, when I required that they assume I would know what they had actually talked about only from reading lilerally what they wrote literally, they gave up with the complaint that the task was impossible. (ibid.: 317)\r\nThe students\' dilemma was not simply that they were being asked to write \"everything\" that was said, where that consisted of some bounded, albeit vast, content. Instead, it was that the task of enumerating what was talked about itself extended what was talked about, providing a continually receding horizon of understandings to be accounted for. The assignment, it turned out, was not to describe some existing content but to generate it. As such, it was an endless task. The students\' failure suggests not that they gave up too soon but that what they were assigned\r\n\r\nPlans\r\n\r\n67\r\n\r\nto do was not what the participants in the conversation themselves did to achieve shared understanding.\r\nAlthough the notion of \"background assumptions\" connotes an actual collection of things that are there in the mind of the speaker ­ a body of knowledge that motivates a particular action or linguistic expression and makes it interpretable ­ Garfinkel\'s exercise, as well as the phenomenology of experience, suggest that there is reason to question the view that background assumptions are part of the actor\'s mental state prior to action:\r\n\r\nAs I dash out the door of my office, for example, I do not consciously entertain the belief that the floor continues on the other side, but if you stop me and ask me whether, when I charged confidently through the door, I believed that the floor continued on the other side, I would have to respond that indeed, I did. (Dreyfus 1982: 25)\r\nA background assumption, in other words, is generated by the activity of accounting for an action when the premise of the action is called into question. But there is no particular reason to believe that the assumption actually characterizes the actor\'s mental state prior to the act. In this respect, the \"taken for granted\" denotes not a mental state but something outside of our heads that, precisely because it is nonproblematically there, we do not need to think about. By the same token, in whatever ways we do find action to be problematical the world is there to be consulted should we choose to do so. Similarly, we can assume the intelligibility of our actions, and as long as the others with whom we interact present no evidence of failing to understand us we do not need to explain ourselves, yet the grounds and significance of our actions can be explicated endlessly. The situation of action is thus an inexhaustibly rich resource, and the enormous problems of specification that arise in cognitive science\'s theorizing about intelligible action have less to do with action than with the project of substituting definite procedures for vague plans, and representations of the situation of action, for action\'s actual circumstances.\r\nTo characterize purposeful action as in accord with plans and goals is just to say again that it is purposeful and that somehow, in a way not addressed by the characterization itself, we constrain and direct our actions according to the significance that we assign to a particular context. How we do that is the outstanding problem. Plans and goals do not provide the solution for that problem; they simply restate it. The dependency of significance on a particular context, every particular\r\n\r\n68\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ncontext\'s open-endedness, and the essential contingency of contextual elaboration are resources for practical affairs but perplexities for a science of human action. And, to anticipate the analysis in Chapter 9, it is an intractable problem for projects that rest on providing in advance for the significance of canonical descriptions ­ such as instructions ­ for situated action.\r\n\r\n6\r\nSituated Actions\r\nThis total process [of Trukese navigation] goes forward without reference to any explicit principles and without any planning, unless the intention to proceed to a particular island can be considered a plan. It is nonverbal and does not follow a coherent set of logical steps. As such it does not represent what we tend to value in our culture as \"intelligent\" behavior.\r\n(Gladwin 1964: 175)\r\nThis chapter turns to recent efforts within anthropology and sociology to challenge traditional assumptions regarding purposeful action and shared understanding. A point of departure for the challenge is the idea that commonsense notions of planning are not inadequate versions of scientific models of action, but rather are resources for people\'s practical deliberations about action.1 As projective and retrospective accounts of action, plans are themselves located in the larger context of some ongoing practical activity. And as commonsense notions about the structure of that activity, plans are part of the subject matter to be investigated in a study of purposeful action, not something to be improved on or transformed into axiomatic theories of action.\r\nThe premise that practical reasoning about action is properly part of the subject matter of social studies is due to the emergence of a branch of sociology named ethnomethodology. This chapter describes the inversion of traditional social theory recommended by ethnomethodology and the implications of that inversion for the prowler of purposeful\r\n1 For an exposition of the ethnomethodological premises that underwrite this idea, see Lynch (1993). 69\r\n\r\n70\r\n\r\nHuman­Machine Reconfigurations\r\n\r\naction and shared understanding. To designate the alternative that ethnomethodology suggests (more a reformulation of the problem of purposeful action and a research programme than an alternative theory), I have introduced the term situated action.2 That term underscores the view that every course of action depends in essential ways on its material and social circumstances. Rather than attempt to abstract action away from its circumstances and represent it as a rational plan, the approach is to study how people use their circumstances to achieve intelligent action. Rather than build a theory of action out of a theory of plans, the aim is to investigate how people produce and find evidence for plans in the course of situated action. More generally, rather than subsume the details of action under the study of plans, plans are subsumed by the larger problem of situated action.\r\nThe view of action that ethnomethodology recommends is neither behavioristic, in any narrow sense of that term, nor mentalistic. It is not behavioristic in that it assumes that the significance of action is not reducible to uninterpreted bodily movements. Nor is it mentalistic, however, in that the significance of action is taken to be based, in ways that are fundamental, rather than secondary or epiphenomenal, in the physical and social world. The basic premise is twofold: first, that what traditional behavioral sciences take to be cognitive phenomena have an necessary relationship to a publicly available, collaboratively organized world of artifacts and actions and, second, that the significance of artifacts and actions, and the methods by which their significance is conveyed, have an essential relationship to their particular, concrete circumstances.3\r\nThe ethnomethodological view of purposeful action and shared understanding is outlined in this chapter under five propositions: (1) plans are representations of situated actions; (2) in the course of situated action, representation occurs when otherwise transparent activity becomes in some way problematic; (3) the objectivity of the situations\r\n\r\n2 In saying that I had introduced the term situated action, I meant within the context of the present discussion. Subsequent attributions to the contrary, I by no means intended to suggest that I had coined that phrase! Origins of the phrase in sociological writings go back at least to C. Wright Mills\'s (1940) \"Situated Actions and Vocabularies of Motive.\" Rawls (2002: 20) points out that although Garfinkel\'s ethnomethodological treatment of the relation of action and accounts is consistent with Mills\'s, Garfinkel attends not only to the retrospective character of accounts but also to the prospective and ongoing character of both accounts the actions that they formulate.\r\n3 On the relevance of a phenomenological account of the public availability of objects and artifacts to system design, see Robertson (2002).\r\n\r\nSituated Actions\r\n\r\n71\r\n\r\nof our action is achieved rather than given; (4) a central resource for achieving the objectivity of situations is language, which stands in a generally indexical relationship to the circumstances that it presupposes, produces, and describes; (5) as a consequence of the indexicality of language, mutual intelligibility is achieved on each occasion of interaction with reference to situation particulars rather than being discharged once and for all by a stable body of shared meanings.\r\n\r\nplans are representations of action\r\nThe pragmatist philosopher and social psychologist George Herbert Mead (1934) has argued for a view of meaningful, directed action as two integrally but problematically related kinds of activity. One kind of activity is situated and ad hoc improvisation ­ the part of us, so to speak, that actually acts. The other kind of activity is derived from the first and includes our representations of action in the form of future plans and retrospective accounts. Plans and accounts are distinguished from action as such by the fact that to represent our actions we must in some way to make an object of them. Consequently, our descriptions of our actions come always before or after the fact, in the form of imagined projections and recollected reconstructions.4 Mead\'s treatment of the relation of deliberation and reflection to action is one of the more controversial, and in some ways incoherent, pieces of his theory. But his premise of a disjunction between our actions and our grasp of them at least raises the question for social science of the relationship between projected or reconstructed courses of action and actions in situ. Most accounts of purposeful action have taken this relationship to be a directly causal one, at least in a logical sense (see Chapter 5 in this book). Given a desired outcome, the actor is assumed to make a choice among alternative courses of action, based on the anticipated consequences of each with respect to that outcome. Accounts of actions taken, by the same token, are just a report on the choices made. The student of purposeful action on this view need know only the predisposition of the actor and the alternative courses that are available to predict the action\'s course.\r\n4 Here again, I regret the implication that plans and other forms of imaginative reflection stand somehow outside of action rather than being themselves moments of situated activity (activities of planning, remembering, etc.), displaced in time and space from the occasion anticipated or recollected. The interesting questions for this discussion turn on how it is that activities of planning are invoked and made relevant to the course of some subsequent activity and vice versa. See Chapter 11.\r\n\r\n72\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe action\'s course is just the playing out of these antecedent factors, knowable in advance of and standing in a determinate relationship to the action itself.\r\nThe alternative view is that plans are resources for situated action but do not in any strong sense determine its course. Although plans presuppose the embodied practices and changing circumstances of situated action, the efficiency of plans as representations comes precisely from the fact that they do not represent those practices and circumstances in all of their concrete detail. So, for example, in planning to run a series of rapids in a canoe, one is very likely to sit for a while above the falls and plan one\'s descent.5 The plan might go something like \"I\'ll get as far over to the left as possible, try to make it between those two large rocks, then backferry hard to the right to make it around that next bunch.\" A great deal of deliberation, discussion, simulation, and reconstruction may go into such a plan. But however detailed, the plan stops short of the actual business of getting your canoe through the falls. When it really comes down to the details of responding to currents and handling a canoe, you effectively abandon the plan and fall back on whatever embodied skills are available to you.6 The purpose of the plan in this case is not to get your canoe through the rapids, but rather to orient you in such a way that you can obtain the best possible position from which to use those embodied skills on which, in the final analysis, your success depends. Even in the case of more deliberative, less highly skilled activities we generally do not anticipate alternative courses of action or their consequences until some course of action is already underway. It is frequently only on acting in a present situation that its possibilities become clear, and we often do not know ahead of time, or at least not with any specificity, what future state we desire to bring about. Garfinkel points out that in many cases it is only after we encounter some state of affairs that we find to be desirable that we identify that state as the goal toward which our previous actions, in retrospect, were directed \"all along\" or \"after all\" (1967: 98). The fact that we can always perform a post hoc analysis of situated action that will make it appear to have followed a rational plan says more about the\r\n\r\n5 This example was suggested to me by Randall Trigg, to whom I am indebted for the insight that plans orient us for situated action in this way. (Original footnote.)\r\n6 This phrasing is unfortunate, in suggesting that the plan is somehow jettisoned (see Chapter 1). It would be better to say that your ability to act according to the plan ultimately turns on the embodied skills available to you in situ, which are themselves presupposed, rather than specified, by the plan.\r\n\r\nSituated Actions\r\n\r\n73\r\n\r\nnature of our analyses than it does about our situated actions. To return to Mead\'s point, rather than direct situated action rationality anticipates action before the fact and reconstructs it afterwards.\r\n\r\nrepresentation and breakdown\r\nAlthough we can always construct rational accounts of situated action before and after the fact, when action is proceeding smoothly it is essentially transparent to us. Similarly, when we use what Heidegger terms equipment that is \"ready-to-hand,\" the equipment has a tendency to disappear:\r\nConsider the example (used by Wittgenstein, Polanyi, and MerleauPonty) of the blind man\'s cane. We hand the blind man a cane and ask him to tell us what properties it has. After hefting and feeling it, he tells us that it is light, smooth, about three feet long, and so on; it is occurrent for him. But when the man starts to manipulate the cane, he loses his awareness of the cane itself; he is aware only of the curb (or whatever object the cane touches); or, if all is going well, he is not even aware of that . . . Precisely when it is most genuinely appropriated equipment becomes transparent. (Dreyfus 1991: 65)7\r\nIn contrast, the \"unready-to-hand,\" in Heidegger\'s phrase, comprises occasions wherein equipment that is involved in some practical activity becomes unwieldy, temporarily broken, or unavailable. At such times, inspection and practical problem solving occur, aimed at repairing or eliminating the disturbance to \"get going again.\" In such times of disturbance, our use of equipment becomes explicitly manifest as a goaloriented activity, and we may then try to formulate procedures or rules: \"The scheme peculiar to [deliberating] is the `if­then\'; if this or that, for instance, is to be produced, put to use, or averted, then some ways and means, circumstances, or opportunities will be needed\" (Heidegger, cited in Dreyfus 1991: 72).\r\nAnother kind of breakdown that arises when equipment to be used is unfamiliar is discussed in Chapter 9 in this book in relation to the \"expert help system\" and the problem of instructing the novice user of a machine. The important point here is just that the rules and procedures that come into play when we deal with the unready-to-hand are not self-contained or foundational but contingent on and derived from the\r\n7 This quote has been updated from the citation in the original text, which was drawn from a prepublished manuscript of Dreyfus\'s book. The phrase ready-to-hand, used in that earlier version, has been replaced with the term occurrent.\r\n\r\n74\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsituated action that the rules and procedures represent. The representations involved in managing problems in the use of equipment presuppose the very transparent practices that the problem renders noticeable or remarkable. Situated action, in other words, is not made explicit by rules and procedures. Rather, when situated action becomes in some way problematic rules and procedures are explicated for purposes of deliberation and the action, which is otherwise neither rule based nor procedural, is then made accountable to them.\r\n\r\nthe practical objectivity of situations\r\nIf we look at the world commonsensically, the environment of our actions is made up of a succession of situations that we walk into and to which we respond. As I noted in Chapter 5 in this book, advocates of the planning model not only adopt this commonsense realist view with respect to the individual actor but also attempt to bring concerted action under the same account by treating the actions of others as just so many more conditions of the actor\'s situation. In the same tradition, normative sociology posits and then attempts to describe an objective world of social facts, or received norms, to which our attitudes and actions are a response. Emile Durkheim\'s famous maxim that the objective reality of social facts is sociology\'s fundamental principle (1938) has been the methodological premise of social studies since early in this century. Recognizing the human environment to be constituted crucially by others, sociological norms comprise a set of environmental conditions beyond the material to which human behavior is responsive: namely the sanctions of institutionalized group life. Human action, the argument goes, cannot be adequately explained without reference to these \"social facts,\" which are to be treated as antecedent, external, and coercive vis-a`-vis the individual actor.\r\nBy adopting Durkheim\'s maxim, and assuming the individual\'s responsiveness to received social facts, social scientists hoped to gain respectability under the view that human responses to the facts of the social world should be discoverable by the same methods as are appropriate to studies of other organisms reacting to the natural world. A principal aim of normative sociology was to shift the focus of attention in studies of human behavior from the psychology of the individual to the conventions of the social group. But at the same time that normative sociology directed attention to the community or group, it maintained an image of the individual member rooted in behaviorist\r\n\r\nSituated Actions\r\n\r\n75\r\n\r\npsychology and natural science ­ an image that has been dubbed by Garfinkel the \"cultural dope\": \"By `cultural dope\' I refer to the man-inthe-sociologist\'s-society who produces the stable features of the society by acting in compliance with preestablished and legitimate alternatives of action that the common culture provides\" (1967: 68). Insofar as the alternatives of action that the culture provides are seen to be nonproblematic and constraining on the individual, their enumeration is taken to constitute an account of situated human action. The social facts (that is to say, what actions typically come to) are used as a point of departure for retrospective theorizing about the \"necessary character of the pathways whereby the end result is assembled\" (ibid.: 68).\r\nIn 1954 the sociologist Herbert Blumer published a critique of traditional sociology titled, \"What Is Wrong with Social Theory?\" (see Blumer 1969: 140­52). Blumer argues that the social world is constituted by the local production of meaningful action and that as such the social world has never been taken seriously by social scientists. Instead, Blumer says, investigations by social scientists have looked at meaningful action as the playing out of various determining factors, all antecedent and external to the action itself. Whether those factors are brought to the occasion in the form of individual predispositions, or are present in the situation as preexisting environmental conditions or received social norms, the action itself is treated as epiphenomenal. As a consequence, Blumer argues, we have a social science that is about meaningful human action but not a science of it.\r\nFor the foundations of a science of action Blumer turns to Mead, who offers a metaphysics of action that is deeply sociological. Blumer points out that a central contribution of Mead\'s work is his challenge to traditional assumptions regarding the origins of the commonsense world and of purposeful action:\r\nHis treatment took the form of showing that human group life was the essential condition for the emergence of consciousness, the mind, a world of objects, human beings as organisms possessing selves, and human conduct in the form of constructed acts. He reversed the traditional assumptions underlying philosophical, psychological, and sociological thought to the effect that human beings possess minds and consciousness as original \"givens,\" that they live in worlds of pre-existing and self-constituted objects, and that group life consists of the association of such reacting human organisms. (Blumer 1969: 61)\r\nMead\'s reversal, in putting human interaction before the objectivity of the commonsense world, should not be read as an argument for metaphysical idealism: Mead does not deny the existence of constraints in\r\n\r\n76\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthe environment in which we act. What Mead is working toward is not a characterization of the natural world simpliciter but of the natural world under interpretation or the world as construed by us through language. The latter is precisely what we mean by the social world and, on Mead\'s account, interaction is a condition for that world, while that world is a condition for intentional action.\r\nMore recently, ethnomethodology has turned Durkheim\'s aphorism on its head with more profound theoretical and methodological consequences.8 Briefly, the standpoint of ethnomethodology is that what traditional sociology captures is precisely our commonsense view of the social world (see Sacks 1963; Garfinkel 1967; Garfinkel and Sacks 1970). Following Durkheim, the argument goes, social studies have simply taken this commonsense view as foundational and attempted to build a science of the social world by improving on it. Social scientific theories, under this attempt, are considered to be scientific insofar as they remedy shortcomings in, and preferably quantify, the intuitions of everyday, practical sociological reasoning.\r\nIn contrast, ethnomethodology grants commonsense sociological reasoning a fundamentally different status than that of a defective approximation of an adequate scientific theory. Rather than being resources for social science to improve on, the \"all things being equal\" typifications of commonsense reasoning are to be taken as social science\'s topic. The notion that we act in response to an objectively given social world is replaced by the assumption that our everyday social practices render the world publicly available and mutually intelligible. It is those practices that constitute ethnomethods. The methodology of interest to ethnomethodologists, in other words, is not their own but that deployed by members of the society in coming to know, and making sense out of, the everyday world of talk and action.\r\nThe outstanding question for social science, therefore, is not whether social facts are objectively grounded but how their objective grounding is accomplished. Objectivity is a product of systematic practices or members\' methods for rendering our unique experience and relative circumstances mutually intelligible. The source of mutual intelligibility is not a received conceptual scheme, or a set of coercive rules or norms, but those common practices that produce the typifications of which schemes and rules are made. The task of social studies, then, is to\r\n\r\n8 For extensive consideration of Durkheim\'s aphorism and its ethnomethodological rereading, see Rawls (1996), Garfinkel (2002).\r\n\r\nSituated Actions\r\n\r\n77\r\n\r\ndescribe the practices, not to enumerate their product in the form of a catalogue of commonsense beliefs about the social world. The interest of ethnomethodologists, in other words, is in how it is that the mutual intelligibility and objectivity of the social world is achieved. Ethnomethodology locates that achievement in our everyday situated actions, such that our common sense of the social world is not the precondition for our interaction but its product. By the same token, the objective reality of social facts is not the fundamental principle of social studies, but social studies\' fundamental phenomenon.\r\n\r\nthe indexicality of language\r\nOur shared understanding of situations is due in great measure to the efficiency of language, \"the typifying medium par excellence\" (Schutz 1962: 14). Language is efficient in the sense that, on the one hand, expressions have assigned to them conventional meanings that hold on any occasion of their use. The significance of a linguistic expression on some actual occasion, on the other hand, lies in its relationship to circumstances that are presupposed or indicated by, but not actually captured in, the expression itself.9 Language takes its significance from the embedding world, in other words, even while it transforms the world into something that can be thought of and talked about.\r\nExpressions that rely on their situation for significance are commonly called indexical, after the \"indexes\" of Charles Peirce (1933), the exemplary indexicals being first- and second-person pronouns, tense, and specific time and place adverbs such as here and now. In the strict sense, exemplified by these commonly recognized indexical expressions, the distinction of conventional or literal meaning and situated significance breaks down. That is to say, these expressions are distinguished by the fact that although one can state procedures for finding the expression\'s significance, or rules for its use, the expression\'s meaning can be specified only as the use of those procedures in some actual circumstances (see Bates 1976, Chapter 1).\r\nHeritage (1984: 143) offers as an example the indexical expression \"that\'s a nice one.\" There is, first of all, the obvious fact that this\r\n9 For a semantic theory based on this view of language, see Barwise and Perry (1985). Their work on language and information was highly salient among the audiences to whom these passages were written at the time, centered at the newly formed Center for the Study of Language and Information (CSLI) at Stanford University.\r\n\r\n78\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nexpression will have quite a different significance when uttered by a visitor with reference to a photograph in her host\'s photo album or by one shopper to another in front of the lettuce bin at the grocery store. But although linguists and logicians would commonly recognize the referent of \"that\'s\" as the problematic element in such cases, Heritage points out that the significance of the descriptor nice is equally so. So, in the first case, nice will refer to some properties of the photograph, whereas different properties will be intended in the case of the lettuce. Moreover, in either case whichever sense of nice is intended is not available from the utterance but remains to be found by the hearer through an active search of both the details of the referent and the larger context of the remark. So nice in the first instance might be a comment on the composition of the photograph, on the appearance of the host, or on some indefinite range of other properties of the photo in question. What is more, visitor and host will never establish in just so many words precisely what it is that the visitor intends and the host understands. Their interpretations of the term will remain partially unarticulated, located in their unique relationship to the photograph and the context of the remark. Yet the shared understanding that they do achieve will be perfectly adequate for purposes of their interaction. It is in this sense ­ that is, that expression and interpretation involve an active process of pointing to and searching the situation of talk ­ that language is a form of situated action.\r\nAmong philosophers and linguists, the term indexicality typically is used to distinguish those classes of expressions whose meaning is conditional on the situation of their use in this way from those such as, for example, definite noun phrases whose meaning is claimed to be specifiable in objective, or context-independent terms. But the communicative significance of a linguistic expression is always dependent on the circumstances of its use. A formal statement not of what the language means in relation to any context, but of what the language-user means in relation to some particular context, requires a description of the context or situation of the utterance itself. And every utterance\'s situation comprises an indefinite range of possibly relevant features.10 Our practical solution to this theoretical problem is not to enumerate some subset\r\n\r\n10 The \"problem\" of context was a central preoccupation for cognitive science in the 1980s, as evidenced for example by a seminar series at CSLI titled \"Why Context Won\'t Go Away,\" devoted to discussion of how context might best be represented in philosophical and computational formalisms.\r\n\r\nSituated Actions\r\n\r\n79\r\n\r\nof the relevant circumstances ­ we generally never mention our circumstances as such at all ­ but to \"wave our hand\" at the situation, as if we always included in our utterance an implicit ceteris paribus clause and closed with an implicit et cetera clause. One consequence of this practice is that we always \"mean more than we can say in just so many words\": \"[S]peakers can . . . do the immense work that they do with natural language, even though over the course of their talk it is not known and is never, not even \"in the end,\" available for saying in so many words just what they are talking about. Emphatically, that does not mean that speakers do not know what they are talking about, but instead that they know what they are talking about in that way\" (Garfinkel and Sacks 1970: 342­4, original emphasis). In this sense deictic expressions, time and place adverbs, and pronouns are just particularly clear illustrations of the general fact that all language, including the most abstract or eternal, stands in an essentially indexical relationship to the embedding world.\r\nBecause the significance of an expression always exceeds the meaning of what actually gets said, the interpretation of an expression turns not only on its conventional or definitional meaning, nor on that plus some body of presuppositions, but also on the unspoken situation of its use. Our situated use of language, and consequently language\'s significance, presupposes and implies a horizon of things that are never actually mentioned ­ what Schutz referred to as the \"world taken for granted\" (1962: 74). Philosophers have been preoccupied with this fact about language as a matter of the truth conditionality of propositions, the problem being that the truth conditions of an assertion are always relative to a background, and the background does not form part of the semantic content of the sentence as such (Searle 1979). And the same problems that have plagued philosophers of language as a matter of principle are now practical problems for cognitive science. As I pointed out in Chapter 5 in this book, the view that mutual intelligibility rests on a stock of shared knowledge has been taken over by researchers in cognitive science, in the hope that an enumeration of the knowledge assumed by particular words or actions could be implemented as data structures in the machine, which would then \"understand\" those words and actions. Actual attempts to include the background assumptions of a statement as part of its semantic content, however, run up against the fact that there is no fixed set of assumptions that underlies a given statement. As a consequence, the elaboration of background assumptions is fundamentally ad hoc and arbitrary, and each elaboration of assumptions in principle introduces further assumptions to be elaborated, ad infinitum.\r\n\r\n80\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe problem of communicating instructions for action, in particular certain of its seemingly intractable difficulties, becomes clearer with this view of language in mind. The relation of efficient linguistic formulations to particular situations parallels the relation of instructions to situated action. As linguistic expressions, instructions are subject to the constraint that: \"However extensive or explicit what a speaker says may be, it does not by its extensiveness or explicitness pose a task of deciding the correspondence between what he says and what he means that is resolved by citing his talk verbatim\" (Garfinkel and Sacks 1970: 342­4). This indexicality of instructions means that an instruction\'s significance with respect to action does not inhere in the instruction but must be found by the instruction follower with reference to the situation of its use. Far from replacing the ad hoc methods used to establish the significance of everyday talk and action, therefore, the interpretation of instructions is thoroughly reliant on those same methods. As Garfinkel concludes: \"To treat instructions as though ad hoc features in their use was a nuisance, or to treat their presence as grounds for complaining about the incompleteness of instructions, is very much like complaining that if the walls of a building were gotten out of the way, one could see better what was keeping the roof up\" (Garfinkel 1967: 22). Like all action descriptions, instructions necessarily rely on an implicit et cetera clause to be called complete. The project of instruction writing is ill conceived, therefore, if its goal is the production of exhaustive action descriptions that can guarantee a particular interpretation. What \"keeps the roof up\" in the case of instructions for action is not only the instructions as such, but also their interpretation in use. And the latter has all of the ad hoc and uncertain properties that characterize every occasion of the situated use of language.\r\n\r\nthe mutual intelligibility of action\r\nBy \"index\" Peirce meant not only that the sign relies for its significance on the event or object that it indicates but also that the sign is actually a constituent of the referent. So language more generally is not only anchored in, but in large measure constitutes, the situation of its use. Ethnomethodology generalizes this constitutive function of language still further to action, in the proposition that the purposefulness of action is recognizable in virtue of the methodic, skillful, and therefore takenfor-granted practices whereby we establish the rational properties of actions in a particular context. It is those practices that provide for the\r\n\r\nSituated Actions\r\n\r\n81\r\n\r\n\"analyzability of actions-in-context given that not only does no concept of context-in-general exist, but every use of `context\' without exception is itself essentially indexical\" (Garfinkel 1967: 10).\r\nIn positing the reflexivity of purposeful action and the methods by which we convey and construe action\'s purposes, ethnomethodology does not intend to reduce meaningful action to method. The intent is rather to identify the mutual intelligibility of action as the problem for sociology. To account for the foundations of mutual intelligibility and social order, traditional social science posits a system of known-incommon social conventions or behavioral norms. What we share, on this view, is agreement on the appropriate relation of actions to situations. We walk into a situation, identify its features, and match our actions to it. This implies that, on any given occasion, the concrete situation must be recognizable as an instance of a class of typical situations, and the behavior of the actor must be recognizable as an instance of a class of appropriate actions. And with respect to communication, as Wilson (1970) points out:\r\nthe different participants must define situations and actions in essentially the same way, since otherwise rules could not operate to produce coherent interaction over time. Within the normative paradigm, this cognitive agreement is provided by the assumption that the actors share a system of culturally established symbols and meanings. Disparate definitions of situations and actions do occur, of course, but these are handled as conflicting subcultural traditions or idiosyncratic deviations from the culturally established cognitive consensus. (ibid.: 699)\r\nIn contrast with this normative paradigm, Garfinkel proposes that the stability of the social world is not the consequence of a \"cognitive consensus\" or stable body of shared meanings but of our tacit use of the documentary method of interpretation to find the coherence of situations and actions. As a general process, the documentary method describes a search for uniformities that underlie unique appearances. Applied to the social world, it describes the process whereby actions are taken as evidence, or \"documents,\" of underlying plans or intent, which in turn fill in the sense of the actions (1967, Chapter 3). The documentary method describes an ability ­ the ascription of intent on the basis of evidence, and the interpretation of evidence on the basis of ascribed intent ­ that is as identifying of rationality as the ability to act rationally itself. At the same time, the documentary method is not reducible to the application of any necessary and sufficient conditions, either behavioral or contextual, for the identification of intent. There are no logical formulae\r\n\r\n82\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfor recognizing the intent of some behavior independent of context, and there are no recognition algorithms for joining contextual particulars to behavioral descriptions so that forms of intent can be precisely defined over a set of necessary and sufficient observational data (see Coulter 1983: 162­3).\r\nGiven the lack of universal rules for the interpretation of action, the programme of ethnomethodology is to investigate and describe the use of the documentary method in particular situations. Studies indicate, on the one hand, the generality of the method and, on the other hand, the extent to which special constraints on its use characterize specialized domains of practical activity such as natural science, courts of law, and the practice of medicine.11 In a contrived situation that, though designed independently and not with them in mind, closely parallels both the \"Turing test\" and encounters with Weizenbaum\'s ELIZA programs, Garfinkel set out to test the documentary method in the context of counseling. Students were asked to direct questions concerning their personal problems to someone they knew to be a student counselor, seated in another room. They were restricted to questions that could take yes/no answers, and the answers were then given by the counselor on a random basis. For the students, the counselor\'s answers were motivated by the questions. That is to say, by taking each answer as evidence for what the counselor \"had in mind,\" the students were able to find a deliberate pattern in the exchange that explicated the significance and relevance of each new response as an answer to their question. Specifically, the yes/no utterances were found to document advice from the counselor, intended to help in the solution of the student\'s problem. So, for example, students assigned to the counselor, as the advice \"behind\" the answer, the thought formulated in the student\'s question: \"when a subject asked `Should I come to school every night after supper to do my studying?\' and the experimenter said `My answer is no,\' the subject in his comments said, `He said I shouldn\'t come to school and study\'\" (Garfinkel 1967: 92). In cases where an answer seemed directly to contradict what had come before, students either attributed the\r\n\r\n11 For example, the work of coroners at the Los Angeles Suicide Prevention Center (Garfinkel 1967: 11­18), the deliberations of juries (ibid.: Chapter 4) and courtroom practices of attorneys (Atkinson and Drew 1979), the work of clinic staff in selecting patients for out-patient psychiatric treatment (Garfinkel 1967, Chapter 7), the work of physicians interviewing patients for purposes of diagnosis (Beckman and Frankel 1983), the work of scientists discovering an optical pulsar (Garfinkel, Lynch, and Livingston 1981). (Original footnote.)\r\n\r\nSituated Actions\r\n\r\n83\r\n\r\napparent contradiction to a change of mind on the part of the counselor, as the result of having learned more between the two replies, or to some agenda on the part of the counselor that lent the reply a deeper significance than its first, apparently inconsistent, interpretation would suggest. In other cases, the interpretation of previous answers was revised in light of the current one, or an interpretation of the question was found and attributed to the counselor that rationalized what would otherwise appear to be an inappropriate answer. Generally, Garfinkel observes: \"The underlying pattern was elaborated and compounded over the series of exchanges and was accommodated to each present `answer\' so as to maintain the `course of advice,\' to elaborate what had `really been advised\' previously, and to motivate the new possibilities as emerging features of the problem\" (ibid.: 90).\r\nGarfinkel\'s results with arbitrary responses make the success of Weizenbaum\'s DOCTOR program easier to understand and lend support to Weizenbaum\'s hypothesis that the intelligence of interactions with the DOCTOR program is due to the work of the human participant, specifically, to methods for interpreting the system\'s behavior as evidence for some underlying intent. The larger implications of the documentary method, however, touch on the status of an \"underlying\" reality of psychological and social facts in human interaction, prior to situated action and interpretation:\r\nIt is not unusual for professional sociologists to think of their procedures as processes of \"seeing through\" appearances to an underlying reality; of brushing past actual appearances to \"grasp the invariant.\" Where our subjects are concerned, their processes are not appropriately imagined as \"seeing through,\" but consist instead of coming to terms with a situation in which factual knowledge of social structures ­ factual in the sense of warranted grounds of further inferences and actions ­ must be assembled and made available for potential use despite the fact that the situations it purports to describe are, in any calculable sense, unknown; in their actual and intended logical structures are essentially vague; and are modified, elaborated, extended, if not indeed created, by the fact and matter of being addressed. (Garfinkel 1967: 96)\r\nThe stability of the social world, from this standpoint, is not due to an eternal structure but to situated actions that create and sustain shared understanding on specific occasions of interaction. Social constraints on appropriate action are always identified relative to some unique and unreproducible set of circumstances. Members of the society are treated as being at least potentially aware of the concrete details of their circumstances, and their actions are interpreted in that light. Rather than\r\n\r\n84\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nactions being determined by rules, actors effectively use the normative rules of conduct that are available to produce significant actions. So, for example, there is a normative rule for greetings that runs to the effect: do not initiate greetings except with persons who are acquaintances. If we witness a person greeting another who we know is not an acquaintance, we can either conclude that the greeter broke the rule or infer that via the use of the rule he or she was seeking to treat the other as an acquaintance (Heritage 1984: 126). Such rules are not taught or encoded but are learned tacitly through typification over families of similar situations and actions. Despite the availability of such typifications, no action can fully provide for its own interpretation in any given instance. Instead, every instance of meaningful action must be accounted for separately with respect to specific, local, contingent determinants of significance. The recommendation for social studies, as a consequence, is that instead of looking for a structure that is invariant across situations we look for the processes whereby particular, uniquely constituted circumstances are systematically interpreted so as to render meaning shared and action accountably rational. Structure, on this view, is an emergent product of situated action, rather than its foundation. Insofar as the project of ethnomethodology is to redirect social science from its traditional preoccupation with abstract structures to an interest in situated actions, and the cognitive sciences share in that same tradition, the ethnomethodological project has implications for cognitive science as well.\r\n\r\n7\r\nCommunicative Resources\r\nThus the whole framework of conversational constraints can become something to honor, to invert, or to disregard, depending as the mood strikes.\r\n(Goffman 1975: 311)\r\nCommunicative action occurs in particular moments of actual time, in particular relationships of simultaneity and sequence. These relationships in time, taken together, constitute a regular rhythmic pattern. This regularity in time and timing seems to play an essential, constitutive role in the social organization of interaction . . . Whereas there is no metronome playing while people talk, their talking itself serves as a metronome.\r\n(Erickson 1982: 72)\r\nWe are environments for each other. (McDermott 1976: 27)\r\nAn argument of the preceding chapters was that we never definitively determine the intent behind an action, in that descriptions at the level of intent are not designed to pick out mental states that stand in some relation of strict causality to action or even, in any strong sense, of oneto-one correspondence. Instead, intentional descriptions classify over situations and actions, as typifications that invariably include an \"open horizon of unexplored content\" (Schutz 1962: 14). In spite of this inherent indeterminacy, intentional descriptions not only suffice to classify purposeful behavior but, given the unique and fleeting circumstances of action and the need to represent it efficiently, seem ideally suited to the task. Attributing intent in any particular instance, moreover, is generally\r\n85\r\n\r\n86\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nnonproblematic, even transparent, for members of the society who, from their practical perspective and for their practical purposes, are engaged in the everyday business of making sense out of each other\'s actions. When disputes over the significance of an action do arise, the uncertainty of intentional attributions becomes a practical problem, but in such cases it is the \"right\" interpretation of the action, not the fact of its inherent uncertainty, that is of interest to participants. For students of purposeful action, however, the observation that action interpretation is inherently uncertain does have a methodological consequence; namely it recommends that we turn our focus from explaining away uncertainty in the interpretation of action to identifying the resources by which the inevitable uncertainty is managed. A central tenet of social studies of practical action is that those resources are not only cognitive, but also interactional. While acknowledging the role of conventional meanings and individual predispositions in mutual intelligibility, therefore, this chapter focuses on the neglected other side of shared understanding; namely the local interactional work that produces intelligibility in situ. The starting premise is that interpreting the significance of action is an essentially collaborative achievement. Rather than depend on reliable recognition of intent, mutual intelligibility turns on the availability of communicative resources to detect, remedy, and at times even exploit the inevitable uncertainties of action\'s significance.\r\nTo underscore the breadth and subtlety of the resources available for shared understanding and the precision of their use, this chapter focuses on the richest form of human communication; that is, face-toface interaction. The premise of conversation analyses is that face-toface interaction incorporates the broadest range of possible resources for communication, with other forms of interaction being characterizable in terms of particular resource limitations or additional constraints (see Sacks, Schegloff, and Jefferson 1978).1 In the discussion that follows I consider only a small subset of these resources; for example, I do not include the wealth of prosodic and gestural cues described by students of interaction. The rationale for neglecting those cues here, and in the analysis of Chapter 9, is that the case of human­machine interaction is so limited that the basic resources, let alone the expressive subtleties, of human interaction are in question. The first three sections of this chapter describe the resources of the most unrestricted form of face-to-face\r\n\r\n1 The corpus of studies in conversation analysis is by now a rich and extensive one. For introductions see Goodwin (1981), Heritage (1985), Levinson (1983, Chapter 6).\r\n\r\nCommunicative Resources\r\n\r\n87\r\n\r\ninteraction, everyday conversation. I then consider some modifications to everyday conversation that have developed for specialized purposes in institutional settings and, in Chapter 8, some additional constraints introduced by restrictions on the mutual access of participants to each other and to a common situation. Finally, human­machine communication is analyzed, in Chapter 9, as an extreme form of resource-limited interaction.\r\n\r\nconversation as ensemble work\r\nThe most common view of conversation is that speakers and listeners, pursuing some common topic according to individual predispositions and agendas, engage in an alternating sequence of action and response. For students of human cognition and of language, conversation generally has been treated as epiphenomenal with respect to the central concerns of their fields. Cognitively, conversation is just the meeting ground of individual psychologies, whereas linguistically it is the noisy, real-world occasion for the exercise of basic language abilities. On either view, the additional constraints imposed by situated language use are a complication that obscures the underlying structure of cognitive or linguistic competence. As a consequence, linguists generally have not used actual speech for the analysis of linguistic competence, on the assumption that the phrasal breaks, restarts, hesitations, and the like found in actual speech represent such a defective performance that the data are of no use. And in analyzing idealized utterances, linguists have focused exclusively on the speaker\'s side in the communicative process (Streeck 1980). When one takes situated language use as the subject matter, however, the definition of the field must necessarily shift to communication under naturally occurring circumstances. And when one moves back far enough from the utterances of the speaker to bring the listener into view as well, it appears that much in the actual construction of situated language use that has been taken to reflect problems of speaker performance, instead reflects speaker competence in responding to cues provided by the listener (C. Goodwin 1981: 12­13).\r\nCloser analyses of face-to-face communication indicate that conversation is not so much an alternating series of actions and reactions between individuals as it is a joint action accomplished through the participants\' continuous engagement in speaking and listening (see Schegloff 1972, 1982; C. Goodwin 1981). In contrast to the prevailing preoccupation of linguists and discourse analysts with speaking, where the listener is\r\n\r\n88\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nlargely taken for granted or as extraneous, conversation analysis shows that the action of listening is consequential to the extent that \"the listener\'s failure to act at the right time in the right way literally prevents the speaker from finishing what he was trying to say ­ at least from finishing it in the way he was previously saying it. The speaker, in continuing to speak socially (i.e. in taking account in speaking of what the other is doing in listening), makes accountable the listener\'s violations of expectations for appropriate listening behavior\" (Erickson 1982: 118­19, original emphasis). In the same way that the listener attends to the speaker\'s words and actions to understand them, in other words, the speaker takes the behavior of the listener as evidence for the listener\'s response. Schegloff (1982: 72) offers the example of the lecturer:\r\n\r\nAnyone who has lectured to a class knows that the (often silent) reactions of the audience ­ the wrinkling of brows at some point in its course, a few smiles or chuckles or nods, or their absence ­ can have marked consequences for the talk which follows: whether, for example, the just preceding point is reviewed, elaborated, put more simply, etc., or whether the talk moves quickly on to the next point, and perhaps to a more subtle point than was previously planned.\r\n\r\nThe local resources or contextualization cues by which people produce the mutual intelligibility of their interaction consist in the systematic organization of speech prosody (Gumperz 1982a), body position and gesture (Birdwhistell 1970; Erickson 1982; Scheflen 1974), gaze (C. Goodwin 1981; M. Goodwin 1980), and the precision of collaboratively accomplished timing (Erickson 1982). For example, Erickson suggests that what may be disturbing about certain speaker hesitations in conversation is not so much the interruption of talk as such, but the fact that, when talk stops and starts in temporally unpredictable ways, it is difficult for listeners to coordinate their listening actions (1982: 114). The richness of both simultaneous and sequential coordination \"suggests that conversational inference is best seen not as a simple unitary evaluation of intent but as involving a complex series of judgments, including relational or contextual assessments on how items of information are to be integrated into what we know and into the event at hand\" (Gumperz 1982b: 328­9). As with any skill, in ordinary conversation these judgments are made with such proficiency that they are largely transparent, though at times of breakdown they may become contestable (see Gumperz and Tannen 1979). Viewed as highly skilled performance,\r\n\r\nCommunicative Resources\r\n\r\n89\r\n\r\nthe organization of conversation appears to be closer to what in playing music is called \"ensemble\" work (Erickson 1982: 71) than it is to the common notion of speaker stimulus and listener response.\r\n\r\nconversational organization\r\nOne reason to begin a consideration of interaction with the organization of conversation is that studies of everyday conversation, and more recently studies in specific institutional settings where the type, distribution, and content of turns at talk are constrained in characteristic ways, indicate that all of the various forms of talk (e.g., interviews, cross-examinations, lectures, formal debates, and so on) can be viewed as modifications to conversation\'s basic structure. As the basic system for communication, conversation is characterized by (1) an organization designed to support local, endogenous control over the development of topics or activities and to maximize accommodation of unforeseeable circumstances that arise and (2) resources for locating and remedying communication\'s troubles as part of its fundamental organization.\r\n\r\nLocal Control\r\nTaking ordinary conversation as their subject matter, Sacks, Schegloff, and Jefferson (1978) set out to identify the structural mechanisms by which this most \"unstructured\" of human activities is accomplished in a systematic and orderly way. Two problems for any interaction are the distribution of access to \"the floor\" and, closely related, control over the development of the topic or activity at hand. In contrast to mechanisms that administer an a priori, externally imposed agenda (for example, the format for a debate), the organization of conversation maximizes local control over both the distribution of turns and the direction of subject matter. That is to say, who talks and what gets talked about is decided then and there, by the participants in the conversation, through their collaborative construction of the conversation\'s course.\r\nThat turn taking is a collaborative achievement rather than a simple alternation of intrinsically bounded segments of talk is evident in the common occurrence in actual conversation of simultaneous talk, of joint production of a single sentence, and of silence. The observations that somehow one speaker only takes the floor when two begin together, that a listener may finish the speaker\'s turn without it constituting an interruption, and that any participant in a conversation, including the\r\n\r\n90\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nlast to speak, may begin a new turn out of silence, raise theoretical questions about the proper definition of a turn\'s boundaries and the process by which turn transitions are organized (see C. Goodwin 1981: 2). In answer to such questions, Sacks, Schegloff, and Jefferson (1978) have delineated a set of conventions or normative rules by which turn taking is accomplished. By normative is meant only that these rules describe common practices observed by analysts of conversation. Speakers and listeners do not \"know\" these rules in the sense that they would or could formulate them in so many words. Rather, it can be seen by an observer, having these rules in mind, that they describe the practices by which people in conversation achieve the orderly distribution of turns. The set of rules for turn taking provides that for every place in the course of an utterance that is a projectable completion point for the utterance, one of the following occurs:\r\n(a) The current speaker selects a next speaker, e.g., by directing a question or other implicative utterance at a particular hearer.\r\n(b) Another participant self-selects, by being the first to start speaking.\r\n(c) The current speaker continues.\r\nOptions (a)­(c) are not simply alternatives, but an ordered set. That is to say, at each place where a transition to a new speaker might be effected, the rule set applies as a matter of \"if not (a), then (b) is an option,\" \"if not (b), then (c) is an option\" recursively until a change in speaker occurs. This does not mean, of course, that participants wait to see which rule applies and then act accordingly: the options are theirs to exercise; they are not the workings of some external mechanism. Moreover, the rules are not necessarily, but rather are contingently, applied. Which rule will prevail in any given case is determined by actions taken by the participants at each possible turn-transition place, and the contingency of the rules means that the exercise of each is constrained by the presence of the others in the set independently of their actually being employed on any given occasion. Lower priority options constrain higher priority options ­ for example, for the (b) option to be exercised given the presence of (c), it will need to be employed before (c) is invoked, at which time priority returns to (a).\r\nDue to the ordering of the rule set, the system for turn taking constrains both the way that current speakers develop their talk and the way that others listen. Most obviously, the current speaker has reason to let listeners know where he or she is in the turn\'s course. This may\r\n\r\nCommunicative Resources\r\n\r\n91\r\n\r\nbe done explicitly, through introductions on the order of \"I want to say a couple of things,\" or through the use of story prefaces that announce the onset of an extended multisentence turn with its own distinctive shape (see Sacks 1974). More implicitly, the speaker\'s control of the floor offers some inherent advantage. To preclude the exercise of option (b) before having had a say, the current speaker can extend his or her turn by, for example, withholding a point until after supporting arguments have been made. The speaker does not define the turn unilaterally, however: turn completion is as much a function of the listener\'s inclination to respond as it is a matter of the speaker\'s readiness to yield. The units of which turns are constructed are expandable, not fixed (any unit from a particle to an extended exposition may constitute a turn), and what happens at each possible turn-transition place is contingent on the actions of participants other than the speaker. So, for example, by passing on option (b) at a possible transition place listeners may invite the speaker to continue, turning what could be a speaker change into a pause in the same speaker\'s turn. Or listeners may, on finding in either the speaker\'s exercise of option (a) or failure to exercise option (c), that a turn is completed then look back over what was said to respond to it.\r\nBecause each projectable point of completion is a possible place for speaker change, the turn is interactionally determined over the course of the conversation. And rather than relying on a discrete set of \"turnyielding signals\" (Duncan 1974), speaker continuity or change is managed with reference to the same range of syntactic, semantic, and nonlinguistic resources by which participants construct the significance of what is being said:\r\nBy virtue of its character, it is misconceived to treat turns as units characterized by a division of labor in which the speaker determines the unit and its boundaries, and other parties to the conversation have as their task the recognition of them. Rather, the turn is a unit whose constitution and boundaries involve such a distribution of tasks (as we have noted): That a speaker can talk in such a way as to permit projection of possible completion to be made from his talk, and to allow others to use its transition places to start talk, to pass up talk, to affect directions of talk, and so on, and that their starting to talk, if properly placed, can determine where he ought to stop talk.\" (Sacks, Schegloff, and Jefferson 1978: 42)\r\nThe interactional structure of turn taking presents some distinctive problems for the definition and categorization of units in conversational analysis. For example, one might argue reasonably that silence should\r\n\r\n92\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nbe classified differently according to whether it occurs within the turn of a single speaker (a pause) or between turns of different speakers (a gap) (C. Goodwin 1981: 18). The problem that arises for analysts is exemplified, however, in a case such as the following:2\r\nJohn: Well I, I took this course. (0.5)\r\nAnn: In how to quit? [\r\nJohn: which I really recommend.\r\nThe ambiguous status of the silence in this example as either a pause or a gap is not so much an analytic problem as it is an inherent property of situated talk. That is to say, the silence is treated by Ann as a gap, by John as a pause, such that \"the same silence yields alternative classifications at different moments in time from the perspective of different participants\" (Goodwin 1981: 19). No single classification of the silence will do, as its status is inextricably tied to an event developing over time and is subject to transformation. From Ann\'s point of view, at the point where she begins to speak, John\'s turn appears to be complete. John\'s extension of the turn, however, makes the silence into a pause and Ann\'s turn into an interruption that begins in the midst, rather than at the completion of, his utterance. The status of what constitutes \"John\'s turn\" in this exchange, and therefore the status of the silence, is essentially ambiguous in a way that will not be remedied by any exercise of the analyst. To the contrary, attempts to remedy the ambiguity must do damage to the phenomenon, which is precisely that boundaries of a turn are mutable and that the structure of conversation is achieved by speakers and hearers in this locally developing, contingent way. As a consequence of its interactional nature, the turn is not the kind of object that can be first defined and then examined for how it is passed back and forth between speakers. Instead, intrinsic structural elements of the turn are contingent on the process by which control changes hands between participants in conversation, as is the structure of the conversation produced. The point is not just that speakers can extend the length of their turns by the addition of further units of speech, but that through that essentially transparent mechanism they are able to change the emerging\r\n\r\n2 C. Goodwin (1981:18). Transcripts are presented here with the notation and punctuation of the original source. A full description of the notation system (based on Jefferson 1983 can be found at the end of the chapter. (Original footnote.)\r\n\r\nCommunicative Resources\r\n\r\n93\r\n\r\nmeaning of their talk within a turn to fit the actions of their listener (see C. Goodwin 1981: 11). The localness of the constraints on speakers\' constructions of turns-at-talk, and the turn\'s contingency on the actions of other speakers, make conversation maximally sensitive and adaptable to particular participants and to unforeseen circumstances of the developing interaction. The turn-taking system for conversation demonstrates how a system for communication that accommodates any participants, under any circumstances, may be systematic and orderly, whereas it must be essentially ad hoc.\r\n\r\nSequential Organization and Coherence\r\nIn addition to providing a mechanism for control over the distribution of turns, the turn-taking system bears a direct relation to the control of inferences about the conversation\'s content.3 In general, a coherent conversation is one in which each thing said can be heard as relevant to what has come before. Most locally, this means that the relevance of a turn is conditional on that which immediately precedes it: \"By conditional relevance of one item on another we mean; given the first, the second is expectable; upon its occurrence it can be seen to be a second item to the first; upon its nonoccurrence it can be seen to be officially absent\" (Schegloff 1972: 364). Two utterances that stand in a relationship of conditional relevance of one on the other, in this local sense, constitute an adjacency pair in Schegloff and Sacks\'s terminology (1973), though conditional relevance is not limited to literal adjacency (see Levinson 1983: 304). The first part of an adjacency pair both sets up an expectation with respect to what should come next and directs the way in which what does come next is heard (Schegloff 1972: 367). By the same token, the absence of an expected second part is a notable absence and therefore takes on significance as well. In this way silences, for example, can be meaningful: most obviously, a silence following an utterance that implicates a response will be \"heard\" as belonging to the recipient of the utterance and as a failure to respond. Similarly, a turn that holds the place of the second part of an adjacency pair but cannot be made relevant to the first will be seen as a non sequitur or as incoherent.\r\n3 Sensitivity to readings of the term mechanism, particularly in the context of work on interactive machines, would lead me now to rephrase this sentence. Rather than \"providing a mechanism,\" the turn-taking system describes a practice for managing a distribution of turns and implicates a sequential relevance for things said.\r\n\r\n94\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe conditional relevance of adjacency pairs is an instance of what we might call, following Durkheim, a \"social fact.\" The first part of an adjacency pair constrains the second part in a double sense. The constraint is a matter not only of the coherence or intelligibility of the second part but also of the accountability of the respondent for inferences that the absence of a second part would warrant. For example, in the case of interactions opened by a summons, such as calling someone\'s name or ringing her doorbell:\r\nA member of the society may not \"naively choose\" not to answer a summons. The culture provides that a variety of \"strong inferences\" can be drawn from the fact of the official absence of an answer, and any member who does not answer does so at the peril of one of those inferences being made . . . although members can, indeed \"choose\" not to answer a summons, they cannot do so naively, i.e. they know that if the inference of physical or interactional absence cannot be made, then some other inference will, e.g. they are cold shouldering, insulting, etc. (Schegloff 1972: 367­8)\r\nThe summons­answer pair is an example of a sequence in which the first part implicates a particular type of response in the immediate next turn, to the extent that if no response occurs the first speaker is justified in, for example, repeating the summons. And on eliminating the possibility that the summons has not been heard, and determining that it will in fact not be answered, the summoner is justified in making further inferences regarding the recipient\'s availability, interest, and the like.4 In this sense, we are not so much constrained by the rules of conversation as we are \"caught in a web of inferences\" (Levinson 1983: 321, note 16). That is to say, the rules of conversation are neither strictly optional (their breach does have consequences) nor obligatory (they may be breached without a necessary loss of coherence). They are, however, inexorably meaningful.\r\nAlthough conditional relevance is a constraint on inference, it is a weak constraint in the sense that it does not prescribe what counts\r\n\r\n4 Schegloff (1972: 363) points to the telephone as an example of a technology that embodies the organization of the summons­answer pair: \"In this mechanical age it may be of interest to note that the very construction and operation of the mechanical ring is built on these principles. If each ring of the phone be considered a summons, then the phone is built to ring, wait for an answer, if none occurs, to ring again, wait for an answer, ring again, etc. And indeed, some persons, polite even when interacting with a machine, will not interrupt a phone, but wait for the completion of a ring before picking up the receiver.\" (Original footnote.)\r\n\r\nCommunicative Resources\r\n\r\n95\r\n\r\nas a response to a given action, only that whatever is done next will be viewed as a response. In fact, the range of actions in a second-part position that can be heard as a response is extended, rather than constrained, in virtue of the expectation that adjacency sets up. That is to say, an action that is not in any explicit way tied to the action that it follows will nevertheless be interpreted as a response, in virtue of its position:\r\n\r\nA: Are you coming? B: I gotta work.\r\n\r\n(Goffman 1975: 260)\r\n\r\nThe position of B\'s utterance as a response means that we look for its relevance to A\'s question. So in this case, B\'s statement can be heard as a negative reply, just as B\'s question can be heard as an affirmative reply in the following:\r\n\r\nA: Have you got coffee to go? B: Milk and sugar?\r\n\r\n(Merritt 1977: 325)\r\n\r\nThe sequential implicature exemplified by adjacency pairs is not literally conditional on adjacency but instead allows for multiple levels of embedded sequences aimed at clarification and elaboration. The result is that answers to later questions can precede answers to earlier ones without a loss of coherence:\r\n\r\nB: . . . I ordered some paint from you uh a couple of weeks ago some vermilion\r\nA: Yuh B: And I wanted to order some more the name\'s Boyd\r\n(Request 1) A: Yes//how many tubes would you like sir\r\n(Question 1) B: AnB: U:hm (.) what\'s the price now eh with V.A.T. do you know eh\r\n(Question 2) A: Er I\'ll just work that out for you =\r\n(Hold) B: =Thanks\r\n(Accept) (10. 0)\r\n\r\n96\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nA: Three pound nineteen a tube sir (Answer 2)\r\nB: Three nineteen is it= (Question 3)\r\nA: =Yeah (Answer 3)\r\nB: E::h (1.0) yes u:hm ((dental click)) ((in parenthetical tone)) e:h jus-justa think, that\'s what three nineteen That\'s for the large tube isn\'t it (Question 4)\r\nA: Well yeah it\'s the thirty seven c.c.s (Answer 4)\r\nB: Er, hh I\'ll tell you what I\'ll just eh eh ring you back I have to work out how many I\'ll need Sorry I did- wasn\'t sure of the price you see (Account for no Answer 1)\r\nA: Okay (Levinson 1983: 305)\r\n\r\nThe local system of adjacency pair organization, in its canonical form operating over two turns, can by the accumulation of first parts (e.g., requests and questions) project an extended sequence of expected seconds like that of the last example, that is, [R1(Q1{Q2[Q3(Q4­ A4)A3]A2}Al). As Levinson points out with respect to this example, B\'s final obligation is to account for his failure to provide an answer to Question 1, demonstrating his orientation to the \"social fact\" that an answer is called for. That failure, in turn, effectively constitutes B\'s withdrawal of Request 1, freeing A of the obligation to respond to that original request:\r\n\r\nWhat the notion of conditional relevance makes clear is that what binds the parts of adjacency pairs together is not a formation rule of the sort that would specify that a question must receive an answer if it is to count as a well-formed discourse, but the setting up of specific expectations which have to be attended to. Hence the non-occurrences of a R[equest] 1 and an A[nswer] 1 in [the example] do not result in an incoherent discourse because their absences are systematically provided for. (Levinson 1983: 306)\r\n\r\nThe overall coherence of a conversation, in sum, is accomplished through the development and elaboration of a local coherence operating in the first instance across just two turns, current and next. The\r\n\r\nCommunicative Resources\r\n\r\n97\r\n\r\nresiliency of embedding, however, is such that the backward reach of relevance extends beyond the immediately preceding turn:\r\n\r\nC: (telephone rings) A: Hello. C: Is this the Y? A: You have the wrong number. C: Is this KI five, double four, double o? A: Double four, double six. C: Oh, I am sorry.\r\n\r\n(Goffman 1975: 285)\r\n\r\nIn this case the apology is intelligible only if we view the entire telephone call as its object, not just the utterance of A that it immediately follows. Similarly, to use another example of Goffman\'s (ibid.: 286), the applause at the end of a play is a response not to the delivery of the final line, or the drop of the curtain, but to the entire play. The relevance of an action, in other words, is conditional on any identifiable prior action or event, however far that may extend for the participants (i.e., it may be a lifetime, say, for mother and child), insofar as the previous action can be tied to the current action\'s immediate, local environment. As a consequence, conditional relevance does not allow us to predict from an action to a response, but only to project that what comes next will be a response and, retrospectively, to take that status as a cue to how what comes next should be heard. The interpretation of action, in this sense, relies on the liberal application of post hoc, ergo propter hoc.\r\n\r\nlocating and remedying communicative trouble\r\nCommunication takes place in real environments, under real performance requirements on actual individuals, and is vulnerable therefore to internal and external troubles that may arise at any time, from a misunderstanding to a clap of thunder (Schegloff 1982). Our communication succeeds in the face of such disturbances not because we predict reliably what will happen and thereby avoid problems, or even because we encounter problems that we have anticipated in advance, but because we work, moment by moment, to identify and remedy the inevitable troubles that arise: \"It is a major feature of a rational organization for behavior that accommodates real-worldly interests, and is not susceptible of external enforcement, that it incorporates resources and procedures\r\n\r\n98\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfor repair of its troubles into its fundamental organization\" (Sacks, Schegloff, and Jefferson 1978: 39).\r\nThe resources for detecting and remedying problems in communication, in other words, are the same resources that support communication that is trouble free. With respect to control, for example, the contingency of conversational options for keeping and taking the floor ­ specifically, the fact that transitions should be accomplished at possible turn completion points and not before and that at each possible completion point the speaker may extend his or her turn ­ means that gaps and overlaps can and do occur. The extent to which conversationalists accomplish speaker transitions with a minimum of gap or overlap is the product not only of the \"accurate\" projection of completion points but also of the repair of routine troubles. The following is a simple example of a familiar kind of conversational repair work:\r\n\r\nC: .hhhh aa:: of course under the circumstances Dee I would never:: again permit im tuh see im.\r\nD: Yeah (0.7)\r\nC: tlk. Be:cuz he [\r\nD: Wul did\'e ever git ­ ma:rried\'r anything? C: Hu::h?\r\n[ D: Did yee ever git ­ ma:rried? C: .hhhh I have no idea\r\n(cited in Atkinson and Drew 1979: 40)\r\n\r\nIn addition to negotiating the transfer of control, participants in conversation must be alert to the possibility of substantive troubles of interpretation. Schegloff (1982) points out that tokens such as \"uh huh,\" commonly viewed as a signal from the listener that encourages the speaker to continue, operate as they do not simply because there is a semantic convention to the effect that such tokens claim or signal understanding but rather because through such tokens listeners pass up, at possible transition places, the opportunity to initiate repair on the preceding talk. The same option that provides for ordinary turn transitions, in other words, affords the recipient of an utterance the occasion to assert that he or she has some trouble in understanding or to request some clarification.\r\n\r\nCommunicative Resources\r\n\r\n99\r\n\r\nThe work of repair includes calling the other\'s attention to the occurrence of some troublesome item, remedying it, and resuming the original line of action in which the troublesome item is embedded. Jefferson (1972) identifies two kinds of trouble flag: a questioning repeat and a nonspecific interrogative, for example, \"What?\" or \"Huh?\" The two are different in that the repeat simultaneously flags the fact that there is some troublesome item in the prior talk and locates it for the first speaker:\r\nSteven: One, two, three, ((pause)) four, five, six, ((pause)) eleven, eight, nine, ten.\r\nSusan: \"Eleven\"? ­ eight, nine, ten? (ibid.: 295)\r\nAn interrogative request for clarification, in contrast, leaves it to the first speaker both to locate the item that produced the request and to remedy it. In that case, the location of the item and the remedy may be effected simultaneously, in the first speaker\'s reply:\r\nA: If Percy goes with ­ Nixon I\'d sure like that. B: Who? A: Percy. (ibid.: 296)\r\nIn both cases the adjacency of the trouble flag to the troublesome item is obviously a resource for the latter\'s identification.5 However, listeners generally do not interrupt a speaker to flag some trouble but rather wait for the next turn transition place or point of completion. By permitting the speaker to complete the utterance in which the trouble is heard, the listener is warranted in assuming that there is no unsolicited remedy forthcoming and the complaint becomes a legitimate one (Jefferson 1972: 298).\r\nA side sequence initiated by an assertion of misunderstanding or request for clarification sets up an exchange that the first speaker did not necessarily anticipate, but to which he or she is obliged to respond. That is to say, a failure on the part of the speaker to provide clarification in response to an explicit request is a noticeable absence, is seen as specifically not providing clarification, as opposed to just doing something else. The \"failure to respond\" then becomes something about which complaints can be made or inferences may be drawn (Atkinson and Drew 1979: 57).\r\n\r\n5 It is worth noting in this case that although the \"Who?\" is in fact ambiguous, speaker A appears to have no trouble identifying its referrent. It is hard to account for this in any way other than in virtue of A and B\'s common knowledge of politics, i.e., that it is more likely that \"Percy\" would be a troublesome item in this context than that \"Nixon\" would. Such an analysis cannot be more than conjecture, however. (Original footnote.)\r\n\r\n100\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nIn responding to a request for clarification, the sequential implicativeness of the troublesome utterance is temporarily suspended in favor of finding a remedy for the recipient\'s problem. Routinely in face-to-face conversation the adjacency relation or continuity between utterance and response, and the coherence of the interaction, are sustained across such embedded side sequences. This is true even when the request for clarification results in complete reformulation of the initial utterance. That is to say, although the response may ultimately address the reformulation, not the original utterance, it will still be heard as a response to the original:\r\nM: What=so what did you do did you have people ­ did Morag(.)come(.)down with the car again()or what [\r\nA: When last year M: Mmm how did you manage to shift it back and forward\r\n[ A: Last year I don\'t know ho:w I managed it I got it a::ll in (0.8) two\r\nsuitcases. (cited in Atkinson and Drew 1979: 239)\r\nIn this case it is just because A\'s \"When last year\" cannot be heard as a reply to M\'s question that it is heard as an embedded request for clarification. By the same token, the fact that a reply to M\'s question is deferred makes A\'s response to the reformulation about \"managing it\" relevant to the original question about \"Morag and the car.\"\r\nTurn-transition places provide recurring opportunities for the listener to initiate some repair or request for clarification from the speaker. Alternatively, clarification may be offered by the speaker not because the recipient of an utterance asks for it, but because the speaker finds evidence for some misapprehension in the recipient\'s response:\r\nDr: Hev\'y ever had palpitations (0.6)\r\nPt: Noh. M\' feet ain\'t painin\' me but they swell sometime Dr: No I ­ it\'s when yer heart starts beating really fast an y\'feel\r\nlike y\' can\'t catch yer breath. Pt: No. uh-uh. I never had that\r\n(Frankel 1984: 155)\r\nAlthough the patient here produces a response that is, formally, an answer to the doctor\'s question, the answer reveals a lexical problem\r\n\r\nCommunicative Resources\r\n\r\n101\r\n\r\nthat the doctor detects and remedies. The problem is, of course, unknown to the patient until the remedy is offered: if the doctor had failed to detect the misunderstanding, or had decided to let it pass and had consequently not offered the correction, the conversation to all appearances could have continued on as if there were no trouble. In this case the problem is evidently, from the doctor\'s point of view, worth bothering about: in myriad other cases it is not. That is to say, given the lack of specific criteria for assessing shared understanding in most cases, a crucial part of interactional competence is the ability to judge whether some evidence that the recipient has misunderstood warrants the work required for repair (Jefferson 1972). The decision whether to challenge a troublesome item or to let it pass involves, in part, a weighing of the relative work involved in the item\'s clarification versus the forseeable dangers of letting it go by. The risks of the latter are exemplified by the garden path situation, where speakers fail to identify some communicative trouble at the point where it occurs and discover only at some later point in the interaction that there has been some misunderstanding (see Jordan and Fuller 1975; Gumperz and Tannen 1979).6 At the point of discovery, the coherence of the interaction over some indefinite number of past turns may be called into question, and the source of the trouble may be difficult or impossible to reconstruct. In contrast to the routine problems and remedies that characterize local repair in conversation, such a situation may come close to communicative failure; that is, it may require abandoning the current line of talk or beginning anew.\r\n\r\nspecialized forms of interaction\r\nA distinguishing feature of ordinary conversation is the local, momentby-moment management of the distribution of turns, of their size, and of what gets done in them, those things being accomplished in the course of each current speaker\'s turn. There are, of course, numerous institutionalized settings that prescribe the organization and subject matter of interaction. Interactional organization is institutionalized along two dimensions that are of particular relevance to problems discussed in Chapter 9: (1) the preallocation of types of turn, that is, who speaks when and what form their participation takes and (2) the prescription of the substantive content and direction of the interaction or the agenda.\r\n6 An instance of this in the case of human­machine communication is discussed in Chapter 9. (Original footnote.)\r\n\r\n102\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nPreallocation of Turn Types\r\nAnalysis of encounters between physicians and patients (Frankel 1984) and of the examination of witnesses in the courtroom (Atkinson and Drew 1979) reveals a turn-taking system that is preallocated in terms of both the types of turn and the distribution of those types between the participants. Although there is no explicit formulation of a rule for the organization of talk in medical encounters, for example, Frankel reports that physicians\' utterances almost always take the form of questions (ninety-nine percent of the time), whereas patients\' take the form of answers. And in the courtroom, by definition, the examiner has the sole right to ask questions, whereas the examined is obliged to answer. In the courtroom, the convention that only two parties participate holds in spite of the number of persons present, and with the exception only of certain prescribed methods for \"interruption\" from the other counsel which, in virtue of the prescription of when and how interruption is to be effected, itself becomes a technical matter in the courtroom setting. In both medical and legal settings, the effect of the preallocation of turn types is to deliver control of the proceedings from the \"client\" or layperson back to the \"expert\" or specialist. At the close of each question­answer sequence, control is relinquished to whoever would start another sequence and the expert, having rights to the role of questioner, is repeatedly the one to retake control. Although the constraints on medical or legal interaction can be seen as institutional and in that sense as external to any particular occasion, it is nonetheless the case that in every actual instance the constraints are realized locally and collaboratively. Insofar as the interaction is locally managed, turn-transitions are subject to the same problems that arise in everyday conversation and are remedied via the same methods, as in the following example of an overlap that the witness (W) remedies by repeating her answer to the counsel\'s (C\'s) question:\r\nC: An (.) about how long did you say you ta:lked before (this was) [\r\nW: I don\'t remember C: (started ta kiss (h) a)= W: = I don\'t remember.\r\n(from Atkinson and Drew 1979: 67)\r\nAt the same time, the fact that procedural constraints on turn transitions are managed locally even in these settings means that general\r\n\r\nCommunicative Resources\r\n\r\n103\r\n\r\nconventions of conversational turn-taking can be exploited to further the special purposes of the participants. Because of the fact that pauses in conversation, for example, will be ascribed significance insofar as they are seen to belong to a selected next speaker, a pause following an examination sequence can be used by the examining counsel effectively to comment on the response to the jury, as in the following examination in a rape case cited by Atkinson and Drew (1979: 241):\r\nC: You were out in the woods with the defendant at this point isn\'t that so (1.0)\r\nW: Yeah (7.0)\r\nC: And the defendant (.) took (.) the ca:r (1.0) and backed it (1.0) into some trees didn\'e (0.5)\r\nW: Mm hm [\r\nC: underneath some trees.\r\nIn this case, the preallocated order of turns assigns the seven-second pause to the counsel and ensures that no other speaker will use the pause as an opportunity to take over the floor. The pause is used by the counsel in an unspoken turn that insinuates further \"information\" into the message that the jury receives from the witness\' answer. In the medical encounter, similarly, the physician can use a silence as an unspoken turn ­ in the following example, to avoid having to deliver bad news through disagreement:\r\nPt: This ­ chemotherapy (0.2) it won\'t have any lasting effects on havin\' kids will it? (2.2)\r\nPt: It will? Dr: I\'m afraid so.\r\n(Frankel 1984: 153)\r\nFinally, although respective turns of physician and patient, or counsel and witness, are constrained to be either questions or answers, these are minimal characterizations and provide no instruction for how, or what, specific utterances can be put into such a format. In the courtroom, for example, rules of evidence apply (relevance to the case at hand, status of the evidence as hearsay, the use of leading questions, and the like)\r\n\r\n104\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nwhere the application of those rules is situated and problematic and is itself part of the technical business of the proceedings. And the format of questions and answers in the courtroom accommodates a range of activities, including accusations, challenges, justifications, denials, and the like. Those activities are not prescribed in the way that the question­ answer format is and what counts as a question or an answer is itself liable to challenge. As a consequence, rules for courtroom interaction, like those for everyday conversation, constitute a resource for social order, not a recipe or an explanation.\r\n\r\nAgendas\r\nVarious settings, of course, do comprise prescriptions not only about forms of talk, but also about the substantive direction and purposes of the interaction:\r\nin several different types of speech-exchange situations, there can be occasions in which participation is constructed by a speaker in continuing response to interactional contingencies and opportunities from moment to moment, and occasions in which a participant has a preformed notion, and sometimes a prespecified text, of what is to be said, and plows ahead with it in substantial (though rarely total) disregard for what is transpiring in the course of his talking. (Schegloff 1982: 72)\r\nA major concern for participants in such settings is the distribution of knowledge about the agenda (Beckman and Frankel 1983). The communicative task of novice and expert in a given setting is to coordinate their actions in a way that accommodates their asymmetrical relationship to the interaction\'s institutionalized purposes. At the same time, it is precisely the difference in their respective familiarities vis-a`-vis the setting\'s protocols and purposes that in large measure distinguishes the \"expert\" or specialist from the \"novice\" or layperson (Erickson 1982: 4).\r\nThe work of Beckman and Frankel (1983) on physicians\' methods for eliciting a patient\'s \"chief complaint\" is illustrative. They point out that the medical literature has generally viewed the agenda for medical interviews as the patient\'s, in the sense that it is the patient who comes to the physician with a complaint and who is the source of the information required for the complaint\'s diagnosis. Given this view, a commonly cited problem for physicians is the experience of discovering, at the point where the physician is about to conclude the office visit\r\n\r\nCommunicative Resources\r\n\r\n105\r\n\r\nor at least the history-taking segment of the interview, that the patient has withheld some information that is relevant to a chief complaint. In contrast, by inverting the common view, Beckman and Frankel identify the relevant agenda in medical encounters as the physician\'s and further locate the source of the \"hidden agenda\" problem in ways that the physician\'s actions, in the opening sequence of the clinical encounter, serve systematically to foreclose a complete report of symptoms by the patient.7\r\nThe point of Beckman and Frankel\'s observation that is most relevant for present purposes ­ a point that I return to in Chapter 8 ­ is their insight that analysts of the medical interview have been misconceiving the essential problem for the interaction. Specifically, the problem is not that the patient \"hides\" the agenda, but that the patient, as a novice in this setting, does not understand the institutional purposes of the interaction, that is, the identification of a \"chief complaint,\" or the physician\'s strategy for achieving those purposes. The patient\'s task is misconceived, therefore, if it is viewed as either carrying out the plan of the interview or as failing to do so. The point is rather that the patient does not know the plan and is therefore able to cooperate only to the extent that being responsive to the physician\'s actions, locally, constitutes cooperation in realizing the plan. To the extent that the patient\'s cooperation is contingent on the physician\'s actions, the success of the interview is as well.\r\nThe actual production of an agenda, through local interactional work, is evident in the following excerpt from a career counseling interview reported by Erickson (1982: 77­8; C = counselor, S = student):\r\nC: Well, let\'s start from scratch. What did you get in your English 100 last semester?\r\nS: A \"C\" C: Biology 101? S: \"A\" C: Reading 100? S: \"B\" C: Med tech . . .\"B\"? (medical technology)\r\n\r\n7 Specifically, they cite the physician\'s tendency, given any mention of symptoms by the patient, to engage in early hypothesis testing; \"once hypothesis testing has begun, it is difficult for the patient to get a word in edgewise without deviating from conventional rules of discourse which relate types of speech acts to one another, in this case the relevance of an answer to the question that preceded it\" (1983: 9). (Original footnote.)\r\n\r\n106\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nS: \"B.\" C: Gym? S: \"A\" C: Was that a full credit hour? What was it? S: It was a wrestling . . . two periods. C: Wrestling. (He writes this on the record card, then shifts postural\r\nposition and looks up from the record at the student.) Ok, this semester . . . English 101? S: (Changes facial expression, but no nod or \"mhm\" in response to the question.) C: That\'s what you\'ve got now . . . S: (Nods.) C: Biology 102? Soc Sci 101. (The counselor is looking down.) S: I don\'t have Biology 102. I have, mm, 112. C: The counselor corrects the record card.) Soc Sci 101? S: (Nods.) Mhm. C: Math 95. S: (Nods.) C: Med Tech 112. S: (Nods.) C: Gym. S: (Nods.)\r\n\r\nIn Erickson\'s analysis, this interview comprises two adjacent routines, by which the counselor establishes the student\'s academic status first as a matter of courses completed and then as a matter of courses underway. The problem negotiated by counselor and student is that the counselor\'s behavior is superficially the same across both routines so that the juncture or transition between them, which requires a change in the task of the student, is initially missed by the student. The student\'s failure to respond to the query \"English 101?\" demonstrates the problem to the counselor, who then offers a remedy. Although the organization of this and any interaction can be analyzed post hoc into a hierarchical structure of topics and subtopics, or routines and subroutines, the coherence that the structure represents is actually achieved moment by moment as a local, collaborative, sequential accomplishment. This observation stands in marked contrast to the assumptions of students of discourse to the effect that the actual enactment of interaction is the behavioral realization of a plan. Instead, every instance\r\n\r\nCommunicative Resources\r\n\r\n107\r\n\r\nof coherent interaction is an essentially local production, accomplished collaboratively in real time, rather than \"born naturally whole out of the speaker\'s forehead, the delivery of a cognitive plan\" (Schegloff 1982: 73):\r\n\r\nGood analysis retains a sense of the actual as an achievement from among possibilities; it retains a lively sense of the contingency of real things. It is worth an alert, therefore, that too easy a notion of \"discourse\" can lose us that . . . If certain stable forms appear to emerge or recur in talk, they should be understood as an orderliness wrested by the participants from interactional contingency rather than as automatic products of standardized plans. Form, one might say, is also the distillate of action and interaction, not only its blueprint. If that is so, then the description of forms of behavior, forms of discourse . . . included, has to include interaction among their constitutive domains, and not just as the stage on which scripts written in the mind are played out. (ibid.: 89)\r\n\r\nThe organization of face-to-face interaction is the paradigm case of a system that has evolved in the service of orderly, concerted action over an indefinite range of essentially unpredictable circumstances. What is notable about that system is the extent to which mastery of its constraints localizes and thereby leaves open questions of control and direction, while providing built-in mechanisms for recovery from trouble and error. The constraints on interaction in this sense are not determinants of, but are rather \"production resources\" (Erickson 1982) for, shared understanding. The limits on available resources for accomplishing a shared agenda in a case of \"interaction\" between people and machines, and for detecting and remedying the troubles that that task poses, is the subject of Chapter 9.\r\n\r\nnotation\r\n\r\n[\r\n\r\nBracket indicates a point at which a current speaker\'s talk\r\n\r\nis overlapped by the talk of another, with overlapping talk\r\n\r\ndirectly beneath.\r\n\r\n//\r\n\r\nAlternatively, double oblique lines indicate a point at which a\r\n\r\ncurrent speaker\'s talk is overlapped the talk of a next speaker.\r\n\r\n:\r\n\r\nColons indicate a lengthened syllable, the number of colons\r\n\r\nsuggesting the extent of the lengthening.\r\n\r\n-\r\n\r\nDash indicates a stop, cutting off an utterance.\r\n\r\n?\r\n\r\nQuestion intonation.\r\n\r\n108\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n. =\r\n.hh\r\nItalics ()\r\n(())\r\n(0.0)\r\n(.)\r\n\r\nFull stop, with falling intonation. Equal sign indicates no interval between the end of a prior and the start of a next piece of talk. Audible breath. Dot before indicates inbreath; no dot indicates outbreath. Speaker\'s emphasis Words enclosed in parenthesis indicate either nonlinguistic action, or transcriber\'s uncertainty over the verbatim. Double parenthesis indicates features of the audio other than verbalization, or note from the transcriber. Numbers in parenthesis indicate elapsed time in tenths of a second. Untimed pause.\r\n\r\nFor a more extensive description of notations see Jefferson (1983); Heritage (1984); and Lynch (1985).\r\n\r\n8\r\nCase and Methods\r\nIn this age, in which social critics complain about the replacement of men by machines, this small corner of the social world has not been uninvaded. It is possible, nowadays, to hear the phone you are calling picked up and hear a human voice answer but nevertheless not be talking to a human. However small its measure of consolation, we may note that even machines such as the automatic answering device are constructed on social, and not only mechanical, principles. The machine\'s magnetic voice will not only answer the caller\'s ring, but will also inform him when its ears will be available to receive his message, and warn him both to wait for the beep and confine his interests to fifteen seconds.\r\n(Shegloff 1972: 374)\r\nChapter 9 describes people\'s first encounters with a machine called an expert help system; a computer-based system attached to a large and relatively complex photocopier and intended to instruct the user of the copier in its operation.1 The system\'s identification as an expert help system both locates it in the wider category of so-called expert systems and indicates that a function of this system is to provide procedural instructions to the user. The idea of expert systems in general is that expertise consists in a body of propositions or \"knowledge\" about a particular domain and rules for its use. The knowledge of this system comprises a set of rules about copying jobs and procedures that control both the presentation of instructions to the user on a video display and the operations of the copier itself. The design objective is that the system\r\n1 The system was designed by Richard Fikes at the Xerox Palo Alto Research Center in 1982­1983. (Original footnote.) 109\r\n\r\n110\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nshould provide timely and relevant information to the user regarding the operation of the copier.2 The information should be presented not as a compendium but in a stepwise order wherein each next instruction is invoked by the user\'s successful enactment of the last. To provide the user with appropriate instruction, therefore, the system must somehow recognize the action of the user to which it should respond. It is this problem in particular ­ the problem of the system\'s recognition of the user\'s actions ­ that the analysis explores.\r\n\r\nthe expert help system\r\nIn contrast to relatively unrestricted occasions of human interaction such as ordinary conversation, certain constraints on the event of using the expert help system provide grounds for imagining that one might safely predict, in some detail, just how the event will go:\r\nr The interaction is instrumental. r The possible goals of the interaction are defined by the machine\'s\r\nfunctionality. r The structure of the interaction is procedural, constituted by a\r\nsequence of actions whose order is partially enforced. r The criteria of adequacy for each action can be specified.\r\nBecause in machine operation the user\'s purposes are constrained by the machine\'s functionality, and her actions by its design, it seems reasonable to suppose that the user\'s purposes should serve as a sufficient context for the interpretation of her actions. On this assumption, the strategy that the design adopts is to project the course of the user\'s actions as the enactment of a plan for doing the job and then use the presumed plan as the relevant context for the action\'s interpretation.3\r\n2 The expert help system in this sense would seem to be a strong instantiation of \"configuring the user\" (Woolgar 1991; Grint and Woolgar 1997), a machine whose design inscribes a \"programme for action\" (Latour 1992) or \"script\" (Akrich 1992). I examine this more closely in Chapter 11.\r\n3 As Chapter 5 pointed out, analysts of the intention­action relationship are troubled by the apparently diffuse and tacit nature of intentions in many situations, and the consequent problem of determining just what is the actor\'s \"true\" intent. This seems less of a problem with goal-directed activities, where the goal, as defined by the analyst, can simply be taken a priori as the intent of the actor. The argument of this book, of course, is that the relief from the problem of determining intent that task-oriented interaction seems to offer is only a temporary palliative to the designer\'s problem: the real solution must lie in an alternative understanding of the nature of intentions and their relation to actions ­ one that views the everyday business of identifying intent as an always contingent, practical, and interactional accomplishment. (Original footnote.)\r\n\r\nCase and Methods\r\n\r\n111\r\n\r\nThrough the user\'s response to a series of questions about the state of her original documents and the desired copies, her purposes are identified with a job specification, the specification (represented in the system as a data structure with variable fields) invokes an associated plan, and the enactment of the plan is prescribed by the system as a stepwise procedure.\r\nHaving mapped the user\'s purposes to a job specification and the job specification to a plan, the plan is then effectively ascribed to the user as the basis for interpreting her actions. The rationale for this move is that the plan is conveyed to the user in the form of instructions for a stepwise procedure, the user is following the instructions and consequently, one can assume, is following the plan that the instructions describe. Under that assumption, the effects of certain actions by the user are mapped to a place in the system\'s plan and that mapping is used to locate an appropriate next instruction. The actions by the user that effect changes in the machine\'s state comprise some physical actions on the machine (putting documents into document trays, opening and closing machine covers, and the like), and directives to the system in the form of selections of text on a video display. The hope of the designer is that the effects of these actions by the user can be mapped reliably to a location in the system\'s plan and that the location in the plan will determine an appropriate system response. The relevant sense of \"interaction\" in this case, therefore, is that the provision of instruction is both fitted to the user\'s purposes and occasioned by her actions.\r\nThe design assumes, however, that it is the correspondence of the system\'s plan to the user\'s purposes that enables the interaction. In contrast, the analysis of Chapter 9 indicates that user and system each have a consequentially different relationship to the design plan. Although the plan directly determines the system\'s behavior, the user is required to find the plan, as the prescriptive and descriptive significance of a series of procedural instructions. Whereas the instructions and the procedure that they describe are the object of the user\'s work, they do not reconstruct the work\'s course, nor do they determine its outcome.\r\n\r\nthe problem of following instructions\r\nThe practical problem that the expert help system was designed to solve arises out of the work of following instructions, which in turn implies the work of communicating them. The general task in following instructions is to bring canonical descriptions of objects and actions to bear on the actual objects and embodied actions that the instructions describe\r\n\r\n112\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n(Lynch, Livingston, and Garfinkel 1983). Studies of instruction in cognitive and social science alike have focused, on the one hand, on the problem of providing adequate instructions and, on the other, on the problem of finding the practical significance of instructions for situated action.\r\nSocial studies of the production and use of instructions have concentrated on the irremediable incompleteness of instructions (Garfinkel 1967, Chapter 1) and the nature of the work required to \"carry them out.\" The problem of the instruction-follower is viewed as one of turning necessarily partial descriptions of objects and actions into concrete practical activities with predictable outcomes (Zimmerman 1970; Amerine and Bilmes 1979). A general observation from these studies is that instructions rely on the recipient\'s ability to do the implicit work of anchoring descriptions to concrete objects and actions. At the same time, that work remains largely unexamined by either instruction-writer or recipient, particularly when the work goes smoothly.\r\nIn a study of instruction-following as practical action, Amerine and Bilmes (1990) point out that instructions serve not only as prescriptions for what to do but also as resources for retrospective accounts of what has happened: \"Successfully following instructions can be described as constructing a course of action such that, having done this course of action, the instructions will serve as a descriptive account of what has been done\" (ibid.: 326). More than the \"correct\" execution of an instruction, in other words, successful instruction following is a matter of constructing a particular course of action that is accountable to the general description that the instruction provides. The work of constructing that course is neither exhaustively enumerated in the description, nor completely captured by a retrospective account of what was done. Instructions serve as a resource for describing what was done not only because they guide the course of action but also because they filter out of the retrospective account of the action, or treat as \"noise,\" everything that was actually done that the instructions fail to mention. As Amerine and Bilmes observe: \"If the experiment is `successful,\' if it achieves its projected outcome, the instructions can serve as an account of `what was done,\' although in any actual performance a great deal more is necessarily done than can be comprised in the instructions\" (ibid.: 325).\r\nThe credibility of instructions, moreover, rests on the premise that not only do they describe what action to take, but if they are followed correctly the action will produce a predictable outcome. An unexpected\r\n\r\nCase and Methods\r\n\r\n113\r\n\r\noutcome, accordingly, indicates trouble and warrants some remedy. As long as instructions are viewed as authoritative, the preference in remedying a faulted outcome is to account for the failure in outcome without discrediting the instruction. An obvious solution is to locate the trouble somewhere in the instruction\'s \"execution.\" In assessing the course of the work for troubles in execution, questions inevitably arise concerning the relation of the many actions that were taken that are not specified by the instructions to the faulted outcome. Previously insignificant details may appear crucial, or the meaning of the instructions may be transformed in such a way that they are found not have been followed after all. Amerine and Bilmes give an example, drawn from science experiments in a third-grade classroom, of the kind of problem inherent in reasoning inductively about the relation between courses of action and outcomes:\r\nTo expedite carrying out this lesson two similar and functionally equivalent pans of water were placed on a table in the center of the room and the students were called on by pairs to try the exercise. Toward that end, when, as related above, this activity had become particularly competitive, one of the children approached a pan but was urged by classmates to use the other one because it was \"luckier.\" We are not sure how this notion came about, although in a pair of trials closely preceding this comment the student using the \"unlucky\" pan had failed, while the child using the other one had succeeded. At any rate, the student followed this advice and the experiment was successful. Both of the following two children rushed for the \"lucky\" pan, though the loser settled for the \"unlucky\" one (and succeeded nonetheless). In the case of the next pair, the second child waited for the first to finish using the \"lucky\" pan, and then also used it. The \"unlucky\" pan remained unused thereafter . . . In neither case are such observations by nature illogical or irrelevant . . . But in these science experiments our understanding of the relationship between the practical course of action and its outcome seems to leave no place for \"luck\" . . . Therefore such factors become \"noise.\" (ibid.: 329­30, original emphasis)\r\nThe ability to discriminate between relevant information and \"noise\" in a given domain of action, by invoking both precepts and practice, is a part of what we recognize as expertise. The point of the \"lucky pan\" example is that the process by which that ability is acquired is a fundamentally inductive and ad hoc one, regardless of the degree to which rules of action are encoded and prescribed. In the final analysis no amount of prescription, however precise or elaborate, can relieve situated action \"of the burden of finding a way through an unscheduled future while making a convincing case for what is `somehow\' extracted from that future\" (Lynch, Livingston, and Garfinkel 1983: 233). The latter\r\n\r\n114\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nis the problem of accountably rational action in situ, however adequate the instructions for that action may be.\r\n\r\ncommunicating instructions\r\nAn appreciation for what is required in instruction following makes it easier to understand the problem that the communication of instructions attempts to solve; namely, the troubles inherent in turning an instruction into an action. Motivated by the project of designing instructional computer systems, researchers in artificial intelligence have looked at instruction as a question of communicative resources available to expert and novice. One of the earliest such projects, the Computer-Based Consultant project begun at Stanford Research Institute in the 1970s, continues to direct research on task-oriented communication through \"natural language,\" using what has become the canonical problem of assembling a simple mechanical device. The goal of the original project was:\r\nto produce a computer system that could fill the role of an expert in the cooperative execution of complex tasks with a relatively inexperienced human apprentice. The system was to use rich channels of communication, including natural language and eventually speech. The main function of the consultant was to aid the apprentice in the diagnosis of faulty electromechanical equipment, and the formulation of plans for the assembly, disassembly, and repair of the equipment. (Sacerdoti 1977: 3)\r\nUsing an air compressor as the assembly task, researchers collected a corpus of dialogues in experiments designed to simulate interaction between a person and a computer (see B. Grosz 1981). In these experiments two people ­ one acting as expert and the other acting as apprentice ­ had only limited visual access to each other. Grosz\'s analysis of the corpus turns on the observation that the requirement for successful communication between expert and novice, despite their limited visual access, is a common \"focus\" on the task at hand. Common focus allows the exploitation of language (e.g., definite descriptions such as \"the screw\"), materials (\"the screw visible on the hub of the flywheel\"), and local history (\"the screw loosened previously\") in instruction, whereas language, materials, and history are used, in turn, to maintain the common focus. Grosz\'s concern with the linguistic, interactional, and material bases of successful instruction set the stage for a series of subsequent analyses in which, by varying the resources available for communication, researchers began to explore the relationship of various\r\n\r\nCase and Methods\r\n\r\n115\r\n\r\nnonlinguistic resources to the use of language (for a \"taxonomy\" of these resources, see Rubin 1980).\r\nIn an analysis of transcripts of instructors communicating with an apprentice through face-to-face, telephone, audio-taped, and written media about the assembly of a toy water pump, Burke (1982) found that the most obvious difference, that between speaking and writing, is actually less crucial than the difference between interactive (e.g., a keyboard) and noninteractive (e.g., audio-taped) instruction. The restrictions generally associated with written instruction, in other words, derive not from the writing so much as from the absence of interaction, whereas the effectiveness of verbal instruction derives less from the speech than from the interaction that is generally associated with it. Ochs (1979) relates the distinction of interactive and noninteractive communication to degrees of planning, arguing that in the case of interaction speakers plan only at a general level (the concretization of the plan being contingent and emergent), whereas noninteractive discourse can be entirely planned in advance. Instead, Burke takes the point of view that the instructor\'s task is one of adequate description rather than planning and reports that in the noninteractive modalities of instruction on the assembly task there is a tendency to \"overelaborate\" descriptions, in an apparent attempt to anticipate possible troubles and to compensate for the lack of opportunities for their on-site clarification. In face-to-face instruction, in contrast, Burke found that instructors initially provided minimal descriptions and then monitored the apprentice\'s actions for evidence of the description\'s adequacy or inadequacy. By telephone, where visual access was unavailable but where the interaction remained, the resources for monitoring the actions of the apprentice changed from visual to verbal (e.g., affirmations, repeats, and transformed repeats of the instructions by the apprentice), but the monitoring again guided the description.\r\nCohen\'s (n.d.) analysis of transcripts of instructor and apprentice communicating by telephone or keyboard on the same assembly task confirms the ability of instructors to adjust the level of their descriptions in response to the demonstrated understanding or misunderstanding by the apprentice. He concludes that the principal difference between spoken and written interactive media is that experts in spoken instruction more often explicitly request that the novice identify an object, and often question the novice on his or her success, whereas experts using keyboards subsume reference to objects into instructions for action unless some prior referential miscommunication has occurred (ibid.: 21). Spoken interaction between expert and novice, in that sense, is more finely\r\n\r\n116\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ncalibrated than written, though insofar as both are interactive both support the collaborative construction of a useful description of the objects and actions in question, through practical analyses of the communication\'s success at each turn.\r\n\r\nthe basic interaction\r\nThe aim of the expert help system analyzed in the next chapter is to use the power of the computer to combine the portability of noninteractive instructions with the timeliness, relevance, and effectiveness of interaction. The machine presents the user with a series of video displays. Each display presented to the user either describes the machine\'s behavior or provides the user with some next instructions. In the latter case, the final instruction of each display prescribes an action whose effect is detectable by the system, thereby triggering a change to the next display (Figure 8.1).\r\nThrough the device of display changes keyed to actions by the user, the design accomplishes a simple form of occasioned response, in spite of the fact that only a partial trace of the user\'s behavior is available to the system. Among those user actions that are not available to the system is the actual work of locating referents and interpreting action descriptions: the system has access only to the product of that work. Moreover, within the instruction provided by a given display are embedded instructions for actions whose effects are not detectable by the system. To anticipate our discussion of troubles that arise, if one of these instructions is misconstrued, the error will go by unnoticed. Because the implication of a next display is that prior actions have been noted and that they have\r\n1. MACHINE PRESENTS INSTRUCTION\r\nUser reads instruction interprets referents and action descriptions\r\n2. USER TAKES ACTION\r\nDesign assumes that the user has understood the instruction\r\n3. MACHINE PRESENTS NEXT INSTRUCTION\r\nfigure 8.1. The basic instructional sequence.\r\n\r\nCase and Methods\r\n\r\n117\r\n\r\nbeen found adequate, the appearance of a next instruction will confirm the correctness not only of the prior action narrowly defined but also of all of the embedded actions prescribed by the last instruction.\r\nTo compensate for the machine\'s limited access to the user\'s actions, the design relies on a partial enforcement of the order of user actions within the procedural sequence. This strategy works fairly wells insofar as a particular effect produced by the user (such as closing a cover on the copier) can be taken to imply that a certain condition obtains (a document has been placed in the machine for copying), which, in turn, implies a machine response (the initiation of the printing process). In this sense, the order of user and machine \"turns,\" and what is to be accomplished in each, are predetermined. The system\'s \"recognition\" of turn-transition places is essentially reactive; that is, there is a determinate relationship between certain actions by the user, read as changes to the state of the machine, and the machine\'s transition to a next display. By establishing a determinate relationship between detectable user actions and machine responses, the design unilaterally administers control over the interaction, but in a way that is conditional on the actions of the user.\r\nAt the same time that the system controls the sequence of user actions, the design avoids certain problems that arise when instructions are provided consecutively and in a strict order. Every procedure is represented in the system as a series of steps, each of which has an associated precondition (the effect of a prior action by user or machine) and an associated machine response (display of instructions and/or setting of machine state). Rather than proceeding through these steps consecutively, the system begins processing at the last step of the procedure and checks to see whether that step has been completed. If not, the preconditions are checked and, if they are all satisfied, the step is executed. Each precondition carries with it a reference to the earlier step in the procedure that will satisfy that precondition, so that if an unmet precondition is found the system will return to the earlier step and proceed from there. If, therefore, a procedure is repeated but in the second instance certain conditions hold over from the first, the system will not display instructions for the actions that have already been taken. Beginning with the final step, it will work backwards through the procedure just to the point where an unmet precondition is found and will provide the instruction from that point on. Similarly, if the user takes an action that undoes a condition satisfied earlier, the system will encounter that state again at the next check. This technique produces appropriate instructions not\r\n\r\n118\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nbecause the system knows that this time through differs from the last, but just because, regardless of how they come about, certain detectable conditions (e.g., a document is in the machine) are linked unequivocally to appropriate response (e.g., initiating the printing process). Chapter 9 examines how this design strategy works and how, for the very same reason that it works in some instances, in other instances troubles arise.\r\n\r\nmethods\r\nThe study was directed by two methodological commitments, one general, and the other particular to the problem at hand. Generally, the study began with a commitment to an empirical approach, along with the conviction that situated action cannot be captured empirically through either examples constructed by the researcher, paper-and-pencil observations, or interview reports. Analyses of contrived examples, observations, or interviews all rest on accounts of circumstances that are either imagined or recollected. One objective in studying situated action is to consider just those fleeting circumstances that our interpretations of action systematically rely on, but which our accounts of action routinely ignore. A second objective is to make the relation between interpretations of action and action\'s circumstances our subject matter. Both objectives are clearly lost if we use reports of action as our data.4\r\n4 This is not to say that paper-and-pencil observations have no place. The video analysis was preceded by approximately twenty hours of observation of new users of the same machine, minus the expert help system but equipped with written instructions, in actual office settings. That earlier study was undertaken in response to an unelaborated report, from those who supported the machine and its users \"in the field,\" of user complaints that the machine was too complicated. Given the relative simplicity of even the most complex photocopier, this complaint on face value was puzzling, particularly to the machine\'s designers. The combination of the vagueness of the complaint as reported, and the bewilderment of the designers, intrigued both me and my colleagues Austin Henderson and Richard Fikes at the research center, and we set about to try to ascertain what the \"complexity\" was really about. That led to the paper-and-pencil observations, which convinced us that indeed the machine was somehow too complicated for the novice user who had no previous training; that is, people trying to use the machine were very visibly confused. The methodological problem at that point was that I, as an observer of their troubles, was equally confused. From the observations, therefore, I learned two important lessons. First, that there was indeed a problem. And, second, that to understand the problem would require the use of an adequate, i.e., a videotaped, record. For an analysis of users\' troubles with the original instruction set, see Suchman (1982). (Original footnote.)\r\n\r\nCase and Methods\r\n\r\n119\r\n\r\nAnother approach to the analysis of instructions might be to look at the textual cogency of the instructions themselves. An example offered by Searle (1979) illustrates the problem with such a strategy:5\r\nSuppose a man goes to the supermarket with a shopping list given him by his wife on which are written the words \"beans, butter, bacon, and bread.\" Suppose as he goes around with his shopping cart selecting these items, he is followed by a detective who writes down everything he takes. As they emerge from the store both the shopper and detective will have identical lists. But the function of the two lists will be quite different. In the case of the shopper\'s list, the purpose of the list is, so to speak, to get the world to match the words; the man is supposed to make his actions fit the list. In the case of the detective, the purpose of the list is to make the words match the world; the man is supposed to make the list fit the actions of the shopper. This can be further demonstrated by observing the role of \"mistake\" in the two cases. If the detective goes home and suddenly realizes that the man bought pork chops instead of bacon, he can simply erase the word \"bacon\" and write \"pork chops.\" But if the shopper gets home and his wife points out that he has bought pork chops when he should have bought bacon he cannot correct the mistake by erasing \"bacon\" from the list and writing \"pork chops.\" (ibid.: 4)\r\nThe subject of the present analysis, the user of the expert help system, is in the position of the shopper with respect to the instructions that the system provides; that is, she must make her actions match the words. But in what sense? Like the instructions, a shopping list may be consulted to decide what to do next or to know when the shopping is done, may be cited after the fact to explain why things were done the way they were, and so forth. But also like the instructions, the list does not actually describe the practical activity of shopping (how to find things, which aisles to go down in what order, how to decide between competing brands, etc.); it simply says how that activity is to turn out.6\r\nJust as the list of the shopping\'s outcomes does not actually describe the organization of the activity of shopping, an analysis of instructions will not yield an analysis of the activity of carrying them out. In fact, contrary to the case in the story, there is no reason to believe that if a person has a set of instructions for operating a machine and we generate a description of the activity of operating a machine from watching the\r\n\r\n5 Searle credits this example to Anscombe (1957). The point that Searle is interested in concerns the notion of \"direction of fit\" between words and the world. (Original footnote.)\r\n6 For an inspired ethnographic account of actual practices of shopping, with a particular focus on practical forms of quantitative reasoning see Lave (1988, Chapter 7).\r\n\r\n120\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nperson, that the description we generate should look anything like the instructions. In fact, if our description of the situated activity does mirror the structure of the instructions, there is reason to believe that something is amiss.\r\nUnlike the detective in the story who is supposed to generate a list, our problem as students of situated action is more akin to the problem of a detective who is just sent out and told to report back on what going to the grocery store is all about and how shopping is done. What that description should look like ­ what its terms should be, what its structure should be, what of all that goes on it should report ­ is an open methodological question. If, to put some constraints on the description, we set out with a template that asks for a list just of what the actions come to, then what counts as \"an action\" is prescribed ahead of time as \"its outcome,\" and the list format prescribes the structure of the description. Only that part of the activity that fills in the template will be recorded. The action\'s structure, in other words, will be decided in advance and the method employed by the scientist will ensure that that structure is what is found.\r\nOne further issue that the story touches on is the problem of validity. The story says the detective might \"suddenly realize\" that there is some error in his description. But how might he actually realize that? If we just look for a discrepancy between the shopper\'s list and the detective\'s, what we find might reflect either an error in the shopper\'s activity (it doesn\'t match the list) or in the description (it doesn\'t match the activity). To evaluate which, we must have (a) independent access to the shopper\'s list to compare against the activity and (b) a record of activity. That is to say, two essential methodological resources are (a) the comparison of our own interpretations with those of our subjects and (b) a record that is not contingent on either.\r\nHowever adequate the record, of course, the empirical basis of social studies is not a positive one because we cannot, by definition, provide a literal description of our phenomenon.7 As Wilson (1970) defines literal description: \"Any description of a phenomenon is based on perceived features that the phenomenon displays to the observer. A literal\r\n\r\n7 Galaty (1981) makes a useful distinction between \"data sources,\" as the business of the social world independent of the anthropologist\'s interest in it; \"data,\" as the anthropologically [worked-up] information that appears in the form of, for example, transcripts; and \"analytic objects,\" conceptualized as events, troubles, and the like (ibid.: 91, note 2). The point is that for the social scientist, the data are interpreted already at their source. (Original footnote.)\r\n\r\nCase and Methods\r\n\r\n121\r\n\r\ndescription, then, amounts to asserting that on the basis of those features the phenomenon has some clearly designated property, or what is logically the same thing, belongs to some particular, well-defined class of phenomena\" (ibid.: 72). For a description to be literal, in other words, the class of phenomena of which the described is an instance must be definable in terms of sufficient conditions for counting some instance as a member of the class. For situated action, that would require classification of action not only as the relation of intent to behavior but also as the relation of both to mitigating circumstances ­ a classification that, I argued in Chapter 5, is functionally and criterially different from that applied to intentional descriptions of actions and situations. Moreover, the social scientist\'s description is yet another order of remove from a literal description if the subject of the descriptions is not only the intent of some actor, but also the interpretations of that actor\'s intent by others on the scene. Judgments of correctness and veridicality are replaced in social studies by judgments of adequacy or verisimilarity (Heap 1980: 104), the latter resting on criteria of evidence and warranted inference rather than conditions of truth.\r\nThe problems that the social scientist struggles with in defining her methods are the same problem that, from another view, constitute her subject matter: namely, the uncertain relation between accounts of the significance of action and the observations and inferences on which those accounts must be based. There is no privileged analytic stance for the social scientist that exempts her from the problems of adjudicating the practical objectivity of the social world. The only advantage that accrues to the researcher (a substantial one, it turns out) is recourse to a record of the action and its circumstances, independent of her analysis. The availability of audiovisual technology that can provide such a record, for repeated inspection by the researcher and by colleagues, avoids the reliance on unexplicated resources that characterizes traditional ethnographic accounts. In traditional accounts, the fleeting nature of the events that the ethnographer describes means that the only record that is available for inspection by others is the ethnographer\'s description.\r\nThis study proceeded, therefore, in a setting where video technology could be used in a sort of uncontrolled experimentation. On one hand, the situation was constructed so as to make certain issues observable; specifically, the work of using the machine with the assistance of the expert help system. The construction consisted in the selection of tasks observed to pose problems for new users in \"the real world.\" On the\r\n\r\n122\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nother hand, once given those tasks, the subjects were left entirely on their own. In the analysis, by the same token, the goal was to construct a characterization of the interaction that ensued rather than to apply a predetermined coding scheme. Both predetermined coding schemes and controlled experiments presuppose a characterization of the phenomenon studied, varying only certain parameters to test the characterization. Application of that methodology to the problem of human­machine interaction would be at the least premature. The point of departure for the study was the assumption that we lack a description of the structure of situated action. And because the hunch is that the structure lies in a relation between action and its circumstances that we have yet to uncover, we do not want to presuppose what are the relevant conditions or their relationship to the course of the action. We need to begin, therefore, with observations that capture as much of the phenomenon, and presuppose as little, as possible.8\r\nThe consequence of this commitment to examining the circumstances of action is that we need to begin with a record of events that is not prejudged as to its analytic interest either in advance or in the making. The data for this study, accordingly, are a corpus of videotapes of first-time users of the expert help system.9 First-time users were chosen on the grounds that the system was intended by its designers to be self-explanatory or usable by people with no previous introduction to the machine. More generally, the troubles encountered by first-time users of a system are valuable in that they disclose work required to understand the system\'s behavior that, for various reasons, is masked by the proficient user. This disclosure of the requisite work is the value of studying interactional troubles generally (see Gumperz 1982b: 308) and distinguishes this analysis from the usual \"operability tests.\" That is to say, I am not simply interested in distinguishing \"correct\" from \"erroneous\" moves by the user. Rather, by studying what things look like when they are unfamiliar and troublesome, I hope to understand better what is involved in their mastery.\r\nIn each of the sessions two people, neither of whom had ever used the system before, worked together in pairs. Two people asked to collaborate\r\n\r\n8 I would phrase this characterization of the implications of the contingency of situated activity for research methods more strongly now, as recommending against the project of establishing a \"structure\" altogether. On the premises of poststructural social studies and their implications for method, see, for example, Lynch 1993; Law 2004.\r\n9 The corpus from which the analysis of Chapter 9 is drawn comprises four sessions, each lasting from one and a half to two hours.\r\n\r\nCase and Methods\r\n\r\n123\r\n\r\nTHE USER\r\n\r\nTHE MACHINE\r\n\r\nActions not available to the machine\r\n\r\nActions available to the machine\r\n\r\nEffects available to the user\r\n\r\nfigure 8.2. The analytic framework.\r\n\r\nDesign rationale\r\n\r\nin using a relatively simple machine like a photocopier are faced with the problem of doing together what either could do alone. In the interest of the collaboration, each makes available to the other what she believes to be going on: what the task is, how it is to be accomplished, what has already been done and what remains, rationales for this way of proceeding over that, and so forth. Through the ways in which each collaborator works to provide her sense of what is going on to the other, she provides that sense to the researcher as well. An artifact of such a collaboration, therefore, is a naturally generated protocol.10\r\nA second methodological commitment, which arose from the particular problem of looking at human­machine communication, directed the analysis itself. The aim of the analysis was to find the sense of \"shared understanding\" in human­machine communication. More particularly, I wanted to compare the user\'s and the system\'s respective views of the interaction, over a sequence of events. In working to organize the transcripts of the videotapes, therefore, I arrived at a simple framework (see Figure 8.2). The framework revealed two initial facts about the relationship of user and system. First, it showed that the coherence of the user\'s actions was largely unavailable to the system and something of why that was the case. Beginning with the observation that what the user was trying to do was, somehow, available to me as the researcher, I could ask how that was so. The richest source of information for the researcher is the verbal protocol (recorded in the first column). In reading the instructions aloud, the user locates the problem that she is working on. Her questions about the instructions identify the problem more particularly\r\n\r\n10 Brown, Rubenstein, and Burton (1976) argue persuasively for the use of teams to generate protocols, where the discussions and arguments that unfold are treated as evidence for the individual reasoning of the participants. The actions of the team members can also be viewed as organized by the task of collaboration itself, however, although in the interest of looking at the interaction of both users with the machine I have deliberately avoided taking that view here. It is worth noting, in this regard, that analyses of \"discourse\" undertaken in the interest of building interactive Al systems generally tend to view communication as the coincidence of individual reasoning processes, rather than as an activity with a distinctive character arising from the collaboration itself. (Original footnote.)\r\n\r\n124\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nand further talk provides her interpretations of the machine\'s behavior and clarifies her actions in response.\r\nA second, but equally crucial, resource is visual access to the user\'s actions. Of all of her actions, one could clearly see the very small subset, recorded in the second column, that were actually detected by the system. From the system\'s \"point of view,\" correspondingly, one could see how it was that those traces of the user\'s actions available to the system were mapped onto the system\'s plan, under the design assumption that, for example, button x pushed at this particular point in the procedure must mean that the user is doing y.\r\nThe framework proved invaluable for taking seriously the idea that user and machine were interacting. By treating the center two columns as the mutually available, human­machine \"interface,\" one could compare and contrast them with the outer columns, as the respective interpretations of the user and the design. This comparison located precisely the points of confusion, as well as the points of intersection or \"shared understanding.\" Both are discussed at length in the next chapter.\r\n\r\n9\r\nHuman­Machine Communication\r\nInteraction is always a tentative process, a process of continuously testing the conception one has of . . . the other.\r\n(Turner 1962: original emphasis)\r\nIn Chapter 6 I outlined the view that the significance of actions and their intelligibility resides neither in what is strictly observable about behavior, nor in a prior mental state of the actor, but in a contingently constructed relationship among observable behavior, embedding circumstances, and intent. Rather than enumerating an a priori system of normative rules for meaningful behavior, Chapter 7 described resources for constructing shared understanding, collaboratively and in situ. Faceto-face interaction was presented as the most fundamental and highly developed system for accomplishing mutual intelligibility, exploiting a range of linguistic, demonstrative, and inferential resources.\r\nGiven this view of the basis for action\'s intelligibility, the situation of action can be defined as the full range of resources that the actor has available to convey the significance of his or her own actions and to interpret the actions of others.1 Taking that preliminary definition of the situation as a point of departure, my interest in this chapter is to\r\n1 In light of subsequent readings, I realize that this statement could be taken to imply that \"the situation\" exists somehow in advance of action and that it could at least in principle be fully enumerated and represented in the form of a model to be referenced. The sense of the situation I am after, however, is a radically performative and interactional one, such that action\'s situation is in significant respects constituted through, or stands in a reflexive relationship with, ongoing activity. It is through the latter that the sense and relevance ­ just what the situation comprises ­ is produced, reenacted, contested, and/or transformed. 125\r\n\r\n126\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nconsider \"communication\" between a person and a machine in terms of the nature of their respective situations. For purposes of the analysis, and without ascribing intent in any way, I will assume that the machine is behaving on the basis of resources provided by \"its\" situation, the user in accord with the resources of hers. The aim of the analysis then is to view the organization of human­machine communication, including its troubles, in terms of constraints posed by asymmetries in the respective situation resources of human and machine.\r\nIn the case considered here, we can assume that the situation of the user comprises preconceptions about the nature of the machine and the operations required to use it, combined with moment-by-moment interpretations of evidence found in and through the actual course of its use. The situation of the machine or expert help system, in contrast, is constituted by a plan for the use of the machine, written by the designer, and implemented as the program that determines the machine\'s behavior and sensors that register changes to the machine\'s state, including some changes produced by the user\'s actions. The design plan defines what constitutes intelligible action by the user insofar as the machine is concerned and determines what stands as an appropriate machine response. The intersection of the situations of user and machine is the locus both for successful exploitation of mutually available resources and for problems of understanding that arise out of the disparity of their respective situations.\r\n\r\nengineering an appropriate response\r\nThe practical problem with which the designer of an interactive machine must contend is how to ensure that the machine responds appropriately to the user\'s actions. As in human communication, an appropriate response implies an adequate interpretation of the prior action\'s significance. And as in human communication, the interpretation of any action\'s significance is only weakly determined by the action as such. Every action assumes not only the intent of the actor, but also the interpretive work of the other in determining its significance.2 That work, in turn, is available only through the other\'s response. The significance of any action and the adequacy of its interpretation are judged indirectly, by responses to actions taken and by an interpretation\'s usefulness in\r\n2 See Bruner (1986) for a recent discussion of the contingency of interpretation with respect both to text and to face-to-face interaction. (Original footnote.)\r\n\r\nHuman­Machine Communication\r\n\r\n127\r\n\r\nunderstanding subsequent actions. It is just this highly contingent process that we call interaction.\r\nFor purposes of analysis, we can begin by considering two alternative perspectives on face-to-face interaction, with commensurately different implications for the project of designing interactive machines. The first perspective ties successful interaction to each participant\'s success at anticipating the actions of the other and recommends an interactive interface based on a preconceived model of the user that supports the prediction of actions, the specification of recognition criteria for the actions predicted, and the prescription of an appropriate response. The second view focuses on the ways in which interactional success comprises responses that are occasioned by, and responsive to, unanticipated actions of the other. This focus recommends an interactive interface that maximizes sensitivity to actions actually taken by minimizing predetermined sequences of machine behavior. The former recommendation is constrained by limitations on the designer\'s ability to predict any user\'s actions and the latter by limitations on the system\'s access to and ability to make sense out of the actions that a particular user takes.\r\nThe design strategy in the expert help system is to try to provide the effect of an occasioned response through the use of a predictive model. That is to say, the designer predicts that the user will have one of a set of possible goals, of the form \"use the machine to accomplish outcome x.\" Given that statement of intent, the machine displays a set of instructions that prescribe the actions to be taken, at a level of generality designed to ensure their relevance to any user, whatever the details of her particular situation. Ideally, the instructions tell the user what aspects of her particular situation are relevant for the execution of this plan through the machine\'s operation. By finding or producing the objects and actions described, the user anchors the general instructions to her unique circumstances.\r\nThis chapter looks at some of the consequences of taking a statement of intent and an ascribed plan as grounds for the interpretation of situated action. To anticipate, that strategy involves an insensitivity to particular circumstances that is both the system\'s central resource and its fundamental problem. I look first at the system\'s resources for construing the actions of the user; namely, plans and states. I then consider the problems posed for the designer by the user\'s principal resource, organized under the general rubric of situated inquiries, and by the user\'s ability to find the relevance of the system\'s response to those inquiries. Finally, I look at two classes of communicative breakdown, the false alarm\r\n\r\n128\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nand the garden path. Chapter 10 concludes with implications of the analysis for a general account of mutual intelligibility and for the particular requirements on the design of artifacts that would interact with their users.\r\nthe system\'s situation: plans and detectable states\r\nThe resources of the expert help system include a program that controls its behavior and sensors that register certain changes to its state effected by actions of the user. Initially, the user\'s response to a series of questions about her original documents and desired copies is taken as a statement of her intent, and that statement in turn determines the selection by the machine of one from a set of possible plans (see display 0, p. 169). The plan is then presented to the user in the form of a stepwise set of procedural instructions. The designer assumes that the plan matches the user\'s intent and that in following the procedural instructions the user effectively is engaged in carrying out the plan.\r\nThe design premise is further that as the user takes the actions prescribed by the instructions, those actions will change the state of the machine in predictable ways. By taking those changes to the machine\'s state as traces of the user\'s actions, the designer can effectively specify how the user\'s actions are to be recognized by the system and how the system is to respond. The instructions are grouped in a series of displays such that the last action prescribed by each display produces an effect that is detectable by the system, thereby initiating the process that produces the next display. The design assumption is that by detecting certain of the user\'s actions, the system can follow her course in the procedure and provide instructions as needed along the way.3\r\n\r\n3 Because instructions were sometimes read by the users differently from the way that they were actually written on the displays, the reader will find some inconsistencies between sequences and the displays to which they refer. The sequences comprise verbatim transcriptions of the users\' talk. Double quotes indicate that the user is reading an instruction from the display. The displays reproduce the visual presentation (both textual and illustrative) that the user finds on a video display terminal attached to the photocopier. This includes headings that identify the type of information offered (i.e., \"Assumptions,\" \"Overview,\" \"Instructions\"), the instructions themselves, and pictures of the copier and its parts. The boxed text at the bottom of each display (i.e., \"Change Task Description,\" \"Help,\" \"Start\") act as virtual \"buttons\" that, when selected by the user with the cursor provided, initiate an associated operation. \"Change Task Description\" returns the user to display 0, \"Help\" brings up a display that expands on the current instructions, and \"Start\" begins the copying operation. (Original footnote.)\r\n\r\nHuman­Machine Communication\r\n\r\n129\r\n\r\nThe strategy of tying certain machine states to the presentation of particular next instructions enables the appearance of machine responses occasioned by the user\'s actions. So, in this light, we can view the interaction between A and B in sequence I as the adept completion of what the design attempts. Specifically, A decomposes and re-presents the instructions provided by the system, such that they are fit more precisely to B\'s actions in carrying them out. A is able to do this because of her sensitivity to what B is doing, including B\'s troubles.\r\n\r\nsequence i. A and B are proceeding from a display that established their goal as making two-sided copies of a bound document. Two-sided copying requires an unbound document, so they must begin by making a master unbound copy of their document, using the \"Bound Document Aid\" or BDA.\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot Available to the Machine\r\n\r\nAvailable\r\n\r\nAvailable Design\r\n\r\nto the Machine to the User Rationale\r\n\r\nA: \"To access the BDA, pull the latch labeled Bound Document Aid\": (A and B turn to machine)\r\n(Points) Right there.\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document: Accessing the bound document aid.\r\n\r\nB: (Hands on latch)\r\n\r\nA: \"And lift up to the left.\" (Looks to B, who struggles with the latch) \"Lift up and to the left.\"\r\n\r\nB: (Still struggling)\r\n\r\nA: Okay::\r\n\r\nB: Pu::ll, and lift up to the left. (Looks at picture) Oh, the whole thing. [\r\n\r\nA:\r\n\r\nYea.\r\n\r\nB: Lift up and to the left.\r\n\r\nOpens BDA\r\n\r\n130\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nBelow is the procedure from sequence 1, as represented in the program that controls the display of instructions to the user:\r\n\r\nStep 1 Set Panel [display 1]\r\nStep 2: Tell User \"You need to use the Bound Document Aid . . . \" [display 2]\r\nStep 3: Tell User \"Place your original face down . . . Slide the document cover left . . . \" [display 3]\r\nStep 4: Make Ready. Step 5: Tell User \"Press Start.\" Requirements:\r\nPanel Set (If not, try Step I) RDH raised (if not, try Step 2) Document cover closed (if not, try Step 3) Ready State (if not, try Step 4) [display 4] Step 6: Complete printing Step. Requirements: Printing State (if not, try Step 5)\r\n\r\nRather than proceeding through the steps of the procedure consecutively, the system starts with the last step of the procedure, Step 6 in this case, and checks to see whether it is completed. A step is completed if a check of the machine\'s state confirms that the conditions represented by that step\'s requirements have been met. The requirements in this sense represent features of the system\'s situation (or, more accurately, of the system\'s own state) that are resources in determining an appropriate next instruction or action. When a requirement is found that is not met, a further set of specifications, tied to that requirement, sends the system back to an earlier step in the procedural sequence. The system then displays the instructions tied to that earlier step to the user until another change in state begins the same process again. Each time the user takes an action that changes the machine\'s state, the system compares the resulting state with the end state, returns to the first unfinished step in the sequence, and presents the user with the instructions for that and any subsequent step.\r\nThrough this simple device of working backward through the procedure, the presentation of redundant instructions can be avoided. In sequence II, having discovered that their original document is larger than standard paper, A and B decide to redo the job. They return to the\r\n\r\nHuman­Machine Communication\r\n\r\n131\r\n\r\nsequence ii. Again A and B are making two-sided copies of a bound document, this time with reduction. (The document is still on the copier glass; the document\r\ncover is closed.)\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nB: It\'s supposed to­ it\'ll tell \"Start,\" in a minute.\r\nA: Oh. It will?\r\nB: Well it did: in the past. (pause) A little start: box will:\r\nB: There it goes.\r\nA: \"Press the Start button\"\r\nOkay.\r\n\r\nselects start\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 1\r\n\r\nSelecting the proceedure\r\n\r\ndisplay 4\r\n\r\nReady to print\r\n\r\nstarts printing\r\n\r\njob specification display to select the reduction feature and then direct the machine to proceed.\r\nOn this occasion the system bypasses the instructions to raise the document handler, place the document on the glass, and close the document cover, all of which are irrelevant in that the actions they prescribe have already been taken. The system is able to act appropriately because a detectable machine state (the closed document cover) can be linked by the designer to an a priori assumption about the user\'s intent with respect to a next action (ready to press start). As a result, the system can be engineered to provide the appropriate next instruction in spite of the fact that it does not actually have access to the history of the user\'s actions or even to the presence or absence now of a document on the glass. The result is that although B predicts the system\'s behavior ­ specifically, that it will provide them with a \"Start button\" ­ based on her recollection of an occasion (sequence I) on which the system actually\r\n\r\n132\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nbehaved somewhat differently, her prediction holds. That is, just because on this occasion a relevant feature of the user\'s situation, accessible to the system, causes the system to behave differently, it appears to behave in the same (i.e., predictable) way. In human interaction, this graceful accommodation to changing circumstance is precisely what is expected and is therefore largely taken for granted. The success of the system\'s accommodation in this instance is evident in the accommodation\'s transparency to the users.\r\nOn other occasions, however, the mapping from a machine state to an a priori assumption about the user\'s intent, on which the success of sequence II rests, leads to trouble. I have said that given a statement of the user\'s goal (derived from answers to a series of questions about her originals and desired copies) the system initiates a plan and then tracks the user\'s actions by mapping state changes to a stepwise procedure bound to that plan. In sequence III, A and B have completed the unbound\r\n\r\nsequence iii. Again A and B are making two-sided copies from a bound document (this time having already completed their unbound master copy).\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot Available to the Machine\r\n\r\nAvailable\r\n\r\nAvailable\r\n\r\nto the Machine to the User\r\n\r\nDesign Rationale\r\n\r\nB: Okay, and then it\'ll tell us,\r\nokay, and:: It\'s got to come up with the little start thing soon. (pause)\r\nOkay, we\'ve done all that. We\'ve made our bound copies. (pause)\r\nA: It\'ll go on though, I think. Won\'t it?\r\n\r\ndisplay 1\r\n\r\nSelecting the procedure\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document: Accessing the Bound Document Aid\r\n\r\nB: I think it\'s gonna continue on, after it realizes that we\'ve done all that.\r\n\r\nHuman­Machine Communication\r\n\r\n133\r\n\r\nmaster copy of their document and have gone on to attempt to make their two-sided copies. They find that the page order in the copies is incorrect (a fault not available to the system, which has no access to the actual markings on the page), so they try again. As in sequence II, for them this is a second attempt to accomplish the same job, whereas for the machine it is just another instance of the procedure. On this occasion, however, that discrepancy turns out to matter.\r\nIn sequence II, the system\'s ignorance of the relation between this attempt to make copies and the last did not matter, just because a check of the current state of the machine caused the appropriate behavior. Or, more accurately, the \"current state\" of the interaction could be read as a local, technical matter independent of the embedding course of events. Here, however, a check of the machine\'s current state belies the users\' intent. To appreciate what they are doing now requires that the relation between this attempt and the last is recognized, and the machine state does not capture that relation. So although both users and system are, in some sense, doing the job again, there are two different senses of what, at this particular point, it means to do so. As far as the users are concerned, they are still trying to make two-sided copies of a bound document, so they leave their job description as such. For the machine, however, the appropriate description of their current goal, having made their master copy, is two-sided copying from an unbound document. The result is that what they in effect tell the machine they are doing is not what they intend to do, and what they intend to do is not available from the current state of the world as the machine is able to see it.\r\nA and B find evidence of this trouble in an extended silence (sequence IV), which suggests that the system is not going to proceed. What A and B discover here is that, from the system\'s \"point of view,\" their intent is determined by their initial statement: that is, to make two-sided copies from a bound document. Statements of intent, however, are inevitably relative to larger purposes and entail smaller ones, and although A and B\'s initial statement still accurately describes their global purpose, it belies their local one. Nor in this instance is their current situation (having failed successfully to produce the two-sided copies from their unbound master) reflected in the system\'s current state (ready to do two-sided copying from a bound original). Their current situation is available only through a history of which the system has no record or through their reports and assertions about their situation, to which the system has no access. Their attempt to make their situation accessible to the system by exploiting its insensitivity to their actual\r\n\r\n134\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence iv. (continued from III).\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot Available to the Machine\r\n\r\nAvailable\r\n\r\nAvailable Design\r\n\r\nto the Machine to the User Mationale\r\n\r\n(8-sec. pause) A: Then again,\r\nmaybe we need to change the task description.\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document\r\n\r\nB: What do you think? A: No.\r\n\r\nselects \"Change\"\r\n\r\ndisplay 0\r\n\r\nUser may want to change job description.\r\n\r\nB: Okay, \"Proceed.\"\r\n\r\nselects \"Proceed\"\r\n\r\ndisplay 1\r\n\r\nMaking two-sided copies from a bound document\r\n\r\nA: Maybe I should just lift it up and put it= [\r\n\r\ndisplay 2\r\n\r\nAccessing the Bound Document Aid\r\n\r\nB: How do we skip this then?\r\n\r\nA: =down again. Maybe it\'ll think we\'re done.\r\n\r\nB: (laughs) Oh, Jean.\r\n\r\nA: There.\r\n\r\nopens bda\r\n\r\nOkay, we\'ve done what we\'re supposed to do.\r\n\r\ndisplay 3\r\n\r\nInstructions for placing document\r\n\r\nHuman­Machine Communication\r\n\r\n135\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot available to the machine\r\n\r\nAvailable\r\n\r\nAvailable Design\r\n\r\nto the machine to the user rationale\r\n\r\nNow let\'s put this down. Let\'s see if that makes a difference. (Looks back to display)\r\n\r\ncloses bda\r\n\r\n(laughs) It did something.\r\nB: (inaudible) Good grief.\r\nA: Oh, it\'s still telling us we need to do a bound document. And we don\'t need to do the bound document because we\'ve done that. You know, maybe we ought to go back to the beginning, and erase that thing about the bound document.\r\nB: Okay, that\'s a good idea.\r\nA: Then say, \"Is it bound?\" just put no.\r\n\r\nselects \"Change\"\r\n\r\nB: Not anymore.\r\nA: And then everything else is constant, isn\'t it? It\'s on standard paper:: [\r\nB: so we\'ll proceed.\r\nA: So let\'s just proceed.\r\n\r\nselects \"No\"\r\nselects \"Proceed\"\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document\r\n\r\ndisplay 0\r\n\r\nUser may want to change job description.\r\n\r\nNew job; two-sided from unbound document\r\n\r\n136\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ncircumstances and \"faking\" the required action fails, but the failure is a failure in performance not in principle. Specifically, if they had opened and closed the document cover, rather than only the Bound Document Aid, they would in fact have achieved the desired effect.\r\n\r\nthe user\'s resource: the situated inquiry\r\nThe premise of a self-explanatory machine is that users will discover its intended use through information found in and on the machine itself, with no need for further instruction. In physical design, for example, the designer anticipates certain questions such that, in the event, an answer is there ready at hand. So the user\'s question \"Where do I grab?\" is answered by a handle fitted to the action of grabbing. In the traditional instruction manual, some further classes of inquiry are anticipated and answers provided. The stepwise instruction set addresses the question \"What do I do next?,\" and the diagram the question \"Where?\" In all cases, however, the questions anticipated and answered must be those that any user of the system might ask, and the occasion for both questions and answers is found by the user. It is this lack of recipient design in the written instruction manual that the expert help system is designed to redress.\r\nFor the novice engaged in a procedural task, the guiding inquiry is some form of the question \"What next?\" The question is an essentially indexical one, relying for its significance on the embedding situation. In the case at hand, the system effectively checks its own state to anticipate the user\'s question and then presents the next outstanding requirement of the selected procedure in response. This design strategy assumes that the job specification represents the user\'s intent, that the intent so represented determines the appropriate plan, and that user and system are engaged in carrying out the procedure for that plan.\r\nThe design assumption, in other words, is that the situation of the question \"What next?\" is just the procedure and that the question is a request for the next step. As long as that assumption holds, the presentation of a next instruction constitutes an appropriate response (see, for example, sequence I). The design assumption fails, however, in cases such as sequence V, where the question \"What next?\" is not a matter of proceeding with the current plan but of its abandonment or repair. This sequence is discussed further below, but, for the moment, the observation is simply that the question \"What do we do then?\" is not, in this instance, a simple request for a \"next\" in the sense of a next step in the\r\n\r\nHuman­Machine Communication\r\n\r\n137\r\n\r\nsequence v. C and D are making 5 two-sided copies of a bound document. (They are using the Bound Document Aid to make a single, unbound master copy\r\nof their original.)\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot Available to the Machine\r\n\r\nAvailable\r\n\r\nAvailable Design\r\n\r\nto the Machine to the User Rationale\r\n\r\nC: \"Instructions. Slide the document cover to the right.\"\r\nD: (Noting output) Okay, it gave us one copy here.\r\n\r\ndisplay 5\r\n\r\nInstructions for copying a bound document: removing the document from the glass.\r\n\r\nC: Okay, \"Slide the document cover right to remove the original.\"\r\n\r\nD: We\'re supposed to have 5 copies and we only got one.\r\n\r\nC: (Looks to output) Oh. (Looks to display) We only got one?\r\n\r\nD: Yea.\r\n\r\n(long pause)\r\n\r\nC: What do we do then?\r\n\r\n(Long pause, both study display)\r\n\r\nprocedure but rather is a request for a remedy to the current trouble. The situation of the inquiry (indicated anaphorically by the \"then,\" viz. \"given that we were supposed to have five copies and we only got one\") is not the procedure itself but the conflict between the apparent outcome of the procedure (a single copy) and their stated intent (five copies). That situation, although clearly described by D, is unavailable in the current state of the machine, which shows no evidence of their trouble. That is, the current state of the machine indicates just that a copy has been made, the design rationale being that they have copied the first page of\r\n\r\n138\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence vi. E and F are making two-sided copies of a bound document. (In response to the instruction to \"close the document cover\" (display 3), they have mistakenly closed the entire BDA instead, and as a consequence have returned to\r\nthe previous instruction to open the BDA (display 2).)\r\n\r\nThe Users\r\nNot Available to the Machine\r\nE: \"Pull the latch labeled­\" We did that. \"Raise­\" We did that. (Studying display) Okay. Okay.\r\nF: \"Lift up on the latch,\" We did that.\r\nE: Now let\'s change::\r\nF: \"Change task description?\"\r\nE: Yes.\r\nF:\r\n\"Describe the document to be copied­\" Oh, we already did: No, we don\'t want to do that.\r\nE: Maybe we have to do it to copy that. [i.e., the next page]\r\nF: (Looks around machine) (laugh) I don\'t know.\r\nE: Well::\r\nF: \"Help\" (laugh)\r\n\"Select the question you would like help with.\"\r\n\r\nThe Machine\r\n\r\nAvailable to Available Design the Machine to the User Rationale\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document\r\n\r\nselects \"Change\"\r\n\r\ndisplay 0\r\n\r\nUser may want to change job specification.\r\n\r\nselects \"Help\"\r\n\r\nUser needs clarification of display.\r\n\r\nHuman­Machine Communication\r\n\r\n139\r\n\r\nThe Users\r\nNot Available to the Machine\r\nE: I guess we still do have to= [\r\nF: We still ha­\r\nE: =answer this.\r\nF: Oh. okay, Alright.\r\nE: Okay.\r\nF: We sti­ but we did all that, didn\'t we?\r\nE: Well, maybe not for this page.\r\n\r\nThe Machine\r\nAvailable to Available Design the Machine to the User Rationale\r\n\r\nan unbound master copy of their bound document and are ready to go on to the second page.\r\nAs a consequence of the fact that the situation of their inquiry is not that which the design anticipates, and is not otherwise accessible to the system, the answer that the system offers ­ do the next step in this procedure ­ is inappropriate. Even in cases where the designer anticipates the need to remedy some trouble in the procedure rather than to go on to a next action, however, the context of a request for help may be problematic (sequence VI).\r\nThe selection of \"Change task description,\" in the context of a loop between display 2 and display 3, and E and F\'s subsequent surprise at the reappearance of display 0 in response, suggests that the intent of their action was not to return to the job specification but to find a next instruction. The inherent ambiguity between any next instruction as either a continuation or as the initiator of a repair is discussed at length below. Our interest here is in the situation of the request for help that follows the return to display 0. Specifically, the selection of the \"Help\" option constitutes a question about that return to display 0, and the larger problem of the loop in which it is embedded. The design, however, takes the situation of the request to be a local one: that is, as having to do with interpreting the contents of display 0 itself.\r\n\r\n140\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence vii. C and D are making two-sided copies of a bound document. (They first must make a single, unbound master copy using the BDA.)\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nC: \"You need to use the Bound Document Aid to make an unbound copy of your original.\" Where is­\r\nOh, here it is.\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 1\r\n\r\nOverview\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document: picture of the BDA.\r\n\r\nTied to the guiding inquiry \"what next?\" is a set of embedded questions about the prescribed actions ­ questions that look for clarification of the forms \"how,\" \"where,\" or \"to what,\" and \"why.\"4 The system\'s responsiveness to requests for elaboration turns again on whether the designer successfully predicts the inquiry. In sequence VII, C\'s question is actually interrupted by the change to display 2, which anticipates that very question. In this instance, it happens that the display change is timed to the mechanism that sets the machine\'s control panel rather than being conditional on any action of the user. Ironically, in part because on this occasion the system\'s behavior is determined not by the user\'s actions but by the internal processing of the system, it appears that the system\'s behavior is occasioned by the user\'s question.\r\nThe fact that the question anticipated turns out to be the user\'s question in this instance marks the success of the design. In sequence VIII, however, the designer\'s prediction fails. In this case, the designer anticipates a question regarding the motivation for the action, whereas the user\'s problem is with the action\'s object. In sequence IX, the question\r\n\r\n4 From the standpoint of the actor concerned with a procedural next, the other two logically possible queries, viz. \"by whom\" and \"when,\" are already answered by the embedding situation ­ though see sequences XVII and XXIII. (Original footnote.)\r\n\r\nHuman­Machine Communication\r\n\r\n141\r\n\r\nsequence viii. C and D are making two-sided copies from a bound document, using the BDA. (They have placed their document on the document glass.)\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\nAvailable to the Machine\r\n\r\nC: Okay, wait a minute. \"Slide the document cover left over your original until it latches.\" (Looks to machine)\r\n\r\nD: (Grasps BDA)\r\nC: The document cover­ (leans over to look in BDA)\r\nD: Oh. (Pulls on document feeder belt, which gives a little) No, no, no. (indicating entire BDA) This would be the document cover, isn\'t it?\r\nC: \"To provide an eyeshield for the copier (inaudible).\"\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 3\r\n\r\nCopying a bound document: Closing the document cover\r\n\r\nwhat is the object is anticipated, whereas B\'s question actually concerns how to do the action. The answer to B\'s inquiry is found not in the instruction, which locates the object, but in the object itself. Similarly, in sequence X a problem in interpreting an instruction is solved through a picture of the object on which the action is to be performed.\r\nWhen the object that B first takes to be implicated in the action description \"lift up and to the left\" resists her attempts to perform the action described, and the description suggests no other interpretation of the action, she finds in the picture a different object. That reinterpretation of the object, in its turn, revises the significance of the action description. In this way a conflict between the action on an object described by an instruction, and the action required by the object itself, can be a resource\r\n\r\n142\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence ix. A and B are making two-sided copies of an unbound document.\r\n\r\nThe Users\r\n\r\nThe Machine\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\nA: \"Place the copies:: on the top paper tray.\"\r\n\r\ndisplay 11\r\n\r\n[Portion omitted in which they locate the tray.]\r\n\r\nBeginning second pass of twosided copies\r\n\r\nA: Okay.\r\n\r\nB: But, (Turning back to display) How do you do that?\r\n\r\nA: (Looking at diagram) \"The top paper tray is to the right of the output tray.\" Place copies in the top paper tray,\" (Turning to tray) Oh, you just lift it up. (Does)\r\n\r\nfor identifying trouble in the interpretation of an instruction and its resolution, as in sequence XI.\r\nIn general, the referential relationship between instructions and the actions and objects they describe is a reciprocal, rather than directional, one. Burke (1982), for example, describes a pump assembly task in which to some extent all of the necessary information for assembling the pump is discoverable in requirements of the materials themselves, specifically the \"fit and stay\" bindings of one component of the pump to another. In spite of the constraints provided by the bindings, Burke noted a difference in confidence between those students who had additional linguistic instruction and those who did not, the former using the instructions, on the one hand, and the task actions and materials, on the other, as mutually informative, such that \"both the instructions and the task actions are treated by the apprentice as problems to be solved. But each is used as a resource to solve the other as a problem\" (ibid.: 178). That is to say, whereas instructions answer questions about objects and actions, they\r\n\r\nHuman­Machine Communication\r\n\r\n143\r\n\r\nsequence x. A and B are making two-sided copies of a bound document.\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nA: \"To access the BDA, pull the latch labeled Bound Document Aid\"::\r\n\r\n(A and B turn to machine)\r\n\r\n(Points) Right there.\r\n\r\nB: (Hands on latch)\r\n\r\nA: \"And lift up to the left.\" (Looks to B, who struggles with the latch) \"Lift up and to the left.\"\r\n\r\nB: (Still struggling)\r\n\r\nA: Okay::\r\n\r\nB: Pu::ll, and lift up to the left. (Looks at picture) Oh, the whole thing= [\r\nA: Yea.\r\n\r\nB: =lift up and to the left.\r\n\r\nOpens BDA\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document: Accessing the bound document aid.\r\n\r\nalso pose problems of interpretation that are solved in and through the objects and actions to which the instructions refer.\r\nA nice example of this reciprocity of description and action described is shown in sequence XII. In this case, rather than the interpretation of the instruction \"Pull the latch, etc.\" being prerequisite to the action\'s execution, the action after the fact clarifies what the instruction intends.\r\nGiven the requests for clarification that are potential responses to any directive, one can easily predict that any one or more of them might occur but not with any certainty which. The design of the expert help\r\n\r\n144\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xi. C and D have mistaken the entire BDA for the \"document cover\" and are caught in a loop between display 3 and display 2 (see also sequence VI).\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nD: Okay. \"Slide the document cover­ left over your original, until it latches.\" (Turns to machine) You know it says \"slide\" ­ this (Finds document cover). Okay.\r\nC: Ohh.\r\nD: (laughs) Ohh, isn\'t that hilarious? Okay. [\r\nC: Okay.\r\nIt was something else that was supposed to go over that.\r\n\r\nCloses cover\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 3\r\n\r\nInstructions for closing document cover\r\n\r\ndisplay 4\r\n\r\nsystem attempts to deal with the problem exhaustively and frequently succeeds. Questions of \"how,\" \"where,\" and \"why\" are answered by a diagram and supplementary description, provided with each next instruction. In all of these instances, however, the user brings the descriptions that the system provides to bear on the material circumstances of her action and brings those circumstances to bear on her interpretation of the descriptions. In other words, the user exploits the meaning of object and action descriptions to find their referents and uses the objects and actions picked out as resources for finding the significance of the description. Through access to these resources the user not only asks but also effectively answers her own situated inquiries.\r\n\r\nHuman­Machine Communication\r\n\r\n145\r\n\r\nsequence xii. E and F are making two-sided copies of a bound document.\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\nAvailable to the Machine\r\n\r\nF: \"To access the BDA, pull the latch labeled Bound Document Aid.\" (Both turn to machine)\r\nE: (Takes hold of latch)\r\nF: Pull it down: just push it down.\r\nE: (Does, BDA starts to open)\r\n\r\nF: (startled) Oh, alright.\r\nThis is what you do. E: Is this what you do?\r\nOh my gosh.\r\n\r\nOpens BDA\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document:\r\n\r\nAccessing the bound document aid.\r\n\r\ndisplay 3\r\n\r\nPlacing the document on the glass\r\n\r\nthe conditional relevance of response\r\nWe have seen how the responsiveness of the system is limited to those occasions where the user\'s actions effect some change in the machine\'s state, which ties the actions to the requirements of the underlying design plan. In principle, the design plan serves as the measure of what constitutes an adequate and appropriate action by the user; namely, one that satisfies the current procedural requirement. The requirements that the system imposes, in this procrustean sense, serve as prescriptions for successful use of the machine. The success assumes, however, that the user interprets the instructions and the system\'s responses in the way that the designer intended.\r\nIn the interest of conveying the intent of the design to the user, and in doing so interactively, the designer tacitly relies on certain conventions of human conversation. Most generally, designer and user share the expectation that the relevance of each utterance is conditional on the last; that given an action by one party that calls for a response, for example, the other\'s next action will be a response. The expectation does\r\n\r\n146\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nnot ensure that any next action in fact will be a response to the last, but it does mean that, wherever possible, the user will look for an interpretation of the next action that makes it so.\r\nThe user\'s expectation, in other words, is that each system response conveys, either implicitly or explicitly, an assessment of the last action she has taken and a recommendation for what to do next. More specifically, given some instruction to which the user responds with an action, the user has the following expectations with respect to the system\'s response:\r\n(a) The system\'s response should be a new instruction, which stands as implicit confirmation of the adequacy of the user\'s previous action.\r\n(b) If the system does not respond, the user\'s previous action is somehow incomplete.\r\n(c) If the system\'s response is to repeat the instruction, the repetition implies that the user\'s previous action should be repeated (i.e., that the procedure is iterative) or that there is some trouble in the previous action that should be repaired.\r\n\r\nA New Instruction Confirms the Previous Action\r\nWe have a general expectation, in carrying out a stepwise procedure, that completion of one action allows progress to a new instruction and a next action. The correlate of the expectation that a completed action indicates readiness for a new instruction is the fact that the appearance of a new instruction is taken, at least initially, as confirmation of the previous action. In sequence XIII, B\'s evidence for the adequacy of A\'s action is simply the fact that it generates a response, which is assumed to be a next instruction. The apparent change to a new instruction confirms the preceding action in spite of the fact that the action description, \"Slide the document cover,\" does not actually seem to fit the action taken. The action taken in fact is not closing the document cover, which is located inside the Bound Document Aid, but instead closing the Bound Document Aid itself. The assumption that display 2 must be a next to display 3, however, masks the fact that they are entering into a loop between those two displays (see also sequence VI).\r\n\r\nNo Response Indicates That the Previous Action Is Incomplete\r\nIn conversation, silences are more than just the absence of talk: they are generally owned by one party or another, and they invariably\r\n\r\nHuman­Machine Communication\r\n\r\n147\r\n\r\nsequence xiii. A and B are making two-sided copies of a bound document. They first must make a single, unbound master copy using the BDA.\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\nAvailable to the Machine\r\n\r\nB: Okay. \"Slide the document cover: left over your original, until it latches.\"\r\nA: (Moves hand to BDA)\r\nB: (Turns to machine) \"Slide the document cover,\" (Looks back to the diagram) that\'s this [i.e., BDA], Right?\r\nA: (Starts to close) We ­ it said left, though. (Looks to display)\r\nB: \"To close the document cover, grasp the cover,\r\nA:\r\nB: slide it firmly to the left.\"\r\n\r\ncloses bound document aid\r\n\r\n(You must) have done that.\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 3\r\n\r\nInstructions for closing document cover\r\n\r\ndisplay 2\r\n\r\nInstructions for opening Bound Document Aid\r\n\r\nacquire significance (see Chapter 7). The significance of silence lies in its relationship to the talk that it follows and, retrospectively, the talk that it can be seen to precede. In particular, the convention that certain utterance types (questions and answers being the canonical example) sequentially implicate the appropriate next utterance produces accountable absences when the next is not forthcoming. An extended silence\r\n\r\n148\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfollowing a question, for example, will be seen as a nonresponse. In the case of the expert help system, there is no response until the user completes the action prescribed by the final instruction of a given display. This design constraint, combined with the user\'s expectation from human interaction regarding sequential implicature and silence, means that the unresponsiveness of the system carries information. Specifically, when an action that is intended to satisfy a final instruction fails to elicit a response, the user takes the unresponsiveness as evidence for trouble in her performance of the action. In sequence XIV, for example, what C and D initially see as a pause comes to be seen, in virtue of its length, as a nonresponse. The nonresponse, in turn, carries information with respect to their last action. Specifically, the nonresponse indicates that this is still, in effect, their turn: that the last action was not, somehow, the action prescribed by this instruction. The evidence that the nonresponse provides ­ that there is some problem in the action taken ­ initiates a reinspection of the instruction, a reidentification of the instruction\'s object, and the action\'s repair.\r\nsequence xiv. C and D are making two-sided copies using the \"Recirculating Document Handler\" (RDH).\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nC: Okay, \"Remove the copies from the output tray.\" (Takes documents from document handler) Okay. Now:\r\n(15-second pause)\r\n(Turns to output) Oh, (Looks back to display)\r\nD: The output tray:\r\nC: This is the output tray.\r\nD: (Points to picture) That\'s the output tray, okay.\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 10\r\n\r\nCopies complete\r\n\r\nHuman­Machine Communication\r\n\r\n149\r\n\r\nRepetition Is Ambiguous Between Iteration and Repair\r\nThere are two conditions on which the system may repeat a prior instruction:\r\n(a) The action taken in response to the instruction should be repeated (the common case, for example, in a procedure that is iterative).\r\n(b) The action taken in response to the instruction is in error in just such a way as to return the system to a state prior to the instruction: in effect, to undo a previous action. This produces a loop.\r\nIn human interaction, (b) does not occur. However, in human interaction repetition is used in a way that does not occur between user and machine, namely, to indicate that:\r\n(c) The action taken in response to the instruction in some way fails to satisfy the intent of the instruction and needs to be remedied.\r\nConsistent with the observation that users import expectations from human interaction to construe the system\'s responses, users failed to recognize the occurrence of (b) and instead read all cases of repetition as either (a) or as (c).\r\n\r\nRepetition as iteration. In procedural instructions there are occasions, illustrated in sequence XV, on which the repeat of an instruction is to be taken at face value, as an explicit directive to do the previous action again.\r\nPurposeful action is characterized by the fact that its projected outcome is a resource for assessing the action\'s course. Where the procedure is a composite one, this function is complicated, however. For one thing, success at a composite procedure depends on reliable ways of discriminating between the procedure\'s outcome and its intermediate states. Particularly for the novice, the expectation that an embedded procedure (in this case, making the unbound master copy of the document) will produce the finished product leads to confusion like that of B in sequence XV, and to more complex misunderstandings, as shown in sequence XVI.\r\nComing to what they take to be the end of the iterative procedure described in display 6, C and D hypothesize that their part in the procedure is finished and that the next turn is the system\'s. That hypothesis is challenged by the system\'s inaction (a silence of eleven seconds), which suggests some incompleteness in their own action and something further for them to do. Their problem, then, is to find a \"next\"; that is,\r\n\r\n150\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xv. A and B are making two-sided copies of a bound document. They have copied the first page of the document, using the BDA.\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nB: \"If more pages are to be copied, then place the next page face down on the glass.\"\r\nA: Just keep it up until we\'re finished with the, with the, uh:\r\nB: Oh, well how do you ­ she was ­ she said on both sides, right?\r\nA: Well that\'s after we finish getting this (indicating document). We\'re just getting the originals to stick up here [i.e., RDH].\r\nB: Oh, you\'re right, you\'re right.\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 6\r\n\r\nIterative procedure for using the BDA\r\n\r\nsome action prescribed by the instructions that is outstanding.5 Given that problem, and its situation in the inherently ambiguous context of a procedure that is both recursive and composite (copying each page once until the end of the document so that the document can be copied five times), one possible solution is to see the persistence of this instruction as a repeat rather than a nonresponse and therefore as a directive to do the procedure again.\r\nIn another case, sequence XVII, the option \"Change task description,\" intended by the designer to enable a repair but noticed in the context of the search for a next turn, suggests iteration where the designer did not intend it.\r\n\r\n5 The outstanding instruction, in fact, is \"Lower the RDH until it latches.\" For the designer, that is the precondition for continuing on to the second pass of the procedure. For the users, however, under the assumption that the procedure is effectively completed, that could only be a sort of coda (like putting away the bowls once one has baked a cake), with no direct consequence for the outcome. (Original footnote.)\r\n\r\nHuman­Machine Communication\r\n\r\n151\r\n\r\nsequence xvi. C and D are making five two-sided copies of a bound document. They have completed the master copy using the BDA.\r\nUnaware of the composite structure of the procedure, and seeking to explain the fact that this procedure has produced only one copy, they have adopted the hypothesis that the remaining four copies are produced automatically,\r\nby the machine, and they are waiting for them to appear.\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\n\r\nD: \"Place the next page face down on the glass. Slide the document cover (inaudible). Lower the RDH until it latches.\" (pause) Okay\r\n(11-second pause)\r\nSo we start over for five? It doesn\'t do it (inaudible)?\r\nC: I guess we just have to do it five times, and then it\'ll: (pause) Do what it says, I guess.\r\n\r\nAvailable to the Machine\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 6\r\n\r\nIterative procedure for using the BDA: when RDH is lowered,\r\n\r\nUser is ready to go on to make multiple copies.\r\n\r\nIf E and F\'s objective in selecting \"Change task description\" is to find a next action, one way that they can make the system\'s response a relevant one is to interpret the return to display 0 iteratively, as telling them to specify their job again. The possibility, if not plausibility, of that interpretation arises from the fact that the difference between going \"backward\" to something already done in a procedure and going \"forward\" to repeat the action is inherently problematical. The difference does not lie in any features of the instruction or action itself, but just in whether the instruction\'s reappearance at a given time is read as a misunderstanding or as intended by the design. (See sequence VI above for the development of the problem.)\r\nFinally, the novice user may expect recursion in what is by design a one-pass procedure. C\'s action in Sequence XVIII of removing the first page of the document and replacing it with a second assumes that this procedure is iterative; viz. copy each page one at a time, until finished. Although taken as a next, however, her action restores a state that\r\n\r\n152\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xvii. E and F are in a loop between display 3 and display 2.\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nE: \"Pull the latch labeled­\" We did that. \"Raise­\" We did that. (Studying display) Okay. Okay.\r\nF: \"Lift up on the latch,\" We did that.\r\nE: Now let\'s change::\r\nF: \"Change task description?\"\r\nE: Yes.\r\nF:\r\n\"Describe the document to be copied­\" Oh, we already did: No, we don\'t want to do that.\r\nE: Maybe we have to do it to copy that [i.e., the next page].\r\nF: (Looks around machine) (laugh) I don\'t know.\r\n\r\nselects \"Change\"\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 2\r\n\r\nInstructions for copying a bound document: Raising the document handler.\r\n\r\ndisplay 0\r\n\r\nUser may want to change job specification.\r\n\r\nfrom the system\'s \"point of view\" appears identical to the state before the action was taken ­ a document in the document handler ­ thereby canceling the action\'s effect. For C, logically, the last page has been removed from the document handler and putting the next page in is prerequisite to going on. For the system there is just a document in the document handler, and its removal is required to go on.\r\nSeen as an instruction to undo their last action, the instruction to \"remove the original\" would stand as evidence of trouble. But by paraphrasing \"remove\" as \"move the first page to make a place for\r\n\r\nHuman­Machine Communication\r\n\r\n153\r\n\r\nsequence xviii. C and D are making four one-sided copies of an unbound document, using the RDH.\r\n\r\nNot Available to the Machine\r\nC: Okay, and face up, Right? First page?\r\n\r\nThe Users\r\n\r\nAvailable to the Machine\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 7\r\n\r\nInstructions for copying an unbound document: Place all originals in RDH.\r\n\r\n\"Press the Start button.\" Where\'s the Start button? (Looks around machine, then to display) D: (Points to display) Start? Right there it is. C: There. (laughs) D: Okay. C:\r\nTa: Oh, it comes right back out.\r\n\r\ndocument placed in rdh\r\n\r\ndisplay 8\r\n\r\nReady to print\r\n\r\nselects start\r\n\r\nstarts\r\ndelivers copies\r\n\r\nDocument is being copied\r\nJob complete\r\n\r\nremoves document\r\n\r\ndisplay 9\r\n\r\nRemoving originals\r\n\r\n(continued)\r\n\r\n154\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xviii (continued)\r\n\r\nThe Users Not Available to the Machine\r\nSo it made four of the first? (Looks at display) Okay.\r\n(Holding second page over the document handler, looks to display) Does it say to put it in yet? D: (inaudible) \"Remove the copies from the output tray.\" C: (inaudible) number two. (Puts second page into document handler)\r\n\"Remove the original­\" Okay, I\'ve re-I\'ve moved the original. And put in the second copy.\r\n\r\nAvailable to the Machine\r\ndocument placed in rdh\r\n\r\nThe Machine\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 10\r\n\r\nRemoving copies from the output tray.\r\n\r\ndisplay 9\r\n\r\nRemoving originals\r\n\r\nthe second,\" C makes this response relevant by turning it into a next, iterative instruction and therefore a confirmation of her last action. (For discussion of this sequence as a \"garden path,\" see below.)\r\nRepetition as repair. The inclination to see each next instruction as a new instruction means that a repetition might not initially even be recognized as such. Recall that this was the case in sequence XIII. In fact, this is another instance of the loop described for sequence VI. Specifically,\r\n\r\nHuman­Machine Communication\r\n\r\n155\r\n\r\nin sequence XIII mislocation of the object referred to as the \"document cover\" leads B to close the entire Bound Document Aid, an action that returns the system to its initial state and causes it to redisplay the first instruction; namely, to open the BDA.6 The design rationale that produces this system response is simple: (i) the user must use the BDA to copy bound documents; (ii) to use the BDA, it must be opened; (iii) if the BDA is closed, the user should be presented with instructions for opening it. However, rather than taking the return to the previous instruction as evidence for some problem in their last action, A and B see it as a next instruction and as confirmation.\r\nThe inclination to mistake a return to a previous instruction for a next can be appreciated by considering the anomalous character of this particular problem in terms of any parallels in human interaction. Although repetition of the first part of an adjacency pair is justified in cases where there is no response, when a response does occur it terminates the sequence and provides for the relevance of a next. Insofar as the user believes her action constitutes a response to the current instruction, then, she has every reason to view the system\'s next turn as a next instruction. The closest situation that one finds in human interaction to the loop in human­machine communication occurs when a response to a sequentially implicative utterance ­ the answer to a summons, for example ­ is not recognized as such:\r\nAs noted, upon the completion of the SA [summons­answer] sequence, the original summoner cannot summon again. The operation of this terminating rule, however, depends upon the clear recognition that an A has occurred. This recognition normally is untroubled. However, trouble sometimes occurs by virtue of the fact that some lexical items, e.g., \"Hello,\" may be used both as summonses and as answers. Under some circumstances it may be impossible to tell whether such a term has been used as a summons or as answer. Thus, for example, when acoustic difficulties arise in a telephone conversation, both parties may attempt to confirm their mutual availability to one another. Each one may them employ the term \"Hello?\" as a summons to the other. For each of them, however, it may be unclear whether what he hears in the earpiece is an answer to his check, or the other\'s summons for him to answer. One may, under such circumstances, hear a conversation in which a sequence of some length is constituted by nothing but alternatively and simultaneously offered \"hellos.\" Such \"verbal dodging\" is typically resolved by the use, by one party, of an item on which a second is conditionally relevant, where that second is unambiguously a second part of a\r\n\r\n6 Fortuitously, the action that the BDA suggests, just because it returns the machine to a previous state, is the only action other than that which the design intends to which the system would respond at all at this point. (Original footnote.)\r\n\r\n156\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ntwo-part sequence. Most typically this is a question, and the question \"Can you hear me?\" or one of its common lexical variants, regularly occurs. (Schegloff 1972: 366)\r\nRecognized as such, a return to a previous instruction that cannot be construed as recursive is evidence for trouble. Sequence XIX is another instance of the same misunderstanding that we saw in sequence XIII.\r\nIn human interaction, when the response to an action is either incoherent or inappropriate, the producer of the original action has recourse to two possible interpretations. She can treat the troublesome response as the product of an error on the listener\'s part (not hearing or mishearing, not understanding or misunderstanding) or as intended. If the troublesome response is seen as the product of some failure of hearing or understanding, the repair may be just to repeat the original action (see Coulter 1979: 30). Unless the trouble is one of hearing, however, we rarely repeat a directive verbatim if there appears to be some problem\r\n\r\nsequence xix. E and F are making two-sided copies of a bound document. They first must make a single, unbound master copy using the BDA.\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\n\r\nF: \"Slide the document cover over your original until it latches.\"\r\nE: (Hand on BDA) F: Just push it down. E:\r\nOkay, here we go. (turns to display) \"Pull the latch la­\" Oh, we already did that.\r\n(pause. They study display)\r\nE: Okay.\r\nF: Okay.\r\n(7-second pause) Now what do we do?\r\n\r\nAvailable to the Machine\r\n\r\nThe Machine\r\nAvailable Design to the User Rationale\r\ndisplay 3\r\n\r\ncloses BDA\r\n\r\ndisplay 2\r\n\r\nHuman­Machine Communication\r\n\r\n157\r\n\r\nsequence xx (continued from XIX).\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nE: \"Pull the latch labeled­\" We did that. \"Raise­\" We did that. (Studying display) Okay. Okay.\r\nF: \"Lift up on the latch,\" We did that.\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 2\r\n\r\nof understanding the first time around. Instead, we try some reformulation or elaboration. If one formulation fails to convey our intended meaning, we try another. Frequently it is not simply that we try an alternative formulation of what we intended before, but that what we intend is conditional on the other\'s response. In that sense, our own intentions are clarified for us by the response of the other.\r\nIn every case, to the extent that we are heard to be repeating ourselves, the repeat is heard as an attempt to correct some problem in understanding the first time around (see Jordan and Fuller 1975). Seen in this light, as a repair-initiator, repetition initiates a review of the repeated instruction. In sequence XX, a review of the instruction confirms that the actions it prescribes have been done. The two alternative responses to the repeat, in that case, are either to assert that the action is complete or to do it again. In face-to-face interaction these alternatives appear to be ordered; that is, we first assert that we have heard a prior utterance and responded to it and then, if the assertion does not suffice, we provide a demonstration. Realizing that in communication with the machine assertions never suffice, that the system has access only to demonstrations or actions, is part of acquiring proficiency in its use.\r\nActually redoing an action frequently uncovers problems of understanding, not just because the same terrain is considered again, but because, considered again, the terrain is seen differently, as in Sequence XXI. However, when a review fails to reveal any new actions,\r\n\r\n158\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xxi. Another case of the loop between display 2 and display 3.\r\n\r\nThe Users\r\nNot Available to the Machine\r\nB: \"Pull the latch labeled bound,\" \"Raise the RDH.\" \"To access the BDA, pull the latch labeled Bound Document Aid,\" Okay, (Gesture to latch, then back to display) we did.\r\nA: Yea.\r\nB: \"And lift up to the left,\" do it again\r\nA:\r\nThere. (To display) I\'m lifting up to the left.\r\nB: Okay. \"Place your original face down on the glass, centered over the registration = [\r\nA: \"guide,\" Okay. [\r\nB: =guide.\"\r\nA: Did that.\r\nB: \"Slide the document co­\"\r\nA: \"cover left over= [\r\nB: Wait a minute. A: =your originals,\"\r\nWell:\r\n\r\nAvailable to the Machine\r\n\r\nThe Machine\r\n\r\nAvailable to the User\r\n\r\nDesign Rationale\r\n\r\ndisplay 2\r\n\r\nopens to bda\r\n\r\ndisplay 3\r\n\r\nHuman­Machine Communication\r\n\r\n159\r\n\r\nThe Users\r\nNot Available to the Machine\r\nB: Here\'s the document glass, (Indicating BDA) is that what they mean?\r\nA: (Looking at BDA) Document cover.\r\nB: \"To close the document cover, grasp the cover and slide it firmly to the left.\"\r\nA: (Finding it) Oh, here\'s the document cover!\r\nB: Oh, Jean, good girl! A: There\'s the document­\r\n(Both turn back to display)\r\nOkay now: [\r\nB: Allright: \"Press: the Start button.\" Jean, you\'re doin\' great. (Both look to BDA)\r\nA: Oh, I see,\r\nB: Alright. A: We don\'t have\r\nto close this big thing. B: No, we were­ we were lookin\' at the wrong thing. We were closing the bound document aid, instead of the: A: instead of the document cover.\r\n\r\nAvailable to the Machine\r\ncloses document cover\r\nselects \"Start\"\r\n\r\nThe Machine Available Design to the User Rationale\r\ndisplay 4 machine starts\r\n\r\n160\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsequence xxii. Again, another case of the loop between display 2 and display 3\r\n\r\nThe Users\r\n\r\nNot Available to the Machine\r\n\r\nAvailable to the Machine\r\n\r\nC: (inaudible, rereads instructions) Okay, are we ready? \"Pull the latch labeled bound ­ to release.\" and then you release:: the, uh, RDH (inaudible.) Okay, are we ready?\r\n\r\n(pause)\r\n\r\nOh, it\'s supposed to do it by itself.\r\n\r\n(pause)\r\n\r\nThe Machine\r\nAvailable Design to the User Rationale\r\ndisplay 2\r\n\r\none reasonable inference is that the next action must be the other\'s. In Sequence XXII, C\'s review indicates that the actions prescribed by the instructions have all been completed; the sense of her \"ready\" here is as in \"ready to go.\" There appears to be nothing further for them to do. Because the logical next step is for the machine to copy the document, C concludes that it must do so without further action on their part. Concluding that it is the system\'s turn offers an alternative to the original interpretation of the repeat as an indication that their action is somehow incomplete. If the system is in fact responding to their last action, that both confirms the action\'s adequacy and accounts for the system\'s failure to provide a next instruction. The length of time that passes with no apparent activity, however, casts doubt on that conclusion, as the system\'s silence takes on the character of a nonresponse. If the system is not responding, there must be some further action for them to take. In sequence XXIII, they again attempt to read the repetition as a directive to repair some problem in the action as it was done the first time through. C\'s \"why\" here is a locally situated one; that is, she is not asking in general about the rationale for this instruction but in particular about its intent now, given their history and present circumstances. Although the answer provided is intended to justify the instruction on any occasion, she attributes to it a significance particular to this occasion. Because their inquiry is situated in their particular circumstances, the\r\n\r\nHuman­Machine Communication\r\n\r\n161\r\n\r\nsequence xxiii (continued from XXII).\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\nAvailable to the Machine\r\n\r\nC: \"Pull the latch labeled bound copy aid to release the ­ RDH\r\nD: (Points) This is the RDH. This [i.e., the latch] is the release.\r\nC: But why does it want it to release it? (To display) \"Release (inaudible) to enable placement of the bound document on the glass,\" so we don\'t have that on the glass like it\'s supposed to be.\r\n\r\nThe Machine\r\nAvailable Design to the User Rationale\r\ndisplay 2\r\n\r\nanswer is taken as an answer to that occasioned inquiry. Specifically, C reads the \"to enable\" clause as relevant to the directive that they release the RDH again, to allow a repair of some fault in the document\'s placement. This attributes to the system substantially greater sensitivity than it has; namely, the ability to tell how the document is sitting on the glass and to notice that it is faulted in some way. Under this interpretation of the design, the directive to re-place the document would be conveyed by re-presenting this instruction to the user until the document is placed correctly. This interpretation not only accounts for the loop in which they\'ve found themselves but also suggests the way out of it.\r\n\r\ncommunicative breakdowns\r\nUsers of the expert help system encounter two forms of communicative breakdown: the false alarm and the garden path. In the first case, a misconception on the user\'s part leads her to find evidence of an error in her actions where none exists; in the second, a misconception on the user\'s\r\n\r\n162\r\n\r\nHuman­Machine Reconfigurations\r\n\r\npart produces an error in her action with respect to the prescribed procedure, the presence of which is masked. In neither case is the breakdown available as such to the system.\r\n\r\nThe False Alarm\r\nI noted earlier that purposeful action is characterized by the fact that projected outcomes of action are a resource for producing the action\'s course. In particular, the effects of actions taken are compared against expected outcomes to judge the action\'s adequacy. Expectations with respect to the effect of actions taken often are not articulated, but are discovered only in the breach. In sequence XXIV the machine offers the users two competing pieces of evidence regarding the adequacy of their last action. The display offers a next instruction, which makes sense as a confirmation of their previous action. The output, however, indicates that the action has failed, in which case the next instruction is irrelevant. From the system\'s \"point of view,\" nonetheless, there is no problem. And because the system detects no problem here, it offers no prescription for a remedy. The result is an interactional impasse, where the question \"What do we do then?\" finds no answer. Or rather, the answer that the system provides makes sense only if what the users intend to do is to continue making a single copy from a bound document.7\r\nWhereas from the point of view of the design that is precisely what they want to do, that intent is not a feature of their situation. Their situation, meanwhile ­ that they intended to produce five copies of the document and have produced only one ­ is unavailable to the system. The consequence is that the users ascribe a (spurious) misunderstanding of their intent to the machine, whereas the machine fails to detect the (genuine) misunderstanding on their part with respect to the structure\r\n\r\n7 The problem here is one of intermediate states vs. outcomes. The procedure for twosided copying requires use of the RDH, but use of that mechanism requires an unbound original. As a consequence of that mechanism constraint, the first pass of the procedure for copying a bound document is directed at producing one, unbound, master copy of the document. This requires a procedure of copying each page, using the BDA, until there is one complete set to be put into the RDH. Although an overview of the procedure was presented in display 1, designed to correct the assumption that this first pass would produce the desired outcome directly, the overview evidently did not do so. D\'s statement of the problem demonstrates their continuing confusion, but the fact that the confusion is unavailable to the system precludes what would be a second chance for the misconception\'s repair. (Original footnote.)\r\n\r\nHuman­Machine Communication\r\n\r\n163\r\n\r\nsequence xxiv. C and D are making two-sided copies of a bound document. They have copied the first page.\r\n\r\nNot Available to the Machine\r\n\r\nThe Users\r\n\r\nC: \"Instructions. Slide the document cover to the right.\"\r\nD: (Noting output) Okay, it gave us one copy here.\r\nC: Okay, \"Slide the document cover right to remove the original.\"\r\nD: We\'re supposed to have 5 copies and we only got one.\r\nC: (Looks to output) Oh. (Looks to display) We only got one?\r\nD: Yea. (long pause)\r\nC: What do we do then?\r\n(long pause, Both study display)\r\n\r\nAvailable to the Machine\r\n\r\nThe Machine\r\n\r\nAvailable Design to the User Rationale\r\n\r\ndisplay 5\r\n\r\nCopying a bound document: Opening the document cover.\r\n\r\nof the procedure. The result is their effort to repair a line of action that is in no way faulty.\r\n\r\nGarden Path\r\nTo the extent that different assumptions of users and designers produce evidence of misunderstanding, there is at least some hope that the trouble might be located and resolved. We looked above at two events taken by users as evidence of trouble: namely, the nonresponse and the repeat. As in sequence XXIV, false expectations with respect to an\r\n\r\n164\r\n\r\nHuman­Machine Reconfigurations\r\n\r\naction\'s effect may lead the user to find evidence for trouble in her performance where, in design terms, none exists. Because in such cases the problem lies in the user\'s expectations (as expressed in her talk) rather than in her (machine-readable) actions, and because the evidence for her expectations that the user provides is unavailable to the machine, the problem itself is unavailable to the machine.\r\nAlthough the user is uncertain of her action in such cases, the action she takes is in fact the action that the design prescribes. Deeper problems arise when the user takes an action other than that prescribed by the design, but one that satisfies the procedural requirement. As a result of the ambiguity of the action\'s effect, the incorrect action is actually \"mistaken\" by the system for some other, correct action, from which it is indistinguishable by the system\'s sensors. As in XXIV, the problem in such cases is inaccessible to the system. But whereas in XXIV the misconception leads the user to find evidence of trouble where, by design, none exists, in these other cases trouble is masked by the fact that the user sees the action as nonproblematic, and by the fact that because the action appears nonproblematic to the system as well, the system\'s response appears to the user to confirm the action.\r\nTake the example in Sequence XVIII above. From the system\'s \"point of view,\" this sequence produces no evidence of trouble. Display 7 instructs the users to place their documents in the Recirculating Document Handler (RDH) and the system\'s sensors \"see\" them do so; display 8 instructs them to press Start; they do, and the machine produces four copies of their document. To a human observer with any knowledge of this machine, however, C\'s question \"So it made four of the first?\" indicates a misunderstanding. Specifically, her question conveys the information that this in fact is not a single-page document but the first page of several. And in contrast to other machines that require the placement of pages on the glass one at a time, copying an unbound document of multiple pages with this machine requires loading the pages all at once.8 The problem here is not simply a failure of anticipation on the designer\'s part. On the contrary, in anticipation of this very situation, the instruction for loading documents explicitly states that all of the pages should\r\n\r\n8 This is an interesting case of the early introduction of an \"innovative\" design feature onto the market. The 8200 copier was one of the first, outside of copy shops, to offer an automatic document feeder (the Recirculating Document Handler), a feature that consequently was unfamiliar to most users.\r\n\r\nHuman­Machine Communication\r\n\r\n165\r\n\r\nbe placed in the document handler. There is no evidence, however, that the instruction is consulted by these users.\r\nOne basic premise of instructions is that they explicate a problem of action: if there is no problem, there is logically no need for instruction. We can infer from the users\' failure to consult the instructions at this point that they have a preconception about what to do, based on past experience. Such preconceptions probably account in large part for the common complaint from designers that people \"ignore\" instructions; they ignore them because they believe that they already know how to proceed. But given the fact of the users\' misconception, the further problem arises when the faulted action goes by unnoticed at the point where it occurs. It does so because what is available to the system is only the action\'s effect, and that effect satisfies the requirements for the next instruction. As an assertion in the form of a question, C\'s statement \"So it made four of the first?\" not only formulates her view of the system\'s last operation, but also requests confirmation of that formulation. Interactionally, her statement provides an occasion for the discovery of the misunderstanding. She even looks to the display for a response. The information provided there is ambiguous enough, however ­ it simply says, \"The copies have been made\" ­ to support her assertion rather than challenge it. As a consequence, the misunderstanding displayed in C\'s question is unavailable to the system, whereas the ambiguity of the system\'s response masks the trouble for the user.\r\nC\'s action of placing the document in the document handler appears, in other words, to be a perfectly adequate response to display 7. The system treats the action as satisfying the directive to place all of the documents in the document handler (where \"all\" in this case comprises one) and therefore provides a next instruction, whereas C and D take the appearance of the next instruction as confirmation that their last action, placing the first page of their document in the document feeder, satisfied the design intent. The start-up of the machine, with no complaint about their prior action, reflects the fact that the directive to \"Start\" has two different, but compatible interpretations. For the users, the significance of the directive is \"make four copies of page 1,\" whereas for the system it is just \"make four copies of the document in the document handler.\" There is nothing in either display 9 or display 10 to indicate the discrepancy. Each is ambiguous enough to be read under either interpretation.\r\nSo at the point where the machine starts to print, C is making four copies of page 1 of her document, whereas the machine is just making\r\n\r\n166\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfour copies of the document in the document handler. This seems, on the face of it, a minor discrepancy. If the machine copies the document, why should it matter that it fails to appreciate more finely the document\'s status as one in a set of three? The problem lies in the consequences of this continuing misunderstanding for the next exchange. The strength of C\'s conception of what is going on (repeating the procedure for each page) provides her with a logical next action (loading her second page into the document handler) in advance of any instruction. The instruction is looked to for confirmation of her action rather than for direction. Her certainty is evident in the terms of the question \"Does it say to put it in yet?\" The deictic pronoun \"it\" with respect to the system as \"next speaker,\" and to the second page as the object of the instruction, the \"in\" with respect to the location of the action, and the \"yet\" with respect to the time of the action, all imply a shared situation that would make the interpretation of those indexical terms nonproblematic. For C, that the instruction will appear and what it will say is not in question ­ only when is in question. Although C is going on to the next run of the procedure, however, the system is still engaged in the completion of the last. What remains is the removal of originals and copies from their respective trays.\r\nThe \"misunderstanding\" between users and system at this point turns on just what the document in the document handler is and how it got there. For C, a first page has been replaced by a second, a necessary step for the next pass of what she takes to be a recursive procedure. For the system, there just is a document in the document handler, and its removal is required for the procedure\'s completion. The result is an impasse wherein both user and system are \"waiting for each other,\" on the assumption that their own turn is complete.\r\nThe instruction to \"Place all of your originals in the RDH\" must be designed for any user who might come along on any occasion. The designer assumes that on some actual occasion the instruction, in particular the relative quantifier \"all,\" will be anchored by the particular user to a particular document with a definite number of pages. Under the assumption that the user will do that anchoring, the system just takes the evidence that something has been put into the RDH as an appropriate response and takes whatever is put there as satisfying the description. On one hand, this means that the system can provide the relevant instruction in spite of the fact that it does not have access to the particular identities of this user or this document. On the other hand, the system\'s\r\n\r\nHuman­Machine Communication\r\n\r\n167\r\n\r\ninsensitivity to particulars of this user\'s situation is the limiting factor on its ability to assess the significance of her actions.\r\n\r\nsummary\r\nThis analysis has tied the particular problem of designing a machine that responds appropriately to the actions of a user to the general problem of deciding the significance of purposeful action. The ascriptions of intent that make purposeful action intelligible and define a relevant response are the result of inferences based on linguistic, demonstrative, and circumstantial evidence. I have argued that one way to characterize machines is by the severe constraints on their access to the evidential resources on which human communication of intent routinely relies. In the particular case considered here, the designer of the expert help system attempts to circumvent those constraints through prediction of the user\'s actions and detection of the effects of actions taken. When the actual course of action that the user constructs proceeds in the way that the design anticipates, effects of the user\'s actions can be mapped to the projected plan and the system can be engineered to provide an appropriate response.\r\nThe new user of a system, however, is engaged in ongoing, situated inquiries regarding an appropriate next action. Although the instructions of the expert help system are designed in anticipation of the user\'s inquiries, problems arise from the user\'s ability to move easily between a simple request for a next action, \"meta\" inquiries about the appropriateness of the procedure itself, and embedded requests for clarification of the actions described within a procedure. In reading the machine\'s response to her inquiries and taking the actions prescribed, the user imports certain expectations from human communication; specifically, that a new instruction in response to an action effectively confirms the adequacy of that action, whereas a nonresponse is evidence that the action is incomplete. In the case of repeated instructions, an ambiguity arises between interpreting the repetition as a straightforward directive to repeat the action or as a directive for its repair. A further problem arises when the action that the user takes in response to an instruction is in error in just such a way as to return the system to a state prior to that instruction. Because this trouble does not arise in human interaction, new users initially fail to recognize the occurrence of such a loop.\r\n\r\n168\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nBecause of the constraints on the machine\'s access to the situation of the user\'s inquiry, breaches in understanding, that for face-to-face interaction would be trivial in terms of detection and repair, become \"fatal\" for human­machine communication (see Jordan and Fuller 1975). In particular, misconceptions with regard to the structure of the procedure lead users to take intermediate states of the procedure as faulted outcomes. Because the intermediate state is nonproblematic from the system\'s point of view, the system offers no remedy. The result is an interactional impasse, with the user finding evidence of trouble in her actions where none in fact exists. In the case of the garden path, in contrast, the user takes an action that is in some way faulted, which nonetheless satisfies the requirements of the design under a different but compatible interpretation. As a result, the faulty action goes by unnoticed at the point where it occurs. And at the point where the trouble is discovered by the user, its source is difficult or impossible to reconstruct.\r\n\r\nHuman­Machine Communication\r\n\r\n169\r\n\r\n170\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nHuman­Machine Communication\r\n\r\n171\r\n\r\n172\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nHuman­Machine Communication\r\n\r\n173\r\n\r\n174\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nHuman­Machine Communication\r\n\r\n175\r\n\r\n10\r\nConclusion to the 1st Edition\r\nThe theme of the original text of Plans and Situated Actions was in one sense an obvious proposition, that insofar as actions are always situated in particular social and material circumstances, the situation is crucial to action\'s interpretation. The very obviousness of this fact about action contributes to the ways in which it has been overlooked. The intellectual tradition of the cognitive sciences, in particular applied logic, has taken abstract structural accounts as the ideal representational form. An adequate account of any phenomenon, according to this tradition, is a formal theory that represents just those aspects of the phenomenon that are true regardless of particular circumstances. This relation of abstract structures to particular instances is exemplified in the relation of plans to situated actions. Plans are taken to be either formal structures that control situated actions or abstractions over instances of situated action, the instances serving to fill in the abstract structure on particular occasions. The research strategy in cognitive science has been to represent mental constructs, such as goals or plans, then stipulate the procedures by which those constructs are realized as action or recognized as the actor\'s intent. The specification of procedures for action, in turn, has presupposed enumeration of the conditions under which a given action is appropriate. These stipulated conditions, ready made and coupled to their associated actions, take the place of a lively, moment-by-moment assessment of the significance of particular circumstances.\r\nIn contrast to this cognitivist view, I have proposed an alternative approach drawn from recent developments in the social sciences, principally anthropology and sociology. The aim of research, according to this approach, is to explore the relation of knowledge and action to the\r\n176\r\n\r\nConclusion to the 1st Edition\r\n\r\n177\r\n\r\nparticular circumstances in which knowing and acting invariably occur. This alternative approach requires corresponding changes in the way in which research on purposeful action proceeds. The first is a fundamental change in perspective, such that the contingency of action on a complex world of objects, artifacts, and other actors, located in space and time, is no longer treated as an extraneous problem with which the individual actor must contend but rather is seen as the essential resource that makes knowledge possible and gives action its sense. The second change is a renewed commitment to grounding theories of action in empirical evidence; that is, to building generalizations from records of particular, naturally occurring activities and maintaining a theory\'s accountability to that evidence. Finally, and perhaps most importantly, this approach assumes that the coherence of action is not adequately explained by either preconceived cognitive schema or institutionalized social norms. Rather, the organization of situated action is an emergent property of moment-by-moment interactions between actors and between actors and the environments of their action.1\r\nThe emergent properties of action mean that it is not predetermined but neither is it random. A basic research goal for studies of situated action, therefore, is to explicate the relationship between structures of action and the resources and constraints afforded by material and social circumstances.2 Ethnomethodology begins from the premise that we need, and have yet to produce, an adequate base of descriptions of situated human practices.3 Because there is no stable observational base, the social sciences \"are talking sciences, and achieve in texts, not elsewhere, the observability and practical objectivity of their\r\n\r\n1 The sense of \"emergent\" here is not meant to invoke its current usage in the context of robotics and complexity theory (of which I at least was unaware in the mid-1980s) but simply a sense of something arising out of ongoing activity, enacted rather than predetermined.\r\n2 Here I would avoid the use of the term structure, with its connotations of an overly a priori and fixed normativity. A more performatively inflected way of phrasing this would be that the significance of actions is inseparable from their enactment in situ, in relation to the social and material circumstances which they in turn help to create.\r\n3 I would add now that there never can be an \"adequate base of descriptions\" in any comprehensive or definitive sense but only with respect to particular purposes at hand. Further, insofar as ethnomethodology assumes that formulations of any kind are of interest only in their relations to lived practice, the aim of studies is not theory-building but rather respecification ­ a retelling that articulates practices in situ. More generally, ethnomethodological studies radically problematize conventional assumptions regarding the relation between theory and its objects. See Lynch 1993, 2001; Garfinkel 2002; Garfinkel and Sacks 1970.\r\n\r\n178\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nphenomena\" (Garfinkel, Lynch, and Livingston 1981: 133). As Heritage has recently stated the problem: \"The `boundaries\' of specific, located ordinary actions, their `units\' or `segments,\' the determination of adequacy in their description or representation ­ all of these questions and many more pose problems which cannot be resolved `in principle\' but which require solution in the context of practical engagement with descriptive tasks\" (1984: 302).\r\nIn this study I have attempted to begin constructing a descriptive foundation for the analysis of human­machine communication.4 A growing corpus of observations from the analysis of everyday human conversation provides a baseline from which to assess the state of interactivity between people and machines. First, the mutual intelligibility that we achieve in our everyday interactions ­ sometimes with apparent effortlessness, sometimes with obvious travail ­ is always the product of in situ, collaborative work. Second, the general communicative practices that support that work are designed to maximize sensitivity to particular participants on particular occasions of interaction. Third, face-to-face communication includes resources for detecting and remedying troubles in understanding as part of its fundamental organization. And fourth, every occasion of human communication is embedded in, and makes use of, an unarticulated background of experiences and circumstances.5 Communication in this sense is not a symbolic process that happens to go on in real-word settings but a real-world activity in which we make use of language to delineate the collective relevance of our shared environment.\r\nThe application of insights gained through research on face-to-face human interaction, in particular conversation analysis, to the study of human­computer interaction promises to be a productive research path.6 The initial observation is that interaction between people and\r\n\r\n4 Again, I would now prefer to say that the aim of the analysis in Plans and Situated Actions was a respecification of the problem of human­machine communication; a new telling, in different terms, aimed at a different understanding.\r\n5 Importantly, this is not meant to suggest that the \"background\" could somehow be fully explicated. Rather, it comprises an open horizon of possibly relevant prior experiences and present circumstances that can be explicated to the extent that is necessary, desirable, or adequate for practical purposes. See the account of Garfinkel\'s exercise regarding the specification of background knowledge in Chapter 5 above.\r\n6 The productivity of this approach depends, of course, on just how lessons learned from face-to-face human interaction are brought to bear. The critique offered in the preceding pages should lend weight to arguments against efforts at direct simulation of human interactional competencies in the machine (see Button 1990). Rather, insights from conversation analysis can serve as indicators of potential design problems and\r\n\r\nConclusion to the 1st Edition\r\n\r\n179\r\n\r\nmachines requires essentially the same interpretive work that characterizes interaction between people, but with fundamentally different resources available to the participants. In particular, people make use of a rich array of linguistic, nonverbal, and inferential resources in finding the intelligibility of actions and events, in making their own actions sensible, and in managing the troubles in understanding that inevitably arise. Today\'s machines, in contrast, rely on a fixed array of sensory inputs, mapped to a predetermined set of internal states and responses. The result is an asymmetry that substantially limits the scope of interaction between people and machines. Taken seriously, this asymmetry poses three outstanding problems for the design of interactive machines: first, the problem of how to lessen the asymmetry by extending the access of the machine to the actions and circumstances of the user; second, the problem of how to make clear to the user the limits on the machine\'s access to those basic interactional resources; and finally, the problem of how to find ways of compensating for the machine\'s lack of access to the user\'s situation with computationally available alternatives.\r\n\r\ntoward practical solutions\r\nIn the design of interactive machines the most common substitute for access to the user and her situation has been the incorporation into the machine of a preconceived representation of the user and her situation or a \"user model.\" User models, constructed in advance as the template against which the user\'s actual actions are mapped, comprise propositions about the domain, the task, the typical user, and the like. Recently, designers concerned with the provision of situated help, or socalled intelligent tutoring systems, have begun extending such models to support local or \"real-time\" assessment of the actions of the computer user (see Burton and Brown 1982; London and Clancey 1982; Woolf and McDonald 1983; Farrell, Anderson, and Reiser 1984; Peachey and McCalla 1986; Shrager and Finin 1982). A primary objective of such systems is to infer the user\'s knowledge and misconceptions about the system by observing her actions rather than relying on either error conditions or explicit requests for help. To appreciate the requirements of this objective, one has simply to imagine those occasions where an expert, watching a novice engaged in some activity, would be moved to\r\ninspiration for solutions, which then are best addressed through the affordances that particular artifacts (input devices, graphical displays, and the like) afford. See Luff, Gilbert, and Frohlich 1990; Thomas 1995.\r\n\r\n180\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nintercede. The outstanding question with respect to this form of coaching is \"Just what does seeing those places where assistance is called for, and knowing what needs to be said, involve?\" Researchers pursuing \"real-time user modeling\" as the basis for a solution to this problem have adopted the following design strategies:\r\n(1) Diagnosis based on differential modeling. A principal strategy for socalled intelligent tutoring systems, or computer-based coaches, has been to work from an ideal model of expert behavior in a given domain, to which the actions of the student can be mapped.7 It is then the difference between expert and student behavior in particular circumstances that serves as the basis for assessing the student\'s knowledge and skills. The diagnosis works both on manifested errors that arise in the course of the student\'s actions and, more subtly, on the omission of actions that, given a particular set of conditions, an idealized expert in those circumstances would take. The rationale for the differential modeling strategy is a combination of predictions based on the model of expert behavior, with techniques for local assessment of the student\'s actions. The success of the strategy turns on the degree of fit between the actions anticipated by the diagnostic model and the actions of the student that are detectable by the machine.\r\n(2) Detection of diagnostic inconsistencies. However felicitous the fit between student actions and diagnostic issues, the design must accommodate the likelihood of misdiagnosis and provide for its detection and repair. In the best intelligent tutoring systems, the accumulating record of student actions includes both actions that manifest some issue that according to the current diagnosis should not appear and actions that fail to manifest some issue that the student seems from prior diagnosis to understand. Evidence of misdiagnosis is found in the amount of \"tear\" or inconsistency in the accumulating record of student actions.8 When the disparity between the developing diagnostic model of what the student knows and doesn\'t know and the understanding demonstrated in subsequent actions reaches a certain threshold, the program may invoke alternative strategies that the student might be using. Possible alternative strategies, identified according to local evidence, are then tested for consistency with the global history of the student\'s actions.\r\n\r\n7 For a critical survey of the state of the art in intelligent tutoring systems at the time, see Wenger 1987.\r\n8 The notion of \"tear,\" and many other subtleties now beginning to be incorporated in the design of computer-based coaches, originates in Burton and Brown\'s work on WEST (1982). (Original footnote)\r\n\r\nConclusion to the 1st Edition\r\n\r\n181\r\n\r\nCrucially, the domain must be sufficiently closed that the set of possible alternative strategies can be enumerated.\r\n(3) Separation of local and global interpretations. Recent tutoring systems begin to make use of a mechanism basic to everyday human communication, namely, the separation and productive interaction between local and global interpretations of the other\'s actions. The diagnosis of student actions in computer-based tutoring systems is accomplished through two independent though interrelated mechanisms: one component that is data driven from the local context of a given action and another that runs over an accumulating history of the student\'s actions with the goal of identifying weaknesses or misunderstandings. As in the interpretation of action in the course of a developing conversation, it is the interaction of these two perspectives that affords the power of the diagnosis. The locality of the data-driven component supports an assessment of each particular action, relatively unconstrained by global preconceptions, whereas the global perspective of the evaluative component supports the interpretation of that action as a reflection of the student\'s general strategies and skills.\r\n(4) The constructive use of trouble. In much the way that ordinary conversation relies on the successful detection, repair, and even exploitation of troubles in understanding, recent tutoring systems adopt a \"constructivist position\" toward errors, such that the inevitability of student misconceptions or weaknesses is turned to pedagogical advantage (Burton and Brown 1982). The goal of the coach in such systems is not to avoid student errors but to make them accessible to the student and therefore instructive. If the student has enough information to identify and repair an error, then it is considered a constructive one. If, on the other hand, the error is not manifest in such a way as to be visible, or is perceived but the student lacks the necessary information for its repair, the trouble is nonconstructive. One major task of the coach, on this view, is to give the student the information required to transform nonconstructive troubles into constructive ones, either by diagnosing the trouble and making it accessible or by providing the information required for its repair.\r\nThis last strategy has recently been generalized as a call to design for the management of trouble (see Brown and Newman 1985). Such an objective implies at least that users are encouraged to use the wider social setting in which a machine is embedded as a resource to remedy the troubles in understanding that inevitably arise. Applied to the design of machines, this recommends incorporating the kind of diagnostic and interactional abilities that characterize the human coach into\r\n\r\n182\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthe machine itself. The problem in applying this later recommendation is that often the \"grain size\" of machine-readable actions is either too small or too large to constrain the analysis of the user\'s actions adequately. So, for example, in the case of the help system examined in Chapter 9, to appreciate the significance of a given user action ­ say, putting a document into the document handler ­ may require reference to a history that extends across procedures as the system tracks them. Alternatively, assessing the user\'s actions may require reference to subprocedures, such as ordering pages of a document correctly, for which there is no trace. In general, if there is more than one understanding that can produce what appears to be the same action, detecting the action does not serve as unequivocal evidence that the understanding is actually in hand. By the same token, if a given skill can be manifest in some indefinite number of different actions, then the absence of an expected action does not necessarily mean the absence of the skill. While in the case of the human coach these ambiguities are resolved through interaction, in the case of a computer-based coach the limits on the machine\'s access pose a difficult design problem. The problem is not simply that communicative troubles arise that do not arise in human communication but rather that when the inevitable troubles do arise, there are not the same resources available for their detection and repair.9\r\n\r\nplans as resources for action\r\nSome researchers in human­computer interaction make the claim that cognitive science and computer technologies have advanced to the point where it is now feasible to build instructional computer systems that are as effective as experienced human tutors (see, for example, Anderson, Boyle, and Reiser 1985). In contrast to this optimism, I have argued that there is a profound and persisting asymmetry in interaction between people and machines, due to a disparity in their relative access to the\r\n9 Although this discussion locates strategies for the solution of the problems identified in the previous chapters in various approaches to the design of so-called intelligent tutoring systems, or \"help\" systems more generally, I would now take a rather different tack. Along with ongoing efforts to develop the art of interface design, the problem of human­machine communication suggests what is at once a more modest and a more radical approach. That is to abandon the attempt to create the \"self-explanatory\" machine in favor of encouraging social arrangements that provide for the necessary time and resources needed to incorporate unfamiliar artifacts effectively into relevant forms of practice. This latter strategy shifts the focus away from the interface narrowly defined and, in so doing, implicates much broader and more profound forms of social change. I return to approaches that adopt this strategy, as various projects in participatory or cooperative design, in Chapter 15.\r\n\r\nConclusion to the 1st Edition\r\n\r\n183\r\n\r\nmoment-by-moment contingencies that constitute the conditions of situated interaction. Because of the asymmetry of user and machine, interface design is less a project of simulating human communication than of engineering alternatives to interaction\'s situated properties. The primary alternative has been to substitute a generalized representation of the situation of action for access to the details of the user\'s particular situation. As in the expert help system analyzed in Chapter 9, the representational scheme favored by many designers has been the plan. The problem for designers is that, as commonsense formulations of intent, plans are inherently vague. To the cognitive scientist, this representational vagueness is a fault to be remedied insofar as a plan is the prerequisite for purposeful action, and the details of action are derived from the completion and modification of the plan. The task of the designer who would model situated action, therefore, is to improve on, or render more precise and axiomatic, the plan.\r\nFor situated action, however, the vagueness of plans is ideally suited to the fact that the detail of intent and action must be contingent on the circumstantial and interactional particulars of actual situations. Given this view of plans, namely, as resources for action rather than as controlling structures, the outstanding problem is not to improve on them but to understand what kind of resource they are. The most promising approach is to begin from the observation that plans are representations or abstractions over action.10 In one sense, this simply joins the problem of plans to the more general, and no less difficult, question of representation. But in another sense, viewing plans as representations is suggestive of what their relation to unrepresented actions might be.\r\nChapter 6 introduced a view, developed recently by Barwise and Perry (1985), that language can be characterized in terms of its efficiency and indexicality. By efficiency is meant simply the ways in which \"expressions used by different people, in different space­time locations, with different connections to the world around them, can have different interpretations, even though they retain the same linguistic meaning\" (ibid.: 5). In its efficiency, language provides us with a shareable resource for talk about the world. At the same time, the efficiency of language\r\n\r\n10 My phrasing here might suggest that I see this kind of reconceptualization as sufficient, but I would emphasize now that this is simply a starting place from which to pursue investigations of how plans, as orienting devices that work in multiple ways are created and used in practice (see Chapter 11). I am grateful to Eevi Beck for having pointed out the potential misreading of this statement and urging me to emphasize the importance of empirical studies. For a study of the fluid nature of rules and agreements in collaborative writing practices, see Beck (1995).\r\n\r\n184\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nrequires that our utterances always be anchored to the unique and particular occasions of their use. In this respect, language is indexical; that is, dependent for its significance on connections to particular occasions and to the concrete circumstances in which an utterance is spoken. This view of language is taken as foundational by Garfinkel (1967) and Garfinkel and Sacks (1970) with respect to the intelligibility and significance of action.\r\nLike other linguistic representations, plans are efficient formulations of situated actions. By abstracting uniformities across situations, plans allow us to bring past experience and projected outcomes to bear on our present actions. As efficient formulations, however, the significance of plans turns on their relation back to the unique circumstances and unarticulated practices of situated activities. A problem for an account of situated action, on this view, is to describe the processes by which efficient representations are brought into productive interaction with particular actions in particular environments. A rich description of this process comes, for example, from research on Micronesian navigation reported by Edwin Hutchins (1983).11 The natives of the Caroline Islands routinely embark on ocean-going canoe voyages that take them several days out of the sight of land. Western researchers traveling with them have found that at any time during the voyage the navigators can indicate the bearings of the port of departure, the target island, and other islands off to the side of the course they are steering, even though these may all be over the horizon and out of sight. They are able to do this and other feats of navigation that are simply impossible for a Western navigator without instruments. What Hutchins reports is that they maintain their course by substituting other environmental referents, that are accessible, for the inaccessible land. In particular, they follow a star path, selected with reference to a sidereal compass or star chart that forms a map between pairs of islands. To maintain their orientation to the star path at any given point in their voyage requires that they consult not only the stars, but also a rich set of changing environmental circumstances ­ the color of the water, the waves, winds and clouds, birds, and so forth ­ which through experience become interpretable for information about the relative position of the canoe. What is notable about Hutchins\'s account of the resources of the Micronesian navigator is that nowhere is a preconceived plan in evidence. The basis for navigation seems to be, instead, local interactions with the environment. In\r\n\r\n11 See also Gladwin (1970), Turnbull (1990, 2000), Lewis (1972), Hutchins (1995).\r\n\r\nConclusion to the 1st Edition\r\n\r\n185\r\n\r\nthis way, navigators maintain their orientation to the star path, which in turn is fixed to the islands of origin and destination.\r\nThe Micronesian example demonstrates how the nature of an activity can be missed unless one views purposeful action as an interaction between a representation and the particular, contingent details of the environment. With respect to plans and actions, Feitelson and Stefik (1977) found this same relation present in the work of geneticists planning scientific experiments. Specifically, they found that geneticists elaborated their plans only far enough to act as a framework in which to organize the constraints of the laboratory. Rather than planning the experiment through an a priori analysis, the experimenters decided what to do next by relating each current observation to their research goals. The experimenters\' expertise lay not in completing the plan but in the ability to generate hypotheses continually and to exploit serendipity in the course of the experiment. The experimental process, being what Feitelson and Stefik call \"event driven,\" allowed the experimenter to \"fish for interesting possibilities\"; that is, to follow up on unanticipated observations and opportunities provided by a particular experimental setup.\r\nFrom these and other examples, we can begin to draw an alternative account of the relation of plans to situated actions. The foundation of actions by this account is not plans but local interactions with our environment, more and less informed by reference to abstract representations of situations and of actions and more and less available to representation themselves. The function of abstract representations is not to serve as specifications for the local interactions but rather to orient or position us in a way that will allow us, through local interactions, to exploit some contingencies of our environment and to avoid others. Although plans can be elaborated indefinitely, they elaborate actions just to the extent that elaboration is useful; they are vague with respect to the details of action precisely at the level at which it makes sense to forego abstract representation and rely on the availability of a particular, embodied response.\r\nThe interesting problem for an account of action, finally, is to describe how it is that we are able to bring efficient descriptions (such as plans) and particular circumstances into productive interaction. The assumption in planning research in cognitive science has been that this process consists in filling in the details of the plan to some operational level. But when we look at actual studies of situated action, it seems that situated action turns on local interactions between the actor and contingencies that, although they are made accountable to a plan, remain essentially\r\n\r\n186\r\n\r\nHuman­Machine Reconfigurations\r\n\r\noutside of the plan\'s scope. Just as it would seem absurd to claim that a map in some strong sense controlled the traveler\'s movements through the world, it is wrong to imagine plans as controlling actions. However, the questions of how a map is produced for specific purposes, how in any actual instance it is interpreted vis-a`-vis the world, and how its use is a resource for traversing the world are both reasonable and productive.12 In the last analysis, it is in the interaction of representation and represented where, so to speak, the action is.13 To get at the action in situ requires accounts not only of efficient, symbolic representations but also of their productive interaction with the unique, unrepresented circumstances in which action in every instance and invariably occurs.\r\nA starting premise of this book was that the project of building interactive machines has more to gain by understanding the differences between human interaction and machine operation than by simply assuming their similarity. My argument has been that as long as machine actions are determined by stipulated conditions, machine interaction with the world, and with people in particular, will be limited to the intentions of designers and their ability to anticipate and constrain the user\'s actions.14 The generality of various representations of situations and actions is the principle resource for this task, whereas the context insensitivity of such representational schemes is the principle limitation. The question, finally, is \"What are the consequences of that limitation?\" The answer will differ according to whether our concern is with practical or theoretical consequences. Practically, ingenious design combined with testing may do much to extend the range of useful machine behavior. Theoretically, understanding the limits of machine behavior challenges our understanding of the resources of human action. Just as the project of building intelligent artifacts has been enlisted in the service of a theory of mind, the attempt to build interactive artifacts, taken seriously, could contribute much to an account of situated human action and shared understanding.\r\n\r\n12 For an illuminating treatment of the relation of maps to territories, see Turnbull (1993). 13 This phrase is echoed in Dourish\'s (2001) syncretic review of revisions to cognitivist\r\nthinking about action in the computer and information sciences. 14 This refers, of course, to those \"programs of action\" that are inscribed in the machine\'s\r\ndesign: the latter by no means limit the range of possible appropriations for technologies in use (Akrich 1992; Latour 1992; Woolgar 1991). The limits to designers\' configuration of the possibilities for technologies in use result not simply in user \"misunderstanding\" but in a wide range of creative appropriations, which have since been explored through a large, and still growing, body of work in social studies of technology (for a recent collection see Oudshoorn and Pinch 2003).\r\n\r\n11\r\nPlans, Scripts, and Other Ordering Devices\r\nI have argued that to treat a plan ­ or any other form of prescriptive representation ­ as a specification for a course of action shuts down precisely the space of inquiry that begs for investigation; that is, the relations between an ordering device and the contingent labors through which it is produced and made reflexively accountable to ongoing activity. Naturalizing plans as representations (mental or otherwise) existing prior to and determining of action obscures the status of planning as itself a form of culturally and historically situated activity, manifest in specific practices and associated artifacts. Taking plans as artifacts, in contrast, recommends a research agenda dedicated to examining the heterogeneous practices through which specific ordering devices are materialized, mobilized, and contested, at particular times and places, with varying effects.\r\nThis latter agenda, fortunately, has progressed along multiple paths in recent years, through the detailed investigation of plans and a plethora of other artifacts involved in social ordering. I can give only an indicative survey of that work here, but it will be sufficient, I hope, to demonstrate the generative lines of inquiry underway. I begin with the question of instructed action in the domain described in the immediately preceding chapters, that of the human­machine interface and its \"scripting,\" and then expand the frame to consider a wide range of what John Law has designated as the \"modes of ordering\" (1994) involved in the (re-)production of complex sites of sociotechnical agency. These include practices of categorization, standardization and coordination, studied through the interests of ethnomethodology, science and technology studies, and information system design.\r\n187\r\n\r\n188\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nconscripting the user\r\nAs a site of both human­machine contact and potential misconnection, the \"user interface\" has been a problematic object since its emergence along with the personal computer and graphical display in the 1970s.1 Bannon (1991) has drawn attention to the various ways in which the technical system defines the point of reference for professional design discourse, beginning with the term user itself, in its identification of persons exclusively through their instrumental relations to machines. Critiques of the term from within the design literature point out that \"the user\" singularizes what is actually a multiplicity and fails to differentiate actors with very different relations to a given artifact. Yet as Agre (1995) observes, for programmers immersed in the closed worlds of system development, \"it becomes difficult to imagine the perspective of somebody who does not view a computer system as a logical anatomy, an ontology made of datastructures, a set of formal relationships and constraints, and a network of paths for data to move along. Since the programmer is imaginatively inside the system, the very concept of a user interface can be difficult to grasp or take seriously\" (ibid.: 73). Viewed from the position of the designer, the interface assumes a machine that is given or at least in hand, whereas its user remains in need of discovery and specification.\r\nAt the same time, prevailing organizational arrangements present the designer with systematic barriers to contact with prospective system users. Marketers fear that developers\' contact with users will trouble the company\'s image; and developers themselves are bound by contracts that require fixed, predefined specifications, which discussion with prospective users would complicate. Off-the-shelf packages, the received wisdom goes, are by definition designed for users not known or knowable in advance. Rather than being taken as challenges to be addressed through innovations in the design process, these conditions are offered as justification for design as usual within the closed confines of the development organization. The parochialism of professional design, Agre concludes, is \"deeply and multiply determined by the material and discursive organization of contemporary technical practices\" (1995: 77).2 Insofar as entrenched arrangements of product\r\n\r\n1 For critical histories, see Cooper and Bowers (1995), Grudin (1990). 2 See also Suchman (1994a, 2002a, 2002b). It continues to be the case in professional\r\ncomputer systems design that the user interface is routinely treated as something to be worked out once the system functionality is defined, and user interface design is\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n189\r\n\r\ndevelopment systematically separate professional designers from prospective technology users, a range of proxy figures have been devised to fill the gap. Experimental subjects are taken to speak on behalf of people encountering technologies in their everyday lives, and human subjects are increasingly replaced, or at least augmented, by scenarios and personae ­ synthetic and imaginary use settings and technology users drawn from more and less extensive encounters with indicative persons and sites. Manageable within the \"time and money\" constraints of an increasingly intensified competitive market for new products and services, these stories and characters stand in for more distal and unruly sites and subjects.3\r\nWoolgar has famously explored professional practices of computer system development under the trope of \"configuring the user\" (1991; Grint and Woolgar 1997). More fundamentally, insofar as the project that Woolgar observed involved the design of an early microcomputer, he proposes that the project contributed, inter alia, to the construction of The User as a social category. By this he means not only the question of who the user of the personal computer might be but also what would be the extent and limits of the actions available to her or him. It is in this latter sense, he proposes, that \"by setting parameters for the users\' actions, the evolving machine attempts to configure the user\" (Grint and Woolgar 1997: 71). Woolgar\'s study follows a product development project with a particular focus on the \"usability trials\" carried out in its later stages. Boundaries were enacted in his study through the stories that his informants told him regarding the user, turning on who had legitimate knowledge of the latter within the company, as well as reported attempts to initiate the idea of going \"out to visit users\" and the resistances met (ibid.: 76). Within the company, Woolgar\'s informants reported to him, knowledge about the user was differentially distributed. Those who were positioned as aligned with users (for example, technical writers\r\n\r\ncorrespondingly positioned on the periphery, and typically in the later stages, of the design process. This despite compelling demonstrations among those committed to more \"user-centered\" design practices of the intimate connections between definitions of functionality and substantive understanding of settings and practices of use. 3 It is important to emphasize that there is no solution to the problem of distance between professional design and technologies-in-use, only different strategies for addressing it. Among other things, these involve different translations of designer and user across the multiple sites in which technologies are configured. For an illuminating study of the \"techniques of virtuality\" that enable design in the midst of complex sociotechnical networks, and in the absence of end users, see Newman (1998). I discuss more radical design/use reconfigurations in Chapter 15.\r\n\r\n190\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ncharged with producing documentation or technical support staff charged with helping customers) complained of the lack of knowledge about users among their engineering counterparts. The latter, however, expressed a general caution against taking users\' views too seriously, given their outsider status; without understanding the technology they couldn\'t know what they really wanted. Given the inadequacies of any specific user, moreover, the suggestion was that design should respond instead to ideas about \"where the market was going,\" or even \"where things were going\"; that is, to a more generalized \"vision\" of the future of computing (ibid.: 78). Based on these stories, Grint and Woolgar propose that rather than a misplaced singularity, references to \"the user\" within the company in part comprised \"a generalized formulation produced for purposes of establishing contrasts between insiders and outsiders\" (ibid.: 77).\r\nTo maintain the boundaries of proprietary knowledge regarding the emerging machine, usability trials were conducted with \"subjects\" recruited from within the company. The search then was for persons who could arguably be positioned as representative of a larger class, irrespective of their status as company insiders; that is, for \"novices.\" Woolgar\'s account goes on to detail usability designers\' struggles with engineers over getting an instantiation of the machine taken to be \"real\" enough; that is, close enough to what uninitiated users would recognized as something that they might encounter in their day-to-day lives. This involved importantly a machine that had been \"enclosed\" into a casing rather than left with its insides exposed as the engineering prototypes were (ibid.: 80). In this respect, Grint and Woolgar propose, as the trial \"subjects\" stood as proxies for the user as outsider, the interior of the machine was reiterated as the domain of the engineer as company insider.\r\nThe sense of configuring developed by Grint and Woolgar is not of the user as an individual actor, however, but rather the incorporation of the user into the sociomaterial assemblage that comprises a functioning machine. The trials themselves were centered on the documentation, \"defining the correct courses of interpretation and action to be followed\" by prospective users (ibid.: 84). In recounting the incident of Ruth, a subject asked to connect a printer to the PC being tested using (as it turned out) a plug designed for a previous model, Grint and Woolgar write: \"An adequate interpretation will make the instructions, the printer and Ruth herself all part of the (larger) machine. That is, in the event of a successful outcome, these entities can be said to stand in an adequately\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n191\r\n\r\nconfigured relation to the machine\" (ibid.: 90). Moreover, as a participant in a trial, Ruth is further oriented to the project of displaying her actions as being in accordance with what the observers expect; in that respect the latter are incorporated into the configuration as well. In this sense, user configuration involves further boundary work, as \"the user\'s character, capacity and possible future actions are structured and defined in relation to the machine\" (ibid.: 92).\r\nBut just how specific and determining is the user\'s configuration, in either design imaginaries or specific situations of use? Woolgar suggests that we adopt the metaphor of \"machine as text\" as a methodological strategy in considering this question, insofar as the machine\'s inherent interpretive flexibility recommends the analogy of design as writing to reading as use. The aim of the metaphor is to destabilize the machine as object, to treat the design/use relation as an uncertain and problematic one, and to open the latter to investigation. Dorothy Smith has a vision of the sociological text (the artifact of sociologist-as-designer) that is relevant here, as a text that is \"conscious of its necessary indexicality and hence that its meaning remains to be completed by a reader who is situated just as [the writer] is ­ a particular woman reading somewhere at a particular time amid the particularities of her everyday world ­ and that it is the capacity of our sociological texts, as she enlivens them, to reflect upon, to expand, and to enlarge her grasp of the world she reads in, and that is the world that completes the meaning of the text as she reads\" (Smith 1987: 106). Applied to artifacts more generally, this perspective orients us to an embodied user, located in a particular, actual, historically constituted site. Moreover, this user is in important respects herself a designer.4 It is not only a machine\'s users who are multiple, in other words, but also the artifact itself. I return to this point below.\r\nAkrich (1992) offers another inquiry into the question of whether and how the composition of a device constrains its uses. Methodologically, she proposes, we need to find cases where the alignment between the constraints that the object effects and the ways in which it can be put to use is problematic. For this she turns to cases of \"technology transfer,\" specifically from industrial societies to \"less developed countries\"\r\n\r\n4 The essential, if largely invisible, role of technology \"users\" in the design of technical systems has been well argued. See, for example, Clement (1993, 1994), Hales (1994). For discussions of cooperation among professional and user designers, see Clement and Van den Besselaar (1993), Greenbaum and Kyng (1991), Schuler and Namioka (1993), and for further discussion of this issue see Chapter 15.\r\n\r\n192\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n(LDCs).5 Objects, she proposes, make subjects; a premise that brings Akrich to the notion of \"scripts\" and of technology use as a process of \"de-scription.\" Like Woolgar, she ascribes to the \"script\" both specificity and scope: \"Designers thus define actors with specific tastes, competences, motives, aspirations, political prejudices, and the rest, and they assume that morality, technology, science, and economy will evolve in particular ways. A large part of the work of innovators is that of `inscribing\' this vision of (or prediction about) the world in the technical content of the new object. I will call the end product of this work a `script\' or a `scenario\'\" (ibid.: 208). Once the artifact is displaced into sites of use, she argues, the work of the user becomes one of \"de-scription,\" of recovering from the object a coherent programme of action (see also Latour 1992: 255). Akrich develops this proposal through the case of photoelectric lighting kits developed in France and exported to Africa. Various design decisions aimed at ensuring that the kits were \"foolproof,\" and would work under all circumstances, turned out instead to render the kits unworkable in the particular sites to which they needed to be, but could not be, adapted. The kit, Akrich concludes, \"represented a large set of technically delegated prescriptions addressed by the innovator to the user\" (1992: 211), but the user so addressed was absent, whereas the users who were present were unable to find themselves and their circumstances within the script.\r\nAlthough the tropes of \"configuration\" and \"de-scription\" have been tremendously generative and are widely cited within the STS literature, they also, on my reading, raise a set of further questions. Both, despite their careful attention to the contingencies of design and use, leave in place an overrationalized figure of the designer as actor, and an overestimation of the ways and extent to which definitions of users and use can be inscribed into an artifact. Akrich underscores the analogy to the film script: \"Thus, like a film script, technical objects define a framework of action together with the actors and the space in which they are supposed to act\" (ibid.: 209). I would suggest however, that the differences between design and film scripts could be just as instructive, if not more, than the comparison. As I believe both Akrich and Woolgar would readily agree, there is no stable designer/user \"point of view\" nor are imaginaries of the user or settings of use inscribed in\r\n\r\n5 See also de Laet and Mol (2000). It has by now become clear, however, that we do not need to travel to find these phenomena: the uncertainties of alignment and fluidity of artifacts are a ubiquitous aspect of design­use relations in more familiar settings as well.\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n193\r\n\r\nanything like a complete or coherent form in the object.6 For tropes of configuration and descripting to align with their subjects and objects, I am suggesting, we need to see the designer\'s view of the user as at once more specific and less. More in that it is specifically located within the various sites, imaginaries, exigencies, and practices that comprise professional design and less in that artifacts are characterized by greater open-endedness and indeterminacy with respect to the question of how they might be incorporated into use. The \"user\" is, in other words, more vaguely figured, the object more deeply ambiguous. It is to the question of the strategic vagueness of scripts, and the indeterminacies of their enactment, that I turn next.\r\n\r\naction according to procedure\r\nIn \"On Formal Structures of Practical Action,\" Garfinkel and Sacks (1970) develop the argument that lived practice inevitably exceeds the enframing moves of its own procedures of order production. That this is the case, they observe, is not first and foremost a theoretical problem for sociology but rather a practical problem for everyday life, solved pragmatically by members of the society in ways good enough for their purposes at hand. Their observation treats as problematic how it is that members of the society nonetheless achieve an alignment between often contradictory ordering devices and the exigencies of heterogeneously enacted and intrinsically indefinite events. To address this topic ethnomethodologically is to eschew received dichotomies of rational action and its alternates; that is, the ad hoc, bricolage, improvisation, or the like (Lynch 1993: 267). Rather than sorting activities into one category or the other, ethnomethodology recommends a \"bracketing\" of these dichotomies, treating the differences that they imply as an effect of the practices in question rather than as resources for the analyst. Action according to procedure, accordingly, is understood \"as identities assigned (often retrospectively) to conjoint activities constructed\r\n6 Agre (1995) directs attention to the body of literature associated with labor process studies of computerization, as documenting the limits on the extent to which a given technology can ever prescribe its use. He includes reference to a study of numerically controlled machine tool operators who appropriated programming facilities meant for changes and bug fixes by professional programmers to customize their machines (Wilkinson 1983, cited p. 71; for the defining history see Noble 1984). He observes that this literature serves as well as a resource for understanding the rationalities involved in user resistance, insofar as new technology initiatives carry political and economic agendas not traditionally beneficial to workers.\r\n\r\n194\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nlocally, with every detail standing as a detail within a here-and-now assemblage that surpasses any general definition . . . \" (ibid.: 279, fn 38). The question shifts from when do actors deviate from standardized procedures, to when, where and how does some course of activity comes to be enacted as action consistent with a rule.\r\nSince the 1980s, studies of science, technology, and medicine have taken a lead in exploring this question, framed as the stabilization and replicability of facts and artifacts within the laboratory and beyond.7 In a study of contemporary cancer research, for example, Fujimura (1992) introduces the trope of the \"standardized package\" in the service of understanding processes through which ordering devices and their enactments are made reproducible across research sites (see also Fujimura 1996). A standardized package incorporates both discursive (theoretical) and material (technological) practices. From Star and Grisemer\'s much cited account of the origins of the Museum of Vertebrate Zoology at the University of California (1989), Fujimura focuses on the story of Joseph Grinell, who attempted to materialize his theory of relations between changing environments and the evolution of species in the collections of the museum itself. In building the museum, Star and Grisemer point out, Grinell concentrated his efforts on developing standardized methods for collecting and cataloguing specimens. But insofar as the latter were available for multiple forms of theorizing, it was those methods and materials, with their characteristic flexibilities as \"boundary objects,\" rather than his theory that endured.\r\nIn attempting to understand the very different fate of dominant theories of cancer, Fujimura points to the relation between the coordination and management of work across heterogeneous and divergent social worlds (the focus of Star and Grisemer\'s analysis) and the stabilization of facts (as developed most famously in Latour 1987). Scientists, Fujimura proposes, construct the standardized package to integrate the coordination of collective working with practices of fact stabilization. It achieves this by combining boundary objects with standardized methods\r\n\r\n7 See, for example, Barley (1986), Barley and Bechky (1993), Barley and Orr (1997), Cambrosio and Keating (1995), Clarke and Fujimura (1992), Collins (1985), Fujimura (1996), Galison (1987, 1997), Garfinkel, Lynch, and Livingston (1981), Jordan and Lynch (1992), Knorr (1981), Knorr Cetina (1999), Knorr Cetina and Mulkay (1983), Latour (1987), Latour and Woolgar (1979), Law (1994), Lynch (1982, 1985a, 1985b, 1988, 1991a, 1991b, 1993), Lynch and Jordan (1995, 2000), Lynch, Livingston, and Garfinkel (1983), Lynch and Woolgar (1990), M\'charek (2005), McNeil (1987), Pickering (1984, 1992, 1995), Singleton (1998), Star (1989a), Traweek (1988).\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n195\r\n\r\n\"in ways which further restrict and define each\" (Fujimura 1992: 169). Fujimura explores in detail the packaging together of a set of \"wellcrafted\" and multifaceted ways of theorizing cancer as genetic with associated methods for its investigation as such. The package as she observed its making included \"standard operating procedures\" through which laboratories could incorporate oncogenetic research into their working practices and align with others very differently located in doing so: \"This combination of abstract, general oncogene theory and the specific, standardized technologies . . . allowed other researchers within ongoing enterprises to locally concretize the abstract in different practices to construct new problems, and the routinization allowed the new idea to move to new sites and be inserted into existing routines with manageable reorganization\" (ibid.: 179, original emphasis). Packaged together, she argues, oncogene theory and associated recombinant DNA procedures operated to consolidate the many actors interested in cancer research aboard a particular technoscientific \"bandwagon\"; that is, molecular biological, and more specifically genetic, cancer research.\r\nLynch and Jordan (1995, 2000; see also Jordan and Lynch 1992) provide a detailed account of the performance of the most widespread and routine of these standard operating procedures, a technique used in gene sequencing known as the polymerase chain reaction or PCR. Lynch and Jordan are interested in the material practices ­ including literary forms ­ by which representational functions are ascribed to genetic materials (2000: 125). They conclude that far from an intrinsic property of a natural object (like DNA), \"genetic information must . . . be embedded in fields of practical and communicative action that enable it to be made visible and intelligible\" (ibid.: 143). In their studies of the production of PCR as a tool and of its circulation across sites, they demonstrate how the technique is both a stabilized, reproducible artifact with \"industrial strength\" and at the same time easily destabilized and always contingent on its reenactment in situ.\r\nThe premise that artifacts rely for their reproducibility on associated performances has been a central tenet of technoscience studies since Latour\'s Science in Action (1987). Latour\'s subsequent case study of the creation of \"the anthrax vaccine\" in nineteenth-century France (1988) demonstrates how the reproducibility of the vaccine as a stable and reliable object was fundamentally contingent on the working practices of French farmers. In building on Latour\'s study, Timmermans and Berg focus on standardization as an effect of distributed, rather than centralized, actors and activities (1997: 275) and summarize their approach as\r\n\r\n196\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nan interest in what they name \"local universality\" (ibid.: 275). The latter underscores the observation that universality rests in every case on particular actions, in turn reliant on historically specific institutional, infrastructural, and material relations. \"Universality\" on their view is not a transcendent quality of knowledge or the applicability of laws and procedures, in other words, but an effect \"produced through binding heterogeneous elements together into a tightly coupled, widely extended network\" (Berg and Timmermans 2000: 31).\r\nDrawing on their respective studies of cardiopulmonary resuscitation (Timmermans 1999) and the administration of medical research protocols (Berg 1997), Timmermans and Berg argue that rather than evidence for a failure of procedures, or resistance on the part of those who are enrolled to carry them out, multiplicity is a requirement for a procedure or protocol\'s functioning as a standard. This implies, in turn, that every form of stabilization includes, irremediably, the presence of instabilities. The latter comprise at once a challenge to the former and the preconditions for its efficacy. With respect to institutional orders of medicine, Timmermans and Berg conclude that \"rather than being the product of ever increasingly tightened networks, medical protocols can coordinate activities over space and time because of the non-docility of the actants which populate these practices\" (1997: 298). Despite the evident necessity of nondocile actants, however, rationalization initiatives ­ the attempt to render practices more standardized and to eliminate undesirable variation ­ continue unabated as managerial projects. Contemporary agendas of \"evidence-based\" medicine are a recent case in point, prescribing further rationalization as a route to efficient and effective care.8\r\n\r\nplans and templates\r\nIn modern discourses of management and organization, master plans and standardized procedures are commonly taken to be necessary to the extension of \"local\" activities over time and space (for relevant histories see Beninger 1986; Yates 1989).These assumptions are located in more specific histories and places, however, by Turnbull\'s (2000) critical examination of discussion and debate around the presence (or absence) of plans in the building of the great medieval Gothic\r\n8 For critical discussions see D. Goodwin (2004), Gregory (2000), Timmermans and Berg (2003).\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n197\r\n\r\ncathedrals. As an icon of premodern European achievement, the Gothic cathedral stands as a challenge to contemporary assumptions regarding the universal and foundational place of planning in the possibility of creating a monumental edifice, as both a social and material accomplishment. Just when, where, and how, Turnbull asks, did plans, maps, and other ordering devices assume such a central place in our sense of possibilities for action? And when, as a corollary, did such representational devices become synonymous with scientifically informed, rational action, \"thereby obscuring the messy practices that underlie them\" (ibid.: 53­4)? Turnbull rejects received accounts of the history of architecture and engineering that posit a sharp discontinuity between the ad hoc, practical, or at best \"purely technical\" bases of premodern building and modern systematic, theory-informed, scientific methods. He points out that the first appearance of a building plan (in contrast to the more ephemeral detail drawing, which might be done on a scrap of wood that would be subsequently discarded or even traced with a stick in the dirt), although highly contested among historians, is located sometime at the end of the Middle Ages, in the late fourteenth century (ibid.: 61). Given the admitted structural perfection of the early medieval Gothic cathedrals such as Chartres, completed by all accounts by 1230, such analyses frame the processes of cathedral building as a mystery, explicable only with reference to the \"genius\" of the great masons taken to have \"master-minded\" the projects (ibid.: 54). As an alternative, Turnbull proposes that we take a more performative approach, treating the great cathedrals as laboratories, in the sense of places in which people, practices, and materials are iteratively shaped, reworked, and translated over time and across space. More than individual genius, he proposes, the three essential components needed to account for the construction process as it might have been enacted are \"talk, tradition and templates\" (ibid.: 55).\r\nDifferences between ways of building, Turnbull argues, are located not in dichotomies of science/technology, theory/practice but \"in the social and technical means by which local and messy knowledge/practices are made robust, coherent, and mobile\" (ibid.: 56). First and foremost among these means, given an extensive network of actors most of whom were not literate, must have been talk ­ between clients and master masons and between the latter and those carrying out the work. The word between is crucial here; that is, given the experimental nature of the project, learning and innovation had not simply to flow in one direction but to circulate throughout the network. A template\r\n\r\n198\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n(a pattern frequently outlined on a thin piece of wood that a stone mason would use to cut a stone to a particular shape) is a material manifestation of a form of constructive geometry having to do with ratios of sizes to spaces and heights, formulated as \"rules of thumb\" (ibid.: 69).9 The template is what Turnbull characterizes as a \"small item of representational technology\" that integrates science and technology, theory and practice, and materializes solutions to specific problems in ways that can be translated reliably within and between sites. \"Provided that stones are sufficiently well cut,\" he concludes, \"according to a system of proportion, and are assembled in a way that contains all the thrusts within vertical columns of stone as revealed in previous building, then accumulation and innovation is possible, given one other factor ­ namely motivation or interest, in this case the religious and aesthetic urge to create heaven on earth\" (ibid.: 77).\r\nAt the same time that the cathedral comprised a passionate laboratory for the reconfiguring of stone, Turnbull points out, it reconfigured as well the persons, roles, and practices of building. The desire for additional resources that might extend the reach of talk, over time and across space, was presumably among the elements that led to innovations in representational artifacts, including the building plan. The sixteenth century saw the emergence of the architect and the corresponding shift in the former role of the masons to that of builder. With that change, in turn, came a gradual disappearance of the embodied practices that underwrote the Gothic structure.10\r\nAlthough the architect and the plan have by now gained preeminence, a close look at contemporary architectural practice reveals not only the primacy of the plan and other differences from the Gothic way of building but a story of ordering systems more mixed and messy as well. In a contribution to research on computer-supported cooperative work, Schmidt and Wagner offer a detailed account of the various coordinative practices and artifacts in play in the creation of the postmodern\r\n\r\n9 The collection of templates into repositories for future reference is reminiscent of the accumulation of \"detail drawings\" in architecture (Schmidt and Wagner 2004). That is, these are heterogeneous, occasioned solutions to specific problems, ordered not according to a standardized classification scheme but spatially, through their association as a collection available for future use. I return to the case described by Schmidt and Wagner below.\r\n10 Turnbull reports that in the early eighteenth century \"Louis XIV ordered a gothic clock tower to be built, but despite the concerted efforts of five architects it collapsed. In the end tie bars and supplementary arches and floors had to be used, exactly the kind of artificial prop the Gothic technique eschewed\" (2000: 79).\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n199\r\n\r\nequivalent of the Gothic cathedral, a major entertainment complex in the city of Vienna (2004).11 They characterize coordinative practices as historically specific and grounded in the use of material artifacts (ibid.: 39). Although bracketing the relevance of talk to the practices and artifacts they describe (as if in response to some imagined protagonist claiming the primacy of talk over material practices), their account is otherwise richly resonant with that of Turnbull. In particular, they make evident both the powerful coordinative effects of the modern-day building plan and the wider field of heterogeneous practices and artifacts on which its efficacy relies.\r\nThe practice of architecture involves on their account \"a plethora of representational artifacts\" (ibid.: 8), in various materials, with greater and lesser degrees of standardization and idiosyncrasy. Preeminent among the former are computer-aided design (CAD) plans, a highly complex, multilayered, and conventionally formatted system of representational diagrams differentiated according to both building dimensions and specialist practitioners. The CAD plan is the artifact in which all of the design decisions that have been worked out in various forms ­ sketches, calculations, technical descriptions, product specifications ­ are recorded and represented. The conditions of possibility for the central, coordinating role of the CAD plan are less an expanded rationality in the person of the architect, however, than the new materialities afforded by computational media, as \"modern CAD applications support the cumulative representation of the design within one and the same `document\', i.e., an integrated file structure, organized in layers, each of which addresses a particular aspect of the design\" (ibid.: 26).12\r\nAlthough Schmidt and Wagner provide an extensive and nuanced account of the by now highly elaborated systems of titling and classification by which plan documents are ordered, what is most striking about their story are the elegant and efficient multiplicities within standard templates (for example, in the meaning of a hyphen in the\r\n\r\n11 The authors begin this otherwise fine article by positioning their project as a remedy to what, on my reading, is a \"straw man\" caricature of absences in the CSCW literature. The corollary is a dismissal of previous work rather than the identification of generative connections. This is, unfortunately, a too frequent move in certain genres of writing in this and related fields.\r\n12 See also Star (1989b) and Henderson (1999). This observation provides the starting place for Schmidt and Wagner\'s design recommendations, focused on the possibilities for further automation of the mechanics of maintaining the coherence of the plan, currently still a largely manual, tedious, and labor-intensive process.\r\n\r\n200\r\n\r\nHuman­Machine Reconfigurations\r\n\r\npolynomial nomenclatures used for plan identification), as well as locally occasioned annotations, embellishments, reworkings, and the like. Like the Gothic cathedral-under-construction in Turnbull\'s account, it is the layers of the CAD plan in modern architectural practice that provide \"a (collective or individual) space for experimentation and change\" (ibid.: 27). At the same time, the proliferation of plan layers over the course of a project, and the independent mobility of plan copies however closely monitored, threaten to overflow the bounds of the plan as ordering system. This means that maintaining a systematic notation and tracking scheme for layers is a perpetual problem for practitioners, and mess is inevitable. The detail drawings, moreover, are at once closely indexed to the plans and invariably exceed the representational grasp of the systems of conventional classification by which the latter are ordered. Rather than attempt the endlessly ramifying, and shifting, task of categorizing their contents and relevance, detail drawings are simply collected together on paper in centrally placed binders indexed for their contents and for their associations with relevant CAD plans (ibid.: 31­2). Schmidt and Wagner conclude that the standardized classificatory and notational techniques employed in the architectural plan \"serve the purposes of coordinating distributed activities, not in spite of but exactly because of their excessive formality\" (ibid.: 48). As in the case of medical protocols studied by Timmermans and Berg, it is the inherent underspecification of the formal plan that affords the space of action needed for its realization. The moral of the story, accordingly, is not that architectural plans fail to maintain the coherence of contemporary building projects, but rather that they achieve their prescriptive efficacy through the contingent labors that they presuppose but leave unspecified.\r\n\r\nseeing in categories\r\nThe Gothic cathedral and contemporary architectural office comprise what Lynch has named \"equipmental complexes\"; that is, material arrangements that \"do not simply provide places where human beings work but instead provide distinctive phenomenal fields in which organizations of `work\' are established and exhibited\" (Lynch 1993: 132). Central to the composition of such complexes is the familiar recognizability of objects and actions, in turn a reflexive accomplishment of discursive and material practices of categorization. Charles Goodwin has identified categorization practices as central to what he terms\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n201\r\n\r\n\"professional vision,\" ways of seeing enacted in airline operations (C. Goodwin and M. Goodwin 1996) at archaeological research sites (C. Goodwin 1994, 2003), in a chemistry laboratory (C. Goodwin 1997), on an oceanographic research vessel (C. Goodwin 1995a), and in the courtroom of the infamous Rodney King trial (C. Goodwin 1994; C. Goodwin and M. Goodwin 1997). Far from a narrowly scopic sense perception, seeing on this account comprises embodied competencies enacted within particular, socially and materially configured, sites of action and interaction.\r\nIn \"The Blackness of Black\" (1997), Charles Goodwin reexamines received assumptions regarding the integrity of color categories across occasions and settings of their use. In taking color categorization as first and foremost a matter of individual cognition, he argues, anthropologists and cognitive scientists have failed to attend to questions of the social and material grounds of perception. He demonstrates this argument through a close study of teaching and learning in a chemistry laboratory. The professor who heads the laboratory specializes in analyses of the chemical composition of ocean water, from which he can reconstruct where waters collected at a given point in the ocean originated, how currents move, and the like. His unique resource in doing these analyses is a particular fiber used as an absorbent. The fiber must be manufactured, a bit of work done by the professor\'s students under his supervision and as part of their apprenticeship in the science of this particular form of chemistry. The procedure for making the fiber is described in a kind of recipe, one line of which is as follows: \"The reaction is stopped after about 10 min. by removing the jet-black fiber and washing it in deionized water\" (ibid.: 119). Goodwin points out that for students engaged in fiber manufacture, this line of the instructions turns out to pose a problem. What, exactly, is the color \"jet-black\" and how do you recognize it?\r\nStarting with the common assumption that black is among the least ambiguous of color terms (as in the use of \"black and white\" to connote something without shade or nuance), Goodwin documents the socially and materially embodied processes through which students are guided by their professor in the perception of blackness in situ. To manufacture the fiber successfully, Goodwin argues, students must learn how to see \"black.\" They do this not categorically, however, but in interaction both with their teacher and with the materials at hand. That is, they engage in a series of judgments regarding what constitutes the proper shade of black, tried and revised as they stir the fiber, pull it from the solution to\r\n\r\n202\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ninspect it more closely, consult with each other and their professor, offer candidate assessments of what is and is not right about a particular shade, and the like. In addition, to enrich the intuitive resources that students have to draw on in assessing the fiber, the professor has coined descriptors that draw on other senses as well. As Goodwin reports: \"`Good\' fiber that had reached the desired color was referred to as gorilla fur, while fiber that was not yet the right color was called orangutan hair\" (ibid.: 124, original emphasis). Recognizing black becomes not a matter of perceiving the canonically objective opposite to white but the product of a collective practice that in turn materializes the categories on which its adequate performance relies.\r\nIn Sorting Things Out (1999), Bowker and Star explore the place of information practices in the creation of ontologies of kinds, orderings, sameness and difference, with a particular interest in the question of how \"values, policies and modes of practice become embedded in large information systems\" (ibid.: 230). Systems of classification, they argue, work to (re-)produce the objects, and the relations of affinity and difference among them, that the classification scheme is designed to represent or describe. Classification schemes in this view are themselves technologies that are designed, implemented, reworked, and continually assessed for their effectiveness and effects. Those effects include associated disattention to whatever exceeds the frame through which recognizable persons, things, and processes are made visible.13 I return to the question of frames and invisible labors in Chapter 15.\r\n\r\nordering from within and without\r\nOne legacy of scientific management is the extent to which technologies designed to measure the efficiency of organizational life, along an ever broader array of dimensions, are increasingly written into the ordering practices through which the work of an organization gets done.14 In a study of airport ground operations, for example, I became intrigued by the analogy between representational devices used by natural scientists in tracking and analyzing the behavior of animal populations\r\n13 It is important to note that such erasures are not by definition a problem: although remaining out of view may result in less reward and recognition, it may also afford spaces in which to act. See Suchman (1995).\r\n14 For recent writings on what Strathern has named \"audit cultures,\" see Strathern (2000), and for a fascinating discussion of the extent to which Taylorism permeates discourses not only within the workplace but beyond, see Banta (1993).\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n203\r\n\r\n(for example, as described in Lynch 1988) and representations used by airline workers to coordinate and report on the movement of planes (Suchman 1993b). A crucial difference, of course, is that representational artifacts used within airline operations are an intrinsic part of the same activity that they are designed to track. Referencing and updating the airline schedule, for example, is a central activity of ground operations workers at the same time that the schedule is taken at the end of the day as a spatial and temporal representation of what they have done. Moreover, looking closely at how online communications and reporting systems are actually used in airline operations underscores the double form of accountability involved in these technologies. That is, the systems designed to track planes are simultaneously used by workers as resources for communicating their own activities to co-workers and by management as resources for evaluating how the operation is running. As currently constituted, the technologies of accountability in airline operations afford a kind of discretionary space or maneuvering room that can be used by workers to maintain a reasonable relation between prescriptive representations like schedules and the actual contingencies of getting airplanes off the ground. New tracking devices (for example, sensors on plane wheels that automatically record the time of \"push back\" of a plane from a gate) at least reconfigure, if not further close down, that space.15\r\nDisplaced from their status as prior and determining, plans, protocols, and other prescriptive representations can once again be investigated for the forms of potency that they do materialize in ordering human activity. Crucial to the agency of these devices are the multiple forms of accountability that they entail. Garfinkel\'s classic study of \"good\" organizational reasons for \"bad\" clinic records takes up the difference between records as endogenous features of a local order of practical action and as \"objective\" accounts appropriable by exogenous interests, in this case the interests of sociologists. As Garfinkel observes for the case of clinic records, reporting procedures are intricately and\r\n\r\n15 In a critique of the design rationale offered for so-called workflow systems, I have argued that these technologies comprise yet another attempt to write prescriptive representations of procedure into the tools with which work gets done, as a device for the normative regulation of organizational behavior (Suchman 1994b). For an influential and illuminating empirical study of the implementation of a workflow system and its creative­resistive accommodation by workers, see Bowers, Button, and Sharrock (1995), and for relevant studies in the context of hospital information system development see Bardram (1997), Bloomfield (1991).\r\n\r\n204\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nsensitively tied to other routinized and valued practices of the setting (1967: 192). The problem for administrators, then, is to make their interests endogenous to the settings that they are charged to administer; that is, to embed their interests of record keeping within the practical activities of relevant organization members.\r\nIt turns out, of course, that despite the attempt to incorporate interests of administration into the work of a local site, reporting procedures can involve members in managing contradictions within an organization\'s manifold structures of accountability. It can happen, for example, that the working order of one site is accountable to, but inadmissible in, the order of another. So, for example, Julian Orr (1996) has described how a Xerox technician in the field, charged with satisfying the customer by getting their machine back into working order, is also charged with producing a record of the call for use in the work of controlling the operations of field service. It is not simply a record, however, because a successful service call is required, by those to whom field service administrators are accountable, not to exceed a prescribed time limit at a given site. To achieve a successful call, therefore, the technician must do whatever is required to get the machine working and to report on the visit in an admissible way. This may include, at times, putting the time spent somewhere else in the record so as to, in Garfinkel\'s apt phrase, \"keep the front office appropriately misinformed\" (1967: 194). It is in these situations that competency comes to involve a dual orientation, both to doing the work and to creatively accounting for it.\r\nZuboff (1988) argues that information technologies introduce an element of what she terms reflexivity into the production process, insofar as their functioning produces further information, usable for other analyses and activities. She cites as an example supermarket scanners, which partially automate the checkout process but also generate data that can be used for inventory control, warehousing, scheduling of deliveries, and market analysis. She calls this extension to automation \"informating\" (ibid.: 10) and sees it as substantively different from previous forms of automation. But knowledge gained through labor can of course be used either as a resource for enhancing people\'s autonomy and control over their work or in shifting control further into the purview of management. The critical variables are who gets to say what information will be collected, as well as how it will be used and for whose benefit.\r\nThe beginning of this chapter considered questions of \"inside\" and \"outside\" in the context of relations between professional designers and technology users. These relations point to the many senses in which, as\r\n\r\nPlans, Scripts, and Other Ordering Devices\r\n\r\n205\r\n\r\nHaraway has suggested, \"objects are boundary projects\" (1991: 201). In the case of professional design, artifacts are configured within locations which they in turn help to constitute, in part through the imagination of other places located elsewhere. Increasingly materialized and embedded in the infrastructures of organizational life, technologies of order production share the problems and possibilities of any other artifact. Sites of professional design, with their multiple, shifting identifications and alliances, are differentiated from the places of artifacts-in-use to the extent and in the ways that boundaries between them are variously reiterated, reconfigured, or erased. Translating the agendas and politics of those \"outside\" the sites of their use, ordering devices arrive as foreign objects that must be domesticated or, if they are too resistant, relegated to the margins. Emerging as endogenous resources for ordering \"from within,\" plans, scripts and other ordering devices are woven intricately and powerfully into the fabric of everyday activity. The question in every case becomes: In which specific worlds are technologies of order production generated, how do they circulate, and who or what are their subjects/objects? What or whose agendas and interests do they translate, with what effects? The design of technology in this sense materializes possibilities for action, among other ways through the location of design itself.\r\n\r\n12\r\nAgencies at the Interface\r\nThis chapter explores the technical practices and cultural imaginaries of the so-called smart machine, not in the form of hardware-based robots or dedicated \"expert\" systems but as a proliferating world of software algorithms and computationally infused objects and environments. If claims for the imminence of the humanoid machine that compelled initiatives in artificial intelligence and robotics during the 1980s subsequently lost their vigor, in the 1990s transformations in computational infrastructures breathed new life into the project of designing humanlike, conversational artifacts. Web-based and wireless technologies in particular inspired renewed attention to the interface as a site for novel forms of connection, both with and through computational devices. Futures projected through the imaginaries of AI and robotics have recently been elaborated within a discourse of software agents, knowbots, and their kin.1 At the same time, the transformation of the Internet into a preeminent site for commerce in the service economy lends additional currency to the promise of personified computational agents, available to provide multiple forms of personal assistance to their human employers.2\r\nSoftware agents and \"smart\" devices are the current expressions of a long-standing dream of artifacts that know us, accompany us, and\r\n1 For an indicative collection on so-called embodied conversational agents, see Cassell, Sullivan, Prevost, and Churchill (1996).\r\n2 See Wise (1998: 416). Wise points out that as well as figuring the user-as-consumer, the futures promised fit with a libertarian commitment to increased agency through individual empowerment.\r\n206\r\n\r\nAgencies at the Interface\r\n\r\n207\r\n\r\nensure that we are always \"at home.\"3 Agent technologies offer the services of a proxy who travels while we stay in place, whereas distributed or \"ubiquitous\" computing, particularly in the form of \"intelligent environments,\" promises to provide us with greater mobility without a loss of familiar ground. Although I remain deeply skeptical regarding the practical realities of implementing these fantasies, I focus here on the realities already manifest in the desires that they assume, the pasts that they restage, and the futures that they project.\r\n\r\nthe software agent: animation and the \"illusion of life\"\r\nBeginning with work in the 1950s on artificial intelligence, our conception of machines has expanded from the instrumentality assigned them in craft and industrial contexts to include a discourse of machine as acting and interacting other. The less visible and somewhat more restrained AI projects of the 1990s played down the personification of machines in favor of technologies of neural networks, genetic algorithms, situated robotics, and the like.4 These developments shifted the project of machine intelligence away from what is now referred to as \"good old-fashioned symbolic information processing\" AI toward a technical practice based in more foundational metaphors of biosocial evolution. Nonetheless, attributions of humanlike machine agency seem as alive as ever in both professional and popular discourse.\r\nA rich source of links to the most recent materializations of the socalled conversational software agent is the Loebner prize.5 Staged as an instantiation of the canonical Turing test of machine intelligence, the prize is awarded each year for the \"most human computer,\" and the contestants comprise a population of creative algorithms and associated databases commonly known as \"chatterbots.\" Established in 1990, the\r\n3 As Brook and Boal observe, \"The wish to leave body, time, and place behind in search of electronic emulation of community does not accidentally intensify at a time when the space and time of everyday life have become so uncertain, unpleasant, and dangerous for so many. . . . [T]he flight into cyberspace is motivated by some of the same fears and longings as the flight to the suburbs: it is another `white flight\'\" (1995: ix).\r\n4 The turn in robotics to the \"situated\" is discussed further in Chapter 13. For a thoughtful, if partisan, review of contemporary developments in cognitive science, AI, and robotics, see Clark (1997, 2003).\r\n5 See http://www.loebner.net/Prizef/loebner-prize.html.\r\n\r\n208\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nprize itself (a gold medal plus cash prize of $100,000) has yet to be awarded, being reserved for the first \"bot\" contestant that convinces the judges that it is a human being. In the interim, the bronze medal and cash prize of $2000 is awarded annually to \"the best entry relative to other entries that year, irrespective of how good it is in an absolute sense.\"6\r\nThe 2004 prize was awarded to ALICE, the Artificial Linguistic Internet Computer Entity.7 When I first encountered ALICE on the Internet in 2000, she appeared in the form of a robot maid, with the body of a vacuum cleaner (a figure that I return to below). We had the following exchange:8\r\n\r\nAlice: Alice: Alice:\r\nAlice: Alice: Alice: Alice: Alice: Alice:\r\n\r\nWhat can I call you? > Lucy How are you Lucy. > I\'m fine Glad to hear it. What\'s new? > I\'m writing a book about human­machine communication. How about you? Are you a professional writer? > How about you?9 Me? >I\'m an anthropologist What is anthropologist, your job? >Yes. I study interaction. This was not a yes or no question. > I study interaction Is interaction a hard subject? > apparently My brain pattern set does not have a response for that. > I understand\r\n\r\n6 See http://www.loebner.net/Prizef/loebner-prize.html, accessed November 24, 2005. 7 See http://www.pandorabots.com/pandora/talk?botid=f5d922d97e345aa1. 8 As with most conversational agents the interactional medium is typed text. The \">\" in\r\nthe transcript indicates my input, lines beginning with Alice the text appearing on my screen in response. 9 I was disconcerted to discover that ALICE took a period at the end of a sentence to indicate what in conversation analysis would be termed a \"turn-transition relevance\" place, regardless of whether I had hit the key on my keyboard to indicate that I was looking for a response. This meant that a second sentence within my turn (for example, my \"How about you?\") was inserted, after the bot\'s response, as my next turn. This quickly led to some breakdowns in the coherence of the exchange.\r\n\r\nAgencies at the Interface\r\n\r\n209\r\n\r\nAlice: Alice: Alice: Alice:\r\n\r\nDo you think about these things? > all the time It must keep you busy. > You bet Alright then. > ta ta See you later.\r\n\r\nOf the various moments of puzzlement and delight over the course of this \"interaction,\" I was most perplexed by the sequence in which my \"yes\" response to ALICE\'s question, \"What is anthropologist, your job?\" engendered the correction, \"This was not a yes or no question.\" The former seemed to me clearly to be a \"yes or no\" question, even for a chatterbot. Interested in pursuing this particular puzzle further, I managed the following day to recreate the conversation to that point and then to continue (now taking care to maintain each of my turns as a single sentence):\r\n\r\nAlice: Alice:\r\nAlice:\r\nAlice: Alice:\r\nAlice: Alice:\r\nAlice: Alice:\r\n\r\nWhat is anthropologist, your job? >Yes. This was not a yes or no question. > When you said this was not a yes or no question, what did you mean? Do you think I should alter my programming? > Well, it was a bit confusing since I thought What is anthropologist, your job was a yes or no question. Interesting. Oh I get it. Very interesting. > Do you think you\'re really interacting with me? I don\'t know whether or not I am interacting with you. I am a chatterbot. Really. > Okay, fair enough Yeah okay, You scratch my back, I\'ll scratch yours. > Well my dear, at least your designer has a sense of humor Well that\'s okay. Have you told many people that your dear at least my designer has a sense of humor? > Hm, I think we better say goodbye Studies show that 99% of people spell Hmm with 2 M\'s. > I think we better say goodbye By \"we\" do you mean you and me? > Uh, yes\r\n\r\n210\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nAlice: Alice: Alice: Alice:\r\n\r\nCough. I get it. > Is that goodbye? Suppose I said yes. > What if you didn\'t Try it and see. > goodbye See you later.\r\n\r\nReaders familiar with the lineage of conversational software since the time of Joseph Weizenbaum\'s ELIZA program (see Chapter 4) will recognize the reappearance of long-standing techniques in this dialogue. I assume, for example, that the word fair in my concession \"Okay, fair enough\" triggers an association within ALICE\'s database with the adage \"You scratch my back, I\'ll scratch yours.\" Similarly for my use of an endearment in the following turn, which seems to send ALICE into a mode of Rogerian therapeutic feedback. I return in Chapter 14 to a closer consideration of occasions of interactional felicity and trouble in the case of conversational agents. At the moment I simply observe the continued evidence within this encounter, however engaging, for the kinds of problems in human­machine communication identified through my study of interactions at the interface twenty years before.\r\nOne thing that has changed since the time of ELIZA, however, is the emergence of some new resources for interface design. In a review article published in 2000, Dehn and van Mulken report that advances in computer graphics now enable animated interface agents. Of the latter, they write: \"Such agents appear on the screen as embodied characters and exhibit various types of life-like behaviours, such as speech, emotions, gestures and eye, head and body movements\" (ibid.: 2). Setting aside for the moment the sense of the term embodied here, we can ask the simpler question of just how these agents differ from conventional cartoon characters. Consider what the classic reference work on animation, Disney Animation: The Illusion of Life (Thomas and Johnston 1981) has to say about cartooning: \"There is a special ingredient in our type of animation that produces drawings that appear to think and make decisions and act of their own volition; it is what creates the illusion of life\" (cited in Bates 1994, my emphasis) (see Fig. 12.1). This seems quite straightforward, using the language of \"appearances\" and \"illusions.\" So what is different about the claims being made for software agents?\r\nThis quote is taken from an article by Joseph Bates in a special issue of the journal Communications of the ACM on intelligent agents (1994). The\r\n\r\nAgencies at the Interface\r\n\r\n211\r\n\r\nfigure 12.1. \"Woggles\" reprinted with permission, from Joseph Bates (1994) The Role of Emotion in Believable Agents. Communications of the ACM 37: 122­5.\r\napproach taken by Bates and his colleagues was to import techniques developed to portray emotion in cartoon characters into a computer program, called Edge of Intention, populated by three cartoon creatures named \"Woggles.\"\r\nThe medium of cartooning is appropriate here in more than a technical sense. What \"emotions\" become in this system are a series of emotional/behavioral attributions mapped to visual features of the figures. So, for example, a state labeled \"sadness\" triggers a \"moping\r\n\r\n212\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nbehavior,\" expressed through a \"decreased muscle tone,\" shorter jumps, and slower actions (ibid.: 124). As with cartoon animation, the artful synthesis of cartoonists\' design work and viewers\' readings results in successful animations. But for Bates and his colleagues, the achievement is more than that. As he puts it, the result of their work is \"creatures with definite emotional reactions to events. A simple example is a Woggle creating an analog of anger when it both experiences an important goal failure and judges that the failure was caused by another Woggle . . . We took care to design an architecture that provided Woggles with strong internal emotional states\" (ibid.: 123­4). In this single passage Bates\'s creatures are simultaneously presented as illusions of life and as important steps along the path to the real thing. Why, if a Woggle has emotional reactions, experience, judgment, and strong internal emotional states does it create only \"an analog of anger\"? The rhetorical operations at work here seem slippery at best.\r\nCommercially successful incarnations of animated software agents include the \"norns\" who populate the computer game series Creatures. According to their creator, Steve Grand, the norns are endowed with \"drives\" (ranging from hungry and thirsty to amorous and lonely) and a set of action scripts. As Kember explains, \"Because norns inhabit a virtual environment, they are referred to as `situated\' autonomous agents\" (2003: 94). Grand conceives of norns as an emergent species, developing to (potentially) evolve into useful agents: \"Some of their offspring, or their cousins, may learn to do useful jobs for people, or simply to keep people entertained until the day comes when we know how to create truly intelligent, conscious artificial beings\" (http://www.cyberlife.co.uk cited in Kember 2003: 105). Through his company Cyberlife, Kember reports, Grand is \"concerned with the revivification of technology by creating lifelike little helpers `who actually enjoy the tasks they are set and reward themselves for being successful\'. The reward is artificial `natural\' selection and survival of the fittest in a Darwinian evolutionary environment which supports and mirrors the economy within which it operates\" (ibid.: 105­6).\r\nAnother well-known proponent of animated interface agents, Pattie Maes, repeats the theme of service to humans. In a 1995 talk titled \"Interacting with Virtual Pets and Other Software Agents,\"10 Maes assures us that the home of the future will be \"half real, half virtual\" and that \"the\r\n\r\n10 See http://www.mediamatic.nl/Doors/Doors2/Maes/Maes-Doors2-E.html, accessed November 6, 2005.\r\n\r\nAgencies at the Interface\r\n\r\n213\r\n\r\nvirtual half of our home won\'t just be a passive data landscape waiting to be explored by us. There will be active entities there that can sense the environment . . . and interact with us. We call these entities software agents.\" Like Bates\'s Woggles, agents are personified in Maes\'s interface as cartoon faces, attributed with capacities of alertness, thinking, surprise, gratification, confusion, and the like. As Maes explains: \"Just like real creatures, some agents will act as pets and others will be more like free agents. Some agents will belong to a user, will be maintained by a user, and will live mostly in that user\'s computer. Others will be free agents that don\'t really belong to anyone. And just like real creatures, the agents will be born, die and reproduce . . . I\'m convinced that we need [these agents] because the digital world is too overwhelming for people to deal with, no matter how good the interfaces we design . . . \" (ibid.: 1). As both the source of our information overload and its remedy, the Internet affords the distributive powers through which the computer others with whom we are to interact have proliferated into populations of specialist providers. Whether figured as agents, assistants, or pets, their reasons for being are to serve and comfort us, to keep us from being overwhelmed in the future workplace/homeplace of cyberspace.11\r\nI return to the rhetorics of ownership, management, free agency, and service below, but for the moment I want to focus on the tropes of liveliness that animate discourses of autonomous software agency. Somewhat paradoxically, it seems, it is actually the persistence of the human­ machine divide rather than its disappearance that makes the prospect of machine autonomy so compelling to those interested in the design of intelligent, interactive artifacts.12 The modernist, post-Enlightenment assumption is that autonomous agency is contained within individuals and is a distinguishing capacity of the human. In this respect the project of designing intelligent artifacts (however \"distributed\" intelligence is understood to be) remains consistent with a tradition that treats separation and autonomy, rather than relatedness, as the mark of humanity. Having systematically established the division of humans and machines, technological imaginaries now evidence worry that once separated from us machines are rendered lifeless and, by implication,\r\n\r\n11 Of course, as Wise (1998: 417) points out, in a variety of ways agent programs can be expected to be a source of unsolicited information as much as a protection from it.\r\n12 For a related argument regarding the modernist, humanistic discourse of AI, see Sack (1997).\r\n\r\n214\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nless. They need to be revitalized, restored to humanness ­ in other words, to be made like us ­ in order that we can be reunited with them. It is the presumed separation between humans and artifacts, in other words, that animates the project of humanlike machines.\r\nIn this respect, also, the interactive machine might be seen as the next logical step after the neutral instrument described by Shapin and Schaffer (1985) in the emergence of the observational sciences (see also Latour 1993; Haraway 1997). The instrument was taken to speak on behalf of the natural object, albeit that the latter\'s words were still in need of translation by the scientist. Now the artifact, the intelligent object, speaks for itself, while similarly erasing, rendering invisible, its coauthors. As Shapin and Schaffer describe the autonomy of scientific facts: \"The matter of fact can serve as the foundation of knowledge and secure assent insofar as it is not regarded as man-made. Each of Boyle\'s three technologies worked to achieve the appearance of matters of fact as given items. That is to say, each technology functioned as an objectifying resource . . . The world of subjects and objects was in place, and scientists were on the side of objects\" (1985: 77).\r\nIt may be obvious why an observational science would be interested in erasing the place of social practice in the emergence of its naturalized objects. But why, in creating computational technologies, do designers increasingly evidence a desire to naturalize them, to obscure their artifactuality? I would suggest in part that it is a kindred desire to that which arguably inspired the development of objectivist science; that is, the desire to disappear and put in one\'s place something transcendent, existing independently of one\'s actions. Kember (2003) considers the question of how researchers in artificial life (ALife), working entirely in the medium of computer hardware and code, nonetheless frame their enterprise as a form of natural science (see also Helmreich 1998; Risan 1997). Key to this translation is the concept of \"emergence\"; roughly, the appearance in running code of regularities neither built in nor anticipated by the programmer. ALife programmers, Kember proposes, sublimate the creationist urge attributed to androcentric masculinity and instead project a creative agency onto and into the computer. The effect of this is less a form of male parthogenesis than a shifting of agency from religion to technoscientific nature, as \"the God-like act of creating life is `stolen\' or appropriated by man and then credited to the computer\" (Kember 2003: 55). Emergence, on this account, is a key concept through which ALife practitioners \"secure a form of digital naturalism in the face of the evident constructivism of `artificial\' life\" (ibid.: 57). The\r\n\r\nAgencies at the Interface\r\n\r\n215\r\n\r\nprogrammer becomes in turn not the invisible hand of creation but the modest witness to the running of self-generating code.\r\nIn his studies of artificial life, Richard Doyle (1997) has proposed that the vitality and autonomy of computational artifacts emerge through the camouflaging of the networks that support them. By \"camouflage\" he means an obfuscation of the embodied activities that are the conditions of possibility for artificial life; that is, \"machines, bodies, desires, and other practices on all sides of the screen\" (ibid.: 7). In contrast, Doyle argues that the animism of artifacts comes from \"a massive assemblage of machines, users and rhetorics that semiotically and materially distribute their `vitality effect\'\" (ibid.: 17). We catch a glimpse of those hidden conditions of possibility in an article by Rosalind Pickard (1997), concerned with the place of emotion as a necessary \"component\" in the constitution of intelligent artifacts. In a footnote Pickard reports that in lab experiments with students playing the computer game Doom, signs of stress came less with the appearance of a new deadly enemy (the intended site of emotional affect) than during times when students were experiencing difficulty configuring the software. This suggests that genuine stress occurs when troubles are \"real life,\" affecting lived accountabilities (in the context of the experiment, for compliance and competence) and consequences (for getting on with the game or task). For the researchers, however, this result is reported only as an amusing anecdote, noted en passant.\r\nCultural analysts like Doyle and Julian Bleecker (1995) analyze the compulsion of the virtual as evidenced in widespread fascination with the Maxis Corporation\'s Sims games as well as with ALife research. Both point to the opportunities these technologies afford their creators/users for a kind of simultaneous safety with risk, a transcendence over the \"world\" in question at the same time that one is somehow incorporated into it, engaged with an autonomous and therefore not fully predictable other. This produces a simultaneous sense of mastery over the virtual from \"outside\" with being \"inside,\" controlled by larger and more powerful forces. The result is a controlled simulation of the experience of not being in control; hence, the best of both worlds.\r\n\r\njeeves for the masses\r\nI want to return, however, to the question of how ALICE and software agents more generally are figured, both in themselves and in their relations with humans (see Fig. 12.2). As I mentioned, at the time of our first\r\n\r\n216\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfigure 12.2. ALICE the chatterbot, winner of the 2000 Loebner prize for the `Most Human Computer\' http://web.archive.org/web/20000520084312/ www.alicebot.org/ last accessed December 26, 2005.\r\nencounter ALICE was represented with a graphic image suggestive of a robot maid.13\r\nAlthough ALICE and her kin are more engaged in entertainment than domestic labor, this embodiment aligns with the common rhetorical positioning of software agents as assistants to their human counterparts. An early animation of the idea of personal agents was offered in the form of \"Phil,\" the bow-tied assistant in Apple Computer\'s\r\n13 This graphic has since been changed to that of a somewhat sterotypically hip young woman with a partially unbottoned blouse who, through advances in animation and speech generation, now has the wind blowing through her hair and greets you aloud. This, of course, shifts the connotations of the kinds of pleasures to be gained through entering into conversation with her. See http://www.alicebot.org/, accessed November 25, 2005.\r\n\r\nAgencies at the Interface\r\n\r\n217\r\n\r\n1984 video \"The Knowledge Navigator.\" Although Phil\'s capacities greatly exceeded those of even the most leading-edge agent technologies today, both ambitious promises and more modest implementations are very much with us. The emergence of software agents as a new site for the configuration of humanlike machines during the 1980s and 1990s coincides as well with two other initiatives, framed in terms of a shift of computation \"out of the box\" of the desktop computer, onto the body in the form of wearable computing, and into built surroundings under the name of intelligent environments. Although generally treated as quite distinctive developments, and notwithstanding their diverse histories, a look across these initiatives suggests some recurring themes.\r\nTo examine these lines of connection more closely, we can start with the observation that discourses of information technology have tended to erase the human labor that continues to be involved in technological production, implementation, maintenance, and the like. A reading across the rhetorics of software agents, wearables, and \"smart\" environments makes evident the absent presence of such erasures. As future visions offered in breathless promise and as a matter of practical necessity, these projects together restage a particular, and highly problematic, utopian dream. That is the fantasy of the perfect, invisible infrastructure: in this case, one that joins together the promise of intelligent machines with the needs of a service economy.14\r\nThe stage is well set by a figure courtesy of British writer P. G. Wodehouse, circa 1923:\r\n`Morning, Jeeves,\' I said.\r\n`Good morning, sir,\' said Jeeves.\r\nHe put the good old cup of tea softly on the table by my bed, and I took a refreshing sip. Just right, as usual. Not too hot, not too sweet, not too weak, not too strong, not too much milk, and not a drop spilled in the saucer. A most amazing cove, Jeeves. So dashed competent in every respect. I\'ve said it before, and I\'ll say it again. (Wodehouse, 1999/1923: 1)\r\nSo opens the first chapter of The Inimitable Jeeves, subtitled \"Jeeves Exerts the Old Cerebellum.\" The inimitability (or not) of Jeeves, and the cultural imaginaries within which Jeeves\'s competencies are attributed to\r\n14 This vision is clearly presented in innumerable invocations of the future of human­ computer interactions, perhaps most notably by Brooks (2002). For critical discussions see Crutzen (2005), Gonzalez (2000), Markussen (1995), Turkle (1995: 145). For an illuminating feminist critique of the \"smart house\" as a project (of which more below), see Berg 1999.\r\n\r\n218\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nhis cerebellum, provide the backdrop for my analysis. Jeeves is the icon of the consummate service provider, the ever-resourceful \"gentleman\'s personal gentleman.\" The just-visible-enough worker, he directs his considerable skills to maintaining the comfort and respectability of his employer, the upper-class, good-natured, but slightly dim-witted Bertie Wooster. Although created close to a century ago, it is evident that in important respects Jeeves prefigures the interactive software agent. Jeeves\'s travels through the interface were exemplified most directly, of course, in the Web search service Ask Jeeves®.15 But in a feature article in the May 2001 issue of the popular magazine Scientific American, Tim Berners-Lee and his coauthors present their vision for the successor to today\'s World Wide Web, named (before its birth, in the manner typical of many software projects) \"The Semantic Web.\" The authors animate their project with a scenario reminiscent of the Knowledge Navigator (1984), though updated to include a hand-held Web device:\r\n\r\nThe entertainment system was belting out the Beatles\' \"We Can Work It Out\" when the phone rang. When Pete answered, his phone turned the sound down by sending a message to all the other local devices that had a volume control. His sister, Lucy, was on the line from the doctor\'s office: \"Mom needs to see a specialist and then has to have a series of physical therapy sessions . . . I\'m going to have my agent set up the appointments.\" Pete immediately agreed to share the chauffeuring.\r\nAt the doctor\'s office, Lucy instructed her Semantic Web agent through her handheld Web browser. The agent promptly retrieved information about Mom\'s prescribed treatment from the doctor\'s agent, looked up several lists of providers, and checked for the ones in-plan for Mom\'s insurance within a 20-mile radius of her home and with a rating of excellent or very good on trusted rating services. It then began trying to find a match between available appointment times (supplied by the agents of individual providers through their Web sites) and Pete and Lucy\'s busy schedules. (Berners-Lee et al. 2001: 36)\r\n\r\n15 On September 23, 2005 the company announced plans to phase out the character of Jeeves, \"citing `user confusion\' over what the butler character represents\" according to a BBC news report (see http://news.bbc.co.uk/1/hi/technology/4275988.stm), and on February 27, 2006 Jeeves was officially disassociated from Ask.com. The flurry of attention paid to this event on the Web included an official Ask.com company page depicting Jeeves\'s \"retirement,\" picturing the character who had comprised the company logo engaged in various forms of leisure and holiday-making (http://sp.uk.ask.com/en/docs/about/jeeveshasretired.html). While the BBC reports that \"Jeeves is named after the extraordinarily knowledgeable and helpful valet character created by celebrated comic novelist P G Wodehouse,\" my request to the company to reproduce the Jeeves logo was met by a refusal and request that I refrain from making any association between the image and the fictional character.\r\n\r\nAgencies at the Interface\r\n\r\n219\r\n\r\nFrom Bertie Wooster\'s trials as a member of the British leisure class, we move to the dilemmas of the baby boomer engaged in a busy working life, called to care for aging parents under a regime of privately insured health care. Although Mom apparently still needs to be transported bodily to her physical therapist, the rest of the logistics are adeptly handled by Pete and Lucy\'s software agents, and with just the right degree of deference. Issues of privacy, trust, and the like are dispatched through the application of appropriate techniques alluded to at relevant moments in the scenario. As the authors explain, \"Pete and Lucy could use their agents to carry out all these tasks thanks not to the World Wide Web of today, but rather the Semantic Web that it will evolve into tomorrow\" (ibid.: 36). The article describes how a new language of machinereadable Web content ­ a system of \"well defined meanings\" ­ will underwrite that evolutionary process (ibid.: 37). The authors conclude that \"[p]roperly designed, the Semantic Web can assist the evolution of human knowledge as a whole,\" by making the latter available for meaningful analysis by software agents (ibid.: 43).\r\nAs the robot was to the industrial imaginary, so the software agent is to the desires and fantasies of the service economy. But rather than machines that can do our heavy lifting for us, the dream now is that every one of us can be a Bertie Wooster, commanding a staff of servants that gets to know us intimately, watches out for us, keeps us informed in just the ways that we need to be (knowing better what those ways are than we do ourselves), and represents us faithfully in our everyday affairs. The ideal that unites agent scenarios is that agents should be enough like us to understand our desires and to figure out on their own how to meet them, but without either their own desires or ambitions or other human frailties that might get in the way of efficient and effective accomplishment of their assigned tasks. The litmus test of a good agent is the agent\'s capacity to be autonomous, on the one hand, and just what we want, on the other. We want to be surprised by our machine servants, in sum, but not displeased.\r\nAt the same time we live in an age that embraces the ideal of the independent, self-motivated, entrepreneurial worker. As Henry Lieberman asks in his article \"Autonomous Interface Agents\": \"Why autonomous agents? An assistant may not be of much practical help if he or she needs very explicit instruction all the time and constant supervision while carrying out actions. Assistants can be time-savers when they are allowed to act independently and concurrently . . . \" (1997: 2). Here then is a classic tension. As management theory has pointed out with respect to the problem of agents and delegation in business administration, the more\r\n\r\n220\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nempowered these others, and the more capable of pursuing their own self-interests rather than ours, the less reliable they are. There is a deep and enduring ambivalence, in other words, inherent in the image of the agent: on the one hand, the agent as faithful representative; on the other, the agent as autonomous, self-directed, and therefore able to pursue its own agenda. Marvin Minsky, cofounder of the Artificial Intelligence laboratory at MIT, puts it more directly: \"There\'s the old paradox of having a very smart slave. If you keep the slave from learning too much, you are limiting its usefulness. But, if you help it to become smarter than you are, then you may not be able to trust it not to make better plans for itself than it does for you\" (quoted in Riecken 1994: 25).\r\nThe ramifications of the agent imaginary are developed by Chasin (1995), who explores identifications across women, servants, and machines in contemporary robotics. Her aim is to trace relations between changes in forms of machinic (re-)production (mechanical to electrical to electronic), types of labor (industrial to service), and conceptions of human­machine difference. Figured as servants, she points out, technologies reinscribe the difference between \"us\" and those who serve us, while eliding the difference between the latter and machines: \"The servant troubles the distinction between we-human-subjects-inventors with a lot to do (on the one hand) and them-object-things that make it easier for us (on the other)\" (ibid.: 73). Domestic service, doubly invisible because (a) it is reproductive and (b) it takes place in the household, is overwhelmingly provided by people ­ and of those predominately women ­ who are displaced and often desperate for employment. The latter are, moreover, positioned as Others to the dominant populace (typically white and affluent, at least in North America and Europe). Given the undesirability of service work, the conclusion might be that the growth of the middle class will depend on the replacement of human service providers by smart machines. The reality, however, is more likely to involve the continued labors of human service providers. Chasin points to the correlation, within the United States at least, between a dwindling middle class and increasingly polarized working and affluent population, and the increase in both the number of household appliances and domestic workers. As she argues: \"In this climate, electronics stabilize the idea that a service class of being(s) is proper and even necessary; here, electronics participate in, and thereby reinforce, the unequal social and psychological dynamics upon which the myth of a constantly expanding middle class depends\" (ibid.: 93).\r\nChasin poses the question (which I return to in Chapters 14 and 15) of how a change in our view of objects from passive and outside the\r\n\r\nAgencies at the Interface\r\n\r\n221\r\n\r\nsocial could help to undo the subject­object binary and all of its attendant orderings, including, for example, male­female, mental­manual, us­them. Although the \"we\" who will benefit from smart technologies may be cast as a universal subject, the very particular locations of those who speak and those who are (at least implicitly) spoken of inevitably entail marks of class and gender and attendant identifications. Moreover, the smart machine\'s presentation of itself as the always obliging, labor-saving device erases any evidence of the labor involved in its production and operation, \"from bank personnel to software programmers to the third-world workers who so often make the chips\" (Chasin 1995: 75). Yet as Ruth Schwartz Cowan (1983) and others since have demonstrated with respect to domestic appliances, the effectiveness of any labor-saving device both presupposes and generates new forms of human labor.\r\n\r\nthe encapsulated and augmented body\r\nWhereas agent technologies promise the services of a proxy who travels while we stay in place, distributed, ubiquitous, or pervasive computing promises to provide us with greater mobility without a loss of familiar ground. The projected disappearance of the computer into the metaphoric woodwork of electronic infrastructure takes two basic forms. First, it involves an embedding of computational processes into our surroundings, becoming part of the environment. And second, it assumes the shape of so-called wearable computing, or the embedding of computation onto or, more radically, into the body.\r\nThe migration of computing into the built environment is an area where life perhaps most clearly seeks to imitate art. A seminal source for the intelligent environment imaginary is the long-running television series Star Trek, where the encapsulated world of the star ship Enterprise becomes the prototype for a perfectly domesticated space. At MIT in the late 1990s, for example, the \"Hal: Next Generation Intelligent Room\" project was explained by its designers this way: \"We are working towards creating environments analogous to those so familiar to Star Trek viewers ­ i.e. rooms that listen to you and watch what you do; rooms you can speak with, gesture to, and interact with in other complex ways.\"16 In these projects the disappearance of the computer is simultaneously the emergence of familiar environments, where \"familiar\"\r\n16 See http://web.archive.org/web/19990224154049/www.ai.mit.edu/projects/hal/ (accessed February 6, 1998).\r\n\r\n222\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nmoves beyond the premise of environments that we know and recognize to environments that know and recognize us. As summarized in an enthusiastic report on work in the Microsoft Research Laboratories \"Easy Living\" group in 2000, \"the vision of intelligent environments is a world of technology that seamlessly and unobtrusively surrounds you with intelligent help\" (Hedberg 2000: 7).17 The new capacities of smart environments reflect the hierarchy of the senses associated with human perception; namely, sight, hearing, touch and (much less frequently) smell, in that order. But where previously seen as necessary to the autonomy and mobility of robots, sensory perception now is the precondition for effectively responsive spaces.\r\nPersonalization is a central preoccupation in smart device projects, not in the sense of users shaping technologies within their own practice but as technologies that recognize their users and shape themselves accordingly. One implication of this objective is the predominance of various forms of surveillance and biometric technologies within smart environment scenarios. So, for example, entry into the demonstration Easy Livingroom on the Microsoft campus in Redmond, Washington, begins with fingerprint recognition (Hedberg 2000: 7). And, of course, ongoing forms of tracking and recognition of user activities is a precondition for engagement, bringing intelligent environment projects directly into the problematic realms of interactivity identified earlier in this book. The focus of research and development is on new technologies of location and tracking, standards and protocols for interoperability between devices and other ramifying complexities of system engineering. But more fundamental questions ­ of what it could mean, in all senses of the word, to be recognized by our environments ­ remain.\r\nWhereas the \"intelligent\" environment promises that we will always be at home, \"smart\" clothing enables mobility without a loss of connection.18 Within affluent technology-intensive locales globally the mobile or cell phone has reached the status of a new form of accessory, which\r\n\r\n17 In a broader consideration of the trope of being \"at home,\" Ahmed proposes that \"The lived experience of being-at-home . . . involves the enveloping of subjects in a space which is not simply outside them: being-at-home suggests that the subject and space leak into each other, inhabit each other\" (2000: 89). She observes as well that assuming the metonymy of body, home, and world is not universal but a sign of privilege (ibid.: 53).\r\n18 In future scenarios, the \"intelligent room\" quickly begins to morph into the figure of the automated agent. As the title of an article in IEEE Intelligent Systems magazine on the MIT Intelligent Room project states it, it\'s \"Roomservice, AI style\" (Hirsh 1999: 8).\r\n\r\nAgencies at the Interface\r\n\r\n223\r\n\r\nworks to extend its wearers\' communicative capabilities over time (through messaging) and across space.19 Portable and hand-held electronic devices operate as augmentations of the body that no longer seem particularly remarkable. And more elaborate forms of \"wearable computing\" are being explored within the worlds of technology research and development.20 These \"wearables\" can be seen as the \"skin\" of the migration of computing into the body, where the body\'s surface is enhanced through computational clothing. MIT\'s wearable computing Web site, for example, offers this account of their project, again with echoes of Jeeves: \"A person\'s computer should be worn, much as eyeglasses or clothing are worn, and interact with the user based on the context of the situation. With heads-up displays, unobtrusive input devices, personal wireless local area networks, and a host of other context sensing and communication tools, the wearable computer can act as an intelligent assistant, whether it be through a Remembrance Agent, augmented reality, or intellectual collectives.\"21 The resonance of the \"wearable\" with the figure of Jeeves is even more explicit in this recent prognostication: \"[wearable] computers will monitor our physiological state, perform the duties of a secretary or butler in managing our everyday life, and protect us from physical harm\" (Barfield and Caudell 2000: 24).\r\nThe most visible proponent of wearable computing has been University of Toronto Professor of Electrical Engineering Steve Mann. Mann\'s work and life address the intersection of the wearable computer as environment and as prosthesis. Mann has been wearing a computer imaging system, comprising various devices, for most of his waking hours for more than twenty years. His definition of the \"personal empowerment\" made possible by the advent of wearable computing includes both personal \"encapsulation\" and bodily \"augmentation\" (Mann and Niedzviecki 2001). Wearable computing in Mann\'s expression of it provides solitude, privacy, protection, and security: an extension of the safe surroundings of home out into the world. Mann\'s extremes cast the desires and premises of the computer as wearable into relief. The mirroring of environments and bodies in the projects of the disappearing and wearable computer suggests a desire always to be recognized,\r\n\r\n19 On mobile technologies and their effects see, for example, Brown, Green, and Harper (2001); Green (2002); Ito, Okabe, and Matsuda (2005).\r\n20 For an instructive study of the problematic alignment between wearable visions and realities in the case of a project of \"augmenting\" Bell Canada technicians, see Viseu (2003, 2005).\r\n21 http://www.media.mit.edu/wearables/ (last accessed November 6, 2005).\r\n\r\n224\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nconnected to familiar environments, while at the same time being fully autonomous and mobile.\r\nThe figure of the software agent as the service worker, increasingly embedded to the point of disappearance into our bodies, clothing, and walls, resonates with another, central to both industrial and postindustrial initiatives around new technologies. This latter figure has been insightfully discussed within science and technology studies under the name of the invisible worker, or invisible infrastructures, from Shapin\'s (1989) observations about the role of technicians in scientific discovery to recent work by Bowker and Star on systems of classification and their erasures (1999). Just as the dream of the robot worker was to relieve us of hard labor, or of the contingencies of managing others so engaged, so the dream of agents at the interface promises to relieve us from having either to perform the mundane work involved in providing services for ourselves or to negotiate the moral dilemmas and practical inconveniences of delegating that work to others who might ­ more and less faithfully ­ represent us.\r\nSoftware agents, \"smart\" environments, and \"wearables\" together are figured within a discourse that makes service the imperative for a global economic infrastructure. We need to keep our eye, accordingly, on the ways in which autonomous machine agency, however subserviently constructed, might be consistent with regulatory practices aimed at foregrounding certain kinds of humans (employers, workers, consumers) and erasing others.22 The relations of upstairs and downstairs, front stage and back, that the service economy presupposes are constituted within a closed world that simultaneously presumes and regenerates the needs, desires, identities, and inequalities that those relations comprise (Kantrowitz 1994). Just as the decorum of Bertie Wooster\'s world is maintained by the supporting activities and discrete interventions of Jeeves, the dream of technology innovators in the service economy is that new sociomaterial agents and infrastructures will make it possible for more and more of \"us\" to be hailed as persons residing upstairs rather than down. My concern, then, is with the kinds of \"wes\" that are posited by this future vision, widening the circle of those who employ, manage, and command to include more and more of \"us,\" while those who serve\r\n\r\n22 I want to make clear here that my concern is not with debates that assume the futures predicted by software agent and smart machine enthusiasts and then consider the \"ethics\" of human­machine relations involved. Rather, it is the prior and more immediate question of what kinds of social relations are assumed to be desirable in these scenarios, whose interests are represented, and whose labors are erased.\r\n\r\nAgencies at the Interface\r\n\r\n225\r\n\r\nus are refantasized from problematic human workers to the now-quiteimitable in silicon Jeeves. Discourses of agency at the interface at once naturalize the desirability of \"service provision,\" and further obscure the specific sociomaterial infrastructures ­ including growing numbers of human workers ­ on which smooth interactions at the interface continue to depend.\r\n\r\n13\r\nFiguring the Human in AI and Robotics\r\nAmong the range of projects underway in contemporary artificial intelligence and robotics research, my interest in this chapter is focused on those initiatives aimed most explicitly at the creation of machines that are humanlike. Just what it means to be humanlike, and how the boundary between humans and nonhumans is correspondingly drawn and redrawn, is of course one of the matters in question. A central premise of this book is that projects in AI and robotics involve a kind of doubling or mimicry in the machine that works as a powerful disclosing agent for assumptions about the human.1 Positioned as exemplary of leading-edge thinking and technical practice, these initiatives in new technology materialize the cultural imaginaries that inspire them and which they work in turn to enact. In the case of AI and robotics, those imaginaries concern the category of the human, on the one hand, and questions of sameness and difference across (and within) the categories of humans, animals, and machines, on the other. One line of generative critique, therefore, is to trace out ways in which the assumptions that underwrite contemporary efforts to configure humanlike machines are remarkably familiar ones, their positioning at the leading edge of technoscientific innovation notwithstanding.\r\nAs a methodological strategy, I adopt a focus developed most explicitly within recent feminist and cultural studies of science; that is, an attention to questions of figuration. Figuration has been discussed\r\n1 I need to make clear that I am not suggesting, as do roboticists themselves, that these projects work as scientific models of the human but rather, that they make evident how roboticists imagine humanness. I return to this point in my discussion of Cog and Kismet below. 226\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n227\r\n\r\nperhaps most famously by cultural historian of science Donna Haraway (1997: 11). Haraway\'s argument is, first, that all language, including the most technical or mathematical, is figural; that is, it is made up of tropes or \"turns of phrase\" that invoke associations across diverse realms of meaning and practice. Technologies, Haraway argues, are forms of materialized figuration; that is, they bring together assemblages of stuff and meaning into more and less stable arrangements. These arrangements imply in turn particular ways of associating humans and machines. One form of intervention into current practices of technology development, then, is through a critical consideration of how humans and machines are currently figured in those practices and how they might be figured ­ and configured ­ differently.2 This effort engages with the broader aim of understanding science as culture, as a way of shifting the frame of research ­ our own as well as that of our research subjects ­ from the discovery of universal laws to the ongoing elaboration and potential transformation of culturally and historically specific practices, to which we are all implicated rather than modest witnesses.3\r\nClaudia Castan~ eda articulates the world-making effects of figuration in a way richly suggestive for how we might explore the category of the human through her close and generative readings of the figure of the child. She develops what she calls a \"theoretical-methodological approach\" (2002: 5) to cultural analysis that begins with a general figure and traces out its specific cultural, historical, and political appearances, urging attention to the double project of identifying the practices through which figures come into being and the work that they do (see also Braidotti 1994: 1). The effects of figuration are political in the sense that the specific discourses, images, and normativities that inform practices of figuration can work either to reinscribe existing social orderings\r\n\r\n2 Kember (2003: 170) identifies figuration, in its mobilization as a means of intervention, as \"visual or verbal images which embody transformations in knowledge, power and subjectivity.\" See also Braidotti (1994), Castan~ eda (2002), Kember (1998). Knorr Cetina (1999) develops a sense of configuration within the experimental sciences as a way of thinking about the agencies of laboratories in arranging scientists, instruments, objects, and practices in ways that together generate a particular science\'s \"reality effects\" (ibid.: 12, 26­33). Of crucial importance in her analysis is the construction of difference between the laboratory and everyday life, as well as across laboratories (ibid.: 44). Different effects are achieved, on Knorr Cetina\'s account, through acts of reconfiguring, an idea that I return to in Chapter 15.\r\n3 On the \"modest witness\" in science studies see Haraway (1997), Latour (1993), Shapin and Schaffer (1985). For indicative writings on science as practice see Franklin (1995), Helmreich (1998), Pickering (1992), Reid and Traweek (2000).\r\n\r\n228\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nor to challenge them. In the case of the human, the prevailing figuration in Euro-American imaginaries is one of autonomous, rational agency, and projects of artificial intelligence reiterate that culturally specific imaginary. At stake, then, is the question of what other possible conceptions of humanness there might be, and how those might challenge current regimes of research and development in the sciences of the artificial, in which specifically located individuals conceive technologies made in their own image, while figuring the latter as universal.\r\n\r\nautomata and agency\r\nThe project of making automata is a recent manifestation of a more long-standing preoccupation, with the agential ­ and more specifically human ­ properties of material things. Framing the question as one of whether things have agency like humans presupposes, however, a (nonproblematized) Euro-American view of what agency could be. In particular, it accepts that \"to be human is to possess agency\" and then proceeds with the question of to whom or to what such attributions should be extended (Lee and Brown 1994: 772). Instead, I adopt the view here that we need to include in our analysis the question of just what constitutes agency in any case, for humans or nonhumans. Efforts to establish criteria of humanness (for example, tool use, language ability, symbolic representation) have always been contentious, challenged principally in terms of the capacities of other animals, particularly the nonhuman primates, to engage in various cognate behaviors. More recently the same kinds of criterial arguments have been made in support of the humanlike capabilities of artificially intelligent machines. Whether the concern is animals or machines, debates within this competitive frame inevitably turn on contests over just what counts as the behaviors in question and who or what can be properly said to demonstrate them.4\r\nHistorically, understandings of agency within Euro-American imaginaries have marked the difference between humans and machines, while always at the same time inviting experiments across the boundary. Historian Jessica Riskin traces projects concerned with the synthesis of artificial life forms ­ artifacts that act in ways taken to be humanlike ­ since the early eighteenth century (2003a, 2003b, 2007). As with contemporary\r\n4 On these contests in the case of animals see, for example, Crist (2000, 2004); with respect to machines see Collins (1990), Collins and Kusch (1998); on both see Edwards (1994).\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n229\r\n\r\nprojects in artificial intelligence and artificial life, Riskin observes that early simulations were conducted as experiments aimed at testing the essence of life and intelligence, of the active and the inert. Her historiography emphasizes the ways in which both sides were transformed in the process, as over the past three centuries human and machine each alternately has served as a model for the other. The earliest attempts to synthesize life in the 1700s were inspired by an emerging materialist sensibility, for example, in the form of a mechanist physiology of the workings of the body. Associated practices of experimental artifice and simulation were understood as methods for investigating the natural and the real, an understanding still evident in contemporary views of experiment and simulation. Riskin cites the famous example of the \"Lady Musician,\" an early automaton built by a Swiss watchmaking family. Not only did the Lady play music, but her eyes also faithfully followed the course of her hands and on occasion, apparently moved by the effects of her own agency, she heaved a great sigh. Riskin locates the growth of factory automation in this history as well: the automatic loom, for example, was designed by the same inventor, Vaucanson, who created the iconic \"defecating duck\" (Riskin 2003b). The loom, like many other forms of industrial machinery, established a new hybrid combining the perfectly accurate machine with its still necessary, but more \"limited,\" human operator. More recently, of course, the relation of nature and artifice has become more fundamentally intertwined, most dramatically in the interventions made possible through the agencies of biotechnology and the \"new\" genetics.5\r\nThe approach that I adopt in this and subsequent chapters is to engage in close reading of the discourses and material practices of projects in robotics and AI. What figures of the human are materialized in these technologies? What are the circumstances through which machines can be claimed, or experienced, as humanlike? And what do those claims and encounters tell us about the particular cultural imaginaries that inform these technoscience initiatives, and how they might be otherwise? To pursue these questions, I consider three elements taken to be necessary for humanness in contemporary AI projects: embodiment, emotion, and sociality.\r\n\r\n5 Anthropological writings on reproductive and biotechnologies have flourished over the past decade. For a founding work see Strathern (1992). For an indicative collection see Franklin and Ragone (1998).\r\n\r\n230\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nembodiment\r\nFeminist theorists have extensively documented the subordination, if not erasure, of the body within the Western philosophical canon.6 Drawing from these observations, Katherine Hayles has traced out the inheritance of this legacy in the processes through which information \"lost its body\" in the emerging sciences of the artificial over the last century (1999: 2).7 Recent developments in AI and robotics appear to reverse this trend, however, taking to heart arguments to the effect that embodiment, rather than being coincidental, is a fundamental condition for intelligence.8 The most widely cited exception to the rule of disembodied intelligence in AI is the initiative named situated robotics, launched by Rodney Brooks in the 1980s. Brooks\'s position has been that rather than a symbolic process that precedes action, cognition must be an emergent property of action, the foundational forms of which he takes to be navigation through a physical environment.9 Like many others, Brooks builds an evolutionary trope into his project, expressed in a mixed metaphor that positions insect behavior as precursor to the genesis of humanoid robots (2002: 40). In her generally critical review of work in AI and robotics, Alison Adam writes that developments under the heading of situated robotics, in particular, \"demonstrate a clear recognition of the way in which embodiment informs our knowledge\" (1998: 149). But what, more precisely, comprises embodiment in this context?\r\nThe first thing to note is that discoveries of the body in artificial intelligence and robotics inevitably locate its importance vis-a`-vis the successful operations of mind or at least of some form of instrumental cognition. The latter in this respect remains primary, however much mind may be formed in and through the workings of embodied action. The second consistent move is the positing of a \"world\" that preexists independent of the body. The body then acts as a kind of receiver for stimuli given by the world, and generator of appropriate responses to it,\r\n\r\n6 For readings on feminist theories of the body, see, for example, Butler (1993), Grosz (1994), Kirby (1997), Price and Shildrick (1999), Schiebinger (2000).\r\n7 See also Adam (1998), Balsamo (1996), Helmreich (1998), Kember (2003). 8 The original publication of Plans and Situated Actions: The Problem of Human­Machine\r\nInteraction (Suchman 1987), I hope, made some contribution to this shift. For related arguments on the social and material grounds of cognition, see also Lave (1988) and Hutchins (1995), and for a critique of disembodied AI from within the field see Agre (1997). 9 Brooks presents his position in Brooks and Steels (1995), Brooks (1999, 2002). See also Grand (2003).\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n231\r\n\r\nthrough which the body \"grounds\" the symbolic processes of mind. Just as mind remains primary to body, the world remains prior to and separate from perception and action, however much the latter may affect and be affected by it. And both body and world remain a naturalized foundation for the workings of mind.10 As Adam points out, the question as framed by Brooks is whether cognition, and the knowledge that it presupposes, can be modeled separately from perception and motor control (1998: 137). Brooks\'s answer is no, but the figure that results from his ensuing work, Adam observes, is \"a bodied individual in a physical environment, rather than a socially situated individual\" (ibid.: 136).\r\nI return to Brooks and the problem of the social below, but it is important to note first that the materialization of even a bodied individual in a physical environment has proven more problematic than anticipated. In particular, it seems extraordinarily difficult to construct robotic embodiments, even of the so-called emergent kind, that do not rely upon the associated provision of a \"world\" that anticipates relevant stimuli and constrains appropriate response. Just as reliance on propositional knowledge leads to a seemingly infinite regress for more traditional, symbolic AI (see Adam 1998; Collins 1990), attempts to create artificial agents that are \"embodied and embedded\" seem to lead to an endless stipulation of the conditions of possibility for perception and action, bodies and environments. Despite Brooks\'s initial assertions that in the case of situated robotics \"the world grounds regress\" (1995: 55), the inadequacies of physicalism as a model for bodies or worlds are reflected in Brooks\'s recent resort to some kind of yet to be determined \"new stuff\" as the missing ingredient for artificial humanness (2002, Chapter 8). However inspired by phenomenologists like Heidegger and Merleau Ponty, and the autopoesis of Maturana and Varela (see Clark 1997: 171), the contingent interactions of biological, cultural-historical and autobiographically experiential embodiment continue to elude what remain at heart functionalist projects (Kember 2003: 65).11 And despite efforts\r\n\r\n10 This view underpins what Smith (1996: 97) characterizes as the stance of Realism, a philosophical position that he critically dislodges through a close reading of relations of world, naturalism, materiality, and the physical (ibid: 138­40). With respect to embodiment, Smith reminds us that \"`The body\' as an entity does not come for free; it is a substantial achievement, one that has to be individuated, carved out from a background, kept in shape, etc., by, among others, the subject whose body it is . . . \" (ibid.: 184). I return to the question of boundaries in Chapter 15.\r\n11 For a compelling articulation of the relevance of a Merleau-Pontian view of embodiment for broader fields of computer system design, see Robertson (2002).\r\n\r\n232\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nby sympathetic critics such as Adam and Kember to draw attention to the relevance of feminist theory for AI and robotics, the exigencies of design return researchers from the rhetorics of embodiment to familiar practices of computer science and engineering.\r\n\r\nemotion\r\nSince its advent under the auspices of United States and Japanese research and development laboratories in the 1990s, the project of \"affective computing\" has been hailed in the popular media as a radical movement that promises to turn prevailing notions of machine intelligence upside down. A news story from May 2001 is indicative: \"Affective computing would transform machines from slaves chained to the limits of logic into thoughtful, observant collaborators. Such devices may never replicate human emotional experience. But if their developers are correct, even modest emotional talents would change machines from datacrunching savants into perceptive actors in human society. At stake are multibillion-dollar markets for electronic tutors, robots, advisers and even psychotherapy assistants\" (Piller 2001: A8). Assigned an emancipatory role, emotion is positioned here as the missing ingredient for full (if not quite equal) machine participation in the human world. Sliding between imagery of enslavement and social ineptitude, the capacities of logic and calculation formerly taken as the mark of the human are now relegated to the position of oppressive and limiting forms of reasoning. These stand in the way of full realization of the lucrative benefits to be gained by machinic actors made effective through their endowment with affective competencies.\r\nAffective computing is repeatedly hailed as the discovery by cognitive science and AI (against their own, but by implication all of our, previously held convictions) that \"emotional processes\" as well as reason are necessary to intelligence. \"Intelligence\" in this sense retains its pride of place as the defining capacity of the human, but it is an intelligence now extended in its instrumental efficacy by the sensibilities of affect. Rosalind Picard, noted proponent and director of the Affective Computing Laboratory at the Massachusetts Institute of Technology, explains the choice of names for the project this way: \"The inability of today\'s computers to recognize, express, and have emotions severely limits their ability to act intelligently and interact naturally with us . . . because emotional computing tends to connote computers with an undesirable reduction in rationality, we prefer the term affective computing to denote\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n233\r\n\r\ncomputing that relates to, arises from, or deliberately influences emotions. Affective still means emotional, but may, perhaps usefully, be confused with effective\" (Picard 1997: 280­1, original emphasis).\r\nEmotion is another component, then, needed for effective rationality. More generally, discourses of affective computing evidence some shared starting assumptions:\r\n\"Affect\" comprises a distinguishable domain of cognition that can be analyzed into universal, component parts.\r\nAffect is the expression of an underlying emotional \"state.\" Affective interaction can be achieved through the replication of\r\nbehaviors understood to comprise it, made up of units assembled into a catalogue of affective expressions, productions, recognitions, and normative responses. Emotional states and their affective expression can be understood in terms of their (evolutionary) utility, as a kind of primal but still functional ancestor of contemporary reason.\r\nTaken as discrete states, emotions are available for analysis and replication. Historian of medicine Otniel Dror traces the cataloguing and enumeration of emotion to origins in late-nineteenth and early-twentiethcentury laboratory sciences. These early developers projected a future in which affective sociability would be mediated by emotion-detecting technologies, as \"physiologists, psychologists, and clinicians manipulated, isolated, replicated, standardized, quantified, and recorded emotions. They invented new technologies for visualizing and representing emotions in curves and numeric tables. And they propagated their practices and instruments beyond the narrow confines of the laboratory and clinic\" (Dror 2001: 360). Dror suggests that the power of these technologies came in part from their transgressive hybridity, \"a detached and machinist mode of production that provided intimate and private knowledge\" (1999: 392) for anyone to see.12\r\nIn the laboratory, the drive to produce clear, compelling representations of emotional states (as measured through various physiological changes), led to the co-configuring of imaging technologies and subjects. \"Good and reliable subjects\" were chosen for their ability to display clearly recognizable emotions on demand, whereas those that failed to produce unambiguous and therefore easily classifiable behaviors were left out of the protocol (Dror 1999: 383). These technologies produced\r\n\r\n12 See http://mplab.ucsd.edu/ (last accessed November 7, 2005).\r\n\r\n234\r\n\r\nHuman­Machine Reconfigurations\r\n\r\na catalogue of emotional types, normalized across the circumstances of their occurrence (e.g., as anger, fear, excitement), and treated as internally homogeneous, if variable in their quantity or intensity. Inevitably, normative readings developed based on experimenters\' prior experience and cumulative data. And as inevitably, particularly in the context of the early twentieth century, when these experiments flourished, categories of emotion were mapped to categories of person, affording (often invidious) comparison across, for example, men, on the one hand, and \"women and Negroes,\" on the other (ibid.: 386). At the same time, this was an economy that circulated through, but was discursively separable from, specific bodies. Like other marks on bodies, once materialized as a representation or trace emotions were extractable from their particular contexts of production: \"Emotions were understood as processes in the general scheme of the body-as-machine . . . Thus, emotion was a pattern written in the language of the biological elements that one monitored in, or sampled from, the organism\" (2001: 362).\r\nContemporary affective computing research follows in the tradition traced by Dror, in figuring affective encounters as moments of (predominately visual) \"recognition\" of evidence for underlying emotional states. So, for example, Javier Movellan of the Machine Perception Laboratory at the University of California, San Diego, has engaged in empirical, probabilistic analyses of facial expressions, based on hundreds of thousands of cases and aimed at the effective \"recognition\" of emotion by a \"perceptual\" computer interface.13 In the universalizing and unlocated language characteristic of many such projects, Movellan and colleagues report their aim as being to create \"a catalogue of how people react to the world\" (Piller 2001: A8). The promise is that, as the observer that never blinks, the perceptual computer interface is positioned to know us better than we know ourselves, catching those fleeting moments of expression of which we ourselves are unaware, or that we hope will be missed, and providing readings unencumbered by the fallibility that clouds human perceptions.\r\n\r\nsociability\r\nFigured most famously within the genre of science fiction over thirty years ago, as the Heuristically Programmed Algorithmic (HAL 9000)\r\n13 For an extensive and illuminating exploration of contemporary technologies of brain imaging, including the laboratory production of \"emotions\" and their travels, see Dumit (2004).\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n235\r\n\r\nfigure 13.1. Littlewort, G., Bartlett, M., Fasel, I., Susskind, J., and Movellan, J. An automatic system for measuring facial expression in video. Reprinted from Image and Vision Computing. Copyright with permission from Elsevier.\r\nin the film 2001 (Kubrick and Clark 1968), the fantasy of the sociable machine has been a touchstone for research in humanlike machines. The most frequently cited exemplars of this project are the progeny of MIT\'s Artificial Intelligence Laboratory. Perhaps the best known artifacts are the celebrity robots Cog and Kismet, both born of the \"new AI\" turn away from intelligence figured as symbolic information processing, to humanness as embodiment, affect and interactivity. A project of Rod Brooks, Cog is a robot head and torso built to maximize the integration of a \"perceptual\" system (computer vision) with basic motor \"skills\" (moveable arms and grasping hands). Brooks\'s premise in conceiving Cog was that the robot\'s basic sensorimotor capabilities would enable simple behaviors and interactions with its environment that in turn would build on each other to make more complicated behaviors easier. Brian Scassellati, who as a graduate student in the MIT AI Lab performed much of the labor in implementing Cog\'s most recent instantiations, explains the purpose of the project as being to \"investigate themes of development, physical embodiment, sensory-motor integration, and social interaction\" and to \"study models of human intelligence by constructing them on a physical robot\" (Menzel and D\'Aluisio 2000: 58).\r\n\r\n236\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfigure 13.2. Rodney Brooks with Cog c Peter Menzel/www.menzelphoto.com.\r\nKismet, a progeny of AI researcher Cynthia Breazeal within the larger Sociable Machines Project, is described on the laboratory\'s Web site as follows: \"The Sociable Machines Project develops an anthropomorphic robot called Kismet that engages people in natural and expressive faceto-face interaction. Inspired by infant social development, psychology, ethology, and evolution, this work integrates theories and concepts from these diverse viewpoints to enable Kismet to enter into natural and intuitive social interaction with a human caregiver and to learn from them, reminiscent of parent-infant exchanges.\"14\r\nKismet\'s software is conceptualized as a model of \"drives,\" its state of well-being as one of homeostatic balance among them. The aim of Kismet\'s social interaction is to activate the drives (enacted through facial configurations recognizable as \"calmness, happiness, sadness, anger, surprise, disgust, tiredness\") through the presentation by the robot\'s interactional partners of \"stimuli,\" at levels of intensity that will\r\n14 See http://www.ai.mit.edu/projects/sociable/overview.html (last accessed November 7, 2005).\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n237\r\n\r\nfigure 13.3. Cynthia Breazeal with Kismet c Donna Coveney/MIT.\r\nengender appropriate responses and avoid \"distress.\"15 A premise of the design is that both Kismet and its human interlocutors learn over the course of an encounter, in a trajectory aimed at mutual adjustment and increasingly appropriate forms of engagement.\r\nCastan~ eda reminds us to locate \"purportedly general claims about the child in particular discursive, cultural, and geopolitical contexts\" (2002: 5). Among other things, the figure of the child in Euro-American imaginaries carries with it a developmental trajectory, a becoming made up of inevitable stages and unfulfilled potentialities, that in the case of Kismet simultaneously authorizes the continuation of the project and accounts for its incompleteness. Both Cog and Kismet are represented through an extensive corpus of media renderings ­ stories, photographs, and, in Kismet\'s case, QuickTime videos available on the MIT Web site. Pictured from the \"waist\" up, Cog appears in media photos as freestanding if not mobile, and Kismet\'s Web site offers a series of recorded \"interactions\" between Kismet and Breazeal as well as between Kismet and selected other human partners. Like other conventional documentary productions, these representations are framed and narrated in ways that\r\n15 For an extended interview with Breazeal regarding the project, see Menzel and D\'Aluisio (2000: 66­71).\r\n\r\n238\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ninstruct the viewer in what to see. Sitting between the documentary film and the genre of the system demonstration or demo, the videos create a record that can be reliably repeated and reviewed in what becomes a form of eternal ethnographic present. These reenactments thereby imply that the capacities they record have an ongoing existence ­ that they are themselves robust and repeatable and that like any other living creatures Cog and Kismet\'s agencies are not only ongoing but also continuing to develop and unfold.\r\n\r\nthe humanlike machine as a fetishized object\r\nIn their contribution to the animation of objects, narratives of the humanlike machine rely on two recurring lacunae, one historical and one future oriented. Historically, devices made to perform at particular moments, as a contingent outcome of extensive networks and intensive hours of human labor, are rendered eternally and autonomously operational through the intercession of various representational media (demonstration videos, technical reports, media accounts, and Web sites).16 The existence of such documents creates an archival record of the existence of humanlike artifacts, an existence reiterated through extended networks of further citation. Prospectively, the efficacies demonstrated are narrated as portents of developing capacities, from which the rest of human capabilities will logically and inevitably follow. Together these rhetorical leaps conjure into existence an imaginative landscape increasingly populated by \"socially intelligent\" artifacts, approaching closer and closer approximation to things that both think and feel like you and me. Through these modes of erasure of human labors and nonhuman alignments, the autonomous artifact is brought into being.\r\nIn a series of recent writings (2002a, 2002b, 2007) Fox Keller considers the ways in which automata, among other devices, have been taken to validate mechanical­cybernetic accounts of biology. The machine in this paradigm is naturalized, so that its development can be construed as evidence for that which it is taken to replicate. This move, in turn,\r\n16 When asked in an interview in 2000 how many person hours it had taken to develop Kismet, Breazeal replied (in a way suggestive of the shared ancestry and technical investments made in Cog and Kismet): \"Oh God, I don\'t even want to think about it . . . There\'s tons of infrastructure code that isn\'t specifically for this robot. Code to specifically run Kismet is probably two full-time people working for 2.5 years. The total size of all the software tools we have developed to support our computation environment is huge\" (Menzel and D\'Aluisio 2000: 66).\r\n\r\nFiguring the Human in AI and Robotics\r\n\r\n239\r\n\r\nis based in a natural scientific paradigm of models, inspired by naturally occurring phenomena, which are then offered as experimental test beds from which explanatory theories regarding those phenomena can be generated. In \"Booting up Baby\" (in press), Keller points to what she names \"the apparently circular trajectory\" (ibid.: 253) involved in the logics of the Sociable Machines project, insofar as it materializes current discourses in developmental psychology and then represents itself as an independent testbed in which to assess their adequacy. Keller raises more specific concerns premised on the possible realization of the promises of the project, involving, for example, the implementation of humanoid robot caregivers. My own concern is less that robotic visions will be realized (though real money will be diverted from other projects and spent on them) than that the discourses and imaginaries that inspire them will retrench, rather than challenge and hold open for contest, received conceptions of humanness. As Keller concludes: \"If there is a disturbing circularity in the expectations for robotic simulations of human development, and if I am right in suggesting that the same problem arises in the use of computer simulations [in physics, biology, etc.], then the issue becomes a more general one\" (ibid.: 255).\r\nPursuing a quite different line of analysis in a discussion of the \"apparent irrationality\" of the worship of fetishes and idols as social others, anthropologist Alfred Gell follows religious scholars in proposing that it is precisely the fact that taking things as human is strange that gives the practices their distinctive character and religious efficacy or their \"enchantment\" (1998: 123). He goes on to consider how it is that people can simultaneously know that entities are categorically different from persons and at the same time attribute social agency to them. The key, he argues, is to locate the latter not in any necessary physical attributes (such as inanimate thing versus incarnate person) but in social relations: \"it does not matter, in ascribing `social agent\' status, what a thing (or a person) `is\' in itself; what matters is where it stands in a network of social relations\" (ibid.: 123). The resonance of this observation with claims for artificial intelligence and robotics, however, warrants closer scrutiny. On one hand, the latter share the rejection of material essentialism identified by Gell, seeing silicon and electrical circuitry as an alternative to flesh and blood. In this respect Gell\'s argument regarding social agency would seem to support the projects described above. A critical difference, however, lies in the extent to which the sciences of the artificial share the other central element of an anthropological theory of objects and agencies; that is, a radical relationality. Reading\r\n\r\n240\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nAI discourses would seem to indicate that the project is less to displace an individualist conception of agency with a relational one so much as to displace the biological individual with a computational one. All else in traditional humanist understandings of the nature of agency seems unquestioned. How it might be otherwise ­ how the labors and contingencies of technological agencies might be recovered without a necessary loss of enchantment ­ is the topic of the following chapter.\r\n\r\n14\r\nDemystifications and Reenchantments of the Humanlike Machine\r\nSince the outset of the discipline, anthropology has been signally preoccupied with a series of problems to do with ostensibly peculiar relations between persons and `things\' which somehow `appear as\', or do duty as, persons.\r\n(Gell 1998: 9)\r\nAs this epigraph from Alfred Gell suggests, the distinction of humans and nonhumans marks a relation that has been extensively explored not only by anthropologists but also by their research subjects, among other ways through the fungibility of persons and things. My interest in this book is to contribute to explorations of these \"peculiar relations\" at a particular site of contemporary cultural imaginaries, that is, the computing sciences and arts. I have posited that the fascinations of artificial personhood for AI practitioners involve a kind of mimesis that works as a powerful disclosing agent for associated assumptions about the human.1 In this chapter I explore those assumptions through some specific encounters with contemporary humanlike machines, read through the lens of recent developments in the anthropology of science and technology and related fields.2 Capacities for action are recast in these writings from\r\n1 Sherry Turkle (1984) was among the first to take up the broader question of the \"aliveness\" of computational artifacts and the workings of the computer as what she names an \"evocative object\" for the human. I use the term mimesis here in the sense developed by Michael Taussig, as \"the faculty to copy, imitate, make models, explore difference, yield into and become Other\" (1993: xiii).\r\n2 More specifically, my aim in this chapter and the next is to identify the outlines of a figure of humanness more consistent with conceptualizations currently under construction within the fields of cultural anthropology (Downey and Dumit 1997; Gell 1998; Strathern 241\r\n\r\n242\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ninherent capabilities to possibilities generated and reiterated through specific sociomaterial assemblages and enactments. These approaches shift the frame of reference from the autonomous human individual to arrangements that produce effective forms of agency within ramifying networks of social and material relations. Just how those networks are drawn and \"cut\" (Strathern 1996), and with what agential effects, is a practical, political, and aesthetic question, as well as a materially consequential one.\r\nFor scholars in the humanities and the social sciences, projects of artificial life in its various forms conjoin with ongoing reexamination of the tradition of liberal humanism and its figurings of persons, agency, and the like. This project of articulating the \"posthuman\" has been extensively described by Hayles (1999, 2002, 2005), who sees initiatives in the fields of situated robotics and artificial life as indicators of more profound shifts in the human sciences and in contemporary society. The position that I develop below intersects with that of Hayles but also differs in what I believe are critical (in both senses of that term) ways. I embrace Hayles\'s analysis of the history of the information sciences and the discursive disembodiment of mind and share her interest in the possibilities that computing affords for rethinking traditional conceptions of the human. But whereas Hayles anticipates resistance to projects in situated robotics and artificial life from those wedded to a conservative humanism (2005: 143), my own resistance to those projects is based on quite different grounds. I discuss these grounds in detail below, but in brief my concern is that, like their predecessors, these projects continue to restage the parochial and conservative forms of liberal humanism that in Hayles\'s reading they leave behind.\r\nAt the same time, my own analyses of initiatives in the design of humanlike machines have been concerned with resisting too easy elisions of difference at the human­computer interface. My approach has been to slow down discourses of the \"smart\" machine to attend closely to the practices through which purportedly intelligent and interactive artifacts are realized, including just what conceptions of intelligence and interaction are in play. The result of this is an enduring skepticism regarding the rhetorics of machine intelligence and an interest in\r\n\r\n1999; Taussig 1993), science and technology studies (Casper 1994; Collins 1990; Cussins 1998; Haraway 1991, 1997; Latour 1993, 1999; Law and Mol 2002; Lenoir 2002), feminist theory (Barad 2003; Braidotti 1994, 2002; Butler 1993; Halberstam and Livingston 1995), and cultural studies (Balsamo 2000; Doyle 2003; Featherstone and Burrows 1995; Hayles 1999, 2002, 2005; Kember 2003).\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 243\r\ndemystifying the specific technologies and practices about which these discourses make their claims.\r\nWith the critique of the previous chapter in mind, I turn here to particular encounters with several of the most highly acclaimed realizations of the intelligent machine, the situated robots Cog and Kismet. In offering some different readings of these projects from those available in popular media representations, I hope to indicate how encounters at the human­ computer interface could support more radical reworkings of the figures of both. This alternative is further elaborated through the case of an artifact sited more provocatively at the intersection of AI and new media art, performance artist Stelarc\'s Prosthetic Head.3 My interrogation of the Head expands the unit of analysis to incorporate the ongoing labors of design practitioners, the unruly contingencies and material particularities of computational artifacts, and the artfully collusive performances that make up encounters at the human­computer interface.4 In pursuing this line of research, I engage the body of scholarship that emphasizes the inseparability of the human from the artifactual and renders the relation as a more radically irreducible and intimate one. Taken together, these reflections are meant to contribute to the project that Taussig has named the demystification and reenchantment of lively things (1993: 1).\r\nmystifications and enchantments\r\nA close consideration of humanlike machines suggests a radical inversion of the premises that inform AI and robotics projects, of even the most \"situated\" kind. Rather than flawed approximations of autonomous agency, we can take these artifacts as demonstrations that\r\n3 In her essay \"Flesh and Metal: Reconfiguring the Mindbody in Virtual Environments\" (2002), Hayles shifts her focus from AI and robotics to the computational arts, where she finds resources for a more radical rethinking of bodies, embodied experience, and the (post-)human. I share this assessment of where we might look for practices at the human­computer interface more aligned with recent critical reconceptualizations of persons and things.\r\n4 Hayles\'s discussion of the installation Traces is highly resonant with my argument here, in pointing to the designers\' deliberate avoidance of effects that would obscure the particularities of the computational medium and their orientation to the interactions between persons and the VR environment. On her account, the designers turned problems that they encountered in getting a computationally generated avatar to exactly track the user\'s body into a lesson: \"rather than regarding the avatar as a mirroring puppet, they think of it as a trace emerging from the borderlands created by the energetic body in motion. What was a tracking problem is thus tranformed into the possibility of creative play between user and avatar\" (2002: 308­9).\r\n\r\n244\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nagencies ­ whether robotic or human ­ might need to be conceptualized on very different grounds. It is at this point that recent critical writings on subjects, objects, and relations between them become relevant for rethinking interactions between humans and machines. In Strange Encounters, for example, Sara Ahmed develops a critique of the figure of \"the stranger\" by extending Marx\'s analysis of commodity fetishism (as the substitution of an enigmatic object for the social relations of labor) to include fantasy as well as materiality or a \"fetishism of figures\" (2000: 4). Among other moves, Ahmed argues, this form of fetishism involves cutting off a figure from the histories of its determination through particular, embodied encounters. The figure is treated as \"having a nature,\" as being something that is and that has effects, rather than as an effect in itself. Ahmed\'s interest is not only in how such figures are produced but also in how they are put to work in particular times and places, including the labor that the fetishized figure conceals.\r\nIn an argument from a very different domain, but with strong resonances to Ahmed\'s, Gell (1998) has explored the \"enchantment\" of objects brought about through the masking of labors of production. Like Taussig, Gell starts from Walter Benjamin\'s proposal that mimetic practices, resulting in a plethora of images and simulacra, are based in a compulsion to imitate the world as a means of gaining access to it (see Gell 1998: 100; Taussig 1993: 20). Rejecting the idea of mimesis as a \"primitive faculty\" inherited from the past, Gell and Taussig adopt the category of mimesis as the more particular production of figures whose salient property is their resemblance to an original. They then use the concept to analyze a range of practices of magic and sorcery and their associated artifacts. Gell traces the history of this form of object enchantment back to Tylor, who, in Primitive Culture (1875), defined primitivism in terms of animism or the attribution of life and sensibility to inanimate things, as well as to Frazer (1900), Malinowski (1935), and Mauss (1902, 1954) in their studies of magic and the efficacy of objects in relations of exchange. Mauss\'s theories of exchange, in particular, consider how gifts act as extensions of persons and inspire Gell\'s theory of the agencies of art and of artifacts more generally. Artifacts are, by definition, Gell proposes, those objects taken to be instruments or outcomes of social agency. A found object like a stone, placed on a mantelpiece, becomes an art object and an artifact, indexing the agency of its finding and placement. At the same time, the enchanted object\'s effects are crucially tied to the indecipherability of prior social action in the resulting artifact.\r\nIt is through the specific materialities of the artifact, crucially, that its effects, and the absent presences on which they depend, are achieved.\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 245\r\nTaussig (1993) takes as his focus what he characterizes as \"the twolayered notion of mimesis that is involved [in Benjamin\'s analysis] ­ a copying or imitation, and a palpable, sensuous connection between the very body of the perceiver and the perceived\" (1993: 21). From this he develops a critique of Frazer\'s typology of sympathetic magic into the two categories of \"imitation\" and \"contact, \" arguing that the two are always intertwined in practice. These observations call out the importance of the particular materialities of objects to their efficacy, however much the latter is also based in ephemeral and intangible imaginings. Indeed, by this analysis the two aspects ­ embodied, sensuous contact and magical efficacy ­ are inextricably intertwined.\r\nDeveloped with respect to fetish figures made of wood, this analysis is richly suggestive for thinking about the computationally powered artifacts of contemporary AI and robotics. A more general characteristic of object fetishism in an age of commodity capitalism, the entanglement of sensuous corporeality and apprehension of the liveliness concealed within things has particular resonance in the case of humanlike machines. This despite the fact that the humanness assumed in discussions of the potential success (or the inevitable failure) of attempts to replicate the human machinically is typically stripped of its contingency, locatedness, historicity, and specific embodiments. If, in contrast, we take the human to be inseparable from our specifically situated social and material circumstances, the question shifts from \"Will we be replicated?\" to something more like \"In what sociomaterial arrangements are we differentially implicated, and with what political and economic consequences?\" This alerts us, in turn, to the possibility of encounters at the interface conceived very differently than as the meeting of a human and a machine, each figured as a self-standing entity possessed of preestablished capabilities. Rather, effective encounters at the computer interface are those moments of moving complicity between persons and things achieved through particular, dynamic materialities and extended socialities.\r\ndemystifications\r\nTo make the preceding argument more concrete, I return to the particular humanlike machines introduced above. I was able to experience my own encounters with the robots Cog and Kismet on a visit to the MIT AI lab in the fall of 2001. Cog, as the graduate student who led our tour explained apologetically, was inactive and had been so for some time. As there were no researchers actively working on its development, Cog was afflicted\r\n\r\n246\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nby a condition commonly known as \"bit rot,\" or the degradation of code in the absence of ongoing maintenance of its compatibility with continually changing software and hardware environments (see Smith 1996: 203). We were, however, able to visit the inanimate Cog sitting in a corner of the lab. Although still an imposing figure of a robot, what struck me most powerfully about Cog was the remainder of its \"body\" not visible in media portrayals. The base of Cog\'s torso was a heavy cabinet from which came an extraordinarily thick sheaf of connecting cables, running centaurlike to a ceiling-high bank of processors that provided the computational power required to bring Cog to life. Seeing the robot \"at home\" in the lab, situated in this \"backstage\" environment, provided an opportunity to see as well the extended network of human labors and affiliated technologies that afford Cog its agency, rendered invisible in its typical media staging as Rod Brooks\'s singular creation and as an autonomous entity.5\r\nAlthough Kismet was operational, in contrast to the interlocutors pictured in the Web site videos, none of our party was successful in eliciting coherent or intelligible behaviors from it. Framed as an autonomously affective entity, Kismet, like Cog, must be said to have failed in its encounters with my colleagues and me. But as in the case of Cog, there are more interesting and suggestive lessons to be learned from the difference between Kismet\'s demonstrated competencies and the Kismet that we encountered. Those lessons require that we reframe Kismet, like Cog, from an unreliable autonomous robot, to a collaborative achievement made possible through very particular, reiteratively developed and refined performances. The contrast between my own encounter with Kismet and that recorded on the demonstration videos makes clear the ways in which Kismet\'s affect is an effect not simply of the device itself but of Breazeal\'s trained reading of Kismet\'s actions and her extended history of labors with the machine. In the absence of Breazeal, correspondingly, Kismet\'s apparent randomness attests to the robot\'s reliance on the performative capabilities of its very particular \"human caregiver.\"6 Like all forms of agency, in other words, Cog and Kismet\'s capacities for action are created out of sociomaterial arrangements that\r\n\r\n5 For a closely related observation in a very different case, see Mialet\'s account of the extended corporeality of physicist Stephen Hawking (Mialet 2003).\r\n6 See http://www.ai.mit.edu/projects/sociable/overview.html (last accessed November 7, 2005). In an interview (Menzel and D\'Aluisio 2000: 71), Breazeal responds to the suggestion that Kismet might be tuned specifically to her as an interactional partner with the hope that this is an early stage of the robot\'s development that will improve with time. One could argue, however, that this is the case with all beings both human and\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 247\r\ninstantiate histories of labor and more and less reliable, always contingent, future reenactments.\r\nIf humanlike robots comprise an other that mimes dominant cultural imaginaries of the human, a more literal doubling is materialized in performance artist Stelarc\'s Prosthetic Head.7 The head is a threedimensional graphical simulacrum of Stelarc\'s own, endowed with the capacity to take queries typed on a keyboard and to respond in automatically generated speech.8 On exhibit at the InterAccess Gallery in Toronto in spring of 2003, the Head was displayed in larger than life-size dimensions on the wall of a darkened room, with no accompanying artifacts other than a pedestal holding a standard computer keyboard.9 My visit to the gallery on March 29, 2003, was motivated by an interest in comparing the Head with previous attempts at conversational agents. I was delighted to discover that on that day the original Stelarc was also on hand, observing encounters with his digital doppelganger.10 Our encounter, lasting over an hour and videotaped independently by my companion and by Stelarc himself, was augmented by Stelarc\'s\r\nnonhuman, from the proverbial \"two-year-old\" child to the artifacts discussed throughout this book. In both cases, intelligibility is tied to increasingly intimate familiarity. 7 See http://www.stelarc.va.com.au/prosthetichead/. The artist credits the following collaborators for the creation of the Head: Karen Marcelo, project coordination, system configuration, alicebot customization (http://karenmarcelo.org/); Sam Trychin, customization of 3D animation and text to speech software; Barrett Fox, 3D modelling and animation (http://www.barrettfox.com/); John Waters, system configuration and technical advice (http://www.shtech.net/); and Richard Wallace, creator of alicebot and AIML (http://alicebot.org/) (Stelarc 2004). 8 It is an interesting feature of conversational agents like the Head that they make evident the greater contingency of competent machinic hearing than of speaking. Although automatic speech generation is a relatively mature and robust technology, speech recognition still requires prolonged \"training\" of machines to the particularities of individual voices. This affords an interesting contrast to human language learning, where comprehension is widely experienced to precede fluent expression. 9 Stelarc reports that the database that informs the Head has since been purchased by the Australian National Gallery in Canberra, The Sherman Galleries in Sydney, and Gilbert Silvermann, an American collector in Detroit. After its exhibition at the InterAccess Gallery, the Head was installed as a four-meter-high display and exhibited at ACMI (The Australian Centre for the Moving Image) in Melbourne. (Stelarc, e-mail communication, August 22, 2005.) 10 Taussig (1993), in a chapter titled \"The Talking Machine,\" remarks on the fascination of European colonists with the fascination of \"primitive\" peoples with the former\'s technologies, \"the white man\'s fascination with the Other\'s fascination with white man\'s magic\" (207), including most dramatically the phonograph. He cites the number of accounts of \"first contact\" between native peoples and technologies, as retold by observing Europeans. On this analysis artifacts like the Prosthetic Head, and I would argue unfamiliar technologies more generally, are aimed at rendering us all as primitives as the creators of these machines look on with fascination.\r\n\r\n248\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nfigure 14.1. The author in conversation with Stelarc\'s Prosthetic Head, Inter Access Gallery, Toronto, Canada 29 March 2003 (photograph courtesy of Andrew Clement).\r\n\r\nresponses to the Head\'s responses to my queries, as well as by his ongoing commentary on the Head and advice on how best to engage with it.\r\nAn encounter with Stelarc\'s Head affords further evidence for the collective and contingent nature of sociomaterial agencies. I offer one indicative exchange:\r\n\r\nStelarc: It also has a simple way of generating poetry on the fly, it\r\n\r\nhas a simple database with keywords, you can say, \"recite a\r\n\r\npoem\" (pause)\r\n\r\nLS:\r\n\r\n(types) \"Recite a poem, please\"\r\n\r\nStelarc: It\'ll, basically put together a bunch of words tha-\r\n\r\n[\r\n\r\nHead:\r\n\r\nYour polite style is very nice.\r\n\r\nOur breathing imploding breathing imploding,\r\n\r\nCity body electric system city excessive replicating,\r\n\r\nAnd city city involuntary imploding. (Smiles)\r\n\r\nLS:\r\n\r\nOh, that was very nice! (laughs, glance to Stelarc, types)\r\n\r\n\"Very nice!\"\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 249\r\n\r\nHead: Thanks, still Lucy.\r\n\r\nLS:\r\n\r\n(types) \"Recite another one.\"\r\n\r\nHead: Bodies not the involuntary so exchanging,\r\n\r\nAbsent inconsequential excessive perhaps city blurring,\r\n\r\nPulsing system electric excessive obsessively. (Smiles)\r\n\r\nLS:\r\n\r\n(laughs) Yeah, right on.\r\n\r\nStelarc: (laughs) And it does have some interesting kind of philo-\r\n\r\nsophical kind of data, and information,\r\n\r\nLS\r\n\r\nYeah?\r\n\r\nStelarc: and definitions, umm . . .\r\n\r\nObs: Can it recite any philosophers, or commentators?\r\n\r\nStelarc: Well for example if you ask it \"What is reductionism\"\r\n\r\n(laughter)\r\n\r\nStelarc: That\'s one of it\'s favorite, my favorite, ah . . .\r\n\r\nLS:\r\n\r\n(types) \"What is reductionism?\"\r\n\r\nHead: Reductionism is the philosophy that all psychology reduces\r\n\r\nto biology, all biology to chemistry, chemistry to physics,\r\n\r\nphysics to mathematical logic. Therefore, according to\r\n\r\nreductionism, I can understand you by logic alone without\r\n\r\nhaving a human brain.\r\n\r\nObs: (laughs) What about emergent properties?\r\n\r\nLS:\r\n\r\n(types) \"Do you believe in reductionism?\"\r\n\r\nHead: Yes I believe in it. Do you?\r\n\r\nLS:\r\n\r\n(laughs, types) \"I\'m not sure.\"\r\n\r\nHead: Is there anything I can say to help you make up your mind?\r\n\r\n(Much laughter all around, including Stelarc)\r\n\r\nLS:\r\n\r\n(types) \"Do yo\" (backspaces to begin over)\r\n\r\nObs: Why doesn\'t he have feelings?\r\n\r\nLS:\r\n\r\n(turns around to Obs) What?\r\n\r\nObs: Why don\'t you have any feelings?\r\n\r\nLS:\r\n\r\n(types) \"Do you have feelings?\"\r\n\r\nHead: As a robot I do not have any human emotion. My appar-\r\n\r\nent emotional responses are simply algorithms designed to\r\n\r\nmake me easier to interact with.\r\n\r\nLS:\r\n\r\n(types) \"Do you think robots should have emotions?\"\r\n\r\nHead: That depends on what you mean by thinking.\r\n\r\nThis sequence is readable for some recurring characteristics of interactions with conversational software. In particular, near the beginning is a moment that reveals a basic, and clearly consequential, difference\r\n\r\n250\r\n\r\nHuman­Machine Reconfigurations\r\n\r\namong the human and nonhuman participants in the encounter. I am referring to the Head\'s \"interruption, \" in its first turn, of Stelarc\'s account of its poetic abilities, indicative of its lack of any awareness of other events in the room around it. As I have elaborated in previous chapters, human­computer interactions occur at a relatively narrow point of intersection, that is, at just those moments when the human participant takes an action that changes the system\'s state (in this case, by hitting the return key on the keyboard). In contrast, human interactions invariably exceed what is made accountable in any direct sense. And it is this contingent horizon of possibly relevant phenomena, I want to propose, that effects interaction\'s open-endedness.11\r\nI return to my exchange with Stelarc\'s Head shortly but want first to pursue for a moment the question of open-endedness and the cybernetic. In \"Cybernetics and the Mangle\" (2002), Andrew Pickering explores the resonance that he sees between the work of mid-twentieth-century British cyberneticists Hal Ashby, Stafford Beer, and Gordon Pask and Pickering\'s own theorizing of practice as \"the emergent interplay of human and material agency\" (ibid.: 414; see also Pickering 1995). He offers as one realization Ashby\'s homeostat, a device designed to achieve self-regulation through an iterative succession of autoreconfigurations ­ a process effecting what Pickering characterizes as a form of \"liveliness.\" He writes: \"I can\'t actually think of any prior example of a real machine that would randomly ­ open-endedly, as I would say ­ reconfigure itself in response to its inputs . . . It seems reasonable, then, to speak of the homeostat as having a kind of agency ­ it did things in the world that sprang, as it were, from inside itself, rather than having to be fully specified from outside in advance\" (ibid.: 417, original emphasis).\r\nI want to focus on the elision in this comment on Ashby\'s homeostat between randomness and open-endedness and also on the association\r\n\r\n11 In an article developed as a contribution to discussion of \"awareness\" within the field of CSCW, Heath et al. present a series of studies that make evident \"the ways in which participants design activities to have others unobtrusively notice and discover actions and events which might otherwise pass unnoticed\" (2002: 317). They make the important point that the mutuality of awareness does not necessarily involve a sameness or even symmetry among participants\' orientations to an ongoing course of action: it is an orientation to the contingent possibility that something might become relevant that is crucial. It is the capacity for the latter, rather than any assumed sameness, that my use of \"asymmetry\" in the case of the human­machine interface is meant to reference. Heath et al. point out that \"awareness\" does not mean some form of general orientation through which relevant events are filtered but rather very particularly selective attention to an environment that, in turn, is highly differentiated. See also Pedersen and Sokoler (1997), Robertson (2002).\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 251\r\nbetween agency and something that comes from \"inside.\" First, what about the relation between randomness and open-endedness? Pickering here treats them as synonymous, though he concedes further on that in the case of the homeostat it is an open-endedness of a delimited kind, however large the space of possibilities. His idea of the mangle, in contrast, turns on a picture of agency as \"indefinitely\" open-ended.12 The agency of the homeostat, moreover, was in an important sense a prespecified one; that is, \"there was a principle of stability hard-wired in.\" In contrast, Pickering observes: \"The mangle is in at least two ways on the wild side of the homeostat ­ involving indefinitely open-ended searches of spaces of agency, and with no fixed principle of assemblage\" (ibid.: 418). This leads him to call for an exploration of differences as well as similarities between instantiations of sociomaterial agency, a point that I return to below. But Pickering concludes with a celebration of cybernetics as a radical alternative to the classical sciences: \"While the latter seek to pin the world down in timeless representations, cybernetics directly thematizes the unpredictable liveliness of the world, and processes of open-ended becoming\" (ibid.: 430).\r\nMy own much more skeptical reading of the cybernetic project hangs on contradictions between the legacy of behaviorism, teleology, and control engineering that I believe still sits at the core of its devices and aspirations and a sense of contingency and interactivity worthy of the name of \"unpredictable liveliness\" and \"open-ended becoming.\"13 To pursue these questions, I turn back to my encounter with Stelarc\'s Head. I was speaking of the Head\'s (apparent) interruption of its progenitor, which in a moment of ironic serendipity takes the form of the Head\'s complimentary remark regarding my own politeness. Rather than being read as rudeness, the Head\'s action demonstrates its inability to perform the kind of competent interruption that rudeness requires, displacing a demonstration of social awareness with a mark of its machinic nature.14 A second moment of mechanism revealed occurs when the Head responds to my compliment on its poetic abilities by addressing\r\n12 Pickering is excited by the possibility that a particular class of cybernetic machines (for example, Ashby\'s \"Musicolor\" device) can serve as instantiations of what he names \"decentred becomings\" (personal communication, November 8, 2005). The latter idea, as developed in his trope of \"the mangle,\" is, I believe, deeply resonant with the forms of reconfiguration that I consider here and in Chapter 15. See Pickering (1995, 2002).\r\n13 On the history of cybernetics, including its universalizing and \"closed world\" rhetorics, see Bowker (1993), Edwards (1996).\r\n14 On the extraordinary competences involved in conversational turn-taking, see, for example, Sacks et al. (1978), Goodwin (1981).\r\n\r\n252\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nme as \"still Lucy.\" The installation at the InterAccess Gallery was configured with a pressure sensitive pad placed at the foot of the pedestal on which the keyboard rested: it is the visitor\'s step onto the pad that activates the software running the Head, effectively \"waking it up\" and initiating a request for the visitor\'s name.15 A standard feature of socalled conversational agents, this salutation effects what Chesher (2004) names an \"avocation,\" a kind of interpolation of the prospective user­ participant into the configuration of the interface. In the case of the Head, the three-dimensional corporeality of the encounter is enhanced by the fact that, rather than sitting at a standard display screen, the visitor stands opposite the Head, which in turn fills her field of view. The activation of the Head software by the pressure-sensitive pad sets up a spatial conjoining of Head and visitor in which both are entrained, in other words, and which marks as well the temporal bounds of a particular exchange. On the day of our encounter, however, the pressure pad was repeatedly failing to transmit, with the result that the Head was liable to shut down and no longer respond to keyed input, in a way that would be appropriate had its interlocutor walked away. The fix for this bug was for the visitor to step off of the pad and then step back onto it again. This interrupted the continuity, however, with the result that the Head treated the ensuing exchange as a new encounter, once again requesting a name. To draw attention to this failure of recognition I introduced myself on reentering the dialogue with the phrase \"I\'m still Lucy\" and was named \"still Lucy\" from that time on.16\r\nWhereas breaches like this reveal the machinic limits of the Head\'s interactional competencies, other moments effect an uncanny sense of presence and of generative spontaneity. The Head\'s poetic abilities, as Stelarc explains, are based on serendipitous juxtapositions from an\r\n\r\n15 The eyes of the Head when not activated are closed: the pressure on the pad initiates its processes in much the same way that a touch of the space bar awakens a sleeping laptop.\r\n16 Stelarc reports that in its subsequent installation at the The Australian Centre for the Moving Image in Melbourne approximately 1,500 people went through the exhibition every day for five months, and the Head performed flawlessly (Stelarc, e-mail communication, August 22, 2005). In any case, I cite this breakdown not as anything extraordinary or as diminishing of the Head\'s success. On the contrary, I would argue that in important respects it is moments like this which reveal the extraordinary achievements of technical systems. In breaching the general invisibility of the infrastructure that would otherwise go unnoticed, they call our attention to other actors ­ human and nonhuman ­ outside of the frame. I return to this question of framing below.\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 253\r\nfigure 14.2. Prosthetic Head, San Franciso, Melbourne 2003, Programmers Karen Marcelo, Sam Trychin, 3-D models Barrett Fox, reprinted with permission from STELARC.\r\nevocatively seeded database of \"keywords.\" What is not available from the transcript is the singularly enchanting performance of these verses, effected through the cadence of the Head\'s speech and the dynamic animation of its face, particularly the eyes and mouth. Special attention has been paid in the design of the Head to the eyeballs, teeth, and tongue, each of which are separate moving elements in the 3000-polygon mesh model of the artist\'s head from which the Head is constructed.17 This brings us to the second issue raised by Pickering, regarding agency as action initiated \"from inside.\" Pickering here invokes a contrast between things that achieve agency from within themselves or through external specifications. In his consideration of objects endowed with human (or superhuman) properties, Gell points out that mind can only ever be depicted suggestively, as that which is hidden \"inside\" an observable body. In the case of traditional idols, this is typically done through the introduction of some kind of opening or orifice, which designates an exterior­interior distinction to which the opening gives access. Eyes are the canonical example, as \"the windows to the soul\" (1998: 132, 136). In this sense mind and spirit are anthropologically symmetrical alternates, each standing for an indexically constituted mind­body contrast, an interior indicated by the surfaces of the body that enclose it. Gell observes: \"There are thus two basic strategies for converting (conceptually) stocks and stones into quasi-persons in artifact-form. The first of these strategies consists of animating the idol by simply stipulating for it a role as a social other. The second consists of providing it with a homunculus, or space for a homunculus, or turning it into a homunculus within some larger entity\" (1998: 133). Gell points to the primacy of vision and of the eyes in Hindu iconography, union coming from eye contact with the gods, as the \"eyes of the god, which gaze at the devotee,\r\n17 See http://www.acmi.net.au/7E8A5C8E6F304A839116C3C74F81440C.htm.\r\n\r\n254\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nmirror the action of the devotee, who gazes at the god\" (1998: 119). Stelarc himself sees his project as a direct challenge to conceptions of consciousness, mind, intelligence, and the like as forms of mysterious interiority. In the context of prevailing figures of humanness, however, the desire to effect an uncanny liveliness for the Head inescapably suggests those very things.\r\nThe poetry that the head recites involves an ingenious use of the stored database of keywords strung together in ways that exploit the often deliberately nonlinear juxtapositions of poetry and the irrepressibly suggestive and meaningful nature of language. One result of this is the generation of what Stelarc characterizes as \"alternate, intimate, involuntary experiences\" for the Head\'s interlocutors.18 The flowing cadence of the Head\'s recitation contributes to the sense of its artistry, with the result that its poetry generates laughter and delight from its listeners. Similarly, the exchange regarding the nature of \"reductionism\" reverberates with its reflexive relevance for the Head as speaker and comprises a moment of astonishingly coherent alignment effected by the well-established technique of matching certain key phrases (\"I\'m not sure\") with associated responses (\"Is there anything I say to help you make up your mind?\").19 What affords the liveliness of the exchange\r\n\r\n18 See http://www.stelarc.va.com.au/index2.html. 19 The Head is based on the long-standing and widely circulating platform called ALICE.\r\nSee http://www.alicebot.org/. (See Chapter 12.) Stelarc explains that the Head\'s \"general knowledge\" is based on the ALICE database, which has had over five hundred contributors since 1995 when \"Alice the Chatterbot\" and AIML (the Artificial Intelligence Mark-up Language) was initiated by programmer Richard Wallace. The Head\'s database has \"inherited\" much of this from ALICE but has also, since late 2002, been altered and extended, as Stelarc explains:\r\nin order to personalize the Head, to more express the artist\'s concerns and concepts. Not only in what it knows and how it says it but also that it develops some of its own \"creative\" capabilities. For example, the Head can make poetry-like sentences and song-like combinations of sounds (generated differently each time it is asked). Much of the Alice data-base is neutral information about the world, but some of it expresses the peculiar beliefs of the programmers. Often exposing particular American biases (the right to bear arms) and certain religious beliefs (a Christian God). Although much of this kind of data has been deleted or adjusted, occasionally the Head gives conflicting answers. It doesn\'t believe in God (me!) but it might still have embedded somewhere a response that contradicts this. So it is a fundamentally schizoid entity. (Aren\'t we all?) (Stelarc, e-mail communication, August 25, 2005)\r\nThis complex and inconsistent \"inheritance,\" as Stelarc characterizes it, is part of what makes up the Head just as ours makes us.\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 255\r\nis the simultaneous recognition of that alignment, of the creative programming labors that stand behind it, and of the ways in which it points, unwittingly, to a future relationship ­ of persuasive discussion ­ that we anticipate actually exceeds the Head\'s capacity.20 That mix of alignment and slippage, and the response that it evokes, is demonstrated most dramatically in the close of the sequence. The question \"Do you think that robots should have emotions?\" again explores the bounds of the Head\'s self-reflective and humanlike capacities. But where the question anticipates an orientation to the problem of emotion, the Head disarmingly organizes its response around a prior problem ­ one moreover that is defining of the project of which the Head is a part ­ that of thought itself.\r\nReflecting on my afternoon with Stelarc and his Head, I am struck by the sense of collaborative performance involved, both within and beyond the gallery walls. Within the encounter all worked together to make the particular assemblage of exhibition space, persons, and artifacts cohere into something if not always intelligible, at least interesting and worthwhile. As Kember characterizes the progeny of researchers in artificial life, \"these novel agents do not so much evolve as coevolve in the dynamic interplay between observer and object, and they are more a facet of communication ­ the desire for life ­ than of computation ­ alife itself\" (2003: 6). Stelarc is interested in what he describes as the \"seductive couplings\" that occur between the head and its interlocutors. He playfully proposes as well that the Head might serve a more useful purpose: of standing in for the artist in response to requests from the media, eager students, and the like. Framed as his virtual double, Stelarc\'s Prosthetic Head does effectively distribute the artist\'s agency. It does so not through any simple form of replication, however, but as an effect of complex and shifting assemblages of persons and things, specifically situated in time and place. It is to the question of differences within such assemblages that I now turn.\r\n20 Stelarc explains that because of the limitations of the AIML programming language, the Head is unable to increase its database from the conversations that it has. \"It is programmed in stimulus­response modules. You anticipate the queries, you provide data for its responses\" (Stelarc 2004). On Stelarc\'s view it is this inability to learn from its conversations that prevents the Head from being an artificial intelligence. At the same time \"as its database increases the head will become more informed and less predictable in its responses. The head will appear to be more autonomous. The artist would then no longer be able to take full responsibility for what his head says\" (Stelarc 2004).\r\n\r\n256\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nreenchantments\r\nThese reflections on encounters at the human­computer interface are meant to contribute to an awakening of the \"congealed life in the petrified objects\" of AI and robotics (Taussig 1993: 1). Contrary to the apparent enlivening of objects promised by the sciences of the artificial, I want to propose that an investment in obscuring the performative foundations of persons and things instead works to deaden the resulting artifacts. To further emphasize these foundations of subject and objecthood, I turn to the question posed by Marilyn Strathern regarding the personification of objects. Strathern approaches the answer by asking a prior question; that is, in what respects might we understand the constitution of persons as a form of reflexive objectification?21 She takes as her frame associated acts of separation and relation, as \"it is through the separation of persons from one another that specific relations are created, and through relations that persons are defined . . . \" (1999: 16). In her earlier studies of Melanesian personhood, Strathern introduces a distinction between \"person\" and \"agent.\" The \"person\" is not a preexisting entity but an object of the regard of others and an objectification of the relations that constitute her. The \"agent,\" in turn, is the one who acts with those relations as cause and reference ­ \"with another in mind\" (1988: 272­4).\r\nThe project of creating a humanlike machine requires that the phrase \"with another in mind\" be questioned more closely, however, than its colloquial sense would suggest. Standard readings within cognitive science would attempt a kind of literal mapping into a model of the mind of one actor of some model of the other. But the context of Strathern\'s statement suggests something else. The mind of the Hagener as Strathern recounts it is not an entity contained within the person but rather the enactment of an elaborate, and elaborating, history of social relationships implying specific agencies and consequences. It is impossible, on Strathern\'s account, to conceptualize Melanesian agency apart from those relations: agents are not the authors of their own acts, albeit that their actions are no less their own. This argument suggests that intentionality needs to be understood not as an attitude of mind located within the individual but as a field of socially and materially mediated relations within which persons act.\r\n\r\n21 Working within a very different intellectual tradition, social philosopher George Herbert Mead makes a related argument in his classic exploration Mind, Self and Society (1934).\r\n\r\nDemystifications and Reenchantments of the Humanlike Machine 257\r\nThese arguments reverberate with others in cultural anthropology as well, located at the interface not between humans and machines but at the moments when humans come into, and go out of, recognized social personhood. Casper (1994, 1998), Franklin (2000), Hogle (1999), Lock (2002), Thompson (Cussins 1998; Thompson 2005), and others concerned with the anthropology of birth and death have drawn our attention to the ways in which these transition zones at the edges of life provide poignant sites for the study of personhood and its problematics. In a moving analysis of neonatal intensive care, Middleton and Brown (2005) cite a physician who observes that at some point in the process of working to keep a premature baby alive it is the baby who, as the physician phrases it, \"decides\" its future. Read through the lens of Strathern\'s discussion of \"cutting the network\" (1996), this observation can be understood not as a statement of the infant\'s acquisition of autonomous agency but as a practical move in the enactment of the sociotechnical networks of which the infant is an integral part. The account by Middleton and Brown describes the ever-ramifying extensions to the network of neonatal intensive care that are now possible: as long as more and more human and nonhuman resources can be brought to bear, the infant body can, at least potentially, be sustained. Rather than reading the physician\'s statement to say that the infant at some point takes over the agency of this collective, we might read it as a statement that at some point the autonomy of the infant must be posited for the collective effort, and ramifying extensions to the network, to be cut. Constituting the infant\'s autonomous agency, in other words, makes it possible at least partially to disengage this morally and emotionally central ­ at once fragile and powerful ­ entity from its reliance on the wider human­nonhuman collective.\r\nThe sciences of the artificial operate in a cultural and historical frame that takes autonomous agency not as an effect of cutting the network, however, but as the precondition for participation in it. Given an ontology of separate things that need to be joined together, machines must in some sense be granted agency to be brought into relationship with us. Given a model of humanness as a set of separate components that need to be incorporated into a coherent whole, and the resulting individual as an entity that needs to be acculturated into a set of social relations, the projects of artificial intelligence make some kind of sense. But what if our starting place comprises configurations of always already interrelated, reiterated sociomaterial practices? What if we understand persons as entities achieved only through the ongoing enactment of\r\n\r\n258\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nseparateness and always in relation with others? Rather than working to create autonomous objects that mimic Cartesian subjects, we might then undertake different kinds of design projects ­ projects discussed in the following chapter under the theme of human­machine reconfigurations.\r\n\r\n15\r\nReconfigurations\r\nAgency is not an attribute but the ongoing reconfigurings of the world. (Barad 2003: 818)\r\nIn this chapter I consider some new resources for thinking about, and acting within, the interface of persons and things. It is here, on the question of alternatives to information theoretic approaches to human­machine interactions, that I believe the ground has shifted most radically over the past twenty years. The shifts involve reconceptualizations of the social and the material and the boundary between them, with associated implications for practices of system design. The explorations are ongoing within relevant areas of cultural anthropology, science and technology studies, feminist theory, new media studies, and experiments in cooperative systems design, each of which is multiple and extensive in themselves and no one of which I can do full justice to here. I hope nonetheless to trace out enough of the lines of resonance that run through these fields of research and scholarship to indicate the fertility of the ground, specifically with respect to rethinking and creatively enacting the interface of humans and machines.\r\nexcluded middles It was the circular move of writing a cognitivist rationality onto machines and then claiming their status as models for the human that first provoked me to question the notion of intelligent, interactive artifacts. My concern then, as now, has to do with the implications of this move both for our notion of what machines are and also with ways\r\n259\r\n\r\n260\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nin which the premises and products of artificial intelligence research continue to restage traditional Euro-American assumptions about the nature of being human. In setting up my critique, however, I fell back into a familiar humanist stance, defending against what I saw as AI\'s attributions of (a certain version of) intelligence and interactivity to machines by effectively reclaiming (a different version of) those qualities for humans. Since then, I have struggled with the question of how to maintain the sense of human­machine difference that I developed in my analysis, while taking to heart the insights generated from subsequent thinking regarding the distributed and enacted character of agency, and the implications of such reconceptualizations for essentialist human­ nonhuman divides.\r\nLatour (1993: 77­8) usefully demarcates a \"Middle Kingdom\" with respect to human­nonhuman relations, within which he locates the space between simple translations from human to nonhuman, on the one hand, and a commitment to maintaining the distinctness and purity of those categories, on the other. Translation in the case of humans and machines involves practices through which capacities taken to be inherent in one are shifted to, or realized through, the other. In resisting the particular translations of intelligence and interactivity recommended by AI in the 1970s and 1980s, I turned to a kind of exercise of purification, attempting to maintain those qualities as exclusively human. I now believe that what we need is to, in Latour\'s words, \"direct our attention simultaneously to the work of purification and the work of hybridization\" (1993: 11) with respect to human­machine boundaries. This involves developing a discourse that recognizes the deeply mutual constitution of humans and artifacts, and the enacted nature of the boundaries between them, without at the same time losing distinguishing particularities within specific assemblages. Recognizing the interrelations of humans and machines, in other words, does not mean that there are no differences. The problem rather is how to understand the nature of difference differently.1\r\nI want to wander about a bit in Latour\'s Middle Kingdom, then, in considering the question of agency in humans and machines. For those like Latour writing within the Actor Network framework and its\r\n\r\n1 Questions of difference have been most extensively considered within feminist and postcolonial scholarship. For some exemplary texts see Ahmed (1998, 2000); Ahmed et al. (2000); Bhabha (1994); Braidotti (1994, 2002); Castan~ eda (2002); Franklin, Lury, and Stacey (2000); Gupta and Ferguson (1997); Strathern (1999); Turnbull (2000); Verran (2001).\r\n\r\nReconfigurations\r\n\r\n261\r\n\r\naftermath, agency is understood as a material-semiotic attribute not locatable in either humans or nonhumans.2 Agency on this view is rather an effect or outcome, generated through specific configurations of human and nonhuman entities. Moreover, in a move echoing the Melanesian conception of personhood described by Strathern (see Chapter 14), the entities involved do not precede their incorporation into such configurations in any simple way but emerge through their participation in various networks of relations. In the words of Callon, the network of interest for Actor Network Theory (ANT) is \"not a network connecting entities which are already there, but a network which configures ontologies. The agents, their dimensions, and what they are and do, all depend on the morphology of the relations in which they are involved\" (1999: 185­6). ANT\'s call for a \"generalized symmetry\" in analyses of human and nonhuman contributions to social order performed a powerful intervention into sociological preoccupations with human agency, as the latter \"[l]iberated from its containment in human entities . . . is dispersed through the networks\" (Ashmore et al. 1994: 2). I return to the question of symmetry below. But I turn first to the rich body of empirical studies that have specified, elaborated, and deepened the senses in which human agency is only understandable once it is reentangled in the sociomaterial relations that the \"modern constitution\" (Latour 1993) has, since the seventeenth century, so exhaustingly attempted to take apart.\r\n\r\nmutual constitutions\r\nA growing corpus of studies of sites of sociomaterial practice over the past twenty years provide compelling empirical demonstrations of how capacities for action can be reconceived on foundations quite different from those of a humanist preoccupation with the individual actor living in a world of separate things. This body of work is too extensive to be comprehensively reviewed, but a few indicative examples can serve as illustration.\r\n2 The phrase material-semiotic was coined by Haraway (1991: 194­5) to indicate the ways in which the natural and the cultural, or the material and the meaningful, are inextricably intertwined. Although not cited in the early formulations of Actor Network Theory, the writings of Haraway and other feminist science studies scholars have since become increasingly central to writings \"after\" ANT. See, for example, the articles collected in Law and Mol (2002). I return to regenerative discussions of agency and difference within feminist scholarship below.\r\n\r\n262\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nThe question of human­nonhuman relations has been intensively explored within science studies. Pickering (1995) develops the metaphor of the \"mangle\" to create a performative account of knowledge practices, including centrally the construction of machines that \"variously capture, seduce, download, recruit, enroll or materialize\" human agency (ibid.: 7). Key to Pickering\'s analysis is time, the view that what he names material agency is always temporally emergent in practice, rather than fixed in either subjects or objects (see also Lynch, Livingston, and Garfinkel (1983)). Knorr-Cetina adopts a trope of \"epistemic cultures\" to think about laboratories as mutually shaping arrangements of scientists, instruments, objects, and practices aimed at the production of observably stabilized instantiations of \"reality effects\" (1999: 26­33). The notion of reconfiguration is central to her analysis as well, as the process through which subject/object relations are reworked. Considered over time, she argues, reconfigurations comprise what are commonly termed skills or expertise: \"The alignments . . . work through the body of the scientist, but they also involve a drastically rearranged environment, a new life-world in which new agents ineract and move. When we ascribe skills to a person . . . the person acts as a symbol ­ a stand-in for the common life-world with objects, which, in the laboratory . . . is continually recreated\" (219­20). Knorr Cetina\'s argument here has resonance as well with Lynch\'s (1991) formulation of \"topical contextures\" to indicate the inseparability of knowledge practices and the phenomenal fields of action that they at once constitute and inhabit, and with Ingold\'s (2000) analysis of skill not as an attribute of a body, but of a system of relations involving the artisan\'s presence in a specifically configured sociomaterial environment.\r\nIn his exploration of what he terms \"professional vision,\" Charles Goodwin has carried out a series of studies focused on the sociomaterial interactions through which practitioners learn to see the phenomena that constitute the objects of their profession (C. Goodwin 1994, 1995a, 1997, 2003). A central argument is that these phenomena are not preexisting but are constituted as disciplinarily relevant objects through occasioned performances of competent seeing (see also Goodwin and Goodwin 1996, 1997). In looking at gestures and their objects, for example, Goodwin argues that the relation is a \"symbiotic\" one; that is, \"a whole that is both different from, and greater than its parts, is constructed through the mutual interdependence of unlike elements\" (2003: 20). Symbiotic gestures, Goodwin argues, are not referring to something outside of themselves: rather, the gesture\'s objects are integral components\r\n\r\nReconfigurations\r\n\r\n263\r\n\r\nof the gesture itself (ibid.: 40, note 1). In the case of archaeologists \"defining features\" of relevance in a site of excavation, for example, Goodwin observes that a \"feature\" does not simply present itself but must be made visible through the embodied work of the archaeologist, including talk with colleagues, gestures, inscriptions in the dirt, and various forms of record keeping, mapping, and the like (see also Latour 1999: 58­61). In this way \"a feature as a semiotic object . . . emerges as the product of both actual patterning in the soil being investigated, and the cultural categories and embodied practices used by archaeologists to make it visible as a particular kind of phenomenal object\" (ibid.: 29). At the same time, the objects being defined and their categorization exist within a professional matrix of social and material accountability, subject to contest by the readings of others and by the objects themselves; for example, in the discovery of roots extending from what has been previously identified as a post mold, indicating instead the presence of a tree (ibid.: 30). Archaeological knowledge, on this analysis, comprises relations between particular culturally and historically constituted practices and their associated materials and tools. It is out of those relations, quite literally, that the objects of archeological knowledge and the identity of competent archeologist are co-constructed.\r\nAlthough not concerned specifically with interactive machines, Goodwin\'s analysis provides further support for the wider argument against attributions of agency either to humans or to artifacts and gives us, in turn, a different way of understanding the problem of attributions of knowledge and agency to machines. The problem is less that we attribute agency to computational artifacts than that our language for talking about agency, whether for persons or artifacts, presupposes a field of discrete, self-standing entities.3 As an alternative, we can take the interface not as an a priori or self-evident boundary between bodies and machines but as a relation enacted in particular settings and one, moreover, that shifts over time.\r\nThe shifting nature of body­machine boundaries is enacted quite literally in the case of technology-intensive medicine, and here again an instructive series of studies are available. Dawn Goodwin (2004) describes the practices through which patients in surgery are \"transitioned\" through anaesthetic states, a process involving the radical reconfiguration of their capacity for action; specifically, for the sustenance\r\n\r\n3 Latour makes a closely related argument, using the example of the gun. See Latour (1999: 179­80). See also Casper (1994), Law (1987).\r\n\r\n264\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nof their own life support. Over the course of an anaesthesia, agencies involved in the maintenance of vital bodily functions are progressively delegated from the patient as an autonomously embodied entity to an intricately interconnected sociomaterial assemblage and then back again.4 Through a series of cases, Goodwin demonstrates how the technologies of anaesthesia are joined to the patient\'s body, in ways that render the latter highly dependent and vulnerable but nonetheless intensely (albeit sometimes ambiguously) communicative. This joining is analyzed as a delicate choreography involving patients, medical practitioners, and machines.5 Goodwin argues that questions of agency are crucial both to assess policy with respect to medical practice and to deepen our understanding of the dense sociotechnical arrangements that comprise much of contemporary medical activities and institutions.\r\nIn a related argument developed through the case of reproductive technoscience, Thompson (Cussins 1998; Thompson 2005) argues against the idea that medical interventions inherently objectify patients and thereby strip them of their agency. She observes that in the case of infertility clinics \"the woman\'s objectification, naturalization, and bureaucratization involve her active participation and are managed by herself as crucially as by the practitioners, procedures, and instruments\" (Cussins 1998: 167). Conversely, objectification does not inherently or necessarily lead to alienation, nor does it stand always in opposition to subjectivity or personhood. Among other things, the clinic relies on the possibility of separation (of egg and sperm from the bodies that produce them) without alienation. Cussins locates alienation not in objectification per se, but in the breakdown of synechdochal relations between parts and whole that make objectification of various forms into associated forms of agency. It is this process \"of forging a functional zone of compatibility that maintains referential power between things of different kinds\" that she names ontological choreography (ibid.: 192). Medical ethics and accountability, she argues, need to be founded\r\n\r\n4 The particular expertise of the anaesthetic practitioner on this account is to manage the often unruly contingencies of the unfolding course of anaesthesia through a combination of skillfully embodied techniques, reading of signs, professional judgments, and legitimating accounts, which together provide the grounds for practical action. See also Heath et al. 2002, Hirschauer 1991, Mort et al. 2005.\r\n5 The trope of \"choreography\" was introduced by Charis Thompson (Cussins 1998, Thompson 2005), whose work I return to below.\r\n\r\nReconfigurations\r\n\r\n265\r\n\r\nnot in the figure of the rational, informed citizen but in the conditions for the maintenance of those crucial relations that configure identities and selves and that might allow them to be reconfigured in desired ways.\r\nThe assemblage of the pregnant woman has been the focus as well of Casper\'s research on experimental fetal surgery, where categories of the human and associated agencies take on a particular salience and urgency (1994, 1998). In the context of debates over abortion within the United States, the figuring of \"fetal patients\" has consequences that resonate not only within but also well beyond the walls of the surgery. In addressing this tricky political terrain, Casper calls for a methodological strategy aimed at \"grounding the construction of social identities and subject positions in concrete practices, more specifically the practices through which fetal humanity, including agency, is socially and technologically shaped\" (1994: 2). A central moral of Casper\'s story is that questions of agency are inseparable from the more extended frames of reference in which entities are entangled or, alternatively, that their separation is itself a strategically consequential act. I return to the question of frames below but note for the moment that Casper\'s analysis suggests in turn that the politics of fetal agency cannot be adequately debated without taking as our primary unit the woman plus fetus, within the context of the latter\'s contested material and symbolic status and its implications for actual women\'s lives.\r\nWhereas fetal surgery would stand as among the most maximally invasive of medical procedures, a different sense of the fluidity of body­ machine boundaries is provided by Prentice\'s ethnographic interviews with physicians engaged in its surgical opposite (2005). Minimally invasive or \"keyhole\" surgery, as it has developed over the past few decades, has involved a series of shifts in the gaze of the surgeon and attendant practitioners from the interior of the patient\'s body ­ formerly achieved through a correspondingly large incision ­ to views mediated first through microscopy and now through digital cameras and large screen monitors. Prentice finds that surgeons accustomed to operating within previous configurations of patient and instruments express a sense of disorientation when they are translated into the reconfigured sociotechnical network of video camera and monitor. One surgeon with whom Prentice speaks reports an experience not only of his gaze but also of his hands and entire body, effectively leaving the site of the patient\'s body and \"going to work on the monitor\" or image instead; a translation\r\n\r\n266\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nthat he finds deeply alienating.6 In contrast, Prentice found that surgeons who have performed minimally invasive surgery mediated by camera and monitor throughout their career report a very different phenomenal shift. Far from being alienated from the patient, they experience themselves as proprioceptively shifted more directly and proximally into the operative site, with the manipulative instruments serving as fully incorporated extensions of their own acting body.7 As Prentice observes of these cases: \"When the patient\'s body is distributed by technology, the surgeon\'s body reunites it through the circuit of his or her own body\" (ibid.: 8). These differences suggest again that questions of alignment or dislocation, relation or alienation, are not immanent in human­machine boundaries or even, a priori, in particular human­machine configurations. Rather, they are effects lived and experienced within multifaceted subject­object assemblages.\r\nThe shifting boundaries of humans and machines and their consequences comprise the topic of another study of minimally invasive surgical practices by Aanestad (2003), who focuses on the labors performed by nurses and technicians in aligning the complex sociotechnical environment of the surgical theatre itself.8 Her study follows the installation of multimedia communications technologies (cameras, microphones, and speakers) in a surgical operating theatre in ways intended not only to enable the surgery but also to facilitate communication with viewers outside, including with remotely located surgeons in training. Aanestad\'s analysis follows the course of shifting interdependencies in the surgical assemblage, as changes to existing arrangements necessitate further\r\n\r\n6 It is important to note that this is not a simple distinction between mediated and unmediated access. All of the surgeons with whom Prentice spoke in this study were experienced in keyhole or minimally invasive surgery. The surgeon who reported his sense of disorientation with the latest techniques had previously worked while looking through a microscopic eyepiece; the disruptive shift for him was from that to a video monitor more distal from both his own and the patient\'s body.\r\n7 This sense of the fluidity of body boundaries and their reconfigurability is resonant with Mol\'s findings (2002) regarding the ontologies of subjects, artifacts, and objects in medical practice.\r\n8 The question of visibility­invisibility and framing resonates throughout Aanestad\'s study, as nurses and technicians configure the theatre for transmission of the surgery to remote audiences in ways that center the surgeon and quite literally relegate their own work to the margins, outside the field of view. At the same time, this is not a simple story of power lost, as the technologies become available to them for appropriation in new ways, while their own role in the surgical process becomes more indispensable. On invisible work see Clement (1993), Shapin (1989), Star (1991), Suchman and Jordan (1989); on gendered (re-)appropriations of new technologies see Cherny and Weise (1996), Spender (1996), Terry and Calvert (1997), Wakeford (2000), Wolmark (1999).\r\n\r\nReconfigurations\r\n\r\n267\r\n\r\nchanges in a process that she names the in situ work of \"design in configuration\" (2003: 2). She emphasizes that the agencies of the technologies involved do not exist before their incorporation into the network; for example, as questions of the adequacy of image and sound quality or shifts in the locus of control. Aanestad concludes that introducing telemedicine or other network technologies in such settings requires \"open and evolutionary strategies, which are aimed at enrolling allies, rather than control-oriented, specification-driven strategies\" (ibid.: 16). Her analysis makes clear how in such a setting the capacity for action is relational, dynamic, and collective rather than inherent in specific network elements and how the extension of the network in turn intensifies network dependencies.\r\nTogether these inquiries respecify sociomaterial agency from a capacity intrinsic to singular actors to an effect of practices that are multiply distributed and contingently enacted. Addressing similar questions, but from a position within feminist philosophy and science studies, physicist Karen Barad has proposed a form of materialist constructivism that she names \"agential realism,\" through which realities are constructed out of specific apparatuses of sociomaterial \"intra-action\" (2003). Whereas the construct of interaction suggests two entities, given in advance, that come together and engage in some kind of exchange, intra-action underscores the sense in which subjects and objects emerge through their encounters with each other.9\r\nMore specifically, Barad locates technoscientific practices as critical sites for the emergence of new subjects and objects. Taking physics as a case in point, her project is to work through long-standing divisions between the virtual and the real, while simultaneously coming to grips with the ways in which materialities, as she puts it, \"kick back\" in response to our intra-actions with them (1998: 112; see also Knorr Cetina (1999), Pickering (1984, 1995), Traweek (1988)). Through her close readings of Niels Bohr, Barad insists that \"object\" and \"agencies of observation\" in his view form a nondualistic whole: it is that relational entity that comprises the objective \"phenomenon\" (1996: 170). In a position consistent with Haraway\'s adoption of the compound \"material-semiotic,\" Barad takes concepts and their objects as mutually constitutive. Different \"apparatuses of observation\" enable different, always contingent, subject­object cuts that in turn enable measurement or other forms of\r\n\r\n9 Smith (1996) develops a kindred concept of \"registration\" to describe the partial effects of subject­object difference, generated through processes of engaged participation.\r\n\r\n268\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nobjectification, distinction, manipulation, and the like within the phenomenon. The relation is \"ontologically primitive\" (2003: 815), in other words, or prior to its components; the latter come about only through the \"cut\" effected through a particular apparatus of observation.\r\nOne implication of this view is a more radical understanding of the sense in which \"materiality is discursive (i.e., material phenomena are inseparable from the apparatuses of bodily production: matter emerges out of and includes as part of its being the ongoing reconfiguring of boundaries), just as discursive practices are always already material (i.e., they are ongoing material (re)configurings of the world)\" (Barad 2003: 822). This intimate co-constitution of configured materialities with configuring agencies clearly implies a very different understanding of the human­machine interface. Read in association with the empirical investigations of complex sociomaterial sites described above, \"the interface\" becomes the name for a category of contingently enacted cuts occurring always within sociomaterial practices, that effect \"person\" and \"machines\" as distinct entities, and that in turn enable particular forms of subject­object intra-actions. At the same time, the singularity of \"the interface\" explodes into a multiplicity of more and less closely aligned, dynamically configured moments of encounter within sociomaterial configurations, objectified as persons and machines. It is the differences effected within such configurations that I turn to next.\r\n\r\ndifferences within\r\nThe reconstructions of sociomaterial agency reviewed above are frequently summarized by the proposition that humans and artifacts are mutually constituted. This premise of technoscience studies has been tremendously valuable as a corrective to the entrenched Euro-American view of humans and machines as autonomous, integral entities that must somehow be brought back together and made to interact. But at this point I think that the sense of mutual constitution warrants a closer look. In particular, we are now in a position to elaborate that generative trope along at least two critical dimensions: first, in relation to the dynamic and multiple forms of constitution that are evident in specific sociomaterial assemblages and, second, in terms of questions of difference ­ and more particularly asymmetries ­ within those assemblages.\r\nAs the studies reviewed above and others like them have shown, the constitution of humans and artifacts does not occur in any single time and place, nor does it create fixed human­artifact relations or entities.\r\n\r\nReconfigurations\r\n\r\n269\r\n\r\nRather, artifacts are produced, reproduced, and transformed through ongoing \"labours of division,\" in Law\'s phrase (1996), that involve continuous work across particular occasions and multiple sites of use. This work of production and reproduction across time and space results in very diverse assemblages, involving participants with different histories, relations of familiarity or strangeness, and the like. As Mulcahy points out with respect to technologies (1999), it is their increasingly extensive distribution and the range of variations across user­machine pairings that render protocols, standards, instructions, and the like necessary to the successful production and reliable reproduction of human­ artifact interactions. Empirical investigations of the workings of standards and other technologies aimed at the reproduction of sameness (including those that take the form of plans or instructions examined earlier in this book) provide ample evidence that the agencies of such artifacts do not inhere in the prescriptions themselves but rely on the skilled practices that bring them into alignment with a given case at hand.\r\nMutualities, moreover, are not necessarily symmetries. My own analysis suggests that persons and artifacts do not constitute each other in the same way.10 In particular, I would argue that we need a rearticulation of asymmetry, or more impartially perhaps, dissymmetry, that somehow retains the recognition of hybrids, cyborgs, and quasi-objects made visible through technoscience studies, while simultaneously recovering certain subject­object positionings ­ even orderings ­ among persons and artifacts and their consequences. The emphasis in science and technology studies on symmetrical analysis and the agency of things arose from well-founded concerns to recover for the social sciences and humanities aspects of the lived world ­ for example, \"facts of nature\" and \"technology\" ­ previously excluded from consideration as proper sociological subjects. My project is clearly indebted to these efforts, which provide the reconceptualizations needed to move outside the frame of categorical purification and opposition between social and technical, person and artifact. My own engagement with these questions, however, came first in the context of technoscience and engineering, where the situation is in important respects reversed. Far from being excluded, \"the\r\n\r\n10 As Pickering points out with respect to humans and nonhumans, \"Semiotically, these things can be made equivalent; in practice they are not\" (1995: 15). This notwithstanding the possibility of delegating humanlike actions to machines, or identifying machinelike actions within the activities of humans (see also Collins 1990).\r\n\r\n270\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ntechnical\" in regimes of research and development are centered, whereas \"the social\" is separated out and relegated to the margins. It is the privileged machine in this context that creates its marginalized human others.11\r\nSo what are the possibilities for recovering a sense of particular agencies of the human without at the same time reinstating essentialized human­machine differences? How might we reconceptualize the granting of agency in a way that at once locates the particular accountabilities of human actors, while recognizing their inseparability from the sociomaterial networks through which they are constituted? Analyses ­ including my own ­ that describe the active role of artifacts in the configuration of networks inevitably seem to imply other actors standing just offstage for whom technologies act as delegates, translators, mediators; that is, human engineers, designers, users, and so on. I want to suggest that the persistent presence of designers­users in technoscientific discourse is more than a recalcitrant residue of humanism: that it reflects a durable dissymmetry among human and nonhuman actors. The response to this observation is not, however, to cry \"Aha, it really is the humans after all who are running the show.\" Rather, we need a story that can tie humans and nonhumans together without erasing the culturally and historically constituted differences among them. Those differences include the fact that, in the case of technological assemblages, persons just are those actants who configure material-semiotic networks, however much we may be simultaneously incorporated into and through them.12 I want to keep in view as well the ways in which it matters when things travel across the human­artifact boundary, when objects are subjectified (e.g., machines made not actants but actors) and subjects objectified (e.g., practices made methods or knowledges made commodities).13\r\nApplied to the question of agency, I have argued that in the case of the intelligent machine we are witnessing a reiteration of traditional humanist notions of agency, at the same time ­ even through ­ the\r\n\r\n11 I use \"others\" here in the sense nicely summarized by Lee and Brown as \"all those entities and areas of inquiry that are rendered problematic by expansionist projects, be they formally political or theoretical\" (1994: 773).\r\n12 Pickering (1995: 15) similarly poses the question of who does the \"delegation\" of agencies across actor networks.\r\n13 As Haraway (2003: 4) succinctly reminds us with respect to the machinic and animal, \"the differences between even the most politically correct cyborg and an ordinary dog matter.\"\r\n\r\nReconfigurations\r\n\r\n271\r\n\r\nintra-actions of that notion with new computational media. In the remainder of this chapter I look to further experiments in configuring human­machine boundaries to explore the question of what other directions our relations with machines, both conceptually and practically, might take.\r\n\r\nrereading the human­machine\r\nI turn first to recent counterreadings of the humanlike machine, inspired by feminist discussions of materialities, subjectivities, and cyborg bodies. Like many, my attention was first drawn to these possibilities by Donna Haraway\'s \"whip lashing\" proposal (a phrase that she herself uses to describe those moments when a new idea comes along that turns one\'s head) that we should all prefer to be cyborgs than goddesses (1985/1991: 223). As Wolmark summarizes, in her discussion of the \"Manifesto for Cyborgs\": \"The cyborg\'s propensity to disrupt boundaries and explore differently embodied subjectivities could . . . be regarded as its most valuable characteristic, and it is undoubtedly one of the reasons for its continued usefulness in feminist and cultural theory\" (1999: 6).14 As feminist theorists trace a new path across the problematic terrain of how the sexed and gendered subject might be reconceived, they also provide us with resources for reconceptualizing the agential object. More specifically, feminist retheorizing of the body has been concerned to restore the dynamism emptied out of bodies by the mind­body split by moving through that split onto new terrain. In a similar way, feminist theorists suggest that we might find other grounds for recognizing the agential properties of the material than the operations of a transcendental intelligence over inert, mechanistically animated matter. As Butler famously puts it in Bodies That Matter: \"What I would propose . . . is a return to the notion of matter, not as site or surface, but as a process of materialization that stabilizes over time to produce the effect of boundary, fixity, and surface we call matter . . . Crucially, then, [the construction of bodies] is neither a single act nor a causal process initiated by a subject and culminating in a set of fixed effects\"\r\n14 At the same time, as Balsamo cautions, far from imploding the boundaries of human and machine, for most popular cyborg figures \"Signs of human-ness and, alternatively, signs of machine-ness function not only as markers of the `essences\' of the dual natures of the hybrid, but also as signs of the inviolable opposition of human and machine. This is to say that cyborgs embody human characteristics that reinforce the difference between humans and machines\" (2000: 149).\r\n\r\n272\r\n\r\nHuman­Machine Reconfigurations\r\n\r\n(1993: 9­10). Butler\'s argument that sexed and gendered bodies are materialized over time through the reiteration of norms is suggestive for a view of technology construction as a process of materialization through a reiteration of forms. Butler argues that \"sex\" is a dynamic materialization of always contested gender norms: similarly, we might understand \"things\" or objects as materializations of more and less contested, normative figurations of matter. Much as recognition and intelligibility are central to feminist conceptions of the subject, objects achieve recognition within a matrix of historically and culturally constituted familiar, intelligible possibilities. Technologies, like bodies, are both produced and destabilized in the course of these reiterations.\r\nAn early example of an alternative cyborgian embodiment is provided by Deirdre, the heroine of science fiction writer C. L. Moore\'s 1944 short story, \"No Woman Born.\"15 Deidre prefigures Haraway\'s challenge to the cultural imaginary of the goddess-turned-cyborg. Ambivalently positioned on the boundary of Cartesian and feminist imaginaries, the premise of Moore\'s story is that Deirdre, once an exquisitely beautiful and talented dancer, has been injured in a theater fire to the point that only her brain survives. As the brain of a dancer, however, Deirdre\'s brain is located by Moore in intimate relation to her body. As the story unfolds, it becomes clear that the restoration of Deirdre\'s agency is inseparably tied to the particularities of her rematerialization. We enter the story one year after the tragic fire, during which time Deirdre (Deirdre\'s brain?) has been painstakingly reembodied by Maltzer, a genius physician­ scientist, assisted by a team of unnamed (but apparently greatly talented) sculptors and artists. The story that follows is effectively a set of variations around the theme of Deirdre\'s rematerialization, haunted by questions of memory, identity, recognition, transformation, and otherness. We approach these questions through the person of John Harris, Deirdre\'s former (human) agent and close friend, coming to see her for the first time following the accident. Torn by visions of, on one hand, the irrecoverable figure of Deirdre the human as he knew her and, on the other, culturally inspired imaginings of how the new, robotic Deirdre might be configured, Harris suffers agonies of anticipation in advance of their meeting. His anxieties are not allayed by the comments of her restorer Maltzer, in the anteroom of Deirdre\'s chambers: \"It\'s not that she\'s ­ ugly ­ now . . . Metal isn\'t ugly. And Deirdre . . . well, you\'ll see.\r\n\r\n15 It is notable that this story appears in an anthology of science fiction short stories within which C. L. Moore is the only woman author.\r\n\r\nReconfigurations\r\n\r\n273\r\n\r\nI tell you, I can\'t see myself. I know the whole mechanism so well ­ it\'s just mechanics to me. Maybe she\'s ­ grotesque, I don\'t know\" (1975: 67).\r\nThe Deirdre that Harris goes on to meet is less a replica than a new configuration, a reembodiment, of the Deirdre he remembers. In place of a face, she has a delicately modeled ovoid head with a kind of golden mask, in which a slit of aquamarine crystal occupies the place where her eyes would have been. And rather than a simulation of human skin over hinged metal joints, her body is made up of tiny golden coils, infinitely flexible, covered by a robe of very fine metal mesh, all of which she has learned to move with an extraordinary expressiveness and grace at once reminiscent of, and different from, her former dancer\'s body. As Harris struggles to come to terms with the neither­nor, both­and qualities of the new Deirdre, the story unfolds as a succession of reflections on the uncertainties of Deirdre\'s status, in relation to her former identity as Deirdre and to the rest of the human world. First, what is the relation of this new creature to \"Deirdre\" herself? Is \"she\" still alive? And what about the reembodied Deirdre\'s relation to her creator, Maltzer? Is she an extension of him, his property, or an autonomous being, animating the materials that he has provided with her own \"unquenchable\" essence? And is her essence that of the brain that survived or some irreducible spirit that animates her new body? In one of his more posthumanist moments, Harris muses, \"She isn\'t human, but she isn\'t pure robot either. She\'s something somewhere between the two, and I think it\'s a mistake to try to guess just where, or what the outcome will be\" (ibid.: 88). The story\'s pivotal question, on which the plot turns, is whether Deirdre is still human and, if not, whether the rematerialized Deirdre can survive given her singular otherness. Not surprisingly, this question remains unanswered at the story\'s end. But what Moore has achieved is to reframe the cyborg from its reiteratively human replicant form to something that dances elusively, and therefore suggestively, on the boundaries of old and new possibilities. Deidre embodies the ambivalences of mid-twentieth-century technoscience, suggesting the possibilities for new configurations that are fabulous and expansive, while at the same time threatening the reassuring ground of normative categories on which our experiences of relationship, of knowing and being known, depend. Figured alternately as goddess, human, superhuman, and monster, Deirdre powerfully expresses the questions raised by new sociomaterial possibilities and their relations to old struggles around identity and difference.\r\nMore recently, Claudia Castan~ eda (2001) has written about the rematerialization of touch in contemporary robotic artificial intelligence.\r\n\r\n274\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nBeginning from an understanding of touch as always semiotic and relational, and of signs as always entailing materialities, she takes up the question of the skin and its materialization in the form of the robot Cog (see Chapter 13).16 Interactivity is framed by Cog\'s designers as the litmus test of its competencies, with \"the world\" and with its human counterparts. During Cog\'s early, awkward stage, its \"skin\" (described as \"an exquisitely sensitive piezo-electric membrane\" in Dennett 1994: 139) is designed to serve as a protective device against contact, equipped with the requisite sensors and alarms. Castan~ eda explores the premise that Cog\'s embodiment, particularly its skin, is designed to change in response to the robot\'s interactions over time. My skeptical reading of the project falters on the question just how open the possibilities of rematerialization are for Cog given the robot\'s origins in the historical and cultural matrix of the Massachusetts Institute of Technology. But Castan~ eda\'s hopeful reading points us to aspects of Cog that at least signal the possibility of what she names a \"feminist robotics\" (2001: 233).\r\nFirst, and most basically, Cog\'s design (at least on this telling) locates touch as a way of knowing and being in the world. Second, Castan~ eda suggests that Cog embodies a relational conception of the body, one that extends beyond the boundaries of the skin and that is generated through particular, changing combinations of materials and qualities. And finally, as she puts it, Cog is \"neither human nor anti-human, but rather other-than-human\" (ibid.: 232). As such, she argues that Cog\'s reembodiment of the human in different terms generates the possibility, in material form, of embodied alterity, a relation of difference that literally as well as figurally matters. Castan~ eda\'s interest, then, is in just what kind of alterity is, or could be, embodied in the robot, which does not take the human, normatively imagined, as the \"origin and truth against which the robot\'s value is always measured\" (ibid.: 234).17\r\nThe question of how the robot could be other than second term to the human aligns with feminist concerns regarding what Anne Balsamo sums as \"the systems of differentiation that make the body meaningful,\"\r\n\r\n16 It is critical to Castan~ eda\'s reading of Cog that she relies on an account of Cog\'s conception offered by philosopher of mind Daniel Dennett (1994) rather than on accounts or observations of the robot as implemented. This does not diminish the suggestive possibilities of her analysis, only the question of their realization within prevailing robotic imaginaries.\r\n17 For another reflection on the robot\'s current and potential figurations, see Castan~ eda and Suchman (in press).\r\n\r\nReconfigurations\r\n\r\n275\r\n\r\nmost notably those of gender (1996: 21). Power works through binary opposites not in the simple sense that the first term holds power over the second but that their relative positionings ­ including, crucially, as opposites ­ enable their fundamental interrelatedness and the historically sedimented cuts that position them as separate categories to be obscured. In contrast, Judith Halberstam proposes that in her feminist conceptions: \"The intelligent and female cyborg thinks gender, processes power, and converts a binary system of logic into a more intricate network\" (1991: 454). Framed not as the importation of mind into matter, but as the rematerialization of bodies and subjectivities in ways that challenge familiar assumptions about the naturalness of normative forms robots, and cyborg figures more generally, become sites for change rather than just for further reiteration.\r\nFeminist rereadings of the cyborg replace the binaries male­female, human­machine, and subject­object with the possibility of an open horizon of specific, historically and culturally constituted, sociomaterial relations. Crucially, these relations are still power differentiated but in ways that can be recovered, as distributions located in specific configurations. Although the cyborg since Haraway suggests generative new forms of analysis, however, to realize that promise requires shifting out from its popular figuring as a singular, albeit hybrid, entity. The latter inherits a problem that characterizes any strategy centered on a heroic (even monstrous or marginalized) figure; that is, it obscures the presence of distributed sociomaterialities in more quotidian sites of everyday life. Along with the dramatic possibilities of the feminist cyborg, we need to recover the ways in which more familiar bodies and subjectivities are being formed through contemporary interweavings of nature and artifice, for better and worse.18 Put another way, now that the cyborg figure has done its work of alerting us to the political effects, shifting\r\n\r\n18 This includes, for example, the Silicon Valley workers identified by Sandoval (1995), who \"know the pain of the union of machine and bodily tissue\" as they assemble the components of new objects within old regimes of racially and ethnically based difference. Relatedly, Jain (1999) considers the multiple ways in which prostheses are wounding at the same time that they are enabling. In contrast to the easy promise of bodily augmentation, she observes, the fit of bodies and artifacts is often less seamless and more painful than the trope of the cyborg would suggest. Jain (2006) takes legal contests over injury as a public and consequential site for the exploration of attributions of agency across the person­artifact boundary, within the wider dynamics of American commodity culture. Subject to Jain\'s insightful analysis, normative debates over things and their social consequences provide evidence for how the worlds that we inhabit are configured and by whom. This question is further elaborated by Schull (2005, in press),\r\n\r\n276\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nboundaries, and transformative possibilities in human­machine mixings, it is time to get on with investigation of particular configurations and their consequences. How then might we locate conditions for action and possibilities for intervention in the specificities of more mundane sociomaterial assemblages?\r\n\r\ndesign practices\r\nOver the twenty years since the original publication of Plans and Situated Actions, new developments in professional practices of computer systems design have at least provided existence proofs of transformative possibilities. The emergence of increasingly distributed, networked computing during the late 1970s and early 1980s raised questions that clearly went beyond the limits of the human­machine interface narrowly construed to involve collective forms of computer use.19 The turn to the social among computer scientists and information systems designers in the mid-1980s was accompanied by an intensification of interest among social researchers in the material grounds of sociality. Within ethnomethodology and conversation analysis, a growing awareness of the centrality of nonvocal activities (most obviously gaze and gesture) to the organization of face-to-face human interaction inspired a move toward the incorporation of materially based activity into the field of study. From Charles Goodwin\'s attention to the lighting of a cigarette in Conversational Organization (1981) to Goodwin and Goodwin\'s analyses of the interactional organization of eating and talk at a family dinner (1992), Heath\'s attention to the interactional enactment of patient pain (1986), and Schegloff\'s observations regarding the interactional effects of body \"torque\" (1998), interaction analysts increasingly recognized the interorganization of talk and other forms of embodied activity. Among\r\nin her compelling account of the slippage between autonomy and automaticity in the case of human­machine couplings at the interface of video gambling machines. 19 The phrase Computer-Supported Cooperative Work (CSCW) was coined by Irene Greif, then on the faculty in Computer Science and Electrical Engineering at MIT, to convene a small invited workshop in 1984. This led to a series of still ongoing biannual conferences, as well as events held in alternate years under the title of the European CSCW or ECSCW conferences. CSCW is now an established subfield within professional networks of research and development engaged with the design of computer-based systems and devices. The CSCW conferences and journal have been the primary site for both programmatic and empirically based discussion between researchers in the computing and social sciences and the venue for a rich corpus of technical explorations and ethnographically informed investigations of technology-intensive sites of social action.\r\n\r\nReconfigurations\r\n\r\n277\r\n\r\nthose of us immersed in ethnomethodology and newly engaged with the enterprise of computer systems design, absence of attention to the social and material organization of relevant forms of practice ­ from following instructions in the operation of photocopier to maintaining the order of traffic in the air ­ was an obvious site for generative intervention. The corpus of studies is by now extensive and comprises an established resource in the repertoire of design for technology-intensive forms of practice across a range of settings.\r\nA central argument of these studies is that the nature and relevance of environment, objects, and actions are reflexively constituted through the ongoing activities of their habitation, engagement, and recognition. In the context of administering organizations operating across widely distributed locales, moreover, many of the relevant objects materialize technologies of coordination and control ­ procedural instructions, schedules, protocols, and the like ­ that prescribe courses of action designed to be reliably reproduced or available for comparative assessment. Relevant artifacts include, for example, flight progress control strips (Hughes, Randall, and Shapiro 1993), airline schedules (Goodwin and Goodwin 1996; Suchman 1993b), and railway timetables (Heath and Luff 1992). The politics of such artifacts (as for any technologies) include relations between the sites and interests within which coordinative artifacts are generated and those of their use. Like the \"plan\" that forms a focal object for this book, such technologies presuppose an open horizon of sociomaterial practices that inevitably exceed their representational grasp. At the same time, those practices reflexively constitute themselves as implementation of the actions prescribed. As I discussed at length in Chapter 11, the frequent presence of multiple, often contradictory, agendas of workplace auditing, on the one hand, and the work required to enact an orderliness within the work, on the other, lead to various forms of both breakdown and creative resistance. Design for such settings is therefore an inherently ethical project (Robertson 2002: 300).\r\nWhereas Computer-Supported Cooperative Work directs the attention of researchers and systems designers to the sociality of computer use, a second, intersecting research community has taken up the challenge of a more radically conceived interference in existing arrangements of professional systems design. Inspired initially by pilot projects in the Nordic countries, involving codevelopment of information systems among organized workers and politically astute computer scientists, the project of participatory design entered the awareness of North\r\n\r\n278\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nAmerican researchers in the 1980s.20 The by-now extensive body of research that has been conducted under the auspices of participatory design by no means conforms to a single orthodoxy.21 The guiding commitment, however, is to rethinking critically the relations between practices of professional design and the conditions and possibilities of information systems in use. Central to this process is an attunement to the politics of design, that is, an orientation to the inevitable interrelations of agendas of technological change and (re-)distributions of labor with associated implications for both material and symbolic reward.\r\nA common premise for both CSCW and participatory design, arising from their basis in empirical investigations of technologies-in-use across a range of settings, is that design ­ the configuration of artifacts ­ is not the exclusive province of professional practitioners. The necessity and creativity of ongoing practices of design-in-use has by now been extensively documented. Rather than a process that stops at the point of hand-off from production to consumption, design is as an ongoing process of (re-)production over time and across sites. Just what, then, is the role of the professional designer? Although in no way obviating the specific knowledges and material practices of the designer, the object of design must shift. Rather than fixed objects that prescribe their use, artifacts ­ particularly computationally based devices ­ comprise a medium or starting place elaborated in use. Rather than holding stable and separate the identities of \"designer\" and \"user,\" the latter work as categories\r\n\r\n20 Invited by Irene Greif to act as Program Chair for CSCW 1988 and newly aware of activities in Scandinavia, I welcomed the opportunity to encourage this exchange through a series of papers presented at the second annual CSCW conference in 1988. A more dedicated conference was convened in 1990 under the auspices of Computer Professionals for Social Responsibility, with the title Participatory Design of Computer Systems or PDC (see Schuler and Namioka 1993), and these conferences have continued biannually since. For founding volumes in this area see Bjerknes, Ehn, and Kyng (1987), Ehn (1988), and for more recent collections see Greenbaum and Kyng (1991), Schuler and Namioka (1993).\r\n21 Various of the ideas and design practices characteristic of participatory design have by now made their way ­ more and less unscathed ­ into mainstream circulation under the rubric of user-centered design. For thoughtful introductions see Carroll (2000); Landauer (1995); Rogers, Sharp, and Preece (2002). At Xerox PARC during the 1990s I and my colleagues characterized our approach as one of practice-based codesign. Our aim in associating with these particular terms was not to stake out new terrain, but on the contrary to avoid the inexorable slide toward what Verran has named \"hardening of the categories\" that comes with the repetition (and initial captialization) of naming, particularly in the context of competitive R&D. Our intent was to maintain the provisionality and fluidity of our self-descriptions, while acknowledging our relations and indebtedness to an extended research community.\r\n\r\nReconfigurations\r\n\r\n279\r\n\r\ndescribing persons differently positioned, at different moments, and/or with different histories and future investments in projects of technology development (see Suchman 1999, 2002a, 2002b).\r\n\r\ninhabiting the interface\r\nIn her analysis of computer-based work, Susanne Bødker (1991) has discussed the shifting movement of the interface from object to connective medium. She observes that when unfamiliar, or at times of trouble, the interface itself becomes the work\'s object. At other times persons work, as she puts it, \"through the interface,\" enacted as a transparent means of engagement with other objects of interest (for example, a text or an interchange with relevant others). As a case in point, we can consider the reflections of a civil engineer working at a CAD workstation (see also Henderson 1999; Suchman 2000). Although CAD might be held up as an exemplar of the abstract representation of concrete things, for the practicing engineer the story is more complex. Rather than stand in place of the specific locales ­ roadways, natural features, built environments, people, and politics ­ of a project, the CAD system connects the experienced engineer sitting at her worktable to those things, at the same time that they exceed the system\'s representational capacities. The engineer knows the project through a multiplicity of documents, discussions, extended excursions to the project site, embodied labors, and accountabilities: the textual, graphical, and symbolic inscriptions of the interface are read in relation to these heterogeneous forms of embodied knowing. Immersed in her work, the CAD interface becomes for the engineer a simulacrum of the site, not in the sense of a substitute for it but rather of a place in which to work with its own specific materialities, constraints, and possibilities. Like the symbiotic gesture described by Goodwin (2003), the CAD interface in use associates disparate elements both within and beyond its frame at the same time that those elements are essential to its intelligibility and efficacy.\r\nFeminist film theorist Laura Marks describes what she calls \"haptic visuality\" as comprising \"images that encourage a sympathy, intimacy and complicity between work and viewer\" (2002: 3). She uses the term work in this context not with reference to a fetishized object resulting from cinematic practice but as an always only partially representable complex of social and material labors. Such works effect what Marks calls a \"three-dimensional intimacy\" among persons, images and their materiality, and the worlds to which the images connect. Those\r\n\r\n280\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nintimacies, in turn, dissolve the space between object and subject, evoking an embodied response that is more a form of inhabiting the cinematic work than a distanced appraisal of it. Central to such affective effects are the specific materialities of the medium. Marks observes that in the early days of cinema filmmakers demonstrated their fascination with the new medium\'s materialities as much as with its abstract representational power. Seen from this perspective, film is not a neutral conveyor of images, but rather the particular qualities of film stock are themselves an integral part of the imagery and imaginary created. It is not only the film\'s materialities, moreover, that this approach is aimed to recover but also \"the rarely acknowledged workers who toil behind the scenes\" (ibid.: 8). Viewing film is not then a matter of observer and image but an encounter among the efforts and effects of specifically situated persons and things.\r\nArtist Heidi Tikka, in her work titled Mother, Child, offers an indicative case in point of a practice that plays with the multiplicity of materialities involved in so-called new or digital media. This work, which I had the opportunity to experience during its exhibition at the Art Gallery of Ontario in Toronto, Canada, in 2001, employs the shifting dynamics of installation, viewer­user, and onlookers, as well as the ambient environment of the exhibition space to invoke, and affectively evoke, an encounter between caregiver and infant. The piece does this not \"in general\" but always specifically: the caregiver is one particular visitor who enters the space of the installation and sits on a chair, and the infant is one particular infant (Tikka\'s son, recorded on digital video). A deliberate aspect of the piece is the heterogeneity of its forms: actual bodies and objects combine with projected images to comprise a hybrid of social and material elements. Together these elements create an interactive space characterized by a mix of predictability and contingency ­ a fragile stability ­ that affords the installation its affective kinship to the \"real-world\" encounter that it simulates. The three-dimensional image of a child that is projected ­ both technically and psychically ­ onto the soft cloth diaper that the viewer­user holds in her lap can be affected through her motions and orientation to it but dissolves as she stands and places the cloth back onto the chair. In this and other ways, the installation continually reminds us of, rather than conceals, its artifice. As Tikka herself comments, the piece is actually simpler (less reactive) in its composition than we experience it to be. The effects are created through the particular possibilities provided by an artful integration\r\n\r\nReconfigurations\r\n\r\n281\r\n\r\nof persons, objects, spaces, fantasies, remembered experiences, and technologies to evoke and explore an emblematically human encounter but not to replicate it.\r\nI would propose that in such projects the specific materialities of computing are under investigation, and reconfiguration, in forms that more radically challenge traditional imaginaries of the human than do the most ambitious projects in humanoid robotics. Central to this innovative approach is abandonment of the project of the \"smart\" machine endowed with capacities of recognition and autonomous action. Computational media artist Sha Xin Wei works with what he names \"responsive media spaces\" like the Tgarden, an installation populated by specially costumed participants instrumented with sensors, real-time tracking receivers, and media-synthesis generators. As Xin Wei describes it:\r\nThe TGarden software tracks gesture rather than recognizes gesture, because at no place in the software is there a \'model\' that codes the gesture . . . The software does not infer what the player means by her gesture, it merely tracks the gesture and continuously synthesizes responses. So what we have done is to set aside entirely the problem of inferring human intent from behavior, or more generally from observables. Yet by providing and even thickening the sensuous response, we make fertile the substrate for agency. This approach remains agnostic as to whether movements are intentional; the responsive system simply does not need to know. (2002: 457)\r\nMore than conversation at the interface, it is creative assemblages like these that explore and elaborate the particular dynamic capacities that digital media afford and the ways that through them humans and machines can perform interesting new effects. Not only do these experiments promise innovations in our thinking about machines, but they open up as well the equally exciting prospect of alternate conceptualizations of what it means to be human. The person figured here is not an autonomous, rational actor but an unfolding, shifting biography of culturally and materially specific experiences, relations, and possibilities inflected by each next encounter ­ including the most normative and familiar ­ in uniquely particular ways.\r\nMedia scholar Chris Chesher (2004) has proposed a vocabulary of encounters with computer-based art that suggestively reworks information theoretic tropes at the interface. Although his proposal is applicable, I believe, to any example of human­computer interaction, Chesher starts from the premise that new media artists\' noninstrumental applications\r\n\r\n282\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nof technology put the distinctiveness of computer-based forms into greater relief. From his consideration of new media art, Chesher proposes the concept of avocation to describe the arrangements and affordances through which persons are hailed to enter into a particular technological assemblage to become incorporated as integral actants in an associated form of sociomaterial agency. These include not only instrumental possibilities but also multiple and uncertain ways in which \"new media art distracts and summons its users.\" Invocation involves those actions that define the terms of engagement written into the design script or discovered by the participating user, the calling up of events that effect changes to the assemblage. And finally, evocation describes the affective and effective material changes that result; transformations that in turn comprise the conditions of possibility for subsequent avocations. Together these terms articulate the distinctive dynamics of computing and the modes of engagement that it makes possible. The latter are characterized by what Chesher names a form of \"managed indeterminacy,\" effected not only by databases and central processing units but crucially by \"the peripherals that are in contact with materiality\" that opens out from the boundaries of the machine narrowly construed. Offered in part as replacements for the more familiar terms input, processing, and output, these new \"primitive technocultural formations\" expand the space of interaction from the interface narrowly defined to the ambient environments and transformed and transformative subject­ object relations that comprise the lived experience of technological practice.\r\nChesher\'s generative discussion of the distinguishing role of invocations in human­computer interactions provides a new basis on which to consider the forms of asymmetry that I described in Plans and Situated Actions. In particular, I identified as crucial what I characterized then as the machine\'s access to the activities of the user, limited specifically to those that changed its state. Working outside the bounds of AI\'s preoccupations with the agencies of the interactive machine, Chesher is less concerned with questions of human­machine symmetry than with the forms of invocation available and their evocative effects. For both analyses the question of invocation is central, but Chesher\'s framing helps to shift the focus from a preoccupation with whether the machine is like the human to a consideration of specific sociomaterial assemblages, their possibilities, and their consequences. New media artists, their works, and the persons whom the latter engage are configured together through these assemblages. Within that, difference becomes\r\n\r\nReconfigurations\r\n\r\n283\r\n\r\nthe basis for more than the repetition of relations of power, command and control, or obedient service.\r\n\r\nexpanding frames and accountable cuts\r\nThe past twenty years of scholarship in the humanities and social sciences have provided new resources for thinking through the interface of humans and machines. Reappropriation of the cyborg, as a figure whose boundaries encompass intimate joinings of the organic and inorganic, has provided a means of analyzing myriad reformations of bodies and artifacts, actual and imagined. Expanded out from the singular figure of the human­machine hybrid, the cyborg metaphor dissolves into a field of complex sociomaterial assemblages, currently under study within the social and computing sciences. From close readings of encounters at the interface of person and machine, through extended historical and comparative analyses of technology-intensive, distributed worksites, these reconceptualizations have opened a generative wave of new scholarship and practice.\r\nMethodologically, this view of the nature of sociomaterial research objects has two profound consequences. First, it demands attention to the question of frames, of the boundary work through which a given entity is delineated as such. Beginning with the premise that discrete units of analysis are not given but made, we need to ask how any object of analysis ­ human or nonhuman or combination of the two ­ is called out as separate from the more extended networks of which it is part.22 This work of cutting the network is, I have argued, a foundational move in the creation of sociomaterial assemblages as objects of analysis or intervention. In the case of the robot, or autonomous machine more generally (as in the case of the individual human as well), this work takes the form of modes of representation that systematically foreground certain sites, bodies, and agencies while placing others offstage. As I suggested in Chapter 14, this spatial attenuation of the relevant field of agencies is accompanied by the staging of performances repeatable over time through accounts and demonstrations that have themselves been congealed into modes of immutable mobility. Our task as analysts is then to expand the frame, to metaphorically zoom out to a wider view that at once acknowledges the magic of the effects created while\r\n22 This is what Law terms a method assemblage (2004: 14).\r\n\r\n284\r\n\r\nHuman­Machine Reconfigurations\r\n\r\nexplicating the hidden labors and unruly contingencies that exceed its bounds.\r\nAt the same time, a full analysis needs to locate these entities and the sites and moments of their efficacy in still more extended spatial and temporal relations. Encounters at the interface invariably take place in settings incorporating multiple other persons, artifacts, and ongoing activities, all of which variously infuse and inform their course. Questions of scale in the social sciences have traditionally been conceived either as a matter of counting ­ how many more of these units of analysis are there ­ or of reformulation in more general terms. An alternative is to approach scale not as a matter of one to many, little to big, or specific to general but rather of extension in time and space. How far our analysis extends in its historical specificity and reach, or in following out lines of connection from a particular object or site to others, is invariably a practical matter. That is, it is a matter of cutting the network, of drawing a line that is in every case enacted rather than given. The relatively arbitrary or principled character of the cut is a matter not of its alignment with some independently existing ontology but of our ability to articulate its basis and its implications.\r\nThese methodological questions are not privileged issues for the social sciences but an endogenous aspect of every site of sociomaterial configuration. From the designer who must delineate the boundaries of system and user(s) to the surgeon\'s body reconfigured by telemetric vision or the nurse enrolled in redesign of an operating theatre, matters of joining and separation of human and nonhuman are everyday affairs. However entrenched through repetition or provisionally held together, these relations are enacted. The task for critical practice is to resist restaging of stories about autonomous human actors and discrete technical objects in favor of an orientation to capacities for action comprised of specific configurations of persons and things. To see the interface this way requires a shift in our unit of analysis, both temporally and spatially. Temporally, understanding a given arrangement of humans and artifacts requires locating that configuration within social histories and individual biographies for both persons and things. And it requires locating it as well within an always more extended network of relations, arbitrarily ­ however purposefully ­ cut through practical, analytical, and/or political acts of boundary making.\r\nMy concern in this book has been with the specific material-discursive apparatuses through which contemporary relations of humans and machines are rendered intelligible and made real. Karen Barad proposes\r\n\r\nReconfigurations\r\n\r\n285\r\n\r\nthat \"reality is sedimented out of the process of making the world intelligible through certain practices and not others\" (1998: 105). Barad\'s agential realism reminds us that boundaries between humans and machines are not naturally given but constructed in particular historical ways and with particular social and material consequences. As Barad points out, boundaries are necessary for the creation of meaning and, for that very reason, are never innocent. Because the cuts implied in boundary making are always agentially positioned rather than naturally occurring, and because boundaries have real consequences, \"accountability is mandatory\" (ibid.: 187). The accountability involved is not, however, a matter of identifying authorship in any simple sense but rather a problem of understanding the effects of particular assemblages and assessing the distributions, for better and worse, that they perform. As Barad puts it: \"We are responsible for the world in which we live not because it is an arbitrary construction of our choosing, but because it is sedimented out of particular practices that we have a role in shaping\" (ibid.: 102).\r\nIt is on this understanding of boundary making that I would propose that the price of recognizing the agency of artifacts need not be the denial of our own. Now that agencies of things are well established, might we not bring the human out from behind the curtain, so to speak, without disenchantment? This requires, among other things, that we acknowledge the curtain\'s role. Agencies ­ and associated accountabilities ­ reside neither in us nor in our artifacts but in our intra-actions. The question, following Barad, is how to configure assemblages in such a way that we can intra-act responsibly and generatively with and through them. The legacy of twentieth-century technoscience posits autonomous agency as a primary apparatus for the identification of humanness and takes as a goal the reiteration of that apparatus in the project of configuring humanlike machines. Initiatives to develop a relational, performative account of sociomaterial phenomena indicate a different project. This project is based in recognition of the particularities of bodies and artifacts, of the cultural­historical practices through human­machine differences are (re-)iteratively drawn, and of the possibilities for and politics of redistribution across the human­machine boundary. Figured as interactions between humans and machines, the question has been whether the latter are best treated as objects or might one day successfully mimic the capacity of the autonomous human subject. The alternative perspective suggested here takes persons and machines as contingently stabilized through particular, more and less durable, arrangements whose reiteration and/or reconfiguration is the\r\n\r\n286\r\n\r\nHuman­Machine Reconfigurations\r\n\r\ncultural and political project of design in which we are all continuously implicated. Responsibility on this view is met neither through control nor abdication but in ongoing practical, critical, and generative acts of engagement. The point in the end is not to assign agency either to persons or to things but to identify the materialization of subjects, objects, and the relations between them as an effect, more and less durable and contestable, of ongoing sociomaterial practices.\r\n\r\nReferences\r\nAanestad, Margunn (2003). The camera as an actor: Design-in-use of Telemedicine Infrastructure in Surgery. Computer Supported Cooperative Work 12: 1­20.\r\nAdam, Alison (1998). Artificial knowing: Gender and the thinking machine. New York: Routledge.\r\nAgre, Philip (1995). Conceptions of the user in computer systems design. In P. Thomas (ed.)., The social and interactional dimensions of human­computer interfaces (pp. 67­106). Cambridge, UK/New York: Cambridge University Press.\r\nAgre, Philip (1997). Computation and human experience. New York: Cambridge University Press.\r\nAgre, Philip, and Chapman, David (1987). Pengi: An implementation of a theory of activity. Proceedings of AAAI 87: 268­272.\r\nAgre, Philip, and Chapman, David (1990). What are plans for? In Pattie Maes (ed.), Designing autonomous agents: Theory and practice from biology to engineering and back (pp. 17­34). Cambridge, MA: MIT Press. (Original version: Philip E. Agre and David Chapman, What are plans for?, A.I. Memo 1050a, Artificial Intelligence Laboratory, MIT, 1989.)\r\nAhmed, Sara (1998). Differences that matter: Feminist theory and postmodernism. Cambridge, UK: Cambridge University Press.\r\nAhmed, Sara (2000). Strange encounters: Embodied others in post-coloniality. London/New York: Routledge.\r\nAhmed, Sara, Kilby, Jane, Lury, Celia, McNeil, Maureen, and Skeggs, Beverly (2000). Transformations: Thinking through feminism. London/New York: Routledge.\r\nAkrich, Madeleine (1992). The de-scription of technical objects. In W. Bijker and J. Law (eds.), Shaping technology/building society (pp. 205­224). Cambridge, MA: MIT Press.\r\nAllen, James (1983). Recognizing intentions from natural language utterances. In M. Brady and R. Berwick (eds.), Computational models of discourse (Chapter 2). Cambridge, MA: MIT Press.\r\n287\r\n\r\n288\r\n\r\nReferences\r\n\r\nAllen, James (1984). Towards a general theory of action and time. Artificial Intelligence 23: 123­154.\r\nAmerine, Ronald, and Bilmes, Jack (1990). Following instructions. In M. Lynch and S. Woolgar (eds.), Representation in scientific practice (pp. 323­335). Cambridge, MA: MIT Press.\r\nAnderson, John, Boyle, C., and Reiser, B. (1985). Intelligent tutoring systems. Science 228: 456­462.\r\nAnscombe, George (1957). Intentions. Oxford: Blackwell. Appelt, Douglas (1985). Planning English referring expressions. Artificial Intel-\r\nligence 26: 1­33. Ashmore, Malcolm, Wooffitt, Robin, and Harding, Stella (1994). Humans and\r\nothers: The concept of `agency\' and its attribution. American Behavioral Scientist 37(6): 733­738. Atkinson, John, and Drew, Paul (1979). Order in court: The organization of verbal interaction in judicial settings. Atlantic Highlands, NJ: Humanities. Austin, John L. (1962). How to do things with words. Oxford: Clarendon Press. Balsamo, Anne (1996). Technologies of the gendered body: Reading cyborg women. Durham, NC: Duke University Press. Balsamo, Anne (in press). Designing culture: A work of the technological imagination. Durham, NC: Duke University Press. Bannon, Liam (1991). From human factors to human actors: The role of psychology and human­computer interaction studies in system design. In J. Greenbaum and M. Kyng (eds.), Design at work: Cooperative design of computer systems (pp. 25­44). Hillsdale, NJ: Erlbaum. Banta, Martha (1993). Taylored lives: Narrative productions in the age of Taylor, Veblen and Ford. Chicago: University of Chicago Press. Barad, Karen (1996). Meeting the universe halfway: Ambiguities, discontinuities, quantum subjects, and multiple positionings in feminism and physics. In L. H. Nelson and J. Nelson (eds.), Feminism, science, and the philosophy of science: A dialog (pp. 161­194). Norwell, MA: Kluwer. Barad, Karen (1998). Getting real: Technoscientific practices and the materialization of reality. Differences: A Journal of Feminist Cultural Studies 10: 88­128. Barad, Karen (2003). Posthumanist performativity: Toward an understanding of how matter comes to matter. Signs: Journal of Women in Culture and Society 28: 801­831. Bardram, Jakob (1997). Plans as situated action: An activity theory approach to workflow systems. Proceedings of ECSCW 97, Lancaster, UK. Barfield, Woodrow, and Caudell, Thomas (2000). Fundamentals of wearable computers and augumented reality. Mahwah, NJ: Erlbaum. Barley, Stephen (1986). Technology as an occasion for structuring: Evidence from observations of CT scanners and the social order of radiology departments. Administrative Science Quarterly 31: 78­108. Barley, Stephen, and Bechky, Beth (1993). In the back rooms of science: The work of technicians in science labs. Work and Occupations 21: 85­126. Barley, Stephen, and Orr, Julian (eds.). (1997). Between craft and science: Technical work in U.S. settings. Ithaca, NY: Cornell University Press. Barwise, Jon, and Perry, John (1985). Situations and attitudes. Cambridge, MA: MIT Press.\r\n\r\nReferences\r\n\r\n289\r\n\r\nBates, Elizabeth (1976). Language and context: The acquisition of pragmatics. New York: Academic Press.\r\nBates, Joseph (1994). The role of emotion in believable agents. Communications of the ACM 37: 122­125.\r\nBeck, Eevi (1995). Changing documents/documenting changes: Using computers for collaborative writing over a distance. In S. Leigh Star (ed.), Cultures of computing (pp. 53­68). Oxford: Blackwell.\r\nBeckman, Howard, and Frankel, Richard (1983). Who hides the agenda: The impact of physician behavior on the collection of data. Paper presented at the Fourth Annual SREPCIM Task Force on Interviewing, Washington, DC.\r\nBeninger, James (1986). The control revolution: Technological and economic origins of the information society. Cambridge, MA: Harvard University Press.\r\nBerg, Anna Jorunn (1994). A gendered socio-technical construction: The smart house. In D. Mackenzie and J. Wajcman (eds.), The social shaping of technology (pp. 301­313). Milton Keynes: Open University Press.\r\nBerg, Marc (1997). Rationalizing medical work decision-support techniques and medical practices. Cambridge, MA: MIT Press.\r\nBerg, Marc, and Timmermans, Stefan (2000). Order and their others: On the constitution of universalities in medical work. Configurations 8 (1): 31­61.\r\nBerners-Lee, Tim, Hendler, James, and Lassila, Ora (2001). The Semantic Web. Scientific American, May: 36­43.\r\nBerreman, Gerald (1966). Anemic and emetic analyses in social anthropology. American Anthropologist 68(2): 346­354.\r\nBhabha, Homi (1994). The location of culture. London: Routledge. Birdwhistell, Raymond (1970). Kinesics and context: Essays on body motion com-\r\nmunication. Philadelphia: University of Pennsylvania Press. Bjerknes, Gro, Ehn, Pelle, and Kyng, Morten (eds.). (1987). Computers and democ-\r\nracy: A Scandinavian challenge. Aldershot, UK: Avebury. Bleecker, Julian (1995). Urban crisis: Past, present and virtual. Socialist Review\r\n24(1­2): 189­221. Blomberg, Jeanette, Suchman, Lucy, and Trigg, Randall (1996). Reflections\r\non a work-oriented design project. Human­Computer Interaction 11: 237­ 265. Bloomfield, Brian (1991). The role of information systems in the UK National Health Service: Action at a distance and the fetish of calculation. Social Studies of Science 21: 701­734. Blumer, Herbert (1969). Symbolic interactionism. Englewood Cliffs, NJ: Prentice Hall. Bobrow, Daniel, Kaplan, Ron, Kay, Martin, Norman, Donald, Thompson, Henry, and Winograd, Terry (1977). GUS: A frame-driven dialogue system. Artificial Intelligence 8: 155­173. Boden, Margaret (1973). The structure of intentions. Journal of Theory of Social Behavior 3: 23­46. Bødker, Susanne (1991). Through the interface: A human activity approach to user interface design. Hillsdale, NJ: Erlbaum. Bowers, John (2002). Improvising machines: Ethnographically informed design for improvised electro-acoustic music. Norwich, UK, and Stockholm, Sweden: University of East Anglia and Royal Institute of Technology.\r\n\r\n290\r\n\r\nReferences\r\n\r\nBowers, John, Button, Graham, and Sharrock, Wes (1995). Workflow from within and without. In H. Marmolin, Y. Sundblad, and K. Schmidt (eds.), Fourth European Conference on Computer-Supported Cooperative Work (pp. 51­66) Dordrecht: The Netherlands: Kluwer Academic Publishers.\r\nBowker, Geoffrey (1993). How to be universal: Some cybernetic strategies, 1943­ 1970. Social Studies of Science 23: 107­127.\r\nBowker, Geoffrey, and Star, Susan Leigh (1999). Sorting things out: Classification and its consequences. Cambridge, MA: MIT Press.\r\nBrady, Michael, and Berwick, Robert (eds.) (1983). Computational models of discourse. Cambridge, MA: MIT Press.\r\nBraidotti, Rosi (1994). Nomadic subjects. New York: Columbia University Press. Braidotti, Rosi (2002). Metamorphoses: Towards a materialist theory of becoming.\r\nCambridge, UK: Blackwell. Brook, James, and Boal, Iain (eds.). (1995). Resisting the virtual life: The culture and\r\npolitics of information. San Francisco: City Lights. Brooks, Rodney (1999). Cambrian intelligence: The early history of the new AI.\r\nCambridge, MA: MIT Press. Brooks, Rodney (2002). Flesh and machines: How robots will change us. New York:\r\nPantheon Books. Brooks, Rodney, and Steels, Luc (1995). The artificial life route to artificial intelli-\r\ngence: Building embodied, situated agents. Hillsdale, NJ: Erlbaum. Brown, Barry, Green, Nicola, and Harper, Richard (eds.). (2001). Wireless world:\r\nSocial and interactional implications of wireless technology. London: SpringerVerlag. Brown, John Seely, and Newman, Susan (1985). Issues in cognitive and social ergonomics: From our house to Bauhaus. Human­Computer Interaction 1: 359­ 391. Brown, John Seely, Rubenstein, R., and Burton, R. (1976). Reactive learning environment for computer assisted electronics instruction. (BBN Report 3314). Cambridge, MA: Bolt Beranek and Newman, Inc. Bruce, Bertram (1981). Natural communication between person and computer. In W. Lehnert and M. Ringle (eds.), Strategies for natural language processing. Hillsdale, NJ: Erlbaum. Bruner, Jerome (1986). Actual minds, possible worlds. Cambridge, MA: Harvard University Press. Burke, Julie (1982). An analysis of intelligibility and practical activity. Unpublished doctoral dissertation, University of Illinois at Urbana-Champaign. Burton, Richard, and Brown, John Seely (1982). An investigation of computer coaching for informal learning activities. In D. Sleeman and J. S. Brown (eds.), Intelligent tutoring systems (pp. 79­98). London: Academic Press. Butler, Judith (1993). Bodies that matter: On the discursive limits of \"sex.\" New York: Routledge. Button, Graham (1990). Going up a blind alley: Conflating conversation analysis and computational modeling. In P. Luff, N. Gilbert, and D. Frolich (eds.), Computers and conversation (pp. 67­90). London: Academic Press. Button, Graham (1993). Technology in working order: Studies of work, interaction, and technology. London/New York: Routledge.\r\n\r\nReferences\r\n\r\n291\r\n\r\nButton, Graham, Coulter, Jeff, Lee, John R., and Sharrock, Wes (1995). Computers, minds, and conduct. Cambridge, UK: Polity Press.\r\nCallon, Michel (1999). Actor-network theory: The market test. In J. Law and J. Hassard (eds.), Actor network theory and after (pp. 181­195). Oxford: Blackwell.\r\nCambrosio, Alberto, and Keating, Peter (1995). Exquisite specificity: The monoclonal antibody revolution. New York: Oxford University Press.\r\nCarbonell, Jaime (1971). Mixed-intiative man­computer dialogues. (Technical Report 1970). Cambridge, MA: Bolt Beranek and Newman, Inc.\r\nCarey, Susan (1985). Conceptual change in childhood. Cambridge, MA: MIT Press. Carroll, John M. (2003). Situated action in the zeitgeist of human­computer\r\ninteraction. The Journal of the Learning Sciences 12 ( 2): 273­278. Carroll, John M. (2000). Making use: Scenario-based design of human­computer inter-\r\nactions. Cambridge, MA: MIT Press. Casper, Monica (1994). Reframing and grounding nonhuman agency: What\r\nmakes a fetus an agent? American Behavioral Scientist 37: 839­856. Casper, Monica (1998). The making of the unborn patient: A social anatomy of fetal\r\nsurgery. New Brunswick, NJ: Rutgers University Press. Cassell, Justine, Sullivan, Joseph, Prevost, Scott, and Churchill, Elizabeth (eds.).\r\n(1996). Embodied conversational agents. Cambridge, MA: MIT Press. Castan~ eda, Claudia (2001). Robotic skin: The future of touch? In S. Ahmed and\r\nJ. Stacey (eds.), Thinking through the skin (pp. 223­236). London: Routledge. Castan~ eda, Claudia (2002). Figurations: Child, bodies, worlds. Durham, NC/\r\nLondon: Duke University Press. Castan~ eda, Claudia, and Suchman, Lucy (forthcoming). Robot Visions. In\r\nSharon Ghamari-Tabrizi (ed.), Companions with Haraway: Thinking together. Chasin, Alexandra (1995). Class and its close relations: Identities among women,\r\nservants, and machines. In J. Halberstram and I. Livingston (eds.), Posthuman bodies (pp. 73­96). Bloomington: Indiana University Press. Cherny, Lynn, and Reba Weise, Elizabeth (eds.). (1996). Wired women: Gender and new realities in cyberspace. Seattle, WA: Seal. Chesher, Chris (2004). Invocation, evocation and avocation in new media art. Unpublished manuscript, University of Sydney, Australia. Churchland, Paul (1984). Matter and consciousness. Cambridge, MA: MIT Press. Clancey, William (1997). Situated cognition: On human knowledge and computer representations. Cambridge, UK: Cambridge University Press. Clark, Andy (1997). Being there: Putting brain, body, and world together again. Cambridge, MA: MIT Press. Clark, Andy (2001). Mindware: An introduction to the philosophy of cognitive science. New York: Oxford University Press. Clark, Andy (2003). Natural-born cyborgs: Minds, technologies, and the future of human intelligence. Oxford/New York: Oxford University Press. Clarke, Adele, and Fujimura, Joan (eds.). (1992). The right tools for the job: At work in twentieth-century life sciences. Princeton, NJ: Princeton University Press. Clement, Andrew (1993). Looking for the designers: Transforming the `invisible\' infrastructure of computerized office work. AI & Society 7: 323­344. Clement, Andrew (1994). Computing at work: Empowering action by `low-level\' users. Communications of the ACM 37: 53­63.\r\n\r\n292\r\n\r\nReferences\r\n\r\nClement, Andrew, and Van den Besselaar, Peter (1993). A retrospective look at PD projects. Communications of the ACM 36: 29­37.\r\nCognitive Science (1993). Volume 17, No. 1 Special Issue: Situated Action, pp. 1­117.\r\nCohen, John (1966). Human robots in myth and science. London: Allen and Unwin.\r\nCohen, Paul (n.d.). Pragmatics, speaker-reference, and the modality of communication. Unpublished manuscript, Laboratory for Artificial Intelligence, Fairchild Camera and Instrument Corp, Palo Alto, CA.\r\nCohen, Paul, and Perrault, C. Ray (1979). Elements of a plan-based theory of speech acts. Cognitive Science 3: 177­212.\r\nColby, Kenneth, Hilf, Franklin, Weber, Sylvia, and Kraemer, Helena (1972). Turing-like indistiguishability tests for the validation of a computer simulation of paranoid processes. Artificial Intelligence 3: 199­221.\r\nCollins, Harry M. (1985). Changing order: Replication and induction in scientific practice. London/Beverly Hills: Sage.\r\nCollins, Harry M. (1990). Artificial experts: Social knowledge and intelligent machines. Cambridge, MA: MIT Press.\r\nCollins, Harry M., and Kusch, Martin (1998). The shape of actions: What humans and machines can do. Cambridge, MA: MIT Press.\r\nCoombs, Michael, and Alty, James (1984). Expert systems: An alternative paradigm. International Journal of Man­Machine Studies 20: 21­43.\r\nCooper, Greg, and Bowers, John (1995). Representing the user: Notes on the disciplinary rhetoric of human­computer interaction. In P. Thomas (ed.), Social and interactional dimensions of human­computer interfaces (pp. 48­66). Cambridge, UK: Cambridge University Press.\r\nCoulter, Jeff (1979). The social construction of mind. Totowa, NJ: Rowman & Littlefield.\r\nCoulter, Jeff (1983). Rethinking cognitive theory. New York: St. Martin\'s Press.\r\nCowan, Ruth Schwartz (1983). More work for mother: The ironies of household technology from the open hearth to the microwave. New York: Basic Books.\r\nCrist, Eileen (2000). Images of animals: Anthropomorphism and animal mind. Philadelphia: Temple University Press.\r\nCrist, Eileen (2004). Can an insect speak?: The case of the honeybee dance. Social Studies of Science 34: 7­43.\r\nCrutzen, Cecile (1005). Intelligent ambience between heaven and hell: A salvation? Information, Communication Ethics and Society (ICES) 4.\r\nCussins, Charis (1998). Ontological choreography: Agency for women patients in an infertility clinic. In M. Berg and A.-M. Mol (eds.), Differences in medicine (pp. 166­201). Durham, NC: Duke University Press.\r\nde Certeau, Michel (1988). The practice of everyday life. Berkeley, CA: University of California Press.\r\nde Laet, Marianne, and Mol, Annemarie (2000). The Zimbabwe bush pump: Mechanics of a fluid technology. Social Studies of Science 30: 225­263.\r\nde La Mettrie, Julien Offray (1748 (1994)). Man a machine and man a plant. Trans. Richard A. Watson and Maya Rybaka. Indianapolis: Hackett Publishing Co., Inc.\r\n\r\nReferences\r\n\r\n293\r\n\r\nDehn, Doris, and van Mulken, Susanne (2000). The impact of animated interface agents: A review of empirical research. International Journal of Human­ Computer Studies 52: 1­22.\r\nDennett, Daniel (1978). Brainstorms. Cambridge, MA: MIT Press. Dennett, Daniel (1994). The practical requirements for making a conscious robot.\r\nPhilosophical Transactions of the Royal Society of London A, 349: 133­146. di Leonardo, Micaela (1998). Exotics at home: Anthropologies, others, American\r\nmodernities. Chicago: University of Chicago Press. Dourish, Paul (2001). Where the action is: The foundations of embodied interaction.\r\nCambridge, MA: MIT Press. Downey, Gary, and Dumit, Joseph (eds.). (1997). Cyborgs and citadels: Anthropo-\r\nlogical interventions in emerging sciences and technologies. Santa Fe, NM: School of American Research. Doyle, Richard (1997). On beyond living: Rhetorical transformations of the life sciences. Stanford, CA: Stanford University Press. Doyle, Richard (2003). Wetwares: Experiments in postvital living. Minneapolis: University of Minnesota Press. Dreyfus, Hubert (ed.). (1982). Husserl, intentionality and cognitive science. Cambridge, MA: MIT Press. Dreyfus, Hubert (1991). Being-in-the-world: A commentary on Heidegger\'s being and time, division 1. Cambridge, MA: MIT Press. Dreyfus, Hubert (1992). What computers still can\'t do. Cambridge, MA: MIT Press. Dror, Otniel (1999). Scientific image of emotion: Experience and technologies of inscription. Configurations 7: 355­401. Dror, Otniel (2001). Counting the affects: Discoursing in numbers. Social Research 68 (2): 357­378. Dumit, Joseph (2004). Picturing personhood: Brain scans and biomedical identity. Princeton, NJ: Princeton University Press. Duncan, Starkey, Jr. (1974). On the structure of speaker­auditor interaction during speaking turns. Language in Society 3: 161­180. Durkheim, Emile (1938). The rules of the sociological method. New York: The Free Press. Edwards, Derek (1994). Imitation and artifice in apes, humans, and machines. American Behavioral Scientist 37: 754­772. Edwards, Paul (1996). The closed world: Computers and the politics of discourse in Cold War America. Cambridge, MA: MIT Press. Ehn, Pelle (1988). Work-oriented design of computer artifacts. Stockholm: Arbetslivscentrum. Erickson, Frederick (1982). Money tree, lasagna bush, salt and pepper: Social construction of topical cohesion in a conversation among Italian-Americans. In D. Tannen (ed.), Georgetown University roundtable on language and linguistics: Analyzing discourse: Text and talk. Washington, DC: Georgetown University Press. Erickson, Frederick (1982). The counselor as gatekeeper. New York: Academic Press. Farrell, Robert, Anderson, John, and Reiser, Brian (1984). An interactive computer-based tutor for LISP. In Proceedings of the Fourth National Conference on Artificial Intelligence, 106­111. Menlo Park, Calif.: AAAI Press.\r\n\r\n294\r\n\r\nReferences\r\n\r\nFeatherstone, Mike, and Burrows, Roger (1995). Cyberspace, cyberbodies, cyberpunk: Cultures of technological embodiment. London: Sage.\r\nFeitelson, J., and Stefik, Mark (1977). A case study of reasoning in a genetics experiment. (Heuristic Programming Project, Working Paper 77­18). Stanford, CA: Stanford University Press.\r\nFikes, Richard, and Nilsson, Neils (1971). STRIPS: A new approach to the application of theorem proving to problem solving. Artificial Intelligence 2: 189­205.\r\nFitter, Mike (1979). Towards more `natural\' interactive systems. International Journal of Man­Machine Studies 11: 339­349.\r\nFodor, Jerome (1983). The modularity of mind. Cambridge, MA: MIT Press. Frankel, Richard (1984). From sentence to sequence: Understanding the medi-\r\ncal encounter through microinteractional analysis. Discourse Processes 7: 135­ 170. Franklin, Sarah (1995). Science as culture, cultures of science. Annual Reviews of Anthropology 24: 163­184. Franklin, Sarah (2000). Life itself: Global nature and the genetic imaginary. In S. Franklin, C. Lury, and J. Stacey (eds.), Global nature, global culture (pp. 188­227). London: Sage. Franklin, Sarah, and Ragone, Helen (eds.). (1998). Reproducing reproduction: Kinship, power and technological innovation. Philadelphia: University of Pennsylvania Press. Franklin, Sarah, Lury, Celia, and Stacey, Jackie (2000). Global nature, global culture. London: Sage. Frazer, James (1900). The golden bough: A study in magic and religion. London: Macmillan. (Reprinted 1980.) Fujimura, Joan (1992). Crafting science: Standardized packages, boundary objects and \"translation.\" In A. Pickering (ed.), Science as practice and culture (pp. 168­211). Chicago: University of Chicago Press. Fujimura, Joan (1996). Crafting science: A sociohistory of the quest for the genetics of cancer. Cambridge, MA: Harvard University Press. Galaty, James (1981). Models and metaphors: On the semiotic explanation of segmentary systems. In L. Holy and M. Stuchlik (eds.), The structure of folk models (pp. 63­92). New York: Academic Press. Galison, Peter (1987). How experiments end. Chicago: University of Chicago Press. Galison, Peter (1997). Image and logic: A material culture of microphysics. Chicago: University of Chicago Press. Gardner, Howard (1985). The mind\'s new science. New York: Basic Books. Garfinkel, Harold (1967). Studies in ethnomethodology. Englewood Cliffs, NJ: Prentice Hall. Garfinkel, Harold (1972). Remarks on ethnomethodology. In J. Gumperz and D. Hymes (eds.), Directions in sociolinguistics: The ethnography of communication (pp. 301­324). New York: Holt, Rinehart & Winston. Garfinkel, Harold (2002). Ethnomethodology\'s programme: Working out Durkheim\'s aphorism. Lanham, MD: Rowman & Littlefield Publishers. P. 23. Garfinkel, Harold, Lynch, Michael, and Livingston, Eric (1981). The work of a discovering science construed with materials from the optically discovered pulsar. Philosophy of the Social Sciences 111: 131­159.\r\n\r\nReferences\r\n\r\n295\r\n\r\nGarfinkel, Harold, and Rawls, Anne (2002). Ethnomethodology\'s program: Working out Durkeim\'s aphorism. Lanham, MD: Rowman & Littlefield.\r\nGarfinkel, Harold, and Sacks, Harvey (1970). On formal structures of practical actions. In J. McKinney and E. Tiryakian (eds.), Theoretical sociology: Perspectives and development (pp. 337­366). New York: Appleton Century Crofts.\r\nGeertz, Clifford (1973). The interpretation of cultures. New York: Basic Books. Gell, Alfred (1998). Art and agency: An anthropological theory. Oxford: Oxford\r\nUniversity Press. Gilbert, Nigel, and Heath, Christian (eds.). (1985). Social action and artificial intel-\r\nligence. Aldershot, Hampshire, UK/Brookfield, VT: Gower. Gladwin, Thomas (1964). Culture and logical process. In W. Goodenough (ed.),\r\nExplorations in cultural anthropology (pp. 167­177). New York: McGraw­Hill. Gladwin, Thomas (1970). East is a big bird: Navigation and logic on Puluwat Atoll.\r\nCambridge, MA: Harvard University Press. Goffman, Erving (1975). Replies and responses. Language in Society 5: 257­313. Gonzalez, Jennifer (2000). Envisioning cyborg bodies: Notes from current\r\nresearch. In G. E. A. Kirkup (ed.), The gendered cyborg (pp. 58­73). New York/London: Routledge. Goodwin, Charles (1981). Conversational organization: Interaction between speakers and hearers. New York: Academic Press. Goodwin, Charles (1994). Professional vision. American Anthropologist 96: 606­ 633. Goodwin, Charles (1995a). Seeing in depth. Social Studies of Science 25: 237­274. Goodwin, Charles (1995b). Co-constructing meaning in conversations with an aphasic man. Research on Language and Social Interaction 28: 233­260. Goodwin, Charles (1997). The blackness of black: Color categories as situated practice. In L. Resnick, R. Saljo, C. Pontecorvo, and B. Burge (eds.), Discourse, tools and reasoning (pp. 111­142). Berlin: Springer-Verlag. Goodwin, Charles (2003). The body in action. In J. Coupland and R. Gwyn (eds.), Discourse, the body and identity (pp. 19­42). NY: Palgrave/Macmillan. Goodwin, Charles, and Goodwin, Marjorie Harness (1992). Context, activity and participation. In P. Lauer and A. di Luzio (eds.), The contextualization of language (pp. 77­99). Amsterdam: Benjamins. Goodwin, Charles, and Goodwin, Marjorie Harness (1996). Seeing as situated activity: Formulating planes. In Y. Engestrom and D. Middleton (eds.), Cognition and communication at work (pp. 61­95). Cambridge, UK: Cambridge University Press. Goodwin, Charles, and Goodwin, Marjorie Harness (1997). Contested vision: The discursive constitution of Rodney King. In B.-L. Gunnarsson, P. Linell, and B. Nordberg (eds.), The construction of professional discourse (pp. 292­316). New York: Longman. Goodwin, Dawn (2004). Acting in anaesthesia: Agency, participation, and legitimation. Unpublished doctoral dissertation, Lancaster University. Goodwin, Marjorie Harness (1980). Processes of mutual monitoring implicated in the production of description sequences. Sociological Inquiry 50: 303­317. Grand, Steve (2003). Growing up with Lucy: How to build an android in twenty easy steps. London: Weidenfeld & Nicolson.\r\n\r\n296\r\n\r\nReferences\r\n\r\nGreen, Nicola (2002). On the move: Technology, mobility, and the mediation of social time and space. The Information Society 18: 281­292.\r\nGreenbaum, Joan, and Kyng, Morten (1991) (eds.). Design at work: Cooperative design of computer systems (pp. x, 294). Hillsdale, NJ: Erlbaum.\r\nGregory, Judith (2000). Sorcerer\'s apprentice: Creating the electronic health record, re-inventing medical records and patient care. Unpublished doctoral dissertation, Department of Communications, University of California, San Diego.\r\nGrice, H. P. (1975). Logic and conversation. In P. Cole and J. Morgan (eds.), Syntax and semantics: Vol 3. Speech acts (pp. 41­58). New York: Academic Press.\r\nGrint, Keith, and Woolgar, Steve (1997). The machine at work: Technology, work, and organization. Cambridge, UK/Malden, MA: Polity.\r\nGrosz, Barbara (1981). Focusing and description in natural language dialogues. In A. Joshi, B. Webber, and I. Sag (eds.). Elements of discourse understanding. Cambridge, UK: Cambridge University Press.\r\nGrosz, Elizabeth (1994). Volatile bodies: Toward a corporeal feminism. Bloomington: Indiana University Press.\r\nGrudin, Jonathan (1990). The computer reaches out: The historical continuity of interface design. In J. C. Chew and J. Whiteside (eds.), Proceedings of the ACM CHI 90 Conference on Human Factors in Computing Systems, New York: ACM Press, pp. 261­268.\r\nGumperz, John (1982a). Discourse strategies. Cambridge, UK: Cambridge University Press.\r\nGumperz, John (1982b). The linguistic bases of communicative competence. In D. Tannen (ed.)., Georgetown University roundtable on language and linguistics: Analyzing discourse: Text and talk (pp. 323­334). Washington, DC: Georgetown University Press.\r\nGumperz, John, and Tannen, Deborah (1979). Individual and social differences in language use. In C. Fillmore et al. (eds.), Individual differences in language ability and language behavior. New York: Academic Press.\r\nGupta, Akhil, and Ferguson, James (1997). Anthropological locations: Boundaries and grounds of a field science. Berkeley: University of California.\r\nHalberstam, Judith (1991). Automating gender: Postmodern feminism in the age of the intelligent machines. Feminist Studies 17: 439­460.\r\nHalberstam, Judith, and Livingston, Ira (eds.). (1995). Posthuman bodies. Bloomington/Indianapolis: Indiana University.\r\nHales, Mike (1994). Where are designers? Styles of design practice, objects of design, and views of users in CSCW. In D. Rosenberg and C. Hutchison (eds.), Design issues in CSCW (pp. 151­177). New York: Springer-Verlag.\r\nHaraway, Donna (1985/1991). Manifesto for cyborgs: Science, technology and socialist feminisim in the 1980s. In Simians, cyborgs, and women: The reinvention of nature. New York: Routledge. (Originally published in Socialist Review (1985) 80: 65­108.)\r\nHaraway, Donna (1991). Simians, cyborgs, and women: The reinvention of nature. New York: Routledge.\r\nHaraway, Donna (1997). Modest Witness @Second Millenium.FemaleMan Meets OncoMouseTM: Feminism and Technoscience. New York: Routledge.\r\nHaraway, Donna (2003). The companion species manifesto: Dogs, people and significant others. Chicago: Prickly Paradigm Press.\r\n\r\nReferences\r\n\r\n297\r\n\r\nHarding, Sandra (1986). The science question in feminism. Ithaca, NY: Cornell University Press.\r\nHarding, Sandra (1991). Whose science? Whose knowledge?: Thinking from women\'s lives. Ithaca, NY: Cornell University Press.\r\nHayes, Patrick (1981). A construction-specific approach to focused interaction in flexible parsing. In Proceedings of the Nineteenth Annual Meeting of the Association for Computational Linguistics (pp. 149­152). Stanford, CA: Stanford University Press.\r\nHayes, Patrick, and Reddy, Raj (1983). Steps toward graceful interaction in spoken and written man­machine communication. International Journal of Man­ Machine Studies 19: 231­284.\r\nHayles, N. Katherine (1999). How we became posthuman: Virtual bodies in cybernetics, literature, and informatics. Chicago, IL: University of Chicago Press.\r\nHayles, N. Katherine (2002). Flesh and metal: Reconfiguring the mindbody in virtual environments. Configurations 10: 297­320.\r\nHayles, N. Katherine (2005). Computing the human. Theory, Culture & Society 22: 131­151.\r\nHeap, James (1980). Description in ethnomethodology. Human Studies 3: 87­ 106.\r\nHeath, Christian (1986). Body movement and speech in medical interaction. Cambridge, UK/New York: Cambridge University Press.\r\nHeath, Christian, and Luff, Paul (1992). Collaboration and control: Crisis management and multimedia technology in London Undergound line control rooms. Computer-Supported Cooperative Work 1(1): 69­94.\r\nHeath, Christian, and Luff, Paul (2000). Technology in action. Cambridge, UK: Cambridge University Press.\r\nHeath, Christian, Svensson, Marcus, Hindmarsh, Jon, Luff, Paul, and Vom Lehn, Dirk (2002). Configuring awareness. Computer-Supported Cooperative Work 11: 317­347.\r\nHedberg, Sara Reese (2000). After desktop computing: A progress report on smart environments research. IEEE Intelligent Systems and Their Applications 15: 7­9.\r\nHelmreich, Stefan (1998). Silicon second nature: Culturing artificial life in a digital world. Berkeley: University of California Press.\r\nHenderson, Kathryn (1999). On line and on paper: Visual representations, visual culture, and computer graphics in design engineering. Cambridge, MA: MIT Press.\r\nHendrix, Gary (1977). Human engineering for applied natural language processing. In Proceedings of the Fifth International Joint Conference on Artificial Intelligence (pp. 183­191). Cambridge, MA: MIT Press.\r\nHeritage, John (1984). Garfinkel and ethnomethodology. Cambridge, UK: Polity Press.\r\nHirschauer, Stefan (1991). The manufacture of bodies in surgery. Social Studies of Science 21(2): 279­319.\r\nHirsh, Haym (1999). Roomservice, AI-style. IEEE Intelligent Systems and Their Applications March/April: 8­10.\r\nHogle, Linda (1999). Recovering the nation\'s body: Cultural memory, medicine, and the politics of redemption. New Brunswick, NJ: Rutgers University Press.\r\n\r\n298\r\n\r\nReferences\r\n\r\nHughes, John, Randall, David, and Shapiro, Dan (1993). From ethnographic record to system design: Some experiences from the field. Computer-Supported Cooperative Work 1: 123­141.\r\nHutchins, Edwin (1983). Understanding Micronesian navigation. In D. Gertner and A. Stevens (eds.), Mental models (pp. 191­225). Hillsdale, NJ: Erlbaum.\r\nHutchins, Edwin (1995). Cognition in the wild. Cambridge, MA: MIT Press. Hymes, Dell H. (1974). Reinventing anthropology. New York: Random House. Ingold, Tim (2000). The perception of the environment: Essays in livelihood, dwelling\r\nand skill. London/New York: Routledge. Ito, Mimi, Okabe, Daisuke, and Matsuda, Misa (2005). Personal, portable, pedes-\r\ntrian: Mobile phones in Japanese life. Cambridge, MA: MIT Press. Jain, Sarah (1999). The prosthetic imagination: Enabling and disabling the pros-\r\nthesis trope. Science, Technology and Human Values 24: 31­54. Jain, Sarah (2006). Injury: The politics of product design and safety law in the United\r\nStates. Princeton, NJ: Princeton University Press. Jefferson, Gail (1972). Side sequences. In D. Sudnow (ed.), Studies in social inter-\r\naction (pp. 294­338). New York: Free Press. Jefferson, Gail (1983). Issues in the transcription of naturally occurring talk: Carica-\r\nture versus capturing pronunciational particulars. (Tilburg Papers in Language and Literature, no. 34). Amsterdam, The Netherlands: Tilburg University. Jeremijenko, Natalie (2004). If things can talk, what do they say? In N. WaldripFruin and P. Harrigan (eds.), First person: New media as story, performance, and game (pp. 262­287). Cambridge, MA: MIT Press. Jordan, Brigitte, and Fuller, Nancy (1975). On the non-fatal nature of trouble sense-making and sense-managing in Lingua Franca talk. Semiotica 13: 1­31. Jordan, Kathleen, and Lynch, Michael (1992). The sociology of a genetic engineering technique: Ritual and rationality in the performance of the `plasmid prep.\' In A. Clarke and J. Fujimura (eds.), The right tools for the job: At work in twentieth-century life sciences (pp. 77­114). Princeton, NJ: Princeton University Press. Joshi, Arvon, Webber, Bonnie, and Sag, Ivan (eds.) (1981). Elements of discourse understanding. Cambridge, UK: Cambridge University Press. Kantrowitz, Barbara (1994, January 17). The butlers of the digital age will be just a keystroke away. Newsweek, p. 58. Keller, Evelyn Fox (2002a). Making sense of life: Explaining biological development with models, metaphors and machines. Cambridge, MA: Harvard University Press. Keller, Evelyn Fox (2002b). Marrying the premodern to the postmodern: Computers and organisms after WWII. In D. Tofts, A. Jonson, and A. Cavallaro (eds.), Prefiguring cyberculture (pp. 52­65). Cambridge, MA: MIT Press. Keller, Evelyn Fox (2007). Booting up baby. In J. Riskin (ed.), The Sistine gap. Stanford, CA: Stanford University Press. Kember, Sarah (1998). Virtual anxiety: Photography, new technologies and subjectivity. Manchester: Manchester University Press. Kember, Sarah (2003). Cyberfeminism and artificial life. London/New York: Routledge. Kirby, Vicki (1997). Telling flesh: The substance of the corporeal. New York: Routledge.\r\n\r\nReferences\r\n\r\n299\r\n\r\nKnorr Cetina, Karin (1999). Epistemic cultures: How the sciences make knowledge. Cambridge, MA: Harvard University Press.\r\nKnorr Cetina, Karin, and Mulkay, Michael (eds.). (1983). Science observed: Perspectives on the social study of science. London: Sage.\r\nKnorr, Karin (1981). The manufacture of knowledge: An essay on the constructivist and contextual nature of science. Oxford/New York: Pergamon.\r\nKoschmann, Timothy (ed.). (2003). Plans and situated actions: A retro-review. Books & Ideas, Journal of the Learning Sciences 12(2): 257­306.\r\nKubrick, Stanley, and Clarke, Arthur C. (1968). 2001: A Space Odyssey. Landauer, Thomas (1995). The trouble with computers: Usefulness, usability, and\r\nproductivity. Cambridge, MA: MIT Press. Latour, Bruno (1986). Visualization and cognition: Thinking with eyes and\r\nhands. Knowledge and Society 6: 1­40. Latour, Bruno (1987). Science in action: How to follow scientists and engineers through\r\nsociety. Cambridge, MA: Harvard University Press. Latour, Bruno (1988). The pasteurization of France. Cambridge, MA: Harvard Uni-\r\nversity Press. Latour, Bruno (1992). Where are the missing masses: The sociology of a few\r\nmundane artifacts. In W. Bijker and J. Law (eds.), Shaping technology/building society (pp. 225­258). Cambridge, MA: MIT Press. Latour, Bruno (1993). We have never been modern. Cambridge, MA: Harvard University Press. Latour, Bruno (1999). Pandora\'s hope: Essays on the reality of science studies. Cambridge, MA: Harvard University Press. Latour, Bruno, and Woolgar, Steve (1979). Laboratory life: The social construction of scientific facts. Beverly Hills: Sage. Lave, Jean (1988). Cognition in practice: Mind, mathematics, and culture in everyday life. Cambridge/New York: Cambridge University Press. Law, John (1987). Technology and heterogeneous engineering: The case of Portuguese expansion. In W. Bijker, T. Hughes, and T. Pinch (eds.), The social construction of technological systems (pp. 111­134). Cambridge, MA: MIT Press. Law, John (1994). Organizing modernity. Oxford, UK/Cambridge, MA: Blackwell. Law, John (1996). Organizing accountabilities: Ontology and the mode of accounting. In R. Munro and J. Mouritsen (eds.), Accountability: Power, ethos and the technologies of managing (pp. 283­306). London: International Thomas Business Press. Law, John (2002). Aircraft stories: Decentering the object in technoscience. Durham, NC/London: Duke University Press. Law, John (2004). After method: Mess in social science research. London/New York: Routledge. Law, John, and Mol, Annemarie (eds.) (2002). Complexities: Social studies of knowledge practices. Durham, NC/London: Duke University Press. Lee, Nick, and Brown, Steve (1994). Otherness and the actor network: The undiscovered continent. American Behavioral Scientist 37: 772­790. Lenoir, Tim (2002). Embracing the posthuman. Configurations 10: 203­220. Levinson, Stephen (1983). Pragmatics. Cambridge, UK: Cambridge University Press. Lewis, David (1972). We, the navigators. Honolulu: University Press of Hawaii.\r\n\r\n300\r\n\r\nReferences\r\n\r\nLieberman, Henry (1997). Autonomous interface agents. Proceedings of the ACM CHI 97 Conference on human factors in computing systems (pp. 67­74). New York: ACM Press.\r\nLock, Margaret M. (2002). Twice dead: Organ transplants and the reinvention of death. Berkeley: University of California Press.\r\nLondon, Bob, and Clancey, William (1982). Plan recognition strategies in student modeling: Prediction and description. Proceedings of the Second National Conference on Artificial Intelligence, 335­338. Menlo Park, Calif.: AAAI Press.\r\nLuff, Paul, Gilbert, Nigel, and Frohlich, David (eds.). (1990). Computers and conversation. London/San Diego: Academic Press.\r\nLuff, Paul, Hindmarsh, Jon, and Heath, Christian (eds.). (2000). Workplace studies: Recovering work practice and informing system design. Cambridge, UK: Cambridge University Press.\r\nLynch, Michael (1982). Technical work and critical enquiry: Investigation in a scientific laboratory. Social Studies of Science 12: 499­533.\r\nLynch, Michael (1985a). Art and artifact in laboratory science: A study of shop work and shop talk in a research laboratory. London/Boston: Routledge & Kegan Paul.\r\nLynch, Michael (1985b). Discipline and the material form of images: An analysis of scientific visibility. Social Studies of Science 15: 37­66.\r\nLynch, Michael (1988). The externalized retina: Selection and mathematization in the visual documentation of objects in the life sciences. Human Studies 11: 201­234.\r\nLynch, Michael (1991a). Laboratory space and the technological domplex: An investigation of topical contextures. Science in Context 4: 51­78.\r\nLynch, Michael (1991b). Ordinary and scientific measurement as ethnomethodological phenomena. In G. Button (ed.), Ethnomethodology and the human sciences (pp. 77­108). Cambridge, UK: Cambridge University Press.\r\nLynch, Michael (1993). Scientific practice and ordinary action: Ethnomethodology and social studies of science. Cambridge, UK/New York: Cambridge University Press.\r\nLynch, Michael (2001). Ethnomethodology and the logic of practice. In T. Schatzki, K. K. Cetina, and E. Von Savigny (eds.), The practice turn in contemporary theory (pp. 131­148). London/New York: Routledge.\r\nLynch, Michael, and Jordan, Kathleen (1995). Instructed action in, of, and as molecular biology. Human Studies 18: 227­244.\r\nLynch, Michael, and Jordan, Kathleen (2000). Patents, promotions and protocols: Mapping and claiming scientific territory. Mind, Culture & Activity 7: 124­ 146.\r\nLynch, Michael, Livingston, Eric, and Garfinkel, Harold (1983). Temporal order in laboratory work. In K. Knorr and M. Mulkay (eds.), Science observed (pp. 205­238). London: Sage.\r\nLynch, Michael, and Woolgar, Steve (eds.). (1990). Representation in scientific practice. Cambridge, MA: MIT Press.\r\nMacbeth, Douglas (1996). The discovery of situated worlds: Analytic commitments, or moral orders? Human Studies 19: 267­287.\r\nMacKay, D. (1962). The use of behavioral language to refer to mechanical processes. British Journal of Philosophical Science 13: 89­103.\r\n\r\nReferences\r\n\r\n301\r\n\r\nMalinowski, Bronislaw (1935). Coral gardens and their magic. London: Allen & Unwin.\r\nMann, Steve, and Niedzviecki, Hal (2001). Cyborg: Digital destiny and human possibility in the age of the wearable computer. Doubleday Canada.\r\nMarcus, George (1995). Ethnograpy in/of the world system: The emergence of multi-sited ethnography. Annual Reviews of Anthropology 24: 95­ 117.\r\nMarcus, George (ed.). (1999). Critical anthropology now: Unexpected contexts, shifting constituencies, changing agendas. Santa Fe, NM: School of American Research.\r\nMarcus, George, and Fischer, Michael (1986). Anthropology as cultural critique: An experimental moment in the human sciences. Chicago: University of Chicago Press.\r\nMarks, Laura U. (2002). Touch: Sensuous theory and multisensory media. Minneapolis: University of Minnesota Press.\r\nMarkussen, Randi (1995). Constructing easiness ­ Historical perspectives on work, computerization, and women. In S. L. Star (ed.), Cultures of computing (pp. 158­180). Oxford: Blackwell.\r\nMauss, Marcel (1902). A general theory of magic. New York: Norton. Mauss, Marcel (1954). The gift. London: Cohen & West. McCorduck, Pamela (1979). Machines who think. San Francisco, CA: W.H. Free-\r\nman. McDermott, Ray (1976). Kids make sense: An ethnographic account of the itnerac-\r\ntional management of success and failure in one first-grade classroom. Unpublished doctoral dissertation, Stanford University. M\'charek, Amade (2005). The Human genome diversity project: An ethnography of scientific practice. Cambridge, UK: Cambridge University Press. McNeil, Maureen (ed.) (1987). Gender and expertise. London: Free Association Books. Mead, George H. (1934). Mind, self and society from the standpoint of a social behaviorist. Chicago: University of Chicago Press. Menzel, Peter, and D\'Aluisio, Faith (2000). Robo sapiens. Cambridge, MA: MIT Press. Merritt, Marilyn (1977). On questions following questions in service encounters. Language in Society 5: 315­357. Mialet, Helene (2003). Reading Hawking\'s presence: An interview with a selfeffacing man. Critical Inquiry 29: 571­598. Middleton, David, and Brown, Steven (2005). Net-working on a neonatl intensive care unit: The baby as a virtual object. In B. Czarniiawska and T. Hernes (eds.), Actor-network theory and organizing (pp. 307­328). Copenhagen: Copenhagen Business School Press. Miller, George A., Galanter, Eugene, and Pribram, Karl H. (1960). Plans and the structure of behavior. New York: Holt, Rinehart and Winston. Mills, C. Wright (1940). Situated actions and vocabularies of motive. American Sociological Review 5: 904­913. Mol, Annemarie (2002). The body multiple: Ontology in medical practice. Durham, NC: Duke University Press.\r\n\r\n302\r\n\r\nReferences\r\n\r\nMoore, C. L. (1975). No woman born. In T. Scortia and G. Zebrowski (eds.), Human-machines: An anthology of stories about cyborgs (pp. 63­118). New York: Vintage.\r\nMort, Maggie, Goodwin, Dawn, Smith, Andrew, and Pope, Catherine (2005). Safe asleep? Human­machine relations in medical practice. Social Science & Medicine 61: 2027­2037.\r\nMulcahy, Dianne (1999). Working bodies and representations: Tales from a training field. Science, Technology and Human Values 24: 80­104.\r\nNewman, Susan (1998). Here, there, and nowhere at all: Distribution, negotiation, and virtuality in postmodern ethnography and engineering. Knowledge and Society 11: 235­267.\r\nNewell, Allen, and Simon, Herbert (1972). Human problem solving. Englewood Cliffs, NJ: Prentice Hall.\r\nNickerson, Ray (1976). On conversational interaction with computers. In Proccedings of ACM SIGGRAPH workshop, October 14­15, pp. 101­113, Pittsburgh, PA.\r\nNilsson, Neils (1973). A hierarchical robot planning and execution system. (Technical Note 76). Menlo Park, CA: SRI Artificial Intelligence Center.\r\nNoble, David (1984). Forces of production. New York/Oxford: Oxford University Press.\r\nOberquelle, Horst, Kupka, I., and Maass, S. (1983). A view of human­machine communication and cooperation. International Journal of Man­Machine Studies 19: 309­333.\r\nOchs, Eleanor (1979). Planned and unplanned discourse. In T. Givon (ed.), Syntax and semantics: Vol. 12. Discourse and syntax (pp. 51­78). New York: Academic Press.\r\nOrr, Julian (1996). Talking about machines: An ethnography of a modern job. Ithaca, NY: ILR Press.\r\nOudshoorn, Nelly, and Pinch, Trevor (eds.). (2003). How users matter: The coconstruction of users and technologies. Cambridge, MA: MIT Press.\r\nPeachey, D., and McCalla, G. (1986). Using planning techniques in intelligent tutoring systems. International Journal of Man­Machine Studies 24: 77­98.\r\nPedersen, Elin Rønby, and Sokoler, Thomas (1997). AROMA ­ Abstract representation of mediated presence supporting mutual awareness. Proceedings of the ACM CHI 97 Conference on Human Factors in Computing Systems (pp. 51­58). New York: ACM Press.\r\nPeirce, Charles (1933). In C. Hartshorne and P. Weiss (eds.), Collected papers (Vol. 11). Cambridge, MA: Harvard University Press.\r\nPicard, Rosalind (1997). Affective computing. Cambridge, MA: MIT Press. Pickering, Andrew (1984). Constructing quarks: A sociological history of particle\r\nphysics. Edinburgh: Edinburgh University Press. Pickering, Andrew (ed.). (1992). Science as practice and culture. Chicago/London:\r\nUniversity of Chicago Press. Pickering, Andrew (1995). The mangle of practice: Time, agency and science. Chicago:\r\nUniversity of Chicago Press. Pickering, Andrew (2002). Cybernetics and the mangle. Social Studies of Science\r\n32: 413­438.\r\n\r\nReferences\r\n\r\n303\r\n\r\nPiller, Charles (2001, May 13). A step toward creating thoughtful machines. Greenwich Times, A8.\r\nPrentice, Rachel (2005). Swimming in the joint: Surgery, technology, perception. Unpublished manuscript.\r\nPrice, Janet, and Shildrick, Magrit (eds.). (1999). Feminist theory and the body: A reader. Edinburgh: Edinburgh University Press.\r\nPylyshyn, Zenon (1974). Minds, machines and phenomenology: Some reflections on Dreyfus\' What Computers Can\'t Do. Cognition 3: 57­77.\r\nPylyshyn, Zenon (1984). Computation and cognition. Cambridge, MA: MIT Press. Rawls, Anne (1996). Durkheim\'s epistemology: The neglected argument. Amer-\r\nican Journal of Sociology 102(2): 430­482. Rawls, Anne (2002). Editor\'s introduction. In Ethnomethodology\'s programme:\r\nWorking out Durkheim\'s aphorism. Lanham, MD: Rowman & Littlefield Publishers. Pp. 1­76. Reid, Roddey, and Traweek, Sharon (eds.). (2000). Doing Science + Culture: How cultural and interdisciplinary studies are changing the way we look at science and medicine. New York: Routledge. Riecken, Douglas (1994). A conversation with Marvin Minsky about agents. Communications of the ACM 37: 23­29. Risan, Lars (1997). Artificial life: A technoscience leaving modernity? An anthropology of subjects and objects. Retrieved August 10, 2005, from http://anthrobase. com/Txt/R/Risan L 05.htm. Riskin, Jessica (2003a). The defecating duck, or, the ambiguous origins of artificial life. Critical Inquiry 20: 599­633. Riskin, Jessica (2003b). Eighteenth century wetware. Representations 83: 97­125. Riskin, Jessica (ed.). (2007). The Sistine gap: Essays in the history and philosophy of artificial life. Chicago: University of Chicago Press. Robertson, Toni (2002). The public availability of actions and artefacts. ComputerSupported Cooperative Work 11: 299­316. Rogers, Yvonne, Sharp, Helen, and Preece, Jennifer (2002). Interaction design: Beyond human­computer interaction. New York: Wiley. Rubin, Andrea (1980). A theoretical taxonomy of the differences between oral and written languge. In R. Spiro et al. (eds.), Theoretical issues in reading comprehension. Hillsdale, NJ: Erlbaum. Sacerdoti, Earl (1975). The nonlinear nature of plans. In Proceedings of the Fourth International Joint Conference on Artificial Intelligence. Sacerdoti, Earl (1977). A structure for plans and behavior. New York: Elsevier. Sack, Warren (1997). Artificial human nature. Design Issues 13: 55­64. Sacks, Harvey (1963). On sociological description. Berkeley Journal of Sociology 8: 1­16. Sacks, Harvey (1974). An analysis of the course of a joke\'s telling in converstion. In R. Bauman and J. Scherzer (eds.), Explorations in the ethnography of speaking (pp. 337­353). Cambridge, UK: Cambridge University Press. Sacks, Harvey, Schegloff, Emanuel, and Jefferson, Gail (1978). A simplest systematics for the organization of turn-taking in conversation. In J. Schenkein (ed.), Studies in the organization of conversational interaction (pp. 7­55). New York: Academic Press.\r\n\r\n304\r\n\r\nReferences\r\n\r\nSandoval, Chela (1999). New sciences: Cyborg feminism and the methodology of the oppressed. In J. Wolmark (ed.), Cybersexualities (pp. 247­263). Edinburgh: Edinburgh University Press.\r\nSawyer, R. Keith (2003). Improvised dialogues: Emergence and creativity in conversation. Westport, CT: Ablex.\r\nSchaffer, Simon (1999). Enlightened automata. In W. Clark, J. Golinski, and S. Shaffer (eds.), The sciences in enlightened Europe (pp. 126­165). Chicago: University of Chicago Press.\r\nSchank, Robert, and Abelson, R. (1977). Scripts, plans and knowledge. In P. Johson-Laird and P. Wason (eds.), Thinking: Readings in cognitive science. Cambridge, UK: Cambridge University Press.\r\nScheflen, Albert (1974). How behavior means. Garden City, NY: Anchor Press. Schegloff, Emanuel (1972). Sequencing in conversational openings. In J.\r\nGumperz and D. Hymes (eds.)., Directions in sociolinguistics: The ethnography of communication (pp. 346­380). New York: Academic Press. Schegloff, Emanuel (1982). Discourse as an interactional achievement: Some uses of \"uh huh\" and other things that come between sentences. In D. Tannen (ed.), Georgetown University roundtable on language and linguistics: Analyzing discourse and talk (pp. 71­93). Washington, DC: Georgetown University Press. Schegloff, Emanuel (1998). Body torque. Social Research 65: 535­596. Schegloff, Emanuel, and Sacks, Harvey (1973). Opening up closings. Semiotica 7: 289­327. Schiebinger, Londa (ed.). (2000). Feminism & the body. Oxford: Oxford University Press. Schmidt, C., Sridharan, N., and Goodson, J. (1978). The plan recognition problem. Artificial Intelligence 11: 45­83. Schmidt, Kjeld, and Wagner, Ina (2004). Ordering systems: Coordinative practices and artifacts in architectural design and planning. Computer-Supported Cooperative Work 13: 349­408. Schuler, Douglas, and Namioka, Aki (eds.). (1993). Participatory design: Principles and practices. Hillsdale, NJ: Erlbaum. Schull, Natasha (2005). Digital gambling: The coincidence of desire and design. ANNALS of the American Academy of Political and Social Science 597: 65­81. Schull, Natasha (in press). Machine life: Control and compulsion in Las Vegas. Princeton, NJ: Princeton University Press. Schutz, Alfred (1962). Collected papers I: The problem of social reality. The Hague: Martinus Nijhoff. Searle, John (1969). Speech acts: An essay in the philosophy of language. Cambridge, UK: Cambridge University Press. Searle, John (1979). Expression and meaning. Cambridge, UK: Cambridge University Press. Searle, John (1980). The intentionality of intention and action. Cognitive Science 4: 47­70. Sengers, Phoebe (2004). The autonomous agency of STS: Boundary crossings between STS and artificial intelligence. Unpublished manuscript. (Submitted to Social Studies of Science.) Shapin, Steve (1989). The invisible technician. American Scientist 77: 553­563.\r\n\r\nReferences\r\n\r\n305\r\n\r\nShapin, Steven, and Schaffer, Simon (1985). Leviathan and the air-pump: Hobbes, Boyle, and the experimental life. Princeton, NJ: Princeton University Press.\r\nSharrock, Wes, and Button, Graham (2003). Plans and situated actions ten years on. The Journal of the Learning Sciences 12(2): 259­264.\r\nShrager, Jeff and Finin, Tom (1982). An expert system that volunteers advice. Proceedings of the Second National Conference on Artificial Intelligence, 339­340. Menlo Park, Calif.: AAAI Press.\r\nSidner, Candace (1979). Towards a computational theory of definite anaphora comprehension in English discourse. (Technical Report TR-537). Cambridge, MA: MIT AI Laboratory.\r\nSimon, Herbert (1969). The sciences of the artificial. Cambridge, MA: MIT Press. Singleton, Vicky (1998). Stabilizing instabilities: The laboratory in the UK Cer-\r\nvical Screening Program. In M. Berg and A. Mol (eds.), Differences in medicine (pp. 86­104). Durham, NC: Duke University Press. Smith, Brian Cantwell (1996). On the origin of objects. Cambridge, MA: MIT Press. Smith, Dorothy E. (1987). The everyday world as problematic: A feminist sociology. Toronto: University of Toronto Press. Spender, Dale (1996). Nattering on the net: Women, power and cyberspace. Toronto: Garamond. Standage, Tom (2002). The Turk: The life and times of the famous eighteenth-century chess-playing machine. New York: Walker & Co. Star, Susan Leigh (1989a). Regions of the mind: Brain research and the quest for scientific certainty. Stanford, CA: Stanford University Press. Star, Susan Leigh (1989b). Layered space, formal representations and long distance control: The politics of information. Fundamenta Scientiae 10: 125­155. Star, Susan Leigh (1991). Invisible work and silenced dialogues in knowledge representation. In I. Eriksson, B. Kitchenham, and K. Tijdens (eds.), Women, work and computerization (pp. 81­92). Amsterdam: North Holland. Star, Susan Leigh (ed.). (1995). The cultures of computing. Oxford, UK/Cambridge, MA: Blackwell. Star, Susan Leigh, and Griesemer, James (1989). Institutional ecology, `translations\' and boundary objects: Amateurs and professionals in Berkeley\'s Museum of Vertebrate Zoology. Social Studies of Science 19: 387­420. Stelarc (2004). Prosthetic head: Intelligence, awareness and agency. Unpublished manuscript, University of Melbourne. Stich, Stephen (1983). From folk psychology to cognitive science. Cambridge, MA: MIT Press. Strathern, Marilyn (1988). The gender of the gift: Problems with women and problems with society in Melanesia. Berkeley: University of California Press. Strathern, Marilyn (1992). Reproducing the future: Essays on anthropology, kinship, and the new reproductive technologies. New York: Routledge. Strathern, Marilyn (1996). Cutting the network. Journal of the Royal Anthropological Institute 2: 517­535. Strathern, Marilyn (1999). Property, substance, and effect: Anthropological essays on persons and things. London/New Brunswick, NJ: Athlone Press. Strathern, Marilyn (ed.). (2000). Audit cultures: Anthropological studies in accountability, ethics, and the academy. London/New York: Routledge.\r\n\r\n306\r\n\r\nReferences\r\n\r\nStreeck, Jurgen (1980). Speech acts in interaction: A critique of Searle. Discourse Processes 3: 133­154.\r\nSuchman, Lucy (1982). Toward a sociology of human­machine interaction: Pragmatics of instruction following. (CIS Working Paper, Xerox Palo Alto Research Center). Palo Alto, CA: Author.\r\nSuchman, Lucy (1987). Plans and situated actions: The problem of human­machine communication. New York: Cambridge University Press.\r\nSuchman, Lucy (1993a). Response to Vera and Simon\'s `Situated action: A symbolic interpretation.\' Cognitive Science 17(1): 71­76.\r\nSuchman, Lucy (1993b). Technologies of accountability: On lizards and airplanes. In G. Button (ed.), Technology in working order (pp. 113­126). London: Routledge.\r\nSuchman, Lucy (1994a). Working relations of technology production and use. Computer-Supported Cooperative Work 2: 21­39.\r\nSuchman, Lucy (1994b). Do categories have politics? The language-action perspective reconsidered. Computer-Supported Cooperative Work 2: 177­190.\r\nSuchman, Lucy (1995). Making work visible. Communications of the ACM 38(9): 56­64.\r\nSuchman, Lucy (1999). Working relations of technology production and use. In D. Mackenzie and J. Wajcman (eds.), The social shaping of technology, 2nd ed. (pp. 258­268). Buckingham, UK/Philadelphia: Open University Press.\r\nSuchman, Lucy (2000). Embodied practices of engineering work. Mind, Culture & Activity 7: 4­18.\r\nSuchman, Lucy (2001). Building bridges: Practice-based ethnographies of contemporary technology. In M. Schiffer (ed.), Anthropological perspectives on technology (pp. 163­177). Albuquerque: University of New Mexico Press.\r\nSuchman, Lucy (2002a). Located accountabilities in technology production. Scandinavian Journal of Information Systems 14: 91­105.\r\nSuchman, Lucy (2002b). Practice-based design: Notes from the hyper-developed world. The Information Society 18: 1­6.\r\nSuchman, Lucy (2003). Writing and reading: A response to comments on plans and situated actions: The problem of human­machine communication. The Journal of the Learning Sciences 12 (2): 299­306.\r\nSuchman, Lucy (2005). Affiliative objects. Organisation 12(3): 379­399. Suchman, Lucy, Blomberg, Jeanette, Orr, Julian, and Trigg, Randall (1999).\r\nReconstructing technologies as social practice. American Behavioral Scientist 43: 392­408. Suchman, Lucy, and Jordan, Brigitte (1989). Computerization and women\'s knowledge. In K. Tijdens, M. Jennings, I. Wagner, and M. Weggelaar (eds.), Women, work and computerization (pp. 153­160). Amsterdam: North Holland. (Reprinted in P. Agre and D. Schuler (eds.) (1997). Reinventing technology, rediscovering community: Critical explorations in computing as a social practice (pp. 97­105). Greenwich, CT: Ablex.) Suchman, Lucy, Trigg, Randall, and Blomberg, Jeanette (2002). Working artefacts: Ethnomethods of the prototype. British Journal of Sociology 53: 163­179. Taussig, Michael (1993). Mimesis and alterity: A particular history of the senses. London: Routledge.\r\n\r\nReferences\r\n\r\n307\r\n\r\nTerry, Jennifer, and Calvert, Melodie (eds.). (1997). Processed lives: Gender and technology in everyday life. London/New York: Routledge.\r\nThomas, Frank, and Johnston, Ollie (1981). Disney animation: The illusion of life. New York: Abbeville.\r\nThomas, Peter J. (1995). The social and interactional dimensions of human­computer interfaces. Cambridge, UK: Cambridge University Press.\r\nThompson, Charis (2005). Making parents: The ontological choreography of reproductive technologies. Cambridge, MA: MIT Press.\r\nTimmermans, Stefan (1999). Sudden death and the myth of CPR. Philadelphia, PA: Temple University Press.\r\nTimmermans, Stefan, and Berg, Marc (1997). Standardization in action: Achieving local universality through medical protocols. Social Studies of Science 27: 273­305.\r\nTimmermans, Stefan, and Berg, Marc (2003). The gold standard: The challenge of evidence-based medicine and standardization in health care. Philadelphia, PA: Temple University Press.\r\nTraweek, Sharon (1988). Beamtimes and lifetimes: The world of high energy physicists. Cambridge, MA: Harvard University Press.\r\nTrigg, Randall, Blomberg, Jeanette, and Suchman, Lucy (1999). Moving document collections online. In Proceedings of the Sixth European Conference on Computer Supported Cooperative Work (ECSCW): (pp. 331­350). Copenhagen: Kluwer Academic Press.\r\nTuring, Alan (1950). Computing machinery and intelligence. Mind 59(236): 433­ 461.\r\nTurkle, Sherry (1984). The second self: Computers and the human spirit. New York: Simon & Schuster.\r\nTurkle, Sherry (1995). Life on the screen: Identity in the age of the Internet. New York/Toronto: Simon & Schuster.\r\nTurnbull, David (1990). Mapping the world in the mind: A case study of the unwritten knowledge of the micronesian navigators. Deakin University School of Humanities. Geelong: Deakin University Press.\r\nTurnbull, David (1993). Maps are territories, science is an atlas: A portfolio of exhibits. Chicago: University of Chicago Press.\r\nTurnbull, David (2000). Masons, tricksters and cartographers: Comparative studies in the sociology of scientific and indigenous knowledge. Amsterdam: Harwood Academic.\r\nTurner, Ralph (1962). Words, utterances and activities. In Ethnomethodology: Selected readings (pp. 197­215). Harmondsworth, Middlesex: Penguin.\r\nTylor, Edward (1875). Primitive culture. London: Murray. Varela, Francisco, Thompson, Evan, and Rosch, Eleanor (1991). The embodied\r\nmind: Cognitive science and human experience. Cambridge, MA: MIT Press. Vera, Alonso (2003). By the seat of our pants: The evolution of research on\r\ncognition and action. The Journal of the Learning Sciences 12(2): 279­284. Vera, Alonso, and Simon, Herbert (1993). Situated action: A symbolic interpre-\r\ntation. Cognitive Science 17(1): 7­48. Verran, Helen (1998). Re-imagining land ownership in Australia. Postcolonial\r\nStudies 1: 237­254.\r\n\r\n308\r\n\r\nReferences\r\n\r\nVerran, Helen (2001). Science and an African logic. Chicago: University of Chicago Press.\r\nViseu, Ana (2003). Simulation and augmentation: Issues of wearable computers. Ethics and Information Technology 5: 17­26.\r\nViseu, Ana (2005). Augmented bodies: The visions and realities of wearable computers. Unpublished doctoral dissertation, Ontario Institute for Studies in Education, University of Toronto.\r\nWakeford, Nina (2000). Gender and the landscapes of computing in an Internet cafe. In G. Kirkup, L. Janes, K. Woodward, and F. Hovenden (eds.), The gendered cyborg (pp. 291­304). London/New York: Routledge.\r\nWatt, W. C. (1968). Habitability. American Documentation 19(3): 338­351. Wei, Sha Xin (2002). Resistance is fertile: Gesture and agency in the field of\r\nresponsive media. Configurations 10: 439­472. Weizenbaum, Joseph (1983). ELIZA: A computer program for the study of nat-\r\nural language communication between man and machine. Communications of the ACM, 25th Anniversary Issue 29(1): 23­27. (Reprinted from Communications of the ACM 26(1): 36­45, January 1966). Wells, Gordon (2003). Lesson plans and situated learning-and-teaching. The Journal of the Learning Sciences 12(2): 265­272. Wenger, Etienne (1987). Artificial intelligence and tutoring systems: Computational and cognitive approaches to the communication of knowledge. Los Altos, CA: Morgan Kaufmann. Wilkinson, Barry (1983). The shopfloor politics of new technology. London: Heinemann. Wilson, Thomas (1970). Conceptions of interaction and forms of sociological explanation. American Sociological Review 35: 697­709. Winograd, Terry, and Flores, Fernando (1986). Understanding computers and cognition: A new foundation for design. Norwood, NJ: Ablex. Wise, J. Macgregor (1998). Intelligent agency. Cultural Studies 12: 410­428. Wodehouse, P. G. (1999/1923). The inimitable Jeeves. Harmondsworth, UK: Penguin. Wolmark, Jenny (ed.). (1999). Cybersexualities: A reader on feminist theory, cyborgs and cyberspace. Edinburgh: Edinburgh University Press. Wood, Gaby (2002). Living dolls: A magical history of the quest for mechanical life. London: Faber & Faber. Woolf, Beverly and McDonald, David (1983). Human­computer discourse in the design of a PASCAL tutor. Proceedings of the ACM CHI 83 Conference on Human Factors in Computing Systems (pp. 230­234). New York: ACM Press. Woolgar, Steve (1991). Configuring the user: The case of usability trials. In J. Law (ed.), A sociology of monsters: Essays on power, technology and domination. London: Routledge. Yates, JoAnne (1989). Control through communication: The rise of system in American management. Baltimore: Johns Hopkins University Press. Zimmerman, Donald (1970). The practicalities of rule use. In J. Douglas (ed.)., Understanding everyday life (pp. 221­238). Chicago, IL: Aldine. Zuboff, Shoshana (1988). In the age of the smart machine: The future of work and power. New York: Basic Books.\r\n\r\nIndex\r\n\r\nALICE, the Artificial Linguistic Computer Entity, 208, 215, 254\r\nAanestad, Margunn, 266 accountability, 13, 21, 30, 35, 94, 177, 203,\r\n204, 263, 264, 270, 285 Actor Network Theory, 261 Adam, Alison, 12, 35, 64, 230, 231, 232 adjacency pair, 93, 94, 96, 155 affective computing, 232 agency, 2, 5, 187, 203, 206, 207, 214, 228,\r\n239, 242, 246, 250, 251, 253, 256, 265­269, 270, 271, 275, 281, 285 sociomaterial agency, 267, 268, 282 agential object, 271 agential realism, 267, 285 Agre and Chapman, 13, 14 Agre, Philip, 13, 14, 25, 35, 59, 188, 193, 230 Ahmed, Sara, 2, 222, 244, 260 AI. See Artificial Intelligence Akrich, Madeleine, 11, 44, 110, 186, 191 Allen, James, 56, 62 Amerine and Bilmes, 112 animated interface agents, 210, 212 animism, 215, 244 anthropology, 3, 7, 8, 29, 69, 176, 241, 256, 259 artificial intelligence, 2, 3, 31, 36, 51, 53, 56, 57, 65, 114, 207, 226, 255, 260, 273 Ashmore, Malcolm, Wooffitt, Robin, and Harding, Stella, 261 asymmetry, 5, 11, 13, 126, 183, 268, 269 Atkinson and Drew, 98, 99, 102\r\n\r\nautomata, 35, 228, 238 autonomous agency, 219, 224, 243, 257\r\nBalsamo, Anne, 10, 230, 242, 271, 274 Bannon, Liam, viii, 188 Barad, Karen, 242, 259, 267, 285 Bardram, Jakob, 203 Barley, Stephen, 194 Barwise and Perry, 77, 183 Beck, Eevi, 183 Beckman and Frankel, 104 Beninger, James, 196 Berg, Anna Jorunn, 217 Berg, Marc, 196 Berg, Marc, and Timmermans, Stefan,\r\n195­196 Berners-Lee, Tim, 218 Berreman, Gerald, 24 Bhabha, Homi, 260 Birdwhistell, Raymond, 88 Bleecker, Julian, 215 Blomberg, Jeanette, viii, 278 Bloomfield, Brian, 203 Blumer, Herbert, 75­76 Boden, Margaret, 58, 65 Bødker, Susanne, 279 boundaries, 2, 12, 178, 205, 260, 263, 265,\r\n266, 268, 271, 274, 276, 282­285 boundary making, 258, 283, 284 Bowers, John, xii, 188, 203 Bowker and Star, 202, 224 Bowker, Geoffrey, 251 Braidotti, Rosi, 1, 227, 242, 260\r\n\r\n309\r\n\r\n310\r\n\r\nIndex\r\n\r\nBreazeal, Cynthia, 236, 246 Brooks, Rodney, 14, 15, 17, 217, 230, 231,\r\n235 Brown and Newman, 181 Brown, Rubenstein, and Burton, 123 Brown, Steve, 270 Brun Cottan, Francoise, viii Burke, Julie, 115, 142 Burton and Brown, 45, 179­181 Butler, Judith, 230, 242, 271 Button, Graham, 12, 20, 22, 35, 178, 203,\r\n300\r\nCallon, Michel, 261 Carroll, John, 22, 278 Casper, Monica, 1, 242, 257, 263, 265 Castan~ eda, Claudia, 227, 237, 260, 273, 274 Center for the Study of Language and\r\nInformation (CSLI), 77 Centre for Science Studies, Lancaster\r\nUniversity, viii Chapman, David, 13 Chasin, Alexandra, 220 chatterbots, 207 Chesher, Chris, 252, 281 Clancey, William, 17, 35 Clark, Andy, 35, 207, 231 Clarke, Adele, 194 Clement, Andrew, vii, 191, 266 Cog, 226, 235, 238, 243, 245­247, 274 cognitive science, 4, 7, 21, 25, 28, 34, 36, 51,\r\n52, 64, 67, 78, 79, 84, 176, 182, 207, 256 Cohen, Paul, 115 Collins, Harry M., 12, 35, 228, 231, 269 commodity fetishism, 244 common sense knowledge, 64, 65, 76 communicative resources, 86, 114 communicative trouble, 97, 101 computational artifacts, 12, 23, 33, 41, 43,\r\n215, 241, 243, 263 Computer Professionals for Social\r\nResponsibility, 278 Computer-Supported Cooperative Work,\r\n276, 277 conditional relevance, 93, 94, 96, 97, 145 configuration, 1, 5, 6, 11, 21, 25, 186, 190,\r\n191, 192, 252, 257, 258, 261, 265, 267, 268, 270, 271, 275, 278, 284 conversation, 12, 23, 39, 41, 47, 49, 50, 61, 66, 87, 110, 145, 154­162, 178, 181, 281 conversation analysis, 4, 11, 22, 86, 88, 178, 208, 276\r\n\r\nconversational agents, 206, 247, 252 Coombs and Alty, 45, 46 Cooper and Bowers, 188 Coulter, Jeff, 12, 48, 82, 156 Coulter, Lee, and Sharrock, 35 Crist, Eileen, 29, 228 cybernetic, 250 cyborg, 271­276\r\nde Certeau, Michel, 27 de la Mettrie, Julien, 35 de Laet and Mol, 192 demonstration, 238, 246 demystification, 243 Dennett, Daniel, 42, 274 de-scription, 192 design, 3, 6, 8, 10, 22, 23, 30, 32, 35, 43, 44,\r\n70, 109, 111, 116, 117, 124, 126, 127, 136, 145, 167, 178, 179, 181, 186, 188, 191, 192, 205, 257, 259, 267, 276, 277, 285 participatory design, 22, 277, 278 di Leonardo, Michaela, 3 DOCTOR, 48, 49, 83 documentary method of interpretation, 48, 81 Dourish, Paul, 17, 35, 186 Downey and Dumit, 241 Doyle, Richard, 215, 242 Dreyfus, Hubert, 3, 12, 34, 35, 60, 67, 73 Dror, Otniel, 233, 234 Dumit, Joseph, 234 Durkheim\'s aphorism, 74, 76\r\nEdwards, Paul, 228, 251 Ehn, Pelle, 278 ELIZA, 47­50, 82, 210 embodied, 6, 10, 18, 21, 25, 36, 72, 111, 191,\r\n198, 201, 210, 215, 244, 245, 263, 274, 276, 279, 280 embodiment, 230­232 emotions, 210, 211, 215, 232­234, 249, 255 enchantment, 239, 244, 258 Erickson, 85, 88, 104, 105, 106 ethnomethodology, 4, 8, 16, 21, 22, 69, 76, 81, 82, 193, 276 expert systems, 37, 109\r\nface-to-face interaction, 4, 86, 178, 276 Feitelson and Stefik, 185 feminist science studies, 6, 14, 261, 271 Ferguson, James, 8 figuration, 226­228\r\n\r\nIndex\r\n\r\n311\r\n\r\nFikes and Nilsson, 53 Fikes, Richard, 53, 118 Fischer, Michael, 8 Fodor, Jerome, 37 Fox Keller, Evelyn, 238 frames, 283 Frankel, Richard, 100, 102 Franklin, Sarah, 227, 257, 260 Fujimura, Joan, 194, 298\r\nGalison, Peter, 194 garden path, 101, 128, 154, 161, 168 Gardner, Howard, 35 Garfinkel and Sacks, 177, 184, 193 Garfinkel, Harold, 13, 48, 66, 70, 72, 75, 76,\r\n79­83, 112, 177, 178, 184, 194, 203, 204 Garfinkel, Lynch, and Livingston, 82, 178 Geertz, Clifford, 29 Gell, Alfred, 239, 241, 244, 253 Gilbert, Nigel, 35 Gladwin, Thomas, 24, 51, 69, 184 goal, 26, 52, 56, 60, 61, 72, 110 Goffman, Erving, 85, 95, 97 Gonzalez, Jennifer, 217 Goodwin, Charles, 86, 87, 88, 92, 200, 251,\r\n262, 276, 279 Goodwin, Charles and Marjorie Harness,\r\nviii, 262, 276, 277 Goodwin, Dawn, 196, 263 Goodwin, Marjorie Harness, 88, 201 Grand, Steve, 212, 230 Green, Nicola, 223 Greenbaum, Joan, 191, 278 Gregory, Judith, 196 Greif, Irene, 276 Grint and Woolgar, 110, 189 Grosz, Barbara, 114 Grosz, Elizabeth, 230 Grudin, Jonathan, 188 Gumperz and Tannen, 101 Gumperz, John, 62, 88, 122 Gupta, Akhil, 8\r\nHAL 9000, 234 Halberstam, Judith, 275 Hales, Mike, 191 Haraway, Donna, 1, 205, 214, 227, 242, 261,\r\n267, 271, 272, 275 Harding, Sandra, 14 Hayes and Reddy, 39, 50 Hayles, N. Katherine, 36, 230, 242, 243 HCI. See human­computer interaction\r\n\r\nHeap, James, 121 Heath and Luff, 17, 277 Heath, Christian, 35, 250, 276 Helmreich, Stefan, 214, 227, 230 Henderson, Austin, 118 Henderson, Kathryn, 279 Heritage, John, 77, 78, 84, 86, 108, 178 Hogle, Linda, 257 Hughes, Randall and Shapiro, 277 human­computer interaction, 2, 3, 4, 18,\r\n22, 41, 50, 182, 281 human­machine difference, 260 human­nonhuman, 2, 260 Hutchins, Edwin, 25, 184, 230 Hymes, Dell, 3\r\nimaginaries, 1, 6, 26, 191, 192, 206, 213, 217, 219, 220, 226, 228, 229, 237, 241, 247, 272, 274\r\nimmutable mobility, 22, 45, 283 indexical, 71, 77, 79, 81, 136, 184, 191 Ingold, Tim, xi, 262 instruction, 9, 22, 43, 44, 45, 54, 80, 110,\r\n112­116, 118, 167 intelligent artifacts, 35, 36, 51, 186, 213, 215 intelligent environment, 217, 221, 222 intelligent tutoring systems, 179, 180, 182 interactive interface design, 11, 12 interactivity, 5, 8, 10, 12, 178, 222, 235, 251,\r\n260 Interactivity, 23 interface, 2, 5, 250, 268, 276 interpretive flexibility, 191 intra-action, 267 Ito, Okabe and Matsuda, 223\r\nJain, Sarah Lochlann, 275 Jeeves, 215, 217, 223, 224 Jefferson, Gail, 86, 90, 91, 92, 99, 101, 108 Jeremijenko, Natalie, 39 Jordan and Fuller, 101, 157, 168 Jordan and Lynch, 194, 195 Jordan, Brigitte, viii, 266 Jorunn Berg, Anna, 217\r\nKember, Sarah, 35, 212, 214, 227, 230, 232, 242, 255\r\nKensing, Finn, viii Kirby, Vicki, 230 Kismet, 226, 235, 236, 238, 243, 245­247 Knorr Cetina, Karin, 194, 227, 262 Kusch, Martin, 35, 228\r\n\r\n312\r\n\r\nIndex\r\n\r\nKyng, Morten, 191, 278\r\nLandauer, Thomas, 278 Latour, Bruno, 110, 186, 192, 194, 195, 214,\r\n227, 242, 260, 263 Lave, Jean, 26, 119, 230 Law, John, viii, 122, 187, 194, 242, 261, 269,\r\n283 Lee, John R., 12 Lee, Nick, 270 Lenoir, Timothy, 242 Levinson, Stephen, 86, 93, 94, 96 Levy, David, viii Lewis, David, 25, 184 Lieberman, Henry, 219 Lock, Margaret, 257 Luff, Gilbert and Frohlich, 30, 179 Lynch, Livingston, and Garfinkel, 112, 113 Lynch, Michael, 69, 82, 108, 122, 177, 193,\r\n194, 195, 200, 203, 262\r\nMacbeth, Douglas, 17 Machine Perception Laboratory, 234 Maes, Pattie, 212, 213 Mann, Steve, 223 Marcus, George, 1, 8 Marks, Laura, 279 Markussen, Randi, 217 Marshall, Cathy, viii Massachusetts Institute of Technology,\r\n232, 274 materialization, 231, 271, 286 materialized refiguration, 1, 227 material-semiotic, 261 McCorduck, Pamela, 35, 36, 54 McDermott, Ray, 85 M\'charek, Amade, 194 McNeil, Maureen, viii, 194 Mead, George Herbert, 71, 73, 256 Mialet, Helene, 246 Middleton and Brown, 257 Miller, Galanter and Pribram, 13, 59 Mills, C. Wright, 70 mimesis, 244­245 Minsky, Marvin, 220 MIT\'s Artificial Intelligence Laboratory,\r\n14, 235 Mol, Annemarie, 192, 242, 261, 266 Moore, C. L., 272 Mort, Maggie, viii Movellan, Javier, 234\r\n\r\nMulcahy, Dianne, 269 multiplicity, 188, 196, 199, 268, 280 mutual constitution, 260, 268 mutual intelligibility, 10, 29, 30, 34, 52, 63,\r\n71, 76, 79­81, 86, 88, 125, 128, 178\r\nnavigators, 24, 184 new media, 6, 23, 243, 259, 280, 281 Newman, Susan, viii, 189 Noble, David, 193\r\nobjects, 2, 14, 33, 70, 75, 192, 194, 200, 202, 205, 214, 220, 238, 244, 245, 253, 256, 257, 262, 267, 270, 272, 279\r\nOchs, Eleanor, 115 ordering devices, 187, 193, 194, 197, 205 Orr, Julian, viii, 204 Oudshoorn and Pinch, 186\r\nPedersen and Sokoler, 250 Pedersen, Elin, viii performances, 195, 243, 246, 262, 283 performative, 125, 197, 246, 256, 285 pervasive computing, 221 Picard, Rosalind, 215, 232 Pickering, Andrew, 194, 227, 250, 251,\r\n253, 262 plan recognition, 56, 57 planning model, 10, 31, 52, 56­58, 61­63,\r\n74 plans, 5, 13­20, 21, 24, 26, 31, 51, 56, 58, 60,\r\n61, 63, 65, 67, 69­71, 81, 114, 176, 183, 184, 187, 196, 203, 205 Plans and Situated Actions, 2, 8, 176, 178, 230, 276, 282 posthuman, 242 practice, 6, 13, 14, 21, 22, 26, 65, 93, 177, 182, 183, 193, 197, 214, 227, 250, 264, 277, 278, 282, 284 Prentice, Rachel, 265 prescriptive representations, 3, 16, 27, 187, 203 Price and Shildrick, 230 programme of action, 192 prostheses, 275 Pylsyshyn, Zenon, 37\r\nRawls, Ann, 70, 76 recipient design, 45, 136 reconfiguration, 6, 227, 251, 263, 281, 285 reenchantment, 243, 255\r\n\r\nIndex\r\n\r\n313\r\n\r\nreflexivity, 13, 81, 187, 204, 277 repair, 12, 50, 55, 101, 114, 136, 139, 148,\r\n149, 150, 154­161, 162, 163, 167, 168, 180­182 Riskin, Jessica, 35, 228, 229 Robertson, Toni, viii, 70, 231, 250, 277 robotics, 226 Rogers, Sharp and Preece, 278\r\nSacerdoti, Earl, 53, 54, 114 Sack, Warren, 12, 213 Sacks, Harvey, 13, 76, 79, 80, 91 Sacks, Schegloff and Jefferson, 86, 89, 98,\r\n251 Sandoval, Chela, 275 Sawyer, Keith, 52 scale, 284 Scassellati, Brian, 235 Schaffer, Simon, 35 Schank and Abelson, 64 Scheflen, Albert, 88 Schegloff, Emanuel, 23, 87, 88, 93, 94, 97,\r\n98, 104, 107, 156, 276 Schiebinger, Londa, 230 Schmidt, Kjeld, 198 Schuler and Namioka, 191 Schull, Natasha, 275 Schutz, Alfred, 77, 85 Schwartz Cowan, Ruth, 221 science and technology studies, 1, 6, 7, 23,\r\n242, 259, 269 scripts, 11, 48, 64, 65, 107, 110, 192, 205,\r\n212, 282 Searle, John, 60, 62, 63, 79, 119 self-explanatory artifact, 43 Sengers, Phoebe, 14 servants, 219­221 Shakey, 53­54, 55 Shapin and Schaffer, 214, 227 Shapin, Steve, 224, 266 Sharrock, Wes, 12, 20, 22, 203 Shegloff, Emanuel, 109 Simon, Herbert, 15, 17, 18 Singleton, Vicky, 194 situated action, 13, 14, 16, 17, 20, 26, 27, 31,\r\n52, 60, 61, 70, 71, 78, 84, 120, 176, 183, 184, 185, 187 situated robotics, 207, 230, 242 smart technologies, 221 Smith, Brian Cantwell, 231, 267 Smith, Dorothy, 191\r\n\r\nsociability, 234­238 Sociable Machines Project, 236 sociomaterial, 7, 23, 248, 258, 262, 264, 268,\r\n270, 273, 275 sociomaterial assemblages, 190, 242, 268,\r\n276, 282, 283 software agent, 5, 206, 210, 212, 213, 215,\r\n216, 219 speech, 33, 38, 87, 104, 114, 115, 210, 247,\r\n253 speech act theory, 52, 62­63 Stacey, Jackie, viii, 260 Standage, Tom, 35 standard operating procedures, 195 Stanford Research Institute, 53, 54, 114 Star and Grisemer, 194 Star, Susan Leigh, 194, 199, 266 Stelarc, 243, 254, 255 Stelarc\'s Prosthetic Head, 247­250, 255 Stich, Stephen, 37 Strathern, Marilyn, 8, 202, 229, 241, 242,\r\n256, 257, 260, 261 Streeck, Jurgen, 87 STS. See science and technology studies subject/object binary, 221 subject/object relations, 258 subjects, 2, 192, 214, 222, 244, 257, 267, 270 surveillance, 222\r\nTaussig, Michael, 241, 243, 244, 247, 256 The Knowledge Navigator, 217 The Semantic Web, 218 Thomas, Peter, 30, 179 Thompson, Charis, 257, 264 Tikka, Heidi, 280 Timmermans and Berg, 195, 196 Timmermans, Stefan, 196 Traweek, Sharon, 194, 227 Trigg, Randall, viii, 72, 278 Turing, A.M., 47, 82, 207\r\nimitation game, 47 Turkle, Sherry, 33, 34, 36, 38, 42, 217, 241 turn taking, 89, 90, 91, 117 Turnbull, David, 25, 26, 184, 186, 196­199,\r\n260 Turner, Ralph, 125\r\nubiquitous computing, 5 user, 188­191 user interface, 43, 188 user model, 179\r\n\r\n314\r\nVan den Besselaer, Peter, 191 Varela, Thompson and Rosch, 35 Vaucanson, Jacques, 35, 229 Vera, Alonso, 15, 17, 18 Verran, Helen, 1, 26, 260, 278 Viseu, Anna, 223\r\nWagner, Ina, 198 Wakeford, Nina, 266 wearable computing, 217, 221, 223 Weizenbaum, Joseph, 47, 49, 210 Wells, Gordon, 16 Wenger, Etienne, 180 Wilson, Thomas, 81, 120 Winograd and Flores, 18\r\n\r\nIndex\r\nWise, J. Macgregor, 206, 213 Woggles, 211­213 Wolmark, Jennifer, 266, 271 Wood, Gaby, 35 Woolgar, Steve, 11, 44, 110, 186, 194 Work Practice and Technology, viii\r\nXerox Palo Alto Research Center, viii, 6, 7, 8, 14, 109, 278\r\nXin Wei, Sha, 281\r\nYates, Joanne, 196\r\nZimmerman, Don, 112 Zuboff, Shoshana, 204\r\n\r\n',1,'Suchman','Lucy Suchman',NULL,NULL,0,'10.1017/CBO9780511808418','Cambridge University Press','Details of the book on the Cambridge University Press website',1,NULL,0,0,NULL,NULL,0,0),(4,'gaver-ambiguity-as-a-resource-for-design','2019-02-23 20:29:35','2019-09-24 11:59:21','2019-02-23 20:29:08',NULL,1,'published','[]','Ambiguity as a Resource for Design','Ambiguity is usually considered anathema in Human Computer Interaction. We argue, in contrast, that it is a resource for design that can be used to encourage close personal engagement with systems. We illustrate this with examples from contemporary arts and design practice, and distinguish three broad classes of ambiguity according to where uncertainty is located in the interpretative relationship linking person and artefact. Ambiguity of information finds its source in the artefact itself, ambiguity of context in the sociocultural discourses that are used to interpret it, and ambiguity of relationship in the interpretative and evaluative stance of the individual. For each of these categories, we describe tactics for emphasising ambiguity that may help designers and other practitioners understand and craft its use.','William W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a resource for design. In *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems* (CHI \'03). ACM, New York, NY, USA, 233-240. https://doi.org/10.1145/642611.642653\r\n','Ft. Lauderdale, Florida, USA · April 5-10, 2003\r\n\r\nPaper: Designing Design\r\n\r\nAmbiguity as a Resource for Design\r\n\r\nWilliam W Gaver1\r\n\r\nJacob Beaver1\r\n\r\n1Interaction Design Research Studio\r\n\r\nThe Royal College of Art\r\n\r\nLondon, SW7 2EU, UK\r\n\r\nw.gaver / j.beaver @rca.ac.uk\r\n\r\nSteve Benford2\r\n2The Mixed Reality Laboratory University of Nottingham Nottingham, NG8 1BB, UK mbl@cs.nott.ac.uk\r\n\r\nABSTRACT Ambiguity is usually considered anathema in Human Computer Interaction. We argue, in contrast, that it is a resource for design that can be used to encourage close personal engagement with systems. We illustrate this with examples from contemporary arts and design practice, and distinguish three broad classes of ambiguity according to where uncertainty is located in the interpretative relationship linking person and artefact. Ambiguity of information finds its source in the artefact itself, ambiguity of context in the sociocultural discourses that are used to interpret it, and ambiguity of relationship in the interpretative and evaluative stance of the individual. For each of these categories, we describe tactics for emphasising ambiguity that may help designers and other practitioners understand and craft its use.\r\nKeywords Interaction design, Emotion and Affective UI, Design, Theory, Design Tips and Tricks, Heuristics, Interpretation\r\nINTRODUCTION Ambiguity is seldom embraced within traditional Human Computer Interaction. If \"usefulness and usability are the twin goals of HCI research and development\" [14], then ambiguity would seem their nemesis. It is difficult to see how an interface can be usable if the information it conveys is unclear, or useful if its very purpose is uncertain.\r\nInstead of regarding ambiguity as a problem, however, in this paper we suggest that it can be seen as an opportunity. Ambiguity can be frustrating, to be sure. But it can also be intriguing, mysterious, and delightful. By impelling people to interpret situations for themselves, it encourages them to start grappling conceptually with systems and their contexts, and thus to establish deeper and more personal relations with the meanings offered by those systems.\r\nThe ability for ambiguity to evoke personal relationships with technologies is particularly relevant as digital\r\n\r\nPermission to make digital or hard copies of all or part of this work\r\n\r\nfor personal or classroom use is granted without fee provided that\r\n\r\ncopies are not made or distributed for profit or commercial\r\n\r\naPdevramnitsasigoenatnodmthaaket cdoipgiteaslboerahratrhdisconpoiteicseoafnadlltohrepfaurltl ocfitathtiosnwoonrkthfoer\r\n\r\nfpiresrstopnaagl eo.rTcolascsorpooymotuhseerwisigsera,notredrewpiuthboluisthf,eetoprpoovsitdoedn tsheartvceorpsieosratroe\r\n\r\nrneodtismtriabdueteotro dliissttsri,bruetqeudirfeosrpprrioorfitspoercicfiocmpmeremrciisaslioandvaanndt/aogreaafnede. that\r\n\r\nCcootHhpeIire2ws0ib0see3,a,rAotrphririselpn5uo­bt1il0cise,h2,a0nt0do3,tphFoets.tfLuolalnucdsietearrtdviaoernlse,ooFnrlotthroeidrafei,rdsUitsStprAiabg.uet.e\r\n\r\nTo to\r\n\r\ncopy lists,\r\n\r\nCreoqpuyirriegshptr2io0r0s3peAccifmic1p-e5r8m1i1ss3i-o6n30an-7d//0o3r /a00fe0e4....$5.00.\r\n\r\nCHI 2003, April 5­10, 2003, Ft. Lauderdale, Florida, USA.\r\n\r\nCopyright 2003 ACM 1-58113-630-7/03/0004...$5.00.\r\n\r\ntechnologies are designed to support activities outside of work. Traditional concerns for clarity and precision are superseded in such systems by the need to provide rich resources for experience that can be appropriated by users. Ambiguity should not, of course, be allowed to interfere with the accomplishment of well-defined tasks, particularly in safety-critical environments. But in the many emerging applications for everyday life, we argue that ambiguity is a resource that designers should neither ignore nor repress.\r\nAfter all, the everyday world itself is inherently ambiguous: most things in it have multiple possible meanings. Allowing this ambiguity to be reflected in design has several advantages. Most importantly, it allows designers to engage users with issues without constraining how they respond. In addition, it allows the designer\'s point of view to be expressed while enabling users of different sociocultural backgrounds to find their own interpretations. Finally, ambiguity can make a virtue out of technical limitations by providing the grounds for people\'s interpretations to supplement them.\r\nThe rich aesthetic and conceptual potentials of ambiguity have long been exploited in the arts, and we review several examples of contemporary art in considering how ambiguity works. But we are particularly concerned with examining how ambiguity can be used to good effect in design. To orient our discussion, we start by describing four examples of ambiguity in interaction design, which illustrate the appeal of ambiguity and some of its attributes. We then discuss an account of ambiguity that centres on its locus in the relationship between user and system, and show how this can help us understand ambiguity in a variety of situations. Finally, we return to the original four examples, as well as other designs, to illustrate a number of tactics for producing ambiguity. Our purpose throughout is to reveal some of the techniques that interactions designers use in creating compelling designs, and to enable other designers and practitioners to think more precisely ­ whether critically or constructively ­ about ambiguity.\r\nFour Systems that Use Ambiguity Although ambiguity is usually avoided in Human Computer Interaction, there are a growing number of interactive designs that use it to good effect. In this section we describe four in order to provide concrete examples of how ambiguity can appear in technological\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\n233\r\n\r\nPaper: Designing Design\r\n\r\nCHI 2003: NEW HORIZONS\r\n\r\nFigure 1: Sloganbench (top) and Imagebank (bottom)\r\nsystems, before moving to a more analytical account of how it operates.\r\nProjected Realities Projected Realities [8, 9] is a system intended to help increase the presence of older people in a large Dutch housing estate called the Bijlmer. Designed to reflect both concerns that older people felt about the area (which has a bad reputation in the Netherlands) and their pride for this complex physical and cultural environment, the system provided a means for them to spread their opinions within and to the outskirts of the district.\r\nThe most visible elements of the completed system were three Sloganbenches set in local walkways, and an Imagebank designed to sit near a traffic signal adjacent to the area (Figure 1). Sloganbenches served as public furniture, but also contained electronically controlled fabric scrolls inset into their backs which displayed handwritten slogans written by older people from the area. The Imagebank comprised five monitors set into a wood-veneer casing. It showed slices of images collected by the older people to represent their lives. The pieces were connected wirelessly, so that the attitudes expressed by the slogans on local Sloganbenches could be summarised by the images showing on a single roadside Imagebank.\r\nProjected Realities used ambiguity in a number of ways. The slogans and images were presented with little context (even the fact that they originated from older people was spread by word of mouth) so that viewers had to interpret the attitudes they reflected. The mapping between slogans and images was not easily perceived, and occasionally contradictory images were juxtaposed on the Imagebank. Most notably, the objects themselves were unusual ­ the Imagebank looked like an extended TV, and the benches\r\n\r\ncreated a tension between sitting and viewing (since sitting on the bench was likely to hide the slogan). They balanced the familiar with the strange, and as local people encountered the pieces during a week-long trial in the area, they appeared to be attracted by this ambiguity to engage with the system.\r\nDesert Rain Desert Rain is a mixed reality performance that has toured internationally since 1999 [12]. Six players (the audience) are sent on a mission into a virtual world to find six targets (the performers). They explore motels, deserts and underground bunkers, communicating with each other through a live audio link. Once in the virtual world, they have twenty minutes to find their allocated targets, complete the mission, and get to the final room, where the identities of the targets ­ six people who have quite different perspectives on the Gulf war ­ are revealed. The virtual world is projected onto six rain curtains, screens made of water through which performers and players physically pass (Figure 2). In turn, the rain curtains are embedded within a larger physical set, some of which reproduces elements of the virtual world. The central artistic concern of Desert Rain is virtual warfare and the blurring of the boundaries between real and virtual events, especially with regard to the portrayal of warfare on television news, in Hollywood\'s films and in computer games. Both the content and the form of Desert Rain are designed to provoke participants to re-evaluate the boundaries between reality and fiction, and between the real and the virtual. This is achieved by making these boundaries deliberately ambiguous. Desert Rain mixes elements of theatre, installation and computer game to create an ambiguous structure. At the same time, its content mixes 3D game-like graphics with video clips describing people\'s real experiences of the Gulf War. It also seeks to disorientate participants to some extent by providing them with deliberately distorted and ambiguous information, most notably through the use of the rain curtain which provides a continually shifting and blurred view of the virtual world.\r\nThe Pillow The Pillow, a concept prototype by Tony Dunne [8], employs ambiguity at several levels. An LCD screen\r\nFigure 2: Desert Rain (projections on water)\r\n\r\n234\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\nFt. Lauderdale, Florida, USA · April 5-10, 2003\r\n\r\nPaper: Designing Design\r\n\r\nFigure 3: The Pillow\r\nembedded in a plastic brick is enclosed by a transparent plastic pillow, so that the simple geometric shapes it displays are blurred as they permeate the form (Figure 3). These shapes join with processed sounds to indicate passing electromagnetic information from mobile phones, taxis, commercial radio and television, making the Pillow into an unusual sort of radio ­ one that, moreover, casts the viewer into a voyeuristic relationship with the otherwise invisible information that surrounds us.\r\nThe Pillow displays electronic information in an impressionistic, ambiguous way. One can perceive the intensity of electromagnetic flow and capture snatches of intelligible sound, but the information is distorted and fragmented to produce an intriguing rather than informative experience. In addition, the Pillow exists at the cusp of several discourses: it is a radio, but also an aesthetic meditation ­ and perhaps also an artistic one. Finally, the Pillow produces yet another layer of ambiguity: by placing the user in a voyeuristic role it creates an ambivalent relationship with the purpose of the piece itself. The ability to eavesdrop on the electromagnetic spectrum is enticing yet uncomfortable, prompting questions about the ethics of technologies.\r\nHome Health Monitor The Home Health Monitor is a design for a system that gives feedback about the home\'s emotional, social and spiritual health on a daily basis [2]. Light, temperature, and door sensors, for example, would be used to monitor peoples\' activities in various parts of the home. Other sensors measure the stroke rate of a hairbrush, condensation on kitchen windows, or the state of the toilet seat to provide more idiosyncratic clues. Sensor readings and trends are mapped in state space to a collection of sentences drawn from a large number of published horoscopes to automatically generate a bespoke horoscope for the particular household on a given day (Figure 4).\r\nBy using ubiquitous sensing as an indication of the wellbeing of the home, the system (sometimes known as `the Superstitious Home\') offers an alternative to traditionally task-oriented forms of ubiquitous computing. It achieves its effect by allowing horoscopes to provide an ambiguous\r\n\r\nreflection of the state of sensors, which themselves have an ambiguous relationship to the realities of home life. This ambiguity ranges from the limited ability of sensors to monitor home activities to the relationship between measurable variables and emotional ones, and from the vague language used by most horoscopes to the juxtaposition of electronic technology with culturally suspect `fortune-telling.\' The end result is to provide people with a systematic but inconclusive foundation from which to reflect on the emotional state of their home.\r\nClarifying Ambiguity Our examples have included products, systems and events, and their intended settings include homes, performance spaces and public areas. Such variety indicates how many systems may benefit from ambiguity. Yet it is not simply their ambiguities that distinguish our examples, but the net effect of these ambiguities. They are similar insofar as their use of ambiguity makes them evocative rather than didactic, and mysterious rather than explicit. As such, they embody a style of interaction that, while relatively new to HCI, is potentially as encompassing as the more traditional style of overt practicality. This style hinges, in part, on the use of ambiguity, and the examples illustrate several of its features that are key to its understanding.\r\nMost importantly, they highlight the fact that ambiguity is a property of the interpretative relationship between people and artefacts. This distinguishes ambiguity from related concepts such as fuzziness or inconsistency: these are attributes of things, whereas ambiguity is an attribute of our interpretation of them. Things themselves are not inherently ambiguous. They may give rise to multiple interpretations depending on their precision, consistency, and accuracy on the one hand, and the identity, motivations, and expectations of an interpreter on the other.\r\nThis interpretative relationship is the source of ambiguity\'s appeal: by thwarting easy interpretation, ambiguous situations require people to participate in making meaning. This can involve the integration of previously disconnected discourses, the projection of meaning onto an unspecified situation, or the resolution of an ethical dilemma. In each case, the artefact or situation sets the scene for meaningmaking, but doesn\'t prescribe the result. Instead, the work\r\nRemind yourself that although you must fulfil routine obligations, you also need time to enjoy more romantic affairs. If you\'re too overwhelmed by duty, boredom sets in. The last thing you want is to make someone think it\'s their fault. No one\'s to blame. So make space for love; it won\'t work in a vacuum.\r\nFigure 4: Home Health Monitor\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\n235\r\n\r\nPaper: Designing Design\r\nof making an ambiguous situation comprehensible belongs to the person, and this can be both inherently pleasurable and lead to a deep conceptual appropriation of the artefact.\r\nTYPES OF AMBIGUITY Despite the fact that ambiguity is a property of the an interpretative relationship, the likelihood of an ambiguous interpretation can be affected either by attributes of artefacts or by people\'s attitudes alone. For example, interfaces that are imprecise or contradictory are more likely to lead to multiple interpretations than ones that are clear and consistent; people who expect clarity and consistency are more likely to perceive ambiguity than those who do not. In this paper, we focus on the first half of this interpretative relationship to consider how products and systems can be designed to elicit different kinds of ambiguity. In particular, we distinguish three principal kinds of ambiguity: ambiguity of information, of context, and of relationship.\r\nAmbiguity of Information Let\'s start by looking at an old master: Leonardo da Vinci\'s Mona Lisa (c. 1503-07). This is a straightforward figurative painting. Why is it so famous? As Charles Nicolls wrote:\r\nWe don\'t know precisely when it was painted, we don\'t know for certain who she is, and as we stare at her puzzling features for the umpteenth time we are inclined to ask ourselves: `what is it about her?\' [15]\r\nAll this ambiguity is centred on her smile. In Leonardo\'s notes on painting, he says that light and shade should blend \'without lines or borders, in the the manner of smoke\'. [13] This technique is called sfumato, and it accounts for the mystery of Mona Lisa\'s smile. By reducing the definition (or focus) around her lips, Leonardo makes her whole expression indeterminate, and thus a \'terrain for infinite variations\' [17]. With insufficient information to go on, the viewer has to bring that smile into focus in their mind.\r\nNow consider an equally famous, modernist painting. Picasso\'s Guernica (1936) seems to work in the opposite way, by increasing the definition. The painting is full of strong \'lines and borders\', rather like the figures in a cartoon strip. Yet this heightening of contrasts also results in loss of information, which produces a different kind of ambiguity. Are we to take these figures as portraits of unique individuals and animals, or as representations of generic types - that is to say, of ideas? And if each represents an idea, who\'s to say exactly which idea? The more one simplifies an image, the more iconic it becomes, and the more open to interpretation. As Read [16] points out, \'Does the bull represent the concept of violence, or the dictator Franco?\' Again, the viewer has to decide. In order to make the image coherent, the viewer has to find a conceptual focus, as it were, which harmonises all the elements.\r\nIn both these examples, ambiguity arises in the way that information is presented. Now consider the more complex example of an interactive system:\r\n\r\nCHI 2003: NEW HORIZONS\r\nBystander is a prototype mixed reality game designed by one of the authors in collaboration with Blast Theory, a London performance arts group. In the game, two players, one online and the other equipped with mobile technologies, follow somebody moving through the city. Both have access to limited and different kinds of information. In particular, the mobile player\'s location is tracked using GPS data, which is of low spatial and temporal resolution and also prone to errors. Thus the issue is not `What does this display mean?\' but `Do I trust it?\' ­ that is, how does the display correspond with reality?\r\nThe traditional response to ambiguity of information in interactive systems like Bystander is to improve the technology, use statistical methods to set certainty thresholds, or ignore it and hope for the best. Bystander, in contrast, passes the ambiguity directly to players in the form of fuzzy avatars that hint at locations without specifying them. Rather than seeing uncertain GPS information (in this instance) as a flaw, Bystander treats this ambiguous information as a challenge to users, forcing them to join their knowledge of people and cities to the clues offered by the system in order to play the game.\r\nAmbiguity of Context Ambiguity sometimes arises not because things are themselves unclear, but because they may be understood in different contexts, each suggesting different meanings.\r\nOne of the most notorious examples of this is Duchamp\'s Fountain, rejected from a 1917 exhibition (despite the organiser\'s guarantee to show two pieces for the fee of $6) because it was a urinal turned on its side [11]. The Fountain is deeply controversial because it lends itself to several interpretations simultaneously. On the one hand, it is art: the work of one of the 20th century\'s most celebrated artists, sold recently for more than one million dollars [3], and shown in internationally respected museums. On the other hand, it is a just a commodity: a mass manufactured `ready made,\' not created by Duchamp at all, and, to add insult to injury, a toilet.\r\nTo view the Fountain ­ or just to think about it ­ is to enter into this deeply ambiguous situation. Seen as a sculpture, the Fountain\'s graceful lines and intimate enclosure can be aesthetically pleasing. But it is, almost insistently, a urinal. Not only can it be perceived in different ways, but for many people these interpretations are incompatible. Attempts to resolve this tension can be absurd or violent, as when in 1993 a painter first urinated in the Fountain and then hit it several times with a hammer [3]. But this ambiguity and the tensions it evokes are the point of the piece: the source of its power and the conceptual pleasure it has to offer.\r\nIt is not unusual to find artworks designed to be ambiguous. It is more difficult, in contrast, to find examples of commercial products that are ambiguous in terms of their preferred context of interpretation. Product designers work to eliminate ambiguity: their main effort goes into balancing clarity of use (making it intuitive) with richness of semiotic suggestion (making you like what it\r\n\r\n236\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\nFt. Lauderdale, Florida, USA · April 5-10, 2003\r\n\r\nPaper: Designing Design\r\n\r\nstands for). Both aspects of the design attempt to control the user\'s interpretation of the product ­ that is, to reduce ambiguity.\r\nHowever, now that technology is no longer used solely by specialists, with specialist requirements, its users are becoming ever more varied and its uses ever more flexible. Despite the best efforts of product designers, products and services are increasingly treated as if they were open to interpretation. Users will even go against the (semiotic) grain in order to reinterpret a product. Sometimes these reinterpretations will go beyond new applications of an understood product to redefine the very purpose of the thing itself, creating a contextual ambiguity around it.\r\nFor example, the abundance of different ring tones on mobile phones is used by advertisers as an incentive to the youth market. But some mothers have now started playing with ring tones - not to be cool, but to soothe their babies. The mother sets the phone ringing and hands it to the wailing infant. Note that this does not simply involve an unexpected use of the phone to communicate. Instead, much as Duchamp transmuted a base urinal into a celebrated piece of art, so the phone has been transformed into a new kind of baby rattle. This reveals the ability to interpret mobile phones in terms of discourses alien to those of their designers ­ a possibility that designers can recognise and encourage.\r\nBeyond noting and encouraging novel reconceptualisations of existing technologies, however, designers can deliberately set out to create products that implicate several interpretations at once. When successful, this mingling of discourses disrupts easy interpretation of the design, and obliges users to work out ways to make sense of the new situation.\r\nAmbiguity of Relationship As an example of a third type of ambiguity, consider Van Lieshout\'s Bais-ô-Drôme [1]. This is a `love caravan\' consisting of two molded polyester enclosures that are fitted together like an extended trailer. The nondescript and even foreboding exterior hides an interior that might be described as `functionally decadent.\' Liquor bottles are hung on the walls for easy access from a large, cushioned settee, while in the background a sheepskin-covered platform seems simultaneously clinical and sleazy. The whole is a well-constructed and integrated design that manages to leave viewers admiring but uncomfortable.\r\nThere is nothing particularly unclear about the presentation of this piece. In addition, though it extends and merges known product genres in interesting ways, these seem to coexist without tension (though the Duchampian move of claiming a living space as art may trouble some viewers). The ambiguity, instead, arises from the viewer\'s personal relationship with the piece. It is admirably well-crafted ­ but would you want to inhabit it? Under what circumstances? And should so much effort and care be devoted to such a strange mixture of utility and debauchery?\r\nGaver and Martin [10] developed design proposals intended to produce a similar sort of self-examination. The Prayer\r\n\r\nDevice, for example, transmits users\' voices straight up to the skies, allowing people to send their thoughts or supplications to whomever or whatever they think might listen. The Telegotchi is an electronic pet with no buttons, relying on psionic powers for influence. Both these designs work within understood contexts ­ of spirituality on the one hand, and telepathy on the other ­ and invite users to share the experience of believers.\r\nDesigns like these do not simply engender ambivalence, or contradictory emotion. They push us to imagine how we might personally use such products, and what our lives would be like in consequence. As a result of this speculation, we form intellectual, aesthetic, emotional, and moral judgements that can become available for selfreflection. The result of this process can be experiences that are uniquely personal: delightful, disturbing, or both.\r\nIn summary, the three kinds of ambiguity raise different sorts of problem and ask for different sorts of interpretation. Ambiguity of information asks us to project our expectations into an interpretation of incomplete information. Ambiguity of context requires an integration of seemingly incompatible frames of reference. Ambiguity of relationship, finally, evokes a projection of our subjective experiences and attitudes onto new situations.\r\nTACTICS FOR USING AMBIGUITY We chose the examples in the section above both to illustrate how ambiguity is used in the arts and design, and because they are relatively clear illustrations of the three primary loci of ambiguity. In this section, we discuss each kind of ambiguity in more detail, describing specific heuristics for achieving them with reference to our original design examples as well as new ones. Note that our intention here is not to present an exhaustive analysis (indeed we question whether such an analysis is feasible, or even desirable). Instead, we articulate these tactics to help designers recognise, understand and use ambiguity.\r\nEnhancing Ambiguity of Information A number of tactics may be used to enhance ambiguity of information. These focus on creating or reflecting uncertainties about information that are in some way significant. The purpose may be merely to make the system seem mysterious and thus attractive, but more importantly it can also compel people to join in the work of making sense of a system and its context.\r\nUse imprecise representations to emphasise uncertainty.\r\nPerhaps the most prevalent way to introduce ambiguity of information is to display information that is physically or conceptually blurred. For instance, Desert Rain exploits ambiguity of information through the use of the rain curtain to create blurred and shifting images of the virtual world. This treatment is similar to Dunne\'s use of a translucent plastic brick and pillow to obscure the graphics on an LCD display. In both cases, a kind of digital sfumato is achieved by blurring the usual precision of electronic displays.\r\nThe use of deliberate imprecision can extend to tangible and textual displays as well. For instance, Jeremijenko\'s\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\n237\r\n\r\nPaper: Designing Design\r\nLiveWire [18] used a spinning cable to indicate ethernet traffic, while Ishii [5] used pinwheels to indicate network load. The Home Health Monitor appropriates the tendency of horoscopes to use diectic wordings that make vague statements seem definite (e.g. \"work to maintain the creative areas that are personally rewarding and cut your losses elsewhere\"). The Sloganbenches used short, decontextualised phrases to create a similar air of enigma (e.g. \"I used to be restless because of negative thoughts\").\r\nImprecise displays such as these are often described as `ambient\', but they are ambiguous as well. This ambiguity, we believe, is crucial for understanding their appeal: they may be perceptually undemanding, but they require users to fill in the gaps in information that is purposefully imprecise. When successful, such interfaces are not only aesthetically attractive, but conceptually appealing as well.\r\nOver-interpret data to encourage speculation.\r\nThe converse of using blurred representations of information is to over-interpret them (in much the same way that Guernica\'s heightened definition contrasts with the indistinct features of the Mona Lisa). For instance, the Home Health Monitor uses over-interpretation in making statements about the emotional state of the home based on the input from physical sensors. The apparent overconfidence of the system raises questions about the degree to which such interpretations might be justified, seducing users into considering the well-being of their home through their scepticism about the truth of the system\'s suggestions.\r\nOver-interpretations should not be outright nonsense, however. An earlier proposal for a Tweet-to-Text system using voice recognition to give pets the chance to speak [2] is questionable in this regard: it is difficult to suspend disbelief and entertain the notion that the results might be sensible. The design equivalent of gross exaggeration (e.g. \"I\'ve been working on this paper for a million years\"), over-interpretation is best used to draw attention to possible truths rather than simple untruths.\r\nExpose inconsistencies to create a space of interpretation.\r\nInconsistent information from interfaces can also encourage interpretative engagement. For example, the Imagebank used in the Projected Realities system sometimes showed multiple, inconsistent images (e.g. a quiet family scene next to a protest march) to reflect inconsistent slogans appearing on the Sloganbenches. This had the effect of opening a space of possible interpretations ­ the juxtaposed images could be read as indicating the range of Bijlmer realities, or as a mutual rebuke, or as a narrative. However it was interpreted, the point is that it was interpreted, that the juxtaposition of incompatible elements required viewers to build their own meanings from the display.\r\nExposing inconsistency between sources of information (e.g. external sensors) can also be a powerful alternative to trying to resolve or hide it. For instance, just as the uncertainties of GPS tracking in Bystander are revealed to participants, so are inconsistencies revealed between GPS and spoken information. By crafting the inherent\r\n\r\nCHI 2003: NEW HORIZONS\r\nlimitations of the technology into the user experience, the designer can open a space of possibilities that participants must navigate, thus heightening narrative intrigue.\r\nCast doubt on sources to provoke independent assessment.\r\nOver-interpretation and inconsistency are special cases of increasing ambiguity by casting doubt on sources of information. For instance, not only are the Home Health `horoscopes\' imprecise, but they are produced by an unseen mapping from a pattern of sensor readings which have, in the first place, a questionable relationship to the statements being made. The result is to force users to decide for themselves the credence to put on the predictions, either by tracing back the chain of cause and effect in the system or more simply by gauging whether the statements match their experiences.\r\nSimilarly, because the slogans displayed by the Sloganbenches were not contextualised it was difficult on first viewing to recognise that they were produced by older people (this information spread by word of mouth as the system was used). Instead, they appeared simply as statements to be believed or disbelieved. In this they are similar to the artist Jenny Holzer\'s Truisms (1977-9), electronic displays that show a series of bald assertions (e.g. `money creates taste\') that viewers can accept or question. The statements shown by the Sloganbenches, however, could be traced back to the older people, and this tension between abstraction and individuality allowed spectators to consider them either simply as statements or as expressions of older people.\r\nCreating Ambiguity of Context Blocking the interpretation of a product or system in terms of an established discourse creates ambiguity of context. This is useful in spurring people to approach a particular system with an open mind, and more generally to question the assumptions they have about technological genres.\r\nImplicate incompatible contexts to disrupt preconceptions.\r\nThough none of our introductory design examples implicate incompatible contexts as powerfully as Duchamp\'s Fountain, all use this tactic to some degree in interrupting an easy interpretation. The Sloganbenches are not quite public furniture or public displays, and treating them simply as one or the other is problematic (sitting on them blocks the displays; viewing the displays blocks sitting). The Pillow is simultaneously a radio and an aesthetic object. Desert Rain juxtaposes the established media forms of theatre, interactive installation and computer game, and moreover invites militaristic play despite being an anti-war piece.\r\nIn each case, bringing together disparate contexts creates a tension that must be resolved. To engage with the design, participants must rethink their basic assumptions about given genres, and either privilege one discourse over the others or expand their understandings of the discourses to build bridges among them. In doing so, they are encouraged to confront the system ­ and perhaps even technological genres in general ­ from a fresh perspective.\r\n\r\n238\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\nFt. Lauderdale, Florida, USA · April 5-10, 2003\r\nAdd incongruous functions to breach existing genres.\r\nAdding new functions to designs can sometimes move them out of their `home\' genres. From this perspective, the conceptual origin of the Sloganbenches as public furniture is apparent, but they have become something different through the addition of the scrolling displays. Accommodating this augmentation to the notion of public furniture is possible, but requires a redefinition that is fundamental enough to be uncomfortable.\r\nSimilarly, products can split from their original genres when their functionality is used in radically new contexts, as in our example of mobile phones being used as baby rattles. For instance, The Sailor\'s Return is a design proposal for a man who splits his time between an apartment and a two-masted sailing ship [2]. It suggests that his coffee cup could be linked wirelessly to a neon sign (picturing a coffee cup, of course) outside his apartment window. Returning from the ship and having a cup of coffee would cause the sign to light up, signalling to his friends and neighbours that he is home from the sea. Apart from casting the coffee cup as an activity monitor (a mixing of genres that is common in ubiquitous computing research), this proposal transforms a public sign into a private code, allowing us to rethink the potential of public displays in new ways.\r\nBlock expected functionality to comment on familiar products.\r\nTaking away functionality can also separate designs from their native genres. This is yet another way to understand the effect of being able to obscure the Sloganbench displays by sitting on them. Another example of this tactic is a design proposal called Democratic Advertising [10], in which people could use handheld devices to capture and redistribute advertisements shown on public displays. This can be seen as a political device, allowing people unprecedented influence over the visual appearance of public spaces. Yet according to this proposal, people can only move existing advertisements, they cannot alter them or create their own imagery. This can seem frustrating, but it adds an intriguing contextual ambiguity. The system is not a straightforward tool for advertising, nor is it just a simple utopian proposal for legal graffiti; instead it finds a more delicate balance between the two.\r\nPerhaps the purest example of blocking functionality to achieve ambiguity of context is Sarah Pennington\'s design of a mobile phone cover that has no `call\' or `receive\' buttons. The phone is transmuted into a device that can only signal when somebody is trying to call: the owner can\'t pick up or make calls. Through this simple modification, Pennington disrupts our reading of the phone as a communications device, creating instead a rather plaintive reminder of separation. But the result doesn\'t escape its origin as a phone: it is simultaneously phone and not-phone, and this ambiguity is central to its effect.\r\nProvoking Ambiguity of Relationship Ambiguity of relationship creates the condition for a deeply personal projection of imagination and values onto a design. This can allow products and systems to become\r\n\r\nPaper: Designing Design\r\npsychological mirrors for people, allowing them to try on new identities or to question their values and activities.\r\nOffer unaccustomed roles to encourage imagination.\r\nBy their aesthetics and the functionality they offer, products and systems imply a `narrative of use\' [6] and suggest the sorts of people for whom they are appropriate. Designers traditionally strive to craft the semiotics of their products so that a majority of people will relate or aspire to the identities they imply. Reflecting more idiosyncratic roles and activities, however, can give rise to products that create an ambiguity of relationship, spurring people to question their own values.\r\nDunne\'s Pillow [7] is a seminal example of applying ambiguity of relationship to electronic products. Culling electromagnetic information from sources that might include mobile phone calls or baby monitors, it entices people to assume a voyeuristic role amid the airwaves. Similarly, the Prayer Device and Telegotchi also encourage people to adopt potentially unfamiliar perspectives and activities. Described by Dunne [6] as `value fictions,\' these sorts of design use possible technologies to explore implausible values. They act as props for a drama played in everyday life, allowing people to engage in a radical first-person narrative as a kind of experiment in living.\r\nPoint out things without explaining why.\r\nOffering new roles to people emphasises issues of personal identity. Another form of ambiguity of relationship, however, encourages people to consider the personal significance of things, behaviours, or events in their environment. Much as fine art photography has shifted from capturing images of important scenes to making scenes important by capturing their image, so design can draw attention to overlooked aspects of the environment to encourage reflection on their significance.\r\nFor example, the rationale for tracking certain physical events for the Home Health Monitor is not apparent, but the mere fact of their being tracked may arouse curiosity among participants. The flip side of asking whether open doors and frequently-used hairbrushes really reflect wellbeing is to ask what these things do mean. In a similar way, our design for the History Tablecloth [2] uses load sensors and electroluminescent film printed on fabric to highlight locations of objects that have been left on household surfaces for days or weeks. Based in part on ethnographic observations of how people use household surfaces [4], the cloth encourages people to reflect on the different histories of objects in their environment. But their interpretation is left open: the Tablecloth purposely allows the meaning of its display to remain ambiguous to its users. In doing so, it encourages them to reflect on the meaning of this aspect of their environment, aesthetically, culturally, and ­ especially ­ personally.\r\nIntroduce disturbing side effects to question responsibility.\r\nReflection about the balance of desire and ethics can be provoked by designs that seem immediately appealing but which have disquieting implications. The Pillow works this way in providing an aesthetic experience that only\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\n239\r\n\r\nPaper: Designing Design\r\nslowly reveals itself as depending on eavesdropping: it seduces people into a voyeuristic role that may be uncomfortable. Another example, the Dawn Chorus, is a proposal for an artificially-intelligent feeder that uses operant conditioning principles to teach local birds new songs [10]. This whimsical design may be appealing, but on reflection it raises disturbing issues about the ecological effects of interfering with birds\' natural behaviour, not to mention the ability to broadcast one\'s tastes (what if my neighbour is not a Britney Spears fan?).\r\nDesigns such as these reflect and amplify the difficult choices posed by many current technologies. Mobile phones, for instance, allow us to communicate freely, but at the cost of intruding on others and of losing our solitude. Reactive environments may offer convenience at the cost of privacy. Portable computers interfere with the separation of work and home. Such tradeoffs are endemic to new technologies; proposals such as the Pillow and Dawn Chorus provoke us to reflect on these tradeoffs both in the particular and at the level of moral principles.\r\nCONCLUSION: AMBIGUITY AS A VIRTUE Ambiguity is not a virtue in itself, nor should it be used as an excuse for poor design. Many ambiguous systems are merely confusing, frustrating, or meaningless. Nonetheless, as we hope to have shown in this paper, it can be an important factor in crafting interactive designs that are engaging and thought-provoking. Moreover, it has the added advantage (which we have purposely avoided stressing in this paper) of enabling designers to go beyond the limits of their technologies. From this point of view, ambiguity provides a frame of reference that allows the use of inaccurate sensors, inexact mappings, and low-resolution displays because it encourages users to supplement them with their own interpretations and beliefs.\r\nThe most important benefit of ambiguity, however, is the ability it gives designers to suggest issues and perspectives for consideration without imposing solutions. Ambiguity of information impels people to question for themselves the truth of a situation. Contextual ambiguity can question the discourses surrounding technological genres, allowing people to expand, bridge, or reject them as they see fit. Relational ambiguity, finally, can lead people to consider new beliefs and values, and ultimately their own attitudes. In each of these cases, ambiguity frees users to react to designs with scepticism or belief, appropriating systems into their own lives through their interpretations. In the process of reacting to the system either positively or negatively, however, users engage with issues that the designer suggests. Thus ambiguity is a powerful design tool for raising topics or asking questions, while renouncing the possibility of dictating answers. By virtue of this balance, ambiguity both offers an inspiring resource to designers and shows a deep respect for users.\r\n\r\nCHI 2003: NEW HORIZONS\r\nACKNOWLEDGEMENTS This work was supported by the EPSRC as part of the Equator IRC. We are grateful to Andy Boucher, Sarah Pennington Brendan Walker (the RCA Equator Team); Tony Dunne, Tom Roddin, Anne Schlottmann; and Phoebe Sengers (collaborator on the Home Health Monitor).\r\nREFERENCES 1. Atelier van Lieshout. A manual. Kölnischer Kunstverein\r\nand Museum Boijmans van Beuningen, Cologne, 1997.\r\n2. Boucher, A., Gaver, W., Pennington, S., and Walker, B. Equator workbook one: Ideas, scenarios and proposals for the home. Royal College of Art, 2001.\r\n3. BBC online. Available at: http://news.bbc.co.uk/1/hi/ entertainment/arts/1987109.stm\r\n4. Crabtree, A., Hemmings, T., and Rodden, T. Pattern-based support for interactive design in domestic settings. Proc. DIS2002 (London 2002). ACM Press, pp. 265 ­ 275.\r\n5. Dahley, A., Wisneski, C., and Ishii, H. Water Lamp and Pinwheels: Ambient projection of digital information into architectural space. Proc. CHI\'98 Companion (1998), ACM Press, pp. 269-270\r\n6. Dunne, A. Hertzian tales: Electronic products, aesthetic experience and critical design. London, RCACRD Research Publications, 1999.\r\n7. Dunne, A., and Gaver, W. The Pillow: Artist-designers in the digital age. Proc. of CHI\'97 Companion (Atlanta, 1997), ACM Press.\r\n8. Gaver, W., and Dunne, A. (1999). Projected Realities: Conceptual design for cultural effect. Proc. of CHI\'99 (1999), ACM Press.\r\n9. Gaver, W., and Hooker, B. The Presence Project. London, RCACRD Research Publications, 2001.\r\n10. Gaver, W., and Martin, H. Alternatives: Exploring information appliances through conceptual design proposals. Proc. of CHI\'00 (Den Haag). New York, ACM Press.\r\n11. Godfrey, T. Conceptual Art. London, Phaidon, 1998.\r\n12. Koleva, B., Taylor, I., Benford, S., Fraser, M., Greenhalgh, C., Schndelbach, H., vom Lehn, D., Heath, C., Row-Farr, J. & Adams, M. Orchestrating a Mixed Reality Performance. Proc. CHI\'01, (Seattle, 2001), ACM Press.\r\n13. Murray, P., and Murray, L. The Penguin Dictionary of Art and Artists. London: Penguin Books, 1983.\r\n14. Nickerson, R. & Landauer, T. Human-computer interaction: Background and issues. In Helander, M.G., Landauer, T.K. and Prabhu, P. (eds.), Handbook of HumanComputer Interaction, 2nd edition. Amsterdam, The Netherlands: Elsevier Science.\r\n15. Nicolls, C. The Mona Lisa, London Review of Books, 4 April 2002.\r\n16. Read, H. A Concise History of Painting. London, Thames & Hudson, 1959.\r\n17. Sassoon, D. Mona Lisa: The History of the World\'s Most Famous Painting. London, HarperCollins, 2001\r\n18. Weiser, M. and Brown J.S. Designing calm technology. PowerGrid Journal, v.1.01, July 1996.\r\n\r\n240\r\n\r\nVolume No. 5, Issue No. 1\r\n\r\n',1,'Gaver','Bill Gaver, Jacob Beaver, and Steve Benford',NULL,'https://www.blasttheory.co.uk/bt/documents/ambiguity_CHI_2003.pdf',1,'10.1145/642611.642653','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,NULL,NULL,0,0),(5,'heath-collaboration-and-control-crisis-management-and-multimedia-technology-in-london-underground-line-control-rooms','2019-02-23 20:30:48','2019-09-24 12:00:19','2019-02-23 20:30:02',NULL,1,'published','[]','Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms','Despite technical advances over the past few years in the area of systems support for cooperative work there is still relatively little understanding of the organisation of collaborative activity in real world, technologically supported, work environments. Indeed, it has been suggested that the failure of various technological applications may derive from their relative insensitivity to ordinary work practice and situated conduct. In this paper we discuss the possibility of utilising recent developments within sociology, in particular the naturalistic analysis of organisational conduct and social interaction, as a basis for the design and development of tools and technologies to support collaborative work. Focussing on the Line Control Rooms in London Underground, a complex multimedia environment in transition, we begin to explicate the tacit work practices and procedures whereby personnel systematically communicate information to each other and coordinate a disparate collection of tasks and activities. The design implications of these empirical observations, both for Line Control Room and technologies to support cooperative work, are briefly discussed.','Christian Heath and Paul Luff. 1992. Collaboration and control: Crisis management and multimedia technology in London Underground Line Control Rooms. *Computer Supported Cooperative Work* 1, 69. https://doi.org/10.1007/BF00752451\r\n','Computer Supported Cooperative Work (CSCW) 1: 69-94, 1992.\r\n\r\n69\r\n\r\n9 1992 Kluwer Academic Publishers. Printed in the Netherlands.\r\n\r\nCollaboration and Control\r\nCrisis Management and Multimedia Technology in London Underground Line Control Rooms\r\nCHRISTIAN HEATH & PAUL LUFF Department of Sociology, University of Surrey, Guildford, UK; Rank Xerox, Cambridge EuroPARC, 61 Regent Street, Cambridge, UK\r\n(Received 29 October 1991; in final form 7 May 1992)\r\nAbstract. Despite technical advances over the past few years in the area of systems support for cooperative work there is still relatively little understanding of the organisation of collaborative activity in real world, technologically supported, work environments. Indeed, it has been suggested that the failure of various technological applications may derive from their relative insensitivity to ordinary work practice and situated conduct. In this paper we discuss the possibility of utilising recent developments within sociology, in particular the naturalistic analysis of organisational conduct and social interaction, as a basis for the design and development of tools and technologies to support collaborative work. Focussing on the Line Control Rooms in London Underground, a complex multimedia environment in transition, we begin to explicate the tacit work practices and procedures whereby personnel systematically communicate information to each other and coordinate a disparate collection of tasks and activities. The design implications of these empirical observations, both for Line Control Room and technologies to support cooperative work, are briefly discussed.\r\nKey words. Task Coordination, Communicative Practices, Work Practices, Ethnography, CSCW\r\n1. Introduction\r\nIn recent years there have been significant developments in technologies to support cooperative work between multiple users in organisational environments. These tools range from shared text editors and drawing tools (for example, Olson, Olson, Mack and Wellner 1990; Bly 1988) through to systems which support group meetings and decision making (Winograd and Flores 1986, Cosmos 1988, Lee 1990), and include systems to support physically dispersed personnel (Moran and Anderson 1990). These technological developments incorporate innovations in computer architectures, computer networks, and audio-visual communications, and yet despite this enormous scientific investment, it is often found that the actual applications of the technologies fail (Grudin 1988, Markus and Connolly 1990). In their introduction to a book on computer supported cooperative work (CSCW), Galegher and Kraut (1990) suggest that the relative failure of the systems derive\r\n* The research discussed in this paper is supported in part through a project grant from the ESRC/MRC/SERC Joint Initiative on Cognitive Science and Human Computer Interaction and part by Rank Xerox, Cambridge EnroPARC. The authors have greatly benefitted from discussions with Jens Rasmussen, John Gardner, Bernard Conein, Isaac Joseph, Marina Jirotka and Liam Bannon concerning a number of the issues addressed in this paper. The authors are alone responsible for the contents of the piece.\r\n\r\n70\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nfrom their insensitivity to \'what we know about social interaction in groups and organisations\'. Gategher and Kraut continue by arguing that social scientists may well be able to make an important contribution to the design of complex systems to support cooperative work.\r\nIn this light, we are beginning to witness the emergence of a body of research concerned with the social organisation of human conduct in technologically mediated cooperative work environments. Although some of this work has tended to focus on abstract properties of group behaviour, there are also a number of detailed empirical studies of computer supported cooperative work. For example, Linde (1988) has explored the communicative work that takes place in a helicopter cockpit, Hutchins (1990) has described the collaborative use of charts, range-finders and other artifacts in the navigation of large vessels and Nardi and Miller (1990) have shown the collaborative aspects of working with computer spreadsheets in an office environment. However, despite the important contribution of such studies to our tmderstanding of collaborative work, their implications for the design and development of technology, either for the setting in question, or CSCW in general, appear to be difficult to draw..\r\nIn this brief paper we wish to attempt to bridge the gap between the naturalistic analysis of collaborative work in a real world setting and the design of technology to support CSCW. In common with Suchman and Trigg\'s (1989) study of communication in an airline terminal operations room, we aim to show how a sociological and naturalistic analysis of work practice and organisational conduct can inform the design of tools for CSCW. The paper examines the social organisation of collaborative work and task coordination within a Line Control Room on London Underground; a multimedia environment par excellence. It explores the ways in which the participants surreptitiously monitor each other\'s conduct and systematically distribute information concerning changes to, and the current operation of, the service. Drawing on these observations, we discuss their implications for the development of distributed, \'intelligent\' systems to support current work practices, as well as consider more general implications for tools to support cooperative work and the design process.\r\n\r\n2. Methodological considerations\r\nThe investigation of cooperative work supported by complex technologies demands a rather different conceptual and methodological orientation than is commonly found within research on human-computer interaction. The analysis is no longer primarily concerned with the individual and the system, but rather the interaction between different personnel as they coordinate a range of tasks and utilise various tools. The ability to coordinate activities, and the process of interpretation and perception it entails, inevitably relies upon a social organisation; a body of skills and practices which allows different personnel to recognise what\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n71\r\n\r\neach other is doing and thereby produce appropriate conduct. Following recent developments in the psychology of work, we might conceive of this organisation as a form of \'distributed cognition\'; a process in which various individuals develop a interrelated orientation towards a collection of tasks and activities (cf. Hutchins 1989, Olson 1990, Olson and Olson 1991). And yet, even this relatively radical reconceptualisation of the relationship between the individual, his or her activity and the system, does not quite capture the situated and socially organised character of cooperative work. It is not simply that tasks and activities occur within a particular cultural framework and social context, but rather that collaboration necessitates a publicly available set of practices and reasoning, which are developed and warranted within a particular setting, and which systematically inform the work and interaction of various personnel.\r\nWhether one subscribes to a theory of distributed cognition or a more sociological conception of cooperative work, it is clear that we need to move away from laboratory studies of cognition, \"which have deliberately stripped away the supporting context of the everyday world, in an effort to study \'pure\' internal processes\" (Olson 1990), and begin to explore task coordination and computer support in real world, everyday work settings. Fortunately sociology, with its history of field work and ethnography, coupled with the growing corpus of research concerned with contextual analysis of interactional organisation provide the methodological resources through which to begin to explore the situated and social character of collaborative work. Utilising audio and video recordings of \'naturally occurring\' work and collaboration, augmented by field observation and interviews, the process of coordinating multiple activities whilst utilising various tools and technologies, can be subject to detailed and systematic analysis. Drawing on this naturalistic framework, it is hoped that we will not only begin to generate findings concerning the socio-interactional organisation of collaborative work, but, in the long term, also provide a distinctive approach to user-centered design. 1\r\n\r\n3. The technology in the control room\r\nWhilst drawing on materials from a number of Line Control Rooms on London Underground, we focus in particular on the Bakerloo Line. Its Line Control Room is currently undergoing extensive modemisation. For example, at the time of data collection, signalling was in the process of being computerised so that it could be monitored from the Line Control Room at Baker Street. The Bakerloo Line Control Room houses the Line Controller, who coordinates the day to day running of the railway and the Divisional Information Assistant (DIA) whose responsibilities include providing information to passengers through a public address (PA) system and communicating with station managers. It is not unusual however to find a trainee DIA or Controller in the Control Room and a relief\r\n\r\n72\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nController when problems and crises emerge. Figure 1 shows the general layout of the Control Room.\r\n\r\nN· Line INagram\r\nFig. 1. The Bakerloo Line Control Room.\r\nThe Controller and DIA sit together at a semicircular console which faces a\r\ntiled, real time, fixed line diagram which runs nearly the entire length of the room\r\nand shows traffic movement along the Bakerloo Line (from the Elephant and Castle to Queens Park). The console includes touch screen telephones, a radio system for contact with drivers, the PA control keys, and close circuit television (CCTV) monitors and controls for viewing platforms (see Fig. 2). On occasions a trainee DIA (tDIA) or a second Controller (Cii) will sit at this console. In the near future, two or three signal assistants will sit at a similar console next to the Controller and DIA (see Fig. 1) and personnel will also have access to monitors showing real time graphic displays of the line. The Controller and DIA therefore use a range of tools not unlike the technologies being developed in CSCW, including: audio and video channels of communication, shared information displays, and various keypads and monitors.\r\nThe Underground service is coordinated through a paper timetable which specifies: the number, running time and route of trains, crew allocation and shift arrangements, information concerning staff travel facilities, stock transfers, vehicle storage and maintenance etc. Each underground line has a particular timetable, though in some cases the timing of trains will be closely tied to the service on a related line. The timetable is not simply an abstract description of the operation of the service, but is used by various personnel including the Controller, DIA, Signalmen, Duty Crew Managers, to coordinate traffic flow and passenger movement. Both Controller and DIA use the timetable, i~ conjunction with their understanding of the current operation of the service, to determine\r\n\r\nCOLLABORATION ANDCONTROL\r\n\r\n73\r\n\r\nthe adequacy of the service and if necessary initiate remedial action. Indeed, a significant part of the responsibility of the Controller is to serve as a \'guardian of the timetable\' and even if he is unable to shape the service according to its specific details, he should, as far as possible, attempt to achieve its underlying principle: a regular service of trains with relatively brief intervening gaps.\r\n\r\nToMuscehnositvne~~\r\n\r\nTitSleeI~tion\r\n\r\nFig, 2. Line Controller\'s and DIA\'s Desk.\r\nThe timetable is not only a resource for identifying difficulties within the operation of the service but also for their management. For example, the Controller will make small adjustments to the running times of various trains to cure gaps which are emerging between a number of trains during the operation of the service. More severe problems such as absentees, vehicle breakdowns or the discovery of \'suspect packages\' on trains or platforms, which can lead to severe disruption of the service, are often successfully managed by reforming the service. These adjustments are marked in felt pen on the relevant cellophane coated pages of the timetable both by the Controller and the DIA, and communicated to Operators (Drivers), Signalmen, Duty Crew Managers and others when necessary. It is critical that the DIA and others receive information concerning changes to the timetable, otherwise they will not only misunderstand the current operation of the service, but take the wrong courses of action.\r\nDespite important differences in the formal specification of the responsibilities of the Controller and DIA, the various tasks they undertake rely upon extremely close collaboration. Indeed, Control Room personnel have developed a subtle and complex body of practices for monitoring each other\'s conduct and coordinating a varied collection of tasks and activities. These practices appear to stand independently of particular personnel, and it is not unusual to witness individuals who have no previous experience working together, informally, implicitly, yet systematically coordinating their conduct. One element of this extraordinary interweaving of sequential and simultaneous responsibilities and tasks is an emergent and flexible division of labour which allows the personnel to lend\r\n\r\n74\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nsupport to the accomplishment of each others\' tasks and activities and thereby manage difficulties and crises.\r\n\r\n4. Surreptitious monitoring and interrelating tasks\r\nIt is relatively unusual for the Controller or the DIA to tell each other what tasks they are undertaking or explicitly to provide information concerning: the changes they have made to the service, the instructions they have provided to other personnel, or the announcements they have made to passengers. Indeed, given the demands on the Controller(s) and the DIA, especially when dealing with emergencies or difficulties, it would be impossible to abandon the tasks in which they were engaged explicitly to provide information to each other as to what they were doing and why. And yet it is essential that both Controller and DIA remain sensitive to each other\'s conduct, not only to allow them to coordinate specific tasks and activities, but also enable them to gather the appropriate information to grasp the details of the current operation of the service.\r\nConsider for example the work of the DIA. When problems emerge within the \'normal\' operation of the service, the DIA presents information to passengers and, if necessary, coordinates their travel arrangements with the schedule of particular trains. For example, on occasions a Controller will have to turn a train around before it has reached its anticipated destination. The DIA needs to provide information to passengers so that they leave the train at a particular station to enable the train to be reversed or stabled. More generally, unlike others forms of transport, rapid urban transport systems do not provide a timetable to the public. Instead, passengers organise their travel arrangements on the assumption that trains will pass through particular stations every few minutes. When such expectations are broken, or travellers are unable to change at certain stations, or have to leave a train because the line is blocked, then the DIA needs to provide information and advice. The nature of such announcements varies with the circumstances of, and reasons for their production. However, these public announcements do reveal recurrent characteristics. Consider the following instance.\r\nFragment 1 (Abbreviated and simplified)\r\nDIA: Hello and good afternoon Ladies an Gentlemen. Bakerloo Line Information.\r\nDIA: We have a slight gap in our Southbound Bakerloo Line service towards the Elephant an Castle. Your next south bound train, should depart from this station in about another three minutes.\r\nDIA: The next south bound train, should depart from this station in about another three minutes.\r\n... a related announcement follows a couple of minutes later...\r\nEven though the announcement is addressed to the general public, it achieves its performative force, its relevance, by virtue of its design for a specific category of passengers. In the case at hand, the information is only delivered to passengers\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n75\r\n\r\nwho are waiting on a particular station and who will suffer a slight delay before the next train leaves the station. The announcement \'fits\' with their potential experience of the service at this moment in time, and gains its relevance by virtue of that experience. To produce timely and relevant information for passengers, the DIA systematically monitors the service and the actions of his colleagues, and transforms these bits and pieces into carefully tailored announcements for particular categories of passengers who are using the service at some moment in time.\r\nReturning to fragment 1, we enter the scene a little earlier as the Controller calls a driver.\r\nFragment 1 Transcript 2 (Abbreviated and simplified)\r\n... Controller (C) calls Driver (D). . .\r\nC: Control to the train at Chafing Cross South Bound, do you receive?\r\n9 C switches monitor to the pla(orm. . .\r\nC: Control to the train at Chafing Cross South Bound, do you receive?\r\nD: Two Four O Chafing Cross South Bound\r\nC: Yeah, Two Four O. We\'ve got a little bit of an interval behind you. Could you take a couple of minutes in the platform for me please?\r\nD: (( )) Over C: Thank you very much Two Four O.\r\n(5.2)\r\nDIA: Hello and good afternoon Ladies an Gentlemen. Bakerloo Line Information...\r\n\r\nThe announcement emerges in the light of the DIA overhearing the Controller\'s conversation with the driver and assessing its implications for the expectations and experience of travellers using the service. He transforms the Controller\'s request into a relevant announcement by determining who the decision will effect and its consequences. In this case, this is particularly the passengers at Chafing Cross whose train is delayed as a consequence of a problem emerging on the Southbound service. The DIA, a little later, produces a second announcement (not included in the above transcript) to warn passengers who have more recently arrived on the platform that their train is being delayed.\r\nThe DIA does not wait until the completion of the Controller\'s call before preparing to take action. Indeed, in many cases, it is critical that announcements are delivered to passengers as Controllers are making adjustments to the service. In the case at hand, as the call is initiated, we find the DIA progressively monitoring its production and assessing the implications of the Controller\'s request for his own conduct. The technology, and in particular the fixed line diagram, provides resources through which the DIA can make sense of the Controller\'s actions and draw the necessary inferences. At the onset of the call he scans the fixed line diagram to search for an explanation, or provide an account for, why\r\n\r\n76\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nthe Controller is contacting a driver and potentially intervening in the running of the service. By the Controller\'s second attempt to contact the driver, the DIA is moving into a position at the console where he will be able to reach the operating panel for the Public Address system and if necessary make an announcement. On the word \"couple\", at which point he can infer the potential delay that passengers might incur, he grabs the microphone and headset in preparation for the announcement. In consequence, even before the Controller\'s call to the driver is brought to completion, the DIA has set the Public Address system to speak to the passengers on a particular platform and is ready to deliver the announcement.\r\nThe fixed line diagram and the station monitors, provide an invaluable resource for the DIA in producing an account for his colleagues\' interventions in the running of the service. In particular, the common availability of various sources of information in the Line Control Room, allows the DIA to assume, that the current problems in the operation of the service noticed by the Controller are\r\nsimilarly available to the DIA if he scans the various displays. The DIA\'s looking\r\nis motivated and driven by virtue of the Controller\'s attempt to call a driver, and the DIA scans the fixed line diagram in order to provide an account for the upcoming intervention. Moreover, the DIA, is not only able to overhear the Controller, and assume that they have mutual access to the same information displays, but is also able to discern, through peripherally monitoring the actions of his colleague, where the Controller might be looking and what he might have seen. The various information displays, and their use by particular individuals, is publicly visible and can be used as a resource in determining courses of action and for the mutual coordination of conduct.\r\nDespite the necessity to monitor closely the conduct of the Controller, the DIA maintains a certain \'social distance\' providing his colleague with what Hughes (1956) characterises as the \'elbow room with which to fulfil his particular responsibilities\'. More precisely, as the DIA begins to track the call to the driver and prepare to make an announcement, he neither looks at the Controller nor watches the activity of his colleague. Moreover, as he changes positions and moves closer to the Controller, he avoids making his own activity visible or noticeable to his colleague; rather the actions appear to be accomplished independently of the call to the driver, as if the DIA is engaged in some unrelated business. Through his bodily comportment and the ways in which he warily accomplishes his actions, the DIA preserves a careful balance of involvement, overhearing the Controller and monitoring his colleague\'s actions on the periphery of the visual field, whilst avoiding overt attention to the Controller\'s conduct.\r\nCertain phrases or even single words addressed by the Controller to a driver or signalman on the telephone are often enough for the DIA to draw particular inferences and undertake relevant action. For example in fragment 1, the request to \"take a couple of minutes\" allows the DIA to infer that the Controller is attempting to reduce an interval in the Southbound service, a problem that he is unlikely to have noticed until the Controller called the driver. The DIA overhears the call,\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n77\r\n\r\ndevelops an account for intervention and assesses its implications for his own conduct. In the following instance, the DIA, who is apparently engrossed in updating his own timetable, suddenly grabs the phone and calls the Station Manager at Piccadilly Circus on hearing the word \"reverse\".\r\n\r\nFragment 2 (Abbreviated and simplified) C: Controller to South Bound Two Three Three, do you receive D: Two Three Three receiving over. C: Yeah, Two Three Three (.) I\'d like you to reverse at Piccadilly, and you\'ll also be reformed there. I\'ll come back to you when you get to Piccadilly. Over?\r\n9 the call continues. Seconds later the DIA reaches the station manager at Piccadilly Circus... DIA: Two Three Three is going to reverse with with yon, South to North.\r\n9 roughly 3 minutes later following a discussion with the Station Manager. DIA: Good morning Ladies and Gentlemen, (.) Bakerloo Line Information, (1.0) this train is for\r\nPiccadilly Circus only. (1.2) This train for Piccadilly Circus only.\r\n\r\nEven before the Controller has finished speaking to the Driver, the DIA has called the Station Manager at Piccadilly and warned him that the 233 is to be \'detrained\'. On completing the call, the DIA then produces a series of public announcements on each southbound platform before Piccadilly. As the 233 arrives he warns the passengers that \'this train is for Piccadilly only\'. By surreptitiously monitoring the conduct of the Controller, whilst engaged in unrelated and independent action, the DIA is able to discriminate the local environment of activity and assess the implications of certain activities for his own conduct. In the case at hand, by overhearing the word \"reverse\" and gathering the relevant details, the DIA coordinates the action of station staff and passengers with the moment by moment changes made by the Controller to the timetabled service.\r\n\r\nIt is not simply that DIAs happen to remain attentive to the local environment of activity and are able to draw the necessary inferences from the actions of their colleagues. Rather, personnel within the Control Room organise their conduct so that whilst engaged in one activity, they simultaneously monitor the conduct of\r\n\r\n78\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nothers. This double-edged element of performing tasks, is an essential feature of collaborative work within the Line Control Rooms, demanding that participants design their activities so that whilst undertaking one task they remain sensitive to the relatively independent actions of their colleague(s). Producing an activity whilst simultaneously participating in the activities of another, has implications for the ways in which personnel utilise the various tools and technologies within the Line Control Room. So, for example, the DIA may switch his CCTV monitor to a particular platform to enable him to read a number from the front of a train to tell the Controller, even though he is engaged in delivering a public announcement and happened to overhear that problems concerning the the identity of particular trains are emerging. Or, as another example, it is not unusual to find the Controller or DIA switching the telephone handset to the other ear, to enable them to overhear a conversation concerning a new problem emerging in the service. DIAs are provided with headsets with which to make announcements, but it is relatively unusual to see them used \'properly\'. Rather, DIAs hold one side of the headset to one ear, allowing them simultaneously to monitor the actions of their colleagues, while delivering announcements to passengers. Almost all tasks within the Line Control Room are produced as the DIA or Controller simultaneously participates, in a variety of different ways, in the concurrent activities of his colleague(s). The various tools and technologies which are provided to support these tasks, are shaped, corrupted, even abandoned, to enable Control Room personnel to engage simultaneously in activities whilst monitoring the conduct of their colleagues.\r\nIt is widely recognised amongst Line Management on London Underground that many of the skills used by Controllers and DIAs cannot be formally taught, and that working as an apprentice within the Control Room itself, is an essential part of training. The Control Room serves as a testbed for new recruits, with a large percentage of trainees failing to make the grade. Whilst a whole array of factors undoubtedly contribute to the relative difficulty that new recruits find in working in the Control Rooms, it is apparent that learning to perform complex individual tasks, whilst simultaneously participating in, and overseeing, the activities of colleagues, proves particularly difficult for the uninitiated. Indeed, it is interesting to observe how the more senior Controllers and DIAs who act as trainers, place great emphasis on the importance of not simply working with colleagues as a team, but coordinating the production of tasks with colleagues both within and outside the Control Room (cf. BBC1 1991). Trainees, whether DIA or Controller do, of course, have to learn a complex configuration of formal rules, procedures and practices before entering the Control Room, but these are widely regarded as the \'tip of the iceberg\'; it is the tacit, unexplicated body of indigenous skills and practices which are part and parcel of working as a Controller or DIA. In the early days of an apprenticeship, the trainer will repeatedly try and encourage a trainee to monitor continually the surrounding domain of action. Consider the following example where the the trainee is asked by the DIA\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n79\r\n\r\nwhether he overheard an incoming call to the Controller concerning a fire on the track.\r\n\r\nFragment 3 (Abbreviated and simplified)\r\n... Driver (D) calls the Controller (C). .. C: Two Three Three pass your message D: (There\'s) smouldering on the track on the Southbound\r\n9 As C elicits the details, DIA turns to the Trainee DIA (tD1A) and asks... DIA: Do you hear that? Do you get that? tDIA: What was it?\r\n..... they go on to discuss the incident the way its managed by the Controller and how the D1A might assist....\r\n\r\n5. Rendering activities visible\r\nWhilst relying on each other mutually to monitor their conduct and to draw the \'relevant\' inferences, even when they are engaged in a distinct activity, the DIA and Controller employ various devices to keep each other informed of changes to the operation of the service. Activities such as telephone conversations with personnel outside the room, tracking a particular train with the CCTV, or discussions with Line Management concerning the state of the service, are, at least in part, publicly visible within the local milieu, and ordinarily the bits and pieces available can be used to draw the relevant inferences. Other sorts of activities, such as reading the timetable or entering the details of incidents on the various logs are less visible, the details of the activity may not be available to a co-participant who is even seated to one side. Perhaps the most critical activity within the Line Control Room which is not necessarily available to the DIA or relief Controller, is rewriting the timetable; a process known as \'reforming\' the service. Almost all problems which arise in the operation of the service necessitate \'reformations\', where the Controller, actually within the developing course of an event, reschedules particular trains, their crews, and even their destination, so as to maintain, for the practical purposes at hand, a relatively even distribution of traffic along the line. It is essential that both colleagues within the Line Control Room, and personnel outside such as Duty Crew Managers, drivers and even Station Managers, are aware of these changes. Otherwise, these staff will not only fail to enact a range of necessary tasks, but will misunderstand the state of the service and make the wrong decisions. Reforming the service however, is an extremely complex task, which is often undertaken during emergencies, and it is not unusual for the Controller to have little time explicitly to keep his relevant colleagues informed.\r\nOne solution to this potential difficulty is to render features of their individual reasoning and actions \'publicly\' visible by talking though the reformations whilst\r\n\r\n80\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nthey are being accomplished. The Controllers talk \'out loud\', but this talk is not specifically directed towards a colleague within the Control Room. Rather, by continuing to look at, and sketch changes on the timetable, whilst producing talk which is often addressed to oneself, the Controller precludes establishing a \'recipient\' and the interactional consequences it would entail. Talking through the timetable, whilst rendering \'private\' activities \'publicly\' visible, avoids establishing mutual engagement with colleagues which would undermine the ongoing accomplishment of the task in question. Consider the following fragment in which the Controller finishes one reformation and then begins another.\r\n\r\nFragment 4 (Abbreviated and simplified)\r\n... C reads his timetable... C: It\'s ten seventeen to ( ) hhhhhhh\r\n(4.3) C: Right (.) that\'s that one done. C: hhh hhh (.) hhh C: Two O Six (.) Forty Six\r\n(0.7)\r\nC: Two Two Five 9.. the D1A begins to tap on his chair and he and the trainee begin a separate conversation. As they begin to talk C ceases talking out loud...\r\n\r\nWhilst looking at the timetable, the Controller announces the completion of one reformation and begins another. The Controller talks numbers, train numbers, and lists the various changes that he could make to the 206 to deal with the problems he is facing, namely reform the train to 246 or to 225. As the Controller mentions the second possibility, the DIA begins to tap the side of his chair, and a moment or so later, discusses the current problems and their possible solutions with a trainee DIA who is sitting by the DIA\'s side. As soon as the DIA begins to tap his chair and display, perhaps, that he is no longer attentive to his colleague\'s actions, the Controller, whilst continuing to sketch possible changes on the timetable, ceases to talk out loud. Despite therefore, the Controller\'s apparent sole commitment to dealing with specific changes to the service, he is sensitive to the conduct of his colleague, designing the activity so that, at least initially, it is available to the DIA and then transforming the way the task is being accomplished so that it ceases to be \'publicly\' accessible.\r\nWhilst \'self talk\' may primarily be concerned with providing co-present colleagues with the necessary details of changes made by the Controller to the running order of the service, it is interesting to observe that a great deal more information is made available in this way than simply the actual reformations. As in fragment 4, talking to oneself whilst engaged in a potentially \'private\' activity,\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n81\r\n\r\nseems designed to accomplish more than simply providing the facts of the matter. Rather, the Controller renders visible to his colleagues the course of reasoning involved in making particular changes. The natural history of a decision, the Controller\'s reasoning through various alternative courses of action, are rendered visible within the local milieu, and provides colleagues with the resources through which they can assess the grounds for and consequences of \'this particular decision\' in the light of possible alternatives. While the Controller is talking out loud, it is not unusual to find the the DIA following the course of reasoning by looking at his own timetable, and where necessary sketching in the various changes which are made. In this way, DIA and Controller, and if present, trainees and reliefs, assemble the resources for comprehending and managing the service, and preserve a mutually compatible orientation to the \'here and now\', and the operation of the service on some particular day. The information provided through the various tools and technologies, including the CCTV monitors, the fixed line diagram, and information displays, is intelligible and reliable by virtue of this collaborative activity.\r\nOn occasions, it may be necessary for the Controller to draw the DIA\'s attention to particular events or activities, even as they emerge within the management of a certain task or problem. For example, as he is speaking to an operator or signalman, the Controller may laugh or produce an exclamation and thereby encourage the DIA to monitor the call more carefully. Or, as he turns to his timetable or glances at the fixed line diagram, the Controller will swear, feign momentary illness or even sing a couple of bars of a song to draw the DINs attention to an emergent problem within the operation of the service. The various objects used by the Controller and DIA to gain a more explicit orientation from the other(s) towards a particular event or activity, are carefully designed to encourage a particular form of co-participation from a colleague, but rarely demand the other\'s attention. They allow the individual to continue with an activity in which they might be engaged, whilst simultaneously inviting them to carefully monitor a concurrent event. Or, even where it is necessary to gain the explicit attention of the other, the various objects are rarely designed to interrupt the tasks in which he might be engaged. For example, in the following fragment, the Controller puts down the receiver and utters \"Shit\".\r\n\r\nFragment 5 (Abbreviated and simplified)\r\n\r\n9 Ci receives a call from the Duty Crew Manager...\r\n\r\nCi: Okay ta.\r\n\r\n99\r\n\r\ncall and replaces receiver.. 9\r\n\r\nCi: Shit\r\n\r\n9 the DIA turns towards the Controller...\r\n\r\nCi: How the hell did I miss that one.\r\n\r\nDIA: What the car was (examined)?\r\n\r\n82\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nCi: no (.) Two O Seven (2.3)\r\nDIA: Two O Seven (.) (I can\'t find it) Ci: I wrote it there, that\'s \'cos I turned over the page.\r\n... the relief Controller iCii) enters the room... Cii: Have I walked in at the wrong time? Ci: No no there\'s no problem.\r\n... the Controllers go on to discuss the difficulty and its consequences...\r\n\r\nThe Controller\'s exclamation is directed towards his timetable; it serves to encourage rather than demand the DIA\'s attention, and indeed, finding the DIA slowly looking up, the Controller produces a complaint to himself. Only then, does the DIA elicit some further information and engage the participants to look for and discuss the train that has been omitted during a previous spate of reformations. The Controller not only draws the DIA and subsequently the Relief Controller into a discussion about the problem, but also implicitly draws their attention to the unforeseen consequences of earlier changes to the timetable.\r\nThe materials at hand cast some light on the ways in which we might begin to reconsider the organisation of individual work tasks and their relationship to the actions of others. Within the Line Control Room different personnel have particular responsibilities and tasks to perform, which though interrelated, involve a specific individual utilising a body of skills to accomplish a specialised activity, such as reformation. However, it is clear that whilst certain activities are primarily accomplished by specific categories of individuals, the in situ accomplishment of these tasks is sensitive to, and coordinated with, the actions and responsibilities of colleagues within the immediate environment. The competent production of a range of specialised individual tasks within the Control Room is thoroughly embedded in, and inseparable from, a range socio-interactional demands. Indeed, even the production of potentially private activities such as reading and writing are systematically tailored with respect to the current and potentially relevant actions of colleagues.\r\nOne way of conceptualising the socio-interactional organisation of task based activities is to draw on Goffman\'s (1981) discussion of participation framework. Goffman suggests that any activity is dependant upon a particular production format which establishes, or attempts to establish, the ways in which \'those within the perceptual range\' will participate in an event. In the materials at hand, we begin to discern how the design of particular activities may be simultaneously sensitive to the potential demands of different \'recipients\' both within and beyond the local physical environment So, for example, whilst speaking to a signalman on the telephone to ask whether he has corrected the running order of a couple of \'out of turn\' trains, the Controller not only coordinates his talk with his co-conversationalist, but simultaneously emphasises, by volume and repetition of certain elements, details to the DIA. The Controller\'s actions are designed simul-\r\n\r\nCOLLABORATION AND CONVl\'ROL\r\n\r\n83\r\n\r\ntaneously to implicate different forms of co-participation from specific colleagues; one or more who is co-present and one, the \'primary recipient\' who is on the other end of the telephone. In Goffman\'s terms, the production format of the activity is sensitive to multiple, simultaneous demands on the Controller, and implicates different forms of co-participation from all those who are within perceptual range of the event. The same activity is produced to organise a form of participation from co-present and physically distributed colleagues; the activity and the participation framework it generates, merge, momentarily, different ecologies within the organisational milieu.\r\n\r\n6. Overseeing the local environment of events and activities\r\n\r\nThe Controller and the DIA have very distinct responsibilities in the overall management of the service and in the provision of information to staff and passengers. Despite their distinct obligations and skills, the Controller and DIA not only monitor each other\'s activities to gather relevant information with which to coordinate their own conduct, but keep a \'lookout\' for their colleagues, monitoring the environment for actions and events which may have passed unnoticed but be relevant to the conduct of the other. This may require of course, that the Controller or DIA explicitly draw his colleague\'s attention to the event. For example, we join the following fragment during an emergency at Baker Street Station, where passengers have been evacuated and drivers told not to stop. As the DIA provides information to passengers at various stations on the Bakerloo Line, the Controller receives a call from the Station Manager giving the \'all clear\'.\r\n\r\nFragment 6 (Abbreviated and simplified.)\r\n\r\nDIA: Hello and Good Morning Ladies and Gentlemen.\r\n\r\n... C answers the phone and begins conversation...\r\n\r\nDIA: At Baker Street, Circle, Hare\'smith and City, and Metropolitan Line trains, are not stopping at the station as the London Fire Brigade are investigating a report of emergency.\r\n\r\n... C puts receiver down, and snaps fingers. . .\r\n\r\nC: All clear\r\n\r\ntDIA: All clear\r\n\r\nC: Yep\r\n\r\nDIA:\r\n\r\nHello Ladies and Gentlemen, a con\'ection to our last message. All Hammersmith an City and Circle Line and Metropolitan Line trains are now stopping at Baker Street Station. This follows London Fire Brigade investigating reports of emergency at that station. All trains on all lines, that includes the Bakerloo, Jubilee, Metropolitan, Hare\'smith and City and Circle Line are now stopping at Baker Street. Interchange facilities are now...\r\n\r\nWhilst the DIA is warning passengers that the trains are not stopping at Baker Street the Controller receives information which contradicts the announcement.\r\n\r\n84\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nThe Controller does not interrupt the DIA within the delivery of the announcement, but as the DIA completes the first delivery of the information, the Controller snaps his fingers and warns his colleagues of the \'all clear\'. The trainee DIA responds and calls the Station Managers at other locations along the Bakerloo Line to inform them of the news. The DIA, whilst appearing insensitive to the \'all clear\', restarts the announcement to inform passengers that trains are now stopping at Baker Street. Even here however, where we find the Controller explicitly informing the DIA of changes within the provision of the service which are of immediate relevance to the activity at hand, there is evidence to suggest that the DIA is aware of Baker Street reopening before it is announced. Inspection of the first part of the announcement reveals that the Bakerloo Line, which is the main responsibility for the DIA, is omitted. It appears that as the Controller answers the call the DIA infers what is happening and redesigns the announcement within the course of its articulation.\r\nThe flow of information and the responsibility to oversee the environment for the other is not simply one-way. Just as the Controller assumes responsibility for keeping his colleague informed of events which may otherwise pass unnoticed, so the DIA will monitor the operation of the service and draw his colleague\'s attention to any events or problems which may have been missed. Consider the following instance. The Controller finishes a conversation on the telephone, and as he replaces the receiver, the DIA successively glances in the direction of Baker Street Station on the fixed line diagram and the Southbound platform of the station on the CCTV monitor. The successive glances between the two domains, appear to be designed to have the Controller discover, independently of being told by the DIA, that something is amiss at Baker Street. The DIA\'s visual conduct passes unnoticed, and the Controller turns and reads the timetable on the console in front of him. As the Controller, begins to read the timetable, the DIA, realising that the Controller has failed to notice the potential problem, delicately draws his attention to it.\r\n\r\nFragment 7 (Abbreviated and simplified)\r\n... The Controller (C) puts phone down... 9.. The DIA successively glances at the hard line display and station monitor, and as C returns to read the timetable utters .... DIA: Is he holding that train at Baker in the South? 9 The telephone rings, C goes to answer query from shunter and then takes a second call, a query from signals. Throughout the calls the DIA continues to glance at the hard line display and station monitor... 9 37 seconds later9 C: Controller calling the train Baker Street on the South Bound platform? ... C finds that the driver is not waiting for a relief but remaining in the station due to a red signal 9149 C: Oh I see I just wondering because we are blocking back behind you at the moment...\r\n\r\nCOLLABORATION ANDCONTROL\r\n\r\n85\r\n\r\n... C finishes the call and rings the signalman at Piccadilly to find out why the signal is being held...\r\nC: No no no it\'s nothing between you an him an they\'re all piling up behind him. (2.8) Yeh, well let him go at Baker Street please...\r\n((3O.O0))\r\nDIA: Hello Ladies and Gentlemen, Bakerloo Line Information. The next South Bound train is just now leaving Baker Street, an will be with you shortly...\r\n\r\nBefore the Controller is able to deal with the potential problem, he is interrupted by a couple of telephone calls unrelated to the difficulty that the DIA has noticed. During these calls the DIA begins, once again, successively to glance between Baker Street on the fixed line diagram and the platform on the CCTV monitor. The DINs actions appear to be designed to display to the Controller, as he is dealing with the incoming calls, that the difficulty at Baker Street continues to require his immediate attention. In fact, the traffic is already beginning to build back up the line as a train, for some yet to be discovered reason, sits in the platform. As soon as the Controller finishes the second conversation and begins to call the driver, the DIA abandons his almost theatrical attempts to display the increasing urgency of the problem and returns to the activity in which he was engaged before he noticed the difficulty with the Southbound service.\r\nThe personnel within the Control Room therefore not only design their conduct so that, if necessary, elements are publicly visible within the local milieu, but systematically monitor each other\'s actions and the operation of the service, so that they can inform their colleagues of any relevant, but potentially unnoticed, problems. The DIA and the Controller not only \'oversee\' each other\'s actions, but monitor various events both for themselves and for the other(s); drawing, where necessary a colleague\'s attention to some \'matter at hand\'. In mutually monitoring each other\'s conduct and the operation of the service, and initiating remedial action, it is interesting to note how the personnel orientate to, and preserve, a division of labour and certain asymmetries in their relationship. For example, in fragment 7, whilst the DIA has undoubtedly noticed a problem of growing severity at Baker Street, he does not ask the Controller to deal with it or even explicitly point out the problem. Rather, the DIA organises his conduct so as to encourage the Controller to notice the problem for himself, and in some way manage the difficulties at hand. In part, the delicacy of the DINs conduct may be sensitive to pointing out to the Controller something he should have noticed and be dealing with; of rendering the Controller\'s conduct accountable simply by virtue of informing him of a particular difficulty. Despite therefore, the very close collaboration between personnel within the Control Room, and their commitment to preserving a mutually compatible orientation to, and sense of, the current service and their own actions and activities, Controller and DIA, even under quite difficult circumstances, systematically preserve the occupational and territorial rights and responsibilities of their colleagues.\r\n\r\n86\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\n7. Shaping tasks and coordinating activities\r\n\r\nThe continual flow of information between the Controller and DIA and their ability to monitor, and if necessary correct, each others\' actions, are an essential feature of work in the Control Room. The constant updating of information, coupled with the ability and responsibility to make it \'publicly\' available within the local milieu, provides the Controller and the DIA with resources with which to make sense of the operation of the service. Without knowledge of the current \'state of play\', the timing and movement of vehicles at this moment at time, the development of the service and any difficulties on this particular day, the Controller and DIA would be liable to draw the wrong inferences from the various sources of data available to them. There would be a risk that the wrong decisions would be taken and misleading information would be provided to both staff and passengers. The intelligibility of the scene, the possibility of coordinating tasks and activities, rests upon these socially organised and communicative practices.\r\nAn important feature of these practices are the ways in which the accomplishment of specific tasks and responsibilities, even those which appear individual and private, are interactionally organised. Indeed, the framework of collaboration between personnel within the Control Room enables an exploration of issues of growing importance within research on human-computer interaction, namely the ways in which the accomplishment of individual work is embedded within social interaction. Earlier, it was suggested that the production of various tasks within the Control Room, by either Controller or DIA, are not only informed by \'occupational\' procedures, but at the same time are designed to display aspects of the gist of the activity for others who may be co-present. The task is not simply interactionally organised and coordinated with a client or colleague, almost all occupational activities are; rather, the task involves fulfilling simultaneous, but distinct, obligations to differentially positioned colleagues or \'recipients\'. To put it another way, the Controller or the DIA is not simply obliged to fulfil the tasks, but rather to make them visibly available to others who are not directly involved. In consequence, the articulation of even the most apparently \'private\' activities within the Control Room are sensitive to the responsibilities and conduct of colleagues.\r\nCollaborative activity within the Line Control Room also rests upon the ways in which personnel shape their participation with, and are encouraged to participate in, the activities of their colleagues. Practices which successfully \'divide their attention\' and provide information to each other, are not simply small additions to the formal procedures which underlie their various occupational tasks. Rather, they are an essential feature of work in the Control Room and the \'occupational culture\', without which personnel would be unable to accomplish their individual responsibilities and tasks, or coordinate their activities with each other. The fulfilment of the complex configuration of tasks and activities within the\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n87\r\n\r\nLine Control Room rests upon, and is inseparable from, a socio-interactional organisation which provides for their systematic and situational accomplishment.\r\nThe usefulness of the hard line display, the CCTV system, and the accompanying tools, relies upon a collection of tacit practices and procedures through which Controller and DIA coordinate information flow and monitor each others\' conduct. Without the information continually being made public and exchanged between the various personnel, the DIA or Controller\'s interpretation of the information presented by the various technologies would be mistaken. The technology and the information it provides, does not stand independently of the various practices in and through which personnel exchange information and coordinate theft actions. Rather the use of the various systems is thoroughly dependant upon a current version of train movements, running times and changes to the timetable.\r\nFor example, the fixed line diagram displays the position of trains on the Bakerloo Line between Queens Park and the Elephant and Castle. Each train appears as a strip of between two and six lights depending on how many sections of track the train is covering at a particular moment. At any time between 6.30 am and 10.00 pm there are likely to be between 15 and 25 trains indicated on the board. The diagram provides staff within the Control Room and of course visitors, such as management, with the ability to make, at a glance, an initial assessment of the current operation of the service. An even distribution of trains (lights) along the board, with relatively few gaps between the vehicles, both South and North, tends to indicate that the service is running according to plan, i.e. the timetable. Yet, as any Controller knows, such an even distribution of vehicles along the line can conceal important problems which may later lead to difficulties, whether in a few minutes or even a few hours. The fixed line diagram does not tell which particular train is where, or whether the trains are in or out of turn. Neither does it not provide information concerning an upcoming shortage of drivers, vehicles which are causing difficulties, stations which are closed \'due to a London Fire Brigade investigation\' nor reveal any of the complex body of reformations which may have already been undertaken and which may lead to difficulties later in the day. In short, the fixed line diagram and the information it provides is a critical resource in control and crisis management, but only in the light of the natural history of the operation of the service on any particular day. Without knowledge of reformations, out of turns, vehicle problems, station closures, that is the incidents which have occurred and the ways in which they were managed, the technology is largely redundant. The socio-interactional organisation of individual tasks and activities within the Line Control Room, and the ways in which information is continually distributed between personnel, provides for the very possibility of using the tools and technologies at hand.\r\nIn the light of the practices which provide for the continual updating and exchange of information regarding the current state of the service, the technology provides the Controller and DIA with the ability to assess the current operation of\r\n\r\n88\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\ntraffic, and undertake, if necessary, remedial action or provide information to staff and passengers. The \'public\' availability of the technology within the Control Room, whether it is a fixed line diagram, a CCTV screen, a screen-based line diagram or an information display, and the visibility of its use, provide critical resources in the collaboration between Controller and DIA. For example, the DIA and Controller are able to assume that they have equivalent access to the different technological sources of information and that, in principle, observations concerning the current operation of the service are mutually available. More importantly perhaps, the DIA and Controller can use the common sources of information as a reliable means of accounting for a broad range of actions and tasks undertaken by the other. So, for example, in fragment 1 we noted how the DIA turned to the fixed line diagram as a potential source of explanation for the Controller\'s intervention. Moreover, their use of the fixed line diagram and the surrounding monitors of the console is publicly visible, and can be used to determine a particular activity in which the DIA or Controller is engaged, or, as in fragment 7, to display a potential problem which is emerging within the operation of the service. The mutual availability of the various information displays, and the visibility of their use, are important resources for making sense of the actions of a colleague and developing a coordinated response to a particular incident or problem. The technology provides a keystone to the collaboration within the Control Room, not only as a source of interrelated bodies of information, but critically as a medium through which particular activities become visible or publicly available within the local ecology.\r\n\r\nIn exploring the organisation of a work environment such as the Line Control Room, it becomes increasingly difficult to delineate the \'individual\' and the \'collaborative\'. The different personnel within the Control Room clearly have distinct responsibilities, areas of jurisdiction, and specialised tasks which are strictly not undertaken by members of the other occupational categories. Some of these tasks, such as reformations or public announcements involve highly specialised skills and competences and are undertaken by a single individual producing successive interrelated actions. It is also clear that these individual tasks are coordinated with the activities of others. Indeed, a Critical feature of the indigenous organisation of conduct within the Control Room is the participants\' orientation to sequential relationships between individual activities. So, for example in fragment 1, it is possible to see the way in which the Controller\'s intervention engendered a public announcement by the DIA. An announcement, if it is was not forthcoming, might well have been treated as \'noticeably\' absent by the Controller. Whilst these indigenous sequential relationships between particular activities undertaken by different personnel reveal the ways in which particular actions are coordinated, they still preserve a sense of the individual and the collaborative.\r\nTurning to the ways in which individual tasks are accomplished within the Line Control Room, the border between the individual and the collaborative\r\n\r\nCOLLABORATIONAND CONTROL\r\n\r\n89\r\n\r\nbecomes increasingly unclear. The Controller and the DIA produce particular activities, even relatively complex tasks, with respect to the responsibilities and concurrent conduct of their colleague(s), tailoring their actions so that they preserve a mutually coordinated response to particular incidents and events. Moreover, whilst engaged in one activity, we find the Controller and DIA monitoring each other\'s conduct and able to discriminate the local environment with regard to contingencies which may be relevant to either their own conduct or the actions of their colleagues, Work within the Line Control Room does not simply necessitate that the participants distribute information and maintain a compatible orientation to the current scene. Rather, it requires that even the most apparently individual tasks are \'ongoingly\' accomplished, moment by moment, with regard to the conduct and responsibilities of the co-participants. This may involve mutually focussed interaction between Control Room personnel, but in large part it requires Controller and DIA to engage in distinct tasks and activities, whilst simultaneously participating, if only by overhearing, the conduct of their colleague(s). The activities of personnel within the Line Control Room continually flow between the private and the public, between the individual and the collaborative, so that distinctions which demarcate particular forms of cooperative work become increasingly problematic.\r\n\r\n8. The design of tools to support collaborative work\r\nThe analysis of work practice and collaboration within the Line Control Room raises a number of implications for the design and redesign of current technologies within the setting, but also it suggests some wider issues. Indeed, as suggested elsewhere, for example in Rasmussen (1989) and Rasmussen et al. (1990), we can see the ways in which field work and ethnography could provide a useful methodological framework for generating observations concerning work practice and technological support.\r\nOne straightforward way in which the above observations can inform design is in assessing the usefulness of proposed modifications to the technologies in the Control Rooms of London Underground. For example, it has been suggested that in the redesign of another Control Room, personnel should have individual graphic displays of the line rather than a large fixed line diagram. From the observations above, such a modification would appear to undermine the co-participation of staff in a range of activities which are currently a critical part of crisis management. For instance, with such systems, individuals may have difficulties ascertaining the orientation of colleagues to particular activities and events. 2\r\nAnalysis of the details of the work practices in the Control Room could also inform the design of systems that would be sensitive to those practices. It was noted earlier that the timetable is a critical resource for identifying problems and\r\n\r\n90\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nmaintaining the service on the line. In part, the organisational culture in the Control Room is designed to render visible changes made to the timetable, undertaken individually by the Line Controller to colleagues both inside and outside the immediate setting. DIAs, Signal Assistants, Duty Crew Managers and other personnel, will often sketch in the alterations to their own timetables when they learn about changes made by the Controller. However, despite the apparent robustness of the practices that Control Room personnel rely upon to support this continual distribution of information amongst colleagues, it is possible to observe certain difficulties emerging in the setting. For example, with the introduction of Signal Assistants, further pressure is placed on mutual, informal monitoring. As the number of personnel within the Control Room has increased, the problem of informing colleagues of changes to the timetable becomes more severe.\r\nDrawing on observations made by the study of Control Rooms, a system has being proposed, in collaboration with staff at the London Underground, that aims to facilitate the distribution of information about changes to the timetable. The initial design of the system will be based upon detailed analysis of the conventional use of the current timetable and the type of information which is exchanged between Controller, DIA and others concerning the moment by moment changes to the schedule. As noted earlier, the various changes undertaken by the Controller are rarely told explicitly to the DIA, or to others, rather colleagues pick up the changes being made. They then sketch in these adjustments and reformations onto their own timetables. The system\'s design is intended to support both the tasks related to the timetable and the necessary indirect communication which occurs within the Control Room.\r\nOne approach to the design of the interface to the system would be to implement the system utilising screens and electronic pens. The system would consist of a screen which presents pages of the timetable with running times alongside scheduled times. Changing the timetable would be done in a similar way to marking a document. However, as with other distributed CSCW systems these changes could immediately be made available to colleagues in the Control Room in just the way in which they were drawn. This provisional design of the system therefore, is not only sensitive to the conventional uses of the paper document, but also to the forms of collaboration undertaken by Controller, DIA and others. It supports the current forms of information exchange and, by providing running times alongside scheduled times, allows Control Room personnel to identify problems in parallel.\r\nLater extensions to the system would allow for further distribution of information outside the Control Room, communicating timetable changes, in appropriate forms, to staff such as Duty Crew Managers in different locales. From the changes and decisions made by Line Controllers, it may also be possible to elicit a set of conventional and candidate solutions to specific problems faced in the operation of the service. These may then be utilised so that the system could be\r\n\r\nCOLLABORATION AND CONTROL\r\n\r\n91\r\n\r\ndeveloped to allow Controllers to test the consequences of candidate reformations before they are confirmed. It is important that these later extensions to the system would still be informed by detailed analysis of the work practices. The aim of the system is not simply to provide support for complex changes to the timetable, but more to support the systematic, yet informal practices, through which information is exchanged between staff.\r\nThe examination of work practices and task coordination in the Line Control Room may also suggest some more general considerations for designers of CSCW systems. For distributed systems that allow users to have both individual and shared work areas, one problem faced by designers is how to allow users to move easily between the two types of work, how to make the transition from individual work to collaborative work appear \'seamless\' (Ishii 1990). The study of work in the Line Control Room suggests that this problem may be more complex. Unlike the timetables, the fixed line display could be considered as a shared resource. In order for a DIA to oversee the Controller\'s look at the fixed line diagram, the diagram has to be available to both participants. More importantly however, the Controller\'s activity in relation to the diagram has to be available to a co-participant, the activity has to be public. Thus, to facilitate individuals mutually to monitor their co-participants, technologies would have to support a \'seamlessness\' between public and private activities.\r\nThe public nature of the uses of artifacts and technology may not be peculiar to London Underground Control Rooms. Harper and Hughes (forthcoming) mention how controllers and other individuals can see the state of the skies from a glance at the air flight strips, and Goodwin and Goodwin (forthcoming) reveal the ways that looking at monitors is embedded in the organisational environment in the control room of an airport.3 Thus, technologies to support collaborative work may have to be designed in relation to the public, as well as the shared nature of activities. For example, it may be possible to enhance certain aspects of the private work on a conventional computer system to provide public resources for other individuals in the environment.4 However, a more radical development may be possible, utilising technological developments that move away from the dependency on screen-based systems to support computational activities.\r\nSuch technological developments are being undertaken at Xerox PARC, Rank Xerox EuroPARC and other research laboratories, developments that have been collectively termed \'ubiquitous computing\' (Weiser 1991). They include systems which allow users to manipulate both screen objects and paper documents on work surfaces. These systems integrate video projections of screen displays, camera views of desks and locational information generated by digital tablets (Tang and Minneman 1991, Wellner 1991, Newman and Wellner 1992, Ishii and Kobayashi 1992). For example, DigitalDesk (Wellner 1991, Newman and Wellner 1992), enables users to place paper documents on a desk from which a camera can \'read\' items. Meanwhile a projector displays a screen image back onto the table. On such\r\n\r\n92\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\na system it is possible to engage in work on documents and screen objects, preserving the advantages of each. Thus, alternatives could be envisaged to systems utilising the screens and electronic pens mentioned above. In addition, by allowing for the use of paper documents such systems are the beginnings of a technology that allow for both private and public work as well as flexible movement between the two. These systems enable users to monitor the orientations of their co-participants in relation to the activity at hand and thus they provide a resource for supporting the \'public nature\' of activities. By providing large fiat working surfaces \'digital desks\' could be utilised to support co-present, collaborative work. Related developments are also underway that may facilitate distributed working (Tang and Minneman 1991, Ishii and Kobayashi 1992).\r\nStudies of technologically mediated collaboration in the work place may reveal other generic issues relating to CSCW system design. For example, revealing the social and interactive nature of what has been traditionally considered as individual tasks such as reading, writing or typing has implications for the design of systems to support collaborative work.5\r\nIf detailed analysis of collaborative work and the use of various tools and technologies can provide insights for system design, then it may be possible to consider methodological frameworks to facilitate this process. As yet the character of such a methodology is unclear. However, it may be in the form of a collection of practices, including the repeated analysis of fragments of materials of recorded activities in their work setting: a so-called \'structured ethnography\'. The sequential relationships of activities may provide the foundation for such a distinctive approach to \'user-centered design\', an approach that emphasises the tacit practices utilised by personnel to accomplish particular actions and activities and to coordinate their work with others.\r\nIndeed, given the socio-organisational foundations to work and situated practice, and the strong commitment to field work and case analysis in the discipline, it would only seem appropriate that sociology should become increasingly involved in the design and development of tools and technologies. It appears that recent developments in the social sciences may be relevant for the evaluation of prototypes and current systems or for identifying tools to support tasks and interaction for more innovative technologies. In designing collaborative tools based upon an understanding of current work practices, it may be possible to avoid some of the pitfalls which frequently arise in the introduction of \'inappropriate\' systems into real-world environments.\r\n\r\nReferences\r\nBBC1. 1991. Training in Transition. Part of the Training Hour Series, broadcast on 3rd October 1991. London: British Broadcasting Corporation.\r\nBly, S. A. 1988. A Use of Drawing Surfaces in Different Collaborative Settings. In Proceedings of CSCW \'88, 250-256, Portland, Oregon: ACM Press.\r\n\r\nCOLLABORATIONAND CONTROL\r\n\r\n93\r\n\r\nCosmos. 1988. Specification for a Configurable, Structured Message System, Cosmos Report 68.4 Ext/ALV, Queen Mary College, London.\r\nGalegher, J. and Kraut, R. E. 1990. Technology for Intellectual Teamwork: Perspectives on Research and Design. In Intellectual Teamwork: The Social and Technological Foundations of Cooperative Work, eds. J. Galagher, R. E. Kraut, and C. Egido, 1-20. Hillsdale, New Jersey: Lawrence Erlbaum Associates.\r\nGaver, W. W. 1986. Auditory Icons: Using Sound in Computer Interfaces. Human-Computer Interaction, 2: 167-177.\r\nGaver, W. W. 1991. Sound Support for Collaboration. In Proceedings of E-CSCW 1991, 293-324. Amsterdam: Kluwer.\r\nGoffman, E. 1981. Forms of Talk Oxford: Basil Blackwell. Goodwin, C. and Goodwin, M. H. forthcoming. Formulating Planes: Seeing as a Situated Activity. In\r\nDistributed Cognition in the Workplace, eds. D. Middleton and Y. Engesn\'om. Cambridge, UK: Cambridge University Press. Greatbatch, D., Luff, P., Heath, C. C. and Campion, P. 1992. Interpersonal Communication and HumanComputer Interaction: An Examination of the Use of Computers in Medical Consultations. Working Paper, Rank Xerox, Cambridge EuroPARC. Grudin, J. 1988. Why CSCW Applications Fail: Problems in the Design and Evaluation of Organizational Interfaces. In Proceedings of CSCW \'88, 85-93, Portland, Oregon: ACM Press. Harper, R. and Hughes, J. (forthcoming) What a f-ing system! Send \'em all to the same place and then expect us to stop \'era hitting: Making Technology Work in Air Traffic Control. In Technology in Working Order, ed. G. Bulton. Routledge: London. Hughes, E. C. 1956. Men and their Work. The Free Press: Glencoe. Hutchins, E. 1989. A Cultural View of Distributed Cognition. Unpublished Manuscript, University of California: San Diego. Hutchins, E. L. 1990. The Technology of Team Navigation. In Intellectual Teamwork: The Social and Technological Foundations of Cooperative Work, eds. J. Galagher, R. E. Kraut, and C. Egido, t91-221. Hillsdale, New Jersey: Lawrence Erlbanm Associates. Ishii, H. 1990. TeamWorkStation: Towards a Seamless Shared Workspace, In Proceedings of CSCW \'90, 13-26. Los Angeles: ACM Press. Ishii, H. and Kobayashi, A. 1992. Clearface: A Seamless Medium for Sharing Drawing and Conversation with Eye Contact. In Proceedings of CHl \"92. ACM Press. Lee, J. 1990. SIBYL: A Tool for Managing Group Decision Rationale. In Proceedings of CSCW \'90, 79-92, Los Angeles, California: ACM press. Linde, C. 1988. Who\'s in Charge Here? Cooperative Work and Authority Negotiation in Police Helicopter Missions. In Proceedings of CSCW \'88, 52-64. Portland, Oregon: ACM Press. Lull, P. and Heath, C. C. 1991. Preliminary Observations of the Docklands Line Control Room, W1T Report, University of Surrey. Luff, P. and Heath, C. C. forthcoming. System Use and Social Organisation: Observations on Human Computer Interaction in an Architectural Practice In Technology in Working Order, ed. G. Button. Routledge: London. Luff, P., Heath, C. C. and Greatbatch, D. 1992. Tasks-In-Interaction: Paper and Screen Based Documentation in Collaborative Activity, Working Paper, Rank Xerox Cambridge EuroPARC. Markus, M. L. and Connolly, T. 1990. Why CSCW Applications Fail: Problems in the Adoption of Independent Work Tools. In Proceedings of CSCW \'90, 371-380. Los Angeles, California: ACM Press. Moran, T. P. and Anderson, R. J. 1990. The Workaday World as a Paradigm for CSCW Design. In Proceedings of the Conference on Computer Supported Collaborative Work. 381-394. Los Angeles, California: ACM Press. Nardi, B. A. and Miller, J. R. 1990. An Ethnographic Study of Distributed Problem Solving in Spreadsheet Development. In Proceedings of CSCW \'90, 197-208, Los Angeles, California: ACM Press. Newman, W. and Wellner, P. 1992. A Desk Supporting Computer-based Interaction with Paper Documents. In Proceedings of CH1 \'92. ACM Press. Olson, G. M. 1990. Collaborative Work as Distributed Cognition. Unpublished Manuscript. University of Michigan. Olson, G. M. and Olson, J. S. 1991. User-Centered Design of Collaboration Technology. Journal of Organisational Computing 1, (1): 61-83. Olson, J. S., Olson, G. M., Mack, L. A. and Wellner, P. 1990. Concurrent Editing: the Group Interface. In Proceedings of lnteract \'90 - Third 1F1PConference on Human-Computer Interaction, 835-840. Cambridge,\r\n\r\n94\r\n\r\nCHRISTIAN HEATH & PAUL LUFF\r\n\r\nUK: Springer-Verlag. Rasmussen, J. 1989. Coping with Human Errors through System Design: Implications for Ecological Interface\r\nDesign. International Journal of Man Machine Studies. 31: 517-534. Rasmussen, J., A. Pejtersen and Schmidt, K. 1990. Taxonomy for Cognitive Work Analysis. Roskilde: Rise\r\nNational Laboratory. Suchman, L. A. and Trigg, R. H. 1989. Understanding Practice: Video as a Medium for Reflection and Design.\r\nPaper prepared for the 12th IRIS Conference, Skagen, Denmark. Tang, J. C. and Minneman, S. L. 1991. VideoDraw: A Video Interface for Collaborative Drawing, ACM\r\nTransactions on Information Systems. 9 (2): 170-184. Weiser, M. 1991. The Computer for the 21st Century. Scientific American, September. Wellner, P. 1991. The DigitalDesk Calculator: Tactile Manipulation on a Desk Top Display. In Proceedings of\r\nthe ACM Symposium on User Interface Software and Technology (UIST \'91). Winograd, T. and Flores, F. 1986. Understanding Computers and Cognition: A New Foundation For Design.\r\nNorwood, NJ: Addison-Wesley.\r\n\r\nNotes\r\n1. The investigation of the Line Control Rooms on London Underground is one of a number of interrelated case studies concerned with Work, Interaction and Technology currently being undertaken by the authors and David Greatbatch in close collaboration with Cambridge EuroPARC.\r\n2. Preliminary observations of a control room with individualised line displays suggest that the work of the equivalents of Controllers and DIAs has become more localised (Luff and Heath 1991).\r\n3. Obviously, there are public aspects to the uses of technology in domains other than control rooms. For preliminary observations on work and interactional practices in medical consultations and in an architecture practice, see Greatbatch et al. (1992) and Luff and Heath (forthcoming) respectively.\r\n4. For example, Gaver (1986, 1991) suggests the uses of sounds to support both individual and collaborative work.\r\n5. See Luff et al. (1992) for some related issues deriving from studies of interactional and work practices.\r\n\r\nView publication stats\r\n\r\n',1,'Heath','Christian Heath and Paul Luff',NULL,'https://www.researchgate.net/profile/Paul_Luff/publication/242317961_Collaboration_and_Control_Crisis_Management_and_Multimedia_Technology_in_London_Underground_Line_Control_Rooms/links/02e7e51dafea91f02e000000.pdf',1,'10.1007/BF00752451','SpringerLink','Browse the entry in the Springer online library',1,NULL,0,0,NULL,NULL,0,0);
INSERT INTO `bolt_programme` VALUES (6,'bodker-when-second-wave-hci-meets-third-wave-challenges','2019-02-23 20:31:52','2019-09-24 12:00:44','2019-02-23 20:31:10',NULL,1,'published','[]','When second wave HCI meets third wave challenges','This paper surveys the current status of second generation HCI theory, faced with the challenges brought to HCI by the so-called third wave. In the third wave, the use context and application types are broadened, and intermixed, relative to the focus of the second wave on work. Technology spreads from the workplace to our homes and everyday lives and culture. Using these challenges the paper specifically addresses the topics of multiplicity, context, boundaries, experience and participation in order to discuss where second wave theory and conceptions can still be positioned to make a contribution as part of the maturing of our handling of the challenges brought on by the third wave.','Susanne Bødker. 2006. When second wave HCI meets third wave challenges. In *Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles* (NordiCHI \'06), Anders Mørch, Konrad Morgan, Tone Bratteteig, Gautam Ghosh, and Dag Svanaes (Eds.). ACM, New York, NY, USA, 1-8. https://doi.org/10.1145/1182475.1182476','When second wave HCI meets third wave challenges\r\nSusanne Bødker University of Aarhus, Denmark Department of Computer Science\r\nbodker@daimi.au.dk\r\n\r\nABSTRACT\r\nThis paper surveys the current status of second generation HCI theory, faced with the challenges brought to HCI by the so-called third wave. In the third wave, the use context and application types are broadened, and intermixed, relative to the focus of the second wave on work. Technology spreads from the workplace to our homes and everyday lives and culture. Using these challenges the paper specifically addresses the topics of multiplicity, context, boundaries, experience and participation in order to discuss where second wave theory and conceptions can still be positioned to make a contribution as part of the maturing of our handling of the challenges brought on by the third wave.\r\nAuthor Keywords Multiplicity, context, boundaries, experience, participation\r\nACM Classification Keywords H5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.\r\nINTRODUCTION\r\nThe desktop computer has been part of our work-life for a while. Even so many work situations do not consist solely of work at the desktop. Many other artefacts are used in changing configurations with and around the computer. Most user interface design has failed to recognize this, and accordingly we are still stuck with the idea that new design should replace existing artefacts, rather than exist together with them.\r\nMobile technology makes it possible to work in many places, and current mobile technologies often seem to assume that as long as the individual user has access to all her personal documents on her laptop, she can work independently of place. This assumes that everybody would always want to carry along every document one has ever produced\r\n\r\nor received. And on top, many work settings are not about individual documents but presupposes a network-oriented shared use of documents and services across physical place. Furthermore, while moving about, and e.g. working from home, we face a blurring of the boundaries between work and other parts of life, as well as an ongoing reconfiguration of work and non-work technologies. How do we deal with changing configurations of the interfaces in particular such that cross between work and non-work? How do experiences with non-work technology influence work, and how do we deal with those experiences in design of workplace technology?\r\nIn choosing the title \"When second wave HCI meets third wave challenges\" I have indicated that these questions and challenges can, will, and must be addressed in the transition from the second generation HCI, that Bannon [1] identified in his \"from human factors to human actors\" paper, to the third generation or wave, that one might identify as a break with the second wave, theoretically and technologically1.\r\nIn the second wave, focus was on groups working with a collection of applications. Theory focused on work settings and interaction within well-established communities of practice. Situated action, distributed cognition and activity theory were important sources of theoretical reflection, and concepts like context came into focus of analysis and design of human-computer interaction. Rigid guidelines, formal methods, and systematic testing were mostly abandoned for proactive methods such as a variety of participatory design workshops, prototyping and contextual inquiries (contextual inquiry [10] as well as a number of other qualitative approaches to studying use as it happens).\r\nMeanwhile, in the third wave, the use context and application types are broadened, and intermixed. Computers are increasingly being used in the private and public spheres. Technology spreads from the workplace to our homes and everyday lives and culture [5]. New elements of human life are included in the human-computer interaction such as culture, emotion and experience [32], and the focus of the third wave, to some extent, seems to be defined in terms of what the second wave is not: non-work, non-purposeful,\r\n\r\n1 I appreciate the discussions of this phenomenon with a large group of colleagues from the University of Aarhus.\r\n\r\nnon-rational, etc. Conceptually and theoretically, the third wave HCI focuses on the cultural level (e.g. through aesthetics [5, 7, 32, 34], expansion of the cognitive to the emotional [32], or a pragmatic/cultural-historical focus on experience [29]. Methodologically, the third wave has partly moved away from a commitment to users towards a more exploratory take-it-or-leave-it approach [24] where designers seek inspiration from use, e.g. through cultural probes. There are some exceptions to this, not least [7].\r\nNew technologies servicing these developments have appeared; pervasive technologies, augmented reality, small interfaces, tangible interfaces, etc. seem to be changing the nature of human-computer interaction in ways that we don\'t quite understand. We witness the creation of ad-hoc configurations of large and small user interfaces. The new interfaces are moveable and used in changing locations and contexts; different tasks are done through a combination of specialized technologies, whereas the PC idea was to gather as much functionality as possible in one computer. Many new modalities, e.g. gestures, are proposed. However, they are most often presented in theoretical isolation, and as an isolated technical solution.\r\nAt this point in time, where the third wave seems to be breaking away from the second wave, I attempt to look at the relationship in a different way. The second wave has left many problems behind that have not yet been solved. These may to some extent be seen in a new light with what we know about the third wave. Furthermore, there are ways in which the third wave could probably benefit from a more direct confrontation with the theories and methods of the second generation. It is in this space that I try to place this current discussion. As part of this discussion it is sometimes relevant to return, as well, to the first generation of HCI, because of the impact that this generation had, or did not have, on the second wave.\r\nIn order to proceed the discussion we look more specifically into some elements of this discussion. I have already indicated where some of the weaknesses of the second wave might be found, and where the second wave needs more development still. It is those latter parts that I will focus on in the following. In particular, I look into some examples before returning to the general discussion. Specifically, I look at multitudes of hardware and applications, context and use across contexts and communities, and use beyond work. Emotions and experience-based design are addressed as well as reflexivity. Finally, I discuss participation and the possible continuation of \"from human factors to human actors\".\r\nMULTIPLICITY OF INTERACTION\r\nThe desktop computer has been part of our work-life for a while. When one looks at the HCI textbooks, one is tempted to think that HCI has always been about gathering applications on the computer desktop. Even so, we know from\r\n\r\nmany studies that work is rarely work at the desktop only. Many other artefacts are used in changing configurations with and around the computer, as we shall return to in a moment.\r\nThe Xerox STAR [35] in many ways was the predecessor of what we know today as the PC desktop and WIMP interface. As the first what-you-see-is-what-you-get commercial office interface it introduced windows, icons, menus and pointing/the mouse as pointing device into the commercial setting. In my recent work I have been revisiting the STAR design [15], and in doing so, it became evident that STAR was the result of a detailed and serious design effort, and not something that came about because it was \"natural\". E.g. as part of the design process several sets of icons were tested for ease of remembering and recognition. The STAR was based on a small number of design principles that were carried through, even though it was not easy in all instances. As a consequence, many of the elements that we take for granted and find \"natural\" today were results of choices that were little predictable.\r\nMuch of the design from Star was taken over by Windows and Mac, but essential elements were not, e.g. the relationship between documents and applications: In STAR the document came first, and the functionality was attached to the document. In the predecessors, applications made the world go round. In [15] I give examples of how the current PC platform has reduced the multiplicity of devices and interaction possibilities relative to how e.g. STAR dealt with them. In addition this is a reduction to how people work at the real life desktop:\r\nIn a study of tax officers [31] and their use of their physical desktop, it was essential that this use break with the assumptions of the PC desktop in a number of ways: Most strikingly, our analysis showed that the physical desktop spaces were used in various ways other than just as random piles and documents on the desktop. Throughout the taxation process, each document had a location on the desktop. Other resources had locations in a similar manner, the calculator for instance. This was exactly where the electronic information differed, because it was brought up on the computer screen in windows. The physical desktop offered functional spaces that were used to separate and structure the taxation process: last year\'s documents at the back of the desk, etc. Not all documents stayed in one location. Some were moved around as the taxation process took place, and spatial mobility was in this way essential. The relationship between documents were created and maintained in this process: The history of the case as such was maintained because the separation and ordering of year was maintained when the material was laid out on the desk, and repackaged into the file. We investigated a set-up that could be created by somebody, shared by the whole group of tax officers, and adapted to their individual needs (by themselves or by somebody else). This was pointed out to be very different from the support for the individual to produce\r\n\r\na personal desktop look and feel that would last over time, which WIMP provides today.\r\nThe taxation case was analysed using activity theory and distributed cognition as theoretical frameworks. It illustrated one important element of what I call multiple interaction, namely the work that the human user does to make multiple objects and mediators work together. In our work with ship bridges and wastewater plants, we have seen similar ways in which users apply multiple instruments across vast physical spaces, and not only at the desktop [6, 9, 12]. In this type of case, the work carried out by the human user is not only what distributed cognition sees as the cognitive work to transform representations, it is to a very large degree physical transportation and transformation as well, what [9] calls zooming with the feet.\r\nThe wastewater plant turns wastewater into clean water. As analysed in [6] it is the plant manager, together with a small group of workers, who are concerned with the overview and optimisation of the wastewater process. In the wastewater plant, there are many examples of juxtaposed mediators, most of them rather mundane ­ a bucket on a stick, a test tube, and some chemicals are used to test the sludge. What ties these mediators together as they are spread over the vast physical space of the plant, is the movement of the human users through daily rounds and routines, as well as in problem-solving situations [37].\r\nIn these and other case analyses we have worked with various kinds of multi-mediation. [21] introduces the concept of webs-of-technology in an effort to embrace the understanding that we never design single, monolithic devices or systems but technology that must be seen and used in relation to many other devices, applications and systems. Webs-oftechnology are used to describe ubiquitous interaction as a process of negotiation between the users and the technology, focussing on the availability of technology and interpretability of services.\r\n[12] proposed a way of combining the basic figures of thought from activity theory with those of semiotics. Through this model we gave a rather more detailed account of both instrumental and communicative aspects and their interrelation, than what has been seen before in semiotic or activity theoretical HCI. We analyse co-occurring mediators, rather than one at the time. Examples of this are juxtaposed mediators, and situations where language mediation is heavily intertwined in the instrumental mediation. Through the analysis of different kinds of objects ­ immediate and ultimate objects, and the way the division of work influences what are the objects of activity of particular human beings, we have come a step further in understanding how human beings mediate their engagement with objects that are not just singular. Furthermore, the historical development of the mediators, and of the division of work embedding these, are important factors in understanding such mediation. Levels and chains of mediations are two ways in which multiple mediation of these multiple objects\r\n\r\nhappen. On the boundary between the second and the third wave, Bertelsen [5] uses Wartofsky\'s notion of primary, secondary and tertiary artefacts, to add layers of understanding and development to the perspective of multimediation.\r\nThe challenge in the third wave is exactly to encompass multiple mediators, and in particular other than PC-based ones. In actual facts the PC seems to be merely a parenthesis if we look at the development from the STAR to the second generation HCI. The recognition of multiplicity can in some ways be traced back to first generation HCI, in particular to the exploratory early stages. Nonetheless, all that can be said about multiple mediation in the second generation HCI has not yet been said. In the UUID project [16] we are currently working to understand ubiquitous interaction from the perspective that any kind of use is constituted as use of configurations of mediators, that can be chained, juxtaposed, etc. and may substitute for one another depending on the situations and e.g. the level of operationalisation [14]. While these mediators all consist of physical as well as logical elements [4], it is not the border between the physical and the logical as such that is interesting, it is as much the action possibilities or affordances offered by a certain configuration for a certain purpose.\r\nMost user interface design approaches seem to have failed to recognize that there are several mediators and that experiences come from a mixture of sources. Accordingly we are stuck with the idea that new design should replace existing mediators, rather than exist together with them. However, in order to provide methods to achieve this, we need to work towards understanding how mediators in webs or configurations can be isolated, analysed and replaced into the configuration.\r\nCONTEXT AND CHANGING USE CONTEXTS\r\nContext has in many ways been the most central second wave concept. Yet it has in many ways been a concept that many talked about but most failed to define in a way that has been useful to HCI. Engeström\'s triangles [25] have largely been used to enumerate dimensions of context. However, there always seem to be another layer or new dimension of context, and in that respect, attempts to make \"complete\" analyses of context have largely failed, at the same time as the dynamics or dialectics of the original approach are often largely ignored.\r\nA somewhat different approach to understanding this phenomenon has been taken by Star [36], through her notion of boundary objects, and by Brown & Duguid [22]. In both cases the attempts have been to create objects and artefacts that are sufficiently self-contained to travel across contexts of use. Unfortunately none of these discussions have led very far beyond pointing to some issues, and to what I see as a general over-exploitation of the concept of boundary objects. However, that way of thinking resonates well with\r\n\r\nmuch of the design thinking regarding mobile technology: Mobile technology makes it possible to work many places, and current mobile technologies often seem to be designed based on the assumption that as long as the individual user has access to all her personal documents on her laptop, she can work independently of place. Nonetheless, many work settings are not about individual documents but presupposes a network-oriented shared use of documents and services across physical place:\r\nIn our work with construction and energy area managers [17] we have seen how their work can be characterized as highly non-routine with a corresponding high degree of flexibility needed to be able to respond to changes in plans as they occur. Area managers supervise construction and maintenance of public buildings such as schools. They collaborate with janitors and institution managers who are permanently located in the buildings, whereas they themselves travel there only for meetings. Ad hoc meetings on site with carpenters, bricklayers, roofers and other contractors as well as janitors and institution managers are often needed to keep a project on track and coordinate the different efforts. The regular inspection visits offer more time to plan and prepare from the office as do a number of the scheduled meetings. During these meetings it is often necessary to refer to shared material such as blueprints, architect drawings, timelines, contractor bids, most of which belong in the project portfolio. Common to the shared materials is that none of them are available electronically on site. They are normally kept in doublet copies on site (owned by the locals) and in the remote office of the area managers.\r\nNot surprisingly, a great deal of effort goes into `checking information out\' of the various computer applications and other information repositories at the office in preparation for meetings. This requires a certain amount of anticipation of possible needs and meetings during the day. Similarly `checking information into\' the computer applications and institution and project portfolios upon the area managers\' return from site demands work since it is important to recall which changes have been made, and e.g. which pictures taken during the day goes with which project. The area managers move through very different work settings characterised not only by the physical location, but also by the difference in the character of the work tasks, the individual carrying out the task, and the resources; people and tools at hand (computerized and otherwise).\r\nThinking mobility and self-containment of mediators and documents first does not comply well with the networked thinking of e.g. the area managers. They don\'t own documents. They work with many types of documents that are shared with the institutions that they service, and to a large extent it would be preferable if all information and documents were available to every area manager whenever he was in the office, or at a particular site. Accordingly, this perspective on context is much more in line with Weiser\'s programmatic paper [39] where he looks at e.g. pads and\r\n\r\nscreens as something that does not belong to and travel with the human user, but something that is there to be used in situations in particular locations. Bardram et al. [3] have developed the use of such interaction possibilities as large screen and other resources in the environment in activitybased computing, a perspective that specifically aims to address how users may make the most out of such resources in the environment as screens, printers etc., when carrying mobile devises.\r\nBertelsen & Nielsen [8] proposes the use of contextual units as ways of delimiting context for analysis and design. These are dynamic ways of delimiting what we are designing for, yet they are somewhat underdeveloped. Accordingly, context remains a challenge in third wave, partly because the second wave has not completed its achievements. However, the third wave specifically emphasizes the general context of culture and human being, in particular e.g. our being in non-work situations such as in the home, in our engagement with the arts, and with leisure activities.\r\nWith its focus on the home, on leisure, etc. the third wave specifically seems to want to separate these types of activities from work, which the focus in the second wave were. The third wave seems to insist that non-work is special and detached from purposefulness. While the third wave may make a lot of sense, in order to provide a clear-cut focus for analysis and design, the second wave may find the negation of all it stands for somewhat confusing and insist that it still has a contribution to make, by elevating the focus from work to life, instead of negating work.\r\nLet us look at an example from recent empirical work:\r\nIn a public organization that is undergoing major organizational change, a caseworker works in three locations, using two-three network platforms. In order to transfer documents across these sites and platforms, she uses her personal hotmail account, because web-mail is the only resource she knows that can be accessed from all platforms, and hence supports transportation of documents across platforms.\r\nFrom the second-generation theory, this raises questions of how do we deal with configurations of mediators that cross between work and human life in general? How do experiences with non-work technology influence work, and how do we deal with those experiences in design of work-place technology? In line with some of my earlier work (e.g. [13]) it seems that, while moving about, and e.g. working from home, we face a blurring of the boundaries between work and others parts of life, as well as an ongoing reconfiguration of work and non-work technologies. Certain technologies truly are used equally in work and outside, e.g. webbrowsers, which help us retrieve scientific papers, as well as train schedules and give us access to e.g. web-banking. Other technologies such as email and cellular phones, people seem to reconfigure differently ­ some use one mail client and account for all mail, while other juggle several accounts and mail systems. Some have one cell-phone while others draw clear boundaries between when they use\r\n\r\na private phone and when they use a work phone. Some use the same forms of interaction for both, others don\'t.\r\nIf one looks as boundaries as resources [17] it is clear that the boundaries are not drawn once and for all, and hence, by having as research focus only on the non-work, we miss the opportunity to understand the resources that exist on the boundaries, and hence to develop technology and interaction accordingly. As a matter of fact, work is a place where technologies get introduced, and explicit training takes place, an element that is often missed in the discussion of the home. As discussed in [22] one faces the lack of training instruments when introducing non-work technologies, and hence it may be necessary to train a large number of users to be front runners when opening e.g. a new subway ticket system.\r\nThis leads us back to context. The concept draws attention to the connection between a particular mediator and its surroundings, including other mediators, and to e.g. people\'s experience with such other mediators. However the boundary discussion points out that at the same time as we try to delimit a context we should also look out for the resources and work that goes on, on the boundaries of particular contexts.\r\nEXPERIENCE AND REFLEXIVITY\r\nEmotions and experiences are keywords in the third wave. They are a result of the negation and discussion of rationality and purposefulness in the second wave, the focus on non-work, and motivation.\r\nEmotion in relation to design and to HCI has been promoted e.g. by Norman [32] as the next wave from traditional cognition, more or less short-circuiting the second generation HCI. However, Norman seems to be stuck in his cognitivist paradigm, which means that he just sees emotions as add-ons to cognition, as discussed in [18]. Boehner et al. [18] tackle the topic of emotion from a social, interactionist point of view, arguing that meaning in emotion is generated by the interaction of people, and accordingly emotion is understood and often modified by interaction with others rather than through individually generated experience.\r\nMcCarthy and Wright [29] choose a pragmatist view rooted in second generation HCI. Their emphasis is on felt experience bridging between the individual and the collective or cultural levels. To [29], felt experience consists of a number of steps that includes anticipation of the experience as well as reflection and recapitulation of it. They give several examples of how multiple technologies mediate such experience, and point out that felt experience occurs on the boundaries between one-self and others.\r\nWhile experience may seem to be a different perspective on human-computer interaction that than of the second generation, [20, 23] point towards an element of experience\r\n\r\nthat is close to home of second generation HCI, namely that of reflexivity. In much of ubiquitous computing it seems to be an assumption that the computing and hence the interaction can simply be made to disappear, once and for all, from the attention of the human user. The IST project Palcom2 has made an effort of explaining how learning and understanding are essential prerequisites of making computer interfaces disappear from the attention of the user (see also [9]). And, as discussed in [4], [14] takes the view that understanding and disappearing go hand in hand ­ the breakdowns that make the disappeared mediator re-appear are, and must also be, the foundation for learning and reflection. Chalmers [23] uses Heidegger\'s hermeneutic cycle to provide a similar discussion.\r\nBecause experience and reflexivity go hand in hand with ubiquity, learning is closely attached to the reconfiguration of configurations of mediators. Such reconfiguration has to do both with\r\n· a dimension of what activity theory would call operationalisation [14] ­ the dimension that allows the user to form repertoires of operations through which the instruments are handled on the one hand, and to consciously reflect on dealing with the components on the other (see [2, 4, 20, 23, 31]).\r\n· a dimension of wholes and parts described by Palcom as \"Besides the need to be able to construct collections with emergent behaviour from existing ambient components and devices, it is also desirable to be able to de-construct assemblies3.\" When it comes to interaction possibilities, it is important e.g. to de-construct the ubiquitous setting, when there is a malfunction in the configuration.\r\nRe-configurability in the hands of networks of human users leads the way back to a topic that seems to be somewhat forgotten as a research theme, tailorability, not as individual adaptation of technology, but as adaptation and further development through interaction and cooperation among people [38, 27, 28].\r\nHUMAN ACTORS­PARTICIPATION REVISITED\r\nTo the second wave, human actors have meant taking users seriously, specifically users as workers with a particular practice in a particular setting. In the Scandinavian tradition in particular, we have emphasized the active engagement of these users in design. At some level such active user participation is now taken for granted in many design settings. As pointed out in [11] this taken-for-grantedness of participatory methods leads to a lack of reflection or reflexivity on\r\n2 www.ist-palcom.org\r\n3 ibid.\r\n\r\nbehalf of designers as regards their own ways of working. For that reason alone, second generation methods such as participatory design should definitely be ready to take on new methodological challenges. In addition, the multiplicity, context, and transparency/reflexivity discussions challenge the focus with which many second generation methods replace one mediator with another. This calls for change.\r\nA few rebels who are profiling the third wave, have responded, primarily to the transparency discussion, by emphasizing a total, art-focussed breakdown [26] without much commitment to the actual users of the technology [24]. The question is how the third wave could develop a productive, reflexive practice that makes more than artistic statements to provoke us?\r\nFirst of all, the human actor needs to step out of the role as worker in a particular practice, and participate in design as a person who brings her entire life to the design. Yet, the second wave insists on a commitment from the designers to users to ensure that design truly benefits users. In my perspective, the notion of felt life [29] seems like a serious starting point in that direction.\r\nSecondly, Bødker & Christiansen [13] argue that many of the questions that we need to deal with as designers of the new multiple, experience-oriented technology are still so open that we need to make technological experiments in order to understand which questions to ask. This leads to an approach that is quite similar to that of Boehner et al. [19]. It gives a new role to prototyping: design­prototyping need to play a role not only to investigate transparency and operationalisation of interaction, but controlled reflexivity as well. It is important, however, that we do not just \"dump\" technology on people­we need to examine carefully the questions to ask and have respect for the answers we get.\r\nThirdly, and least developed, is the challenge coming from re-configurability (of wholes and parts of configurations) and tailorability. Mørch et al. [30] address the most recent developments in this area, and conclude (in my interpretation) that the challenges lie within tailoring new components that come from outside the context of the immediate configuration of mediators (such as other areas of life), combining different levels of tailoring and integrating with existing mediators and configurations, and supporting cooperation between different users in the reconfiguration process. In other words, tailorability research is ready to face the challenges of the third wave, in cooperation with the rest of second wave HCI. Accordingly, we need to challenge tailoring by moving away from end user programming in isolation and towards configurations with multitudes of physical devices etc.\r\n\r\nHEADING TOWARDS THE REAL THIRD WAVE?\r\nI have provided a collage of concepts, solutions and discussions, sketching what is essentially the boundary work needed for second wave HCI to face the rebellious thoughts from the third wave.\r\nI have emphasized that the second wave should not be abandoned. However, it does indeed need to transcend its conceptions of multiplicity, context and reconfiguration.\r\nThe second and the third wave seem to be stuck on either side of the divide between work on the one hand and leisure, arts, and home on the other; between rationality on the hand and emotion on the other. While development on either side may lead towards a true third wave, I don\'t believe that we get there until we embrace people\'s whole lives and transcend the dichotomies between work, rationality, etc. and their negations.\r\nI am concerned with the possible lack of serious commitment of designers to users. To some extent, this is tied to the artistic, cultural focus of many of the specific projects of the third wave. As I have pointed out, this leads to a situation where mediators either make us break down or act transparently, but where our ability as human beings to learn and cooperate in communities of practice is largely ignored. A reverse \"keep it simple stupid\", that may essentially prevent third wave technologies from becoming true parts of everyday life.\r\nThe emerging third wave seems strongly tied to a kind of consumerism that differs from the underlying co-determination framework of the Scandinavian societies. My young colleagues often bring up issues of how one may do participatory design in the context of the home and of consumer products. A way of proceeding that would truly break with consumerism, would be to move the co-determination framework outside the \"factory gates.\" I imagine making use of people\'s experiences of cooperating and learning, hence supporting them in making informed choices that would radically form their lived lives with technology. I imagine that researchers provide re-configurable alternatives, through design-prototyping, where the questions asked have been carefully examined and the answers digested in cooperation with users. Perhaps, this way we could strike the balance differently between individual and individualized choice on the one hand, and one size fits all on the other? We could perhaps make more out of the cooperation and learning possibilities within and across communities?\r\nBased on the Scandinavian tradition, exactly Scandinavian research may have a chance of doing such projects. Where exactly, they would take us, is an open and interesting question.\r\n\r\nACKNOWLEDGMENTS The present paper is the result of discussions with many colleagues including Olav Bertelsen, Christina Brodersen, Clemens N. Klokmose, Leysia Palen and Marianne Graves Petersen. Olav and Clemens provided many very useful insights and comments to earlier versions of the paper.\r\nREFERENCES 1. Bannon, L. (1986). From human factors to human actors: the role of psychology and human-computer interaction studies in system design, Greenbaum, J. & Kyng, M. (eds). Design at work: cooperative design of computer systems table of contents, Erlbaum, pp. 25-44.\r\n2. Bardram, J. E. & O. W. Bertelsen (1995). Supporting the Development of Transparent Interaction. In Blumenthal, Gornostaev, & Unger (eds.). Human-Computer Interaction. 5th. International Conference, EWHCI `95 Moscow, Russia, July 1995. Selected Papers. Berlin: Springer Verlag (LNCS 1015). pp. 79-90.\r\n3. Bardram, J.E., J. Bunde-Pedersen, and M. Søgaard (2006). Support for Activity-Based Computing in a Personal Computing Operating System. Proceeding of CHI \'06: the SIGCHI conference on Human factors in computing systems, ACM Press, v.1 pp. 211-220.\r\n4. Beaudouin-Lafon, M. (2000) Instrumental interaction: an interaction model for designing post-WIMP user interfaces. I Proceedings of the ACM CHI 2000 Conference, 2000, p.446-453.\r\n5. Bertelsen O. W. (2006). Tertiary Artefactness at the Interface, In Fishwick, P. (ed). Aesthetic Computing, pp. 357-368, MIT press.\r\n6. Bertelsen, O. & Bødker, S. (2002). Interaction through multi-artifacts. In Bagnara, S., Pozzi, S., Rizzo, A. & Wright, P. ECCE 11 - Cognition, Culture and Design Eleventh European Conference on Cognitive Ergonomics, Rome: Instituto di scienze e technologie della cognizione consiglio nazionale delle ricerche, pp. 103-111.\r\n7. Bertelsen, O. & Pold, S. (2004). Criticism as an approach to interface aesthetics. Proceedings of the third Nordic conference on Human-computer interaction, pp. 23-32.\r\n8. Bertelsen, O. W. & Nielsen, C. (1999). Dynamics in Wastewater Treatment: A Framework for Understanding Formal Constructs in Complex Technical Settings. In Bødker, S., M. Kyng & K. Schmidt (eds.). ECSCW \'99, Proceedings of the Sixth European Conference on Computer Supported Cooperative Work, 12-16 September 1999, Copenhagen, Denmark. Dordrecht: Kluwer. pp. 277-290.\r\n\r\n9. Bertelsen, O.W. & Bødker, S. (2001). Cooperation in massively distributed information spaces. In ECSCW 2001: Proceedings of the Seventh European Conference on Computer Supported Cooperative Work, Bonn, Germany, 1620 September 2001. Dordrecht: Kluwer Academic Publishers, 1-18.\r\n10. Beyer, H. & Holtzblatt, K. (1997). Contextual design: A customer-centered approach to systems designs. Morgan Kaufmann.\r\n11. Bødker S. & Iversen, O. (2002). Staging a Professional Participatory Design Practice-Moving PD beyond the Initial Fascination of User Involvement, NordiCHI 2002 Proceedings of Second Nordic Conference on Human-Computer Interaction (Bertelsen, Bødker, Kuutti, eds.) pp.1118.\r\n12. Bødker, S. & Bøgh Andersen, P. (2005). Complex Mediation, Journal of Human Computer Interaction, 20(4), pp. 353-402.\r\n13. Bødker, S. & Christiansen, E. (2004). Designing for ephemarality and prototypicality. Symposium on Designing Interactive Systems Proceedings of the 2004 conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 255-260, 2004.\r\n14. Bødker, S. (1991). Through the Interface ­ a Human Activity Approach to User Interface Design. Hillsdale, NJ: Lawrence Erlbaum Associates.\r\n15. Bødker, S. (in preparation) It is still a STAR. Essay for HCI Remix (Thomas Erickson, David McDonald, editors).\r\n16. Bødker, S. Brodersen, C. & Klokmose, C.N. (2006). UUID Literature Survey, DAIMI.\r\n17. Bødker, S.; Kristensen, J. F.; Nielsen, C.; Sperschneider, W. (2003). Technology for Boundaries. In Proceedings of the 2003 International Conference on Supporting Group Work (GROUP\'03), ACM Press, pp. 311- 320.\r\n18. Boehner, K. DePaula, R., Dourish, P. & Sengers, P. (2005). Affect: from information to interaction. In Bertelsen, O. et al. (eds). Critical Computing Between sense and sensibility, ACM, pp. 59-68.\r\n19. Boehner, K., Gay, G., Sengers, P., Brooke, T., & Chen, X. (2004). Technologies for reflection. in Ubiquitous Computing, in Reflective HCI: Towards a Critical Technical Practice, Workshop, CHI.\r\n20. Bolter, J.D. & Gromala, D (2003).Windows and Mirrors: Interaction Design, Digital Art, and the Myth of Transparency. Cambridge: The MIT Press.\r\n\r\n21. Brodersen, C. and Kristensen, J. F. (2004). Interaction Through Negotiation. To appear in the Proceedings of the 3rd Nordic Conference on Human-Computer Interaction (NordiCHI 2004). Tampere, Finland, 23-27 October 2004.\r\n22. Brown, J. S., & Duguid, P. (1994). Borderline issues: Social and material aspects of design. Human-Computer Interaction, 9(1), 3-36.\r\n23. Chalmers, M. (2004). Coupling and Heterogeneity in Ubiquitous Computing, in Reflective HCI: Towards a Critical Technical Practice, Workshop, CHI.\r\n24. Dunne, A. & Raby, F. (2001). Design Noir: The Secret Life of Electronic Objects. Birkhuser.\r\n25. Engeström, Y. (1987). Learning by expanding. Helsinki: Orienta-Konsultit\r\n26. Fiore, S. (2004). Oppressive interactions: between expression and imagination. in Ubiquitous Computing, in Reflective HCI: Towards a Critical Technical Practice, Workshop, CHI.\r\n27. Gantt, M., & Nardi, B. A. (1992). Gardeners and gurus: Patterns of cooperation among CAD users. In Proceedings CHI \'92, pp. 107-117.\r\n28. Mackay, W. E. (1990). Patterns of sharing customizable software. In Proceedings of ACM CSCW\'90 Conference on Computer-Supported Cooperative Work, ACM, pp. 209-221.\r\n29. McCarthy, J. & Wright, P. (2004). Technology as experience. Cambridge, MA: MIT Press.\r\n30. Mørch, A., Stevens, G., Won, M., Klann, M., Dittrich, Y., Wulf, W. Component-based Technologies for End User Development, in: Communications of the ACM, Vol. 47, No. 9, 2004, S. 59-62.\r\n\r\n31. Nielsen, M.N. & Bødker, S. (2004). Desktop Computing, Australian Journal of Information Systems, special issue 2004, pp. 88-101.\r\n32. Norman, D. A. (2002). Emotion and design: Atrractive things work better. Interactions Magazine, ix (4), 36-42.\r\n33. Petersen, M. G. (2004) Remarkable Computing ­ the Challenge of Designing for the Home. In Proceedings of CHI\'2004, ACM Press, pp. 14451449.\r\n34. Petersen, M.G., Iversen, O., Krogh, P., Ludvigsen, M. (2004) Aesthetic Interaction - A pragmatic aesthetics of interactive systems. In proceedings of ACM DIS2004.\r\n35. Smith, D.C., Irby, C., Kimball, R. Verplank, B. & Harslem, E. (1982). \"Designing the Star User Interface\", BYTE 7(4).\r\n36. Star, S.L. (1989). The structure of ill-structured solutions: boundary objects and heterogeneous distributed problem solving. In Gasser, L. & Huhns, M. (eds.) Distributed artificial intelligence, vol. 2, London: Pitman,pp. 37-54\r\n37. Suchman, L. & Wynn, E. (1984). Procedures and problems in the office. Office: Technology and People, 2, 113-154.\r\n38. Trigg, R, & Bødker, S (1994) From Imlementation to design: Tailoring and the emergence of systematization in CSCW, in Futura, R. & Neuwirth, C: Proceedings of CSCW 94, ACM press, pp. 45-54.\r\n39. Weiser M. (1991). The Computer for the TwentyFirst Century, Scientific American, pp. 94-10.\r\n\r\n',1,'Bodker','Susanne Bødker',NULL,'https://pure.au.dk/ws/files/93115128/nordichipreprint.pdf',1,'10.1145/1182475.1182476','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,NULL,NULL,0,0),(7,'rogers-ubicomp-keynote','2019-05-31 17:21:34','2019-10-26 14:01:16','2019-05-31 17:18:16',NULL,1,'published','[]','Weiser’s vision of Ubicomp: Was it halfway to the future?','Yvonne will give the keynote for the **Ubiquitous Computing** session, reflecting upon her highly influential paper *[Moving on from Weiser’s Vision of Calm Computing: Engaging UbiComp Experiences](/programme/rogers-moving-on-from-weiser-s-vision-of-calm-computing-engaging-ubicomp-experiences \"Read about this paper and download a PDF\")*.',NULL,NULL,1,'Rogers','Yvonne Rogers','Yvonne Rogers *(UCL, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,0,40,NULL,NULL,0,0),(8,'benford-mixed-reality-keynote','2019-05-31 17:28:40','2019-11-06 08:04:08','2019-05-31 17:26:23',NULL,1,'published','[]','A Blast from the Past','The paper *[Orchestrating a Mixed Reality Performance](/programme/koleva-orchestrating-a-mixed-reality-performance \"Read about this paper and download a PDF\")* marks a transition in my own research trajectory. The paper itself presented an ethnographic account of the behind the scenes management of Desert Rain, the [first performance work that we produced with the artists Blast Theory](https://www.blasttheory.co.uk/projects/desert-rain/ \"Read about Desert Rain on the Blast Theory website\"). The theme, scale and professional production qualities of Desert Rain were unlike anything that we had encountered before and ultimately led to a series of further touring works with Blast Theory and other artists, including Can You See me Now, Uncle Roy all Around You as well a various ‘Thrill’ projects with Brendan Walker, that in turn, informed HCI concepts such as ambiguity, seamful design, spectator interfaces and trajectories – much of this as part of the Equator project. Looking back, it is interesting to note a gap of several years between the production of Desert Rain in 1997 and the publication of the paper in 2001 and I wonder if we were struggling with how to frame this work for the HCI community? The challenge for the next 20 years was as much to figure out why and how we were collaborating with artists, gradually refining the approach of ‘performance-led research in the wild’, as it was to deliver further performances and HCI concepts.',NULL,NULL,0,'Benford','Steve Benford','Steve Benford *(Mixed Reality Lab, University of Nottingham, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,0,40,NULL,NULL,0,0),(9,'suchman-taylor-artificial-intelligence-humans-machines-keynote','2019-05-31 17:32:04','2019-10-26 23:10:33','2019-05-31 17:29:11',NULL,1,'published','[]','Human-Machine Reconfigurations: Reflections on Identification/Difference','Lucy (attending via video link) will have a conversation with Alex as part of the keynote for the **Artificial Intelligence, Humans & Machines** session, reflecting upon Lucy\'s highly influential book *[Human-Machine Reconfigurations: Plans and Situated Actions](/programme/suchman-human-machine-reconfigurations-plans-and-situated-actions \"Read about this book\")*.',NULL,NULL,1,'Suchman Taylor','Lucy Suchman *(attending via video link)* and Alex Taylor','Lucy Suchman *(Lancaster University, UK; attending via video link)*<br>\r\nAlex Taylor *(City, University of London, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,30,50,NULL,NULL,0,0),(10,'gaver-arts-design-led-approaches-keynote','2019-05-31 17:34:30','2019-10-07 12:15:48','2019-05-31 17:32:54',NULL,1,'published','[]','Thriving on Uncertainty','Bill will give the keynote for the **Arts & Design-led Approaches** session, reflecting upon his highly influential paper *[Ambiguity as a Resource for Design](/programme/gaver-ambiguity-as-a-resource-for-design \"Read about this paper and download a PDF\")*.',NULL,NULL,1,'Gaver','Bill Gaver','Bill Gaver *(Goldsmiths, University of London, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,0,40,NULL,NULL,0,0),(11,'heath-luff-public-private-spaces-keynote','2019-05-31 17:40:30','2019-09-20 17:11:19','2019-05-31 17:38:30',NULL,1,'published','[]','Ecologies of Action','Christian and Paul will give the keynote for the **Public & Private Spaces** session, reflecting upon their highly influential paper *[Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms](/programme/heath-collaboration-and-control-crisis-management-and-multimedia-technology-in-london-underground-line-control-rooms \"Read about the paper and download a PDF\")*.',NULL,NULL,1,'Heath Luff','Christian Heath and Paul Luff','Christian Heath *(King\'s College London, UK)*<br>\r\nPaul Luff *(King\'s College London, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,0,40,NULL,NULL,0,0),(12,'bodker-breaking-away-from-waves-through-generative-hci-research','2019-05-31 17:42:37','2019-09-12 14:00:41','2019-05-31 17:40:57',NULL,1,'published','[]','Breaking Away from Waves through Generative HCI Research','Susanne will give the keynote for the **New Approaches to Research & Design** session, reflecting upon her highly influential paper *[When second wave HCI meets third wave challenges](/programme/bodker-when-second-wave-hci-meets-third-wave-challenges \"Read about this paper and download a PDF\")*. The talk will in particular focus on how to work generatively with design in research and research in design in the halfway World with multiple technologies, users and use activities. Keywords for the future are participation and malleable technologies. ',NULL,NULL,1,'Bodker','Susanne Bødker','Susanne Bødker *(Aarhus University, Denmark)*',NULL,0,NULL,NULL,NULL,0,NULL,0,40,NULL,NULL,0,0),(13,'fraser-digital-is-physical-how-functional-fabrication-disrupts-ubicomp-design-principles','2019-09-02 15:24:57','2019-11-15 14:37:06','2019-09-02 15:24:57',NULL,1,'published','[]','Digital -is- Physical: How Functional Fabrication Disrupts Ubicomp Design Principles','Ubiquitous computing has long explored design through the conceptual separation of digital and physical materials. We describe how the emergence of the fabrication community in HCI will challenge these conceptual principles. The idea of digital material in ubicomp ‘hides’ lower level abstractions such as physical architectures and materials from designers. As new fabrication techniques make these abstractions accessible to makers, physical materials are being used to encode digital functionality. Form (traditionally physical) and function (traditionally digital) can be mutually expressed within material design. We outline how emerging printed electronics techniques will enable functional fabrication, current limitations and opportunities for end-user fabrication of functional devices, and implications for new principles that emphasise combined physical design of form and function.','Mike Fraser, Jingqi Liu, Jenna Shapiro, Joshua Taylor, and Aluna Everitt. 2019. Digital -is- Physical: How Functional Fabrication Disrupts Ubicomp Design Principles. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 5 pages. [https://doi.org/10.1145/1122445.1122456](https://doi.org/10.1145/1122445.1122456 \"DOI for the article \'Digital IS Physical: How Functional Fabrication Disrupts Ubicomp Design Principles\'\")','1 INTRODUCTION\r\n\r\nIn Onion\'s study of Steampunk culture [15], she quotes the Catastrophone Orchestra and Arts Collective\'s cultural desire for machines that retain some accessibility, “Steampunk machines are real, breathing, coughing, struggling and rumbling parts of the world. They are not the airy intellectual fairies of algorithmic mathematics but the hulking manifestations of muscle and mind, the progeny of sweat, blood, tears, and delusions. The technology of steampunk is natural; it moves, lives, ages, and even dies”. Such work draws inspiration from the first industrial revolution, despite the purpose of steampunk machines being principally cultural rather than functional. In communities of machine enthusiasts, whether steampunks, vintage car owners, traction engine mechanics, and builders of replica early computers, relay computers and Difference Engines, there is an emotive, almost comforting aspect to understanding, building and using machines.\r\n\r\nThe discomfort of disengagement from computers through the layers of miniaturisation and abstraction which have become so widespread provides exactly the right cultural inspiration for fabrication in HCI: the attempt to enable manufacturing of physical, functional objects and devices by end users [1].\r\n\r\nIn this paper, we describe the implications of the emerging fabrication community in HCI for the mixed reality design principles which have underpinned ubiquitous computing. The past two decades have seen an explosion in paradigms which combine physical and digital interfaces in a range of conceptual forms to ubiquitous computing. Tangible [9], embodied [4] and ubiquitous [21] computing have promoted the design of hybrid interfaces in various ways, but all these approaches share in common the notion that digital and physical resources have different and complementary properties and that, in contrast to earlier Graphical User Interfaces (GUIs), physical interface design deserves at least equal status to digital interface design. Our response is informed by Benford and colleagues\'[11] work on mixed reality orchestration, in which performers weave form and function into an illusion of trajectories between physical and digital worlds.\r\n\r\nAs functional materials gain prominence, form (traditionally physical) and function (traditionally digital) become increasingly difficult to separate according to this physical-digital divide. This paper outlines the materials and techniques that are driving this progress, and the design themes of agency, creativity, economy and sustainability that will be disrupted by the changes.\r\n\r\n2 FABRICATION EMPHASISES PHYSICALITY\r\n\r\nRecently we have seen an increasing interest in material design in computing [22] and the emergence of maker communities with craft knowledge across tangible computing, product and industrial design, unconventional electronics, robotics and visual and performance arts [8]. Recent work in HCI on tools to support fabrication includes laser cutting [13] and growth in the applications of cheap 3d printing [12]. There has also been an increase in the broader use of conductive materials to design and print interactive device prototypes [14]. This return to crafting and making is an important agenda for restructuring the boundaries in society between producers and consumers. The emergence of Personal Fabrication [1] in this context is potentially revolutionary, as end-users are enabled to become end-producers, making things that they need on demand at home or in the workplace, recycling locally to enable an improved circular economy, and acquiring greater awareness of the sustainability of their own consumption as a result.\r\n\r\nBaudisch and Mueller [1] describe personal fabrication as conceptually underpinned by two complementary operations, an Analogue-Digital (AD) converter, such as a 3d scanner, and a Digital-Analogue (DA) converter, such as a 3d printer. Intermediate digital data can be seamlessly edited in digital form and then turned back into a copy or new physical object. By this account, fabrication is strongly reliant on previous conceptual models of ubiquitous computing and mixed reality, as a synthesis of physical and digital tools and techniques.\r\n\r\nHowever, in this paper we want to present a more conceptually disruptive view of fabrication, one which specifically takes into account the personal fabrication of electronics, or ‘functional’ fabrication. The many fabrication materials explored in [1] include conductors and semiconductors, electrically responsive materials which enable printed electronics. We suggest that functional fabrication is not just a potential application of the wider fabrication landscape, but could radically change the way designers conceptualise ‘digital’ systems.\r\n\r\nDigital systems are themselves built upon physical architectures, albeit these are often hidden by layers of abstraction. Notions of digital material are founded on well-established computing and communication abstractions which mask the behaviour of an ultimately physical system. As we have become accustomed to authoring software, we have forgotten that the same algorithms can be embodied in physical materials. Functional fabrication enables the idea that digital material is an illusion built upon physical foundations that are newly accessible to the user-as-maker. Indeed, human inputs such as touch sensing, outputs such as LEDs, transistors for building architectural components such as memory or simple processors, even solar cells for supplying power can all be rapidly printed. The materials and processes to do so are making their way out of labs and factories and into fabrication platforms which are becoming increasingly accessible to end users.\r\n\r\n3 FABRICATING ELECTRONICS\r\n\r\nThe wider fabrication ecosystem has been underpinned by cheap microcontrollers such as Arduino consisting of circuit boards mounted with silicon chips alongside accessible software interfaces for designers. While such platforms have been hugely valuable for rapidly producing prototypes, significant economic barriers remain when scaling up production, and physical inefficiencies in these ‘circuit board plus silicon’ approaches constrain size, form and aesthetics. Often, product designers must address form and function separately, form through traditional hands-on materials engagement, and function through constrained choices of existing physical hardware and software APIs.\r\n\r\nA step change in the capabilities and scale of personal fabrication could be enabled by designing, deploying and evaluating new design tools that make accessible material science innovations and electronic design and manufacturing techniques. Three particular innovations are important in the context of enabling end-user access to electronic fabrication: functional materials, thin film devices which use these materials, and accessible printing tools and techniques to create these devices.\r\n\r\n3.1 Organic Electronics\r\n\r\nFunctional plastics are cheap conducting and semi-conducting organic polymer materials that can be arranged or printed to build circuits, transistors, sensors, displays and many other electronic components [2]. This class of materials is particularly interesting because it provides opportunities to cheaply build electronic capabilities that are tightly coupled or even merged with product design materials. The potential level of physical and functional integration achieved by using electronic materials is orders of magnitude greater than Arduino-like approaches.\r\n\r\nSince the discovery in the 1970s that some organic polymers could act as electrical conductors, there has been steadily growing interest in materials science research in conducting and semiconducting plastics, so-called ‘plastic electronics’. These materials can come in a number of forms, but are often processed as liquids or suspensions that can be sprayed or spun onto surfaces [3, 19]. Functional plastics can have conductivities approaching those of metals, yet are inexpensive to produce in quantity [6]. Semiconductors are a special case in which the polymer is ‘doped’ to generate materials called p-type (shortfall of electrons) or n-type (surplus electrons), useful in thin film devices (see below). Major commercial innovations include Organic Light-Emitting Diodes (OLEDs), and Organic Field Effect Transistors (OFETs).\r\n\r\nThere is a strong science and engineering research base in polymer electronics, focusing on measuring and improving the performance and scale of devices in order to approach the performance of silicon. Typically silicon-based components can already be emulated in plastics, for example existing work shows that functional plastics are capable of enabling touch sensing, displays, small computers for processing information, memory, and printed antennas [6].\r\n\r\nThe performance of plastic electronics approaches is not yet comparable with silicon approaches, so for example the OFET has not yet replaced the MOSFET in commercial chip design. However, we are increasingly seeing other benefits to plastic electronics. The clearest benefit is that the materials can be processed at low temperatures, enabling flexible substrates to be used in the printing process without damaging them with heat. This creates opportunities for flexible displays and devices which would not be possible with high temperature, brittle silicon processes. The ability to process at low temperatures also opens up opportunities for integrating plastic electronics in end-user fabrication, because the processes can potentially be more easily encapsulated into safe and accessible consumer platforms.\r\n\r\n3.2 Thin Film Device Engineering\r\n\r\nOne driver of increased interest in these materials over the past two decades has been the massive growth in their use for thin film device engineering. Thin film devices are essentially ‘sandwiched’ layers of such functional materials which interact electrically with one another. Many different devices are possible depending on the ordering and materials used in each of the sandwich layers. Typically, the surrounding ‘bread’ of the sandwich are electrodes, conductive layers that transport current to and from the device. The ‘contents’ of the sandwich are then layers of dielectric, semiconducting, light-emitting or light-activated materials, depending on the device being created.\r\n\r\nA common feature of thin film devices is a thin layer of dielectric (electrically inert) material. Electrical potential on the electrodes can exert influence across the dielectric layer such that the excess holes or electrons in the semiconducting material start to conduct. This creates a ‘sluice gate’ electrical effect which works like a switch. The field effect could activate light emission in the case of Organic Light Emitting Diodes (OLEDs), transistor switching in the case of Thin Film Transistors (TFTs), or be activated by light in the case of Thin Film Photovolatic solar cells (TFPV) [10, 20].\r\n\r\nAs an electrical field effect is required across the dielectric layer in these devices, precision is required to make this layer very thin and uniform for predictable low voltage performance, but with no actual holes through it which would cause a short circuit. So, there are physical limits and optimisations to thin film engineering which have for some time made it difficult to move out of the laboratory or factory. Nonetheless, as these techniques become better understood, researchers have begun to explore how accessible printing techniques could be applied to thin film engineering. Such devices are small enough that they can be used as thin coatings to product designs, or even layered in tiny structures to create complex larger artefacts.\r\n\r\n3.3 Printed Electronics\r\n\r\nPhysical demands on thin film layering precision have traditionally required ‘clean room’ approaches to avoid impurities which could breech layers, as well as expensive and complex coating techniques such as Plasma Vapor Deposition (PVD) to create thin enough films to be electrically appropriate. Our third set of innovations centres on emerging printing techniques which could bring thin film devices out of the lab and into maker spaces. This could allow designers to manipulate materials of form and function together, designing efficient and scalable electronically-functional prototypes based on familiar personal fabrication tools.\r\n\r\nSo far HCI research on fabrication processes with functional materials has been limited principally to technical processes. An increasing body of publications that explore approaches such as screen printing [14], hyroprinting [7]. electrospinning [16], inkjet droplet-on-demand [19], roll-to-roll printing [17] and spray coating [3] all have early adopters within the HCI fabrication community. These early technical explorations are the ‘thin’ end of the wedge in which printed electronics will be increasingly incorporated within accessible makerspace prototyping processes, and increasing efficiency and scale of functional materials processing makes it way from manufacturing into personal fabrication. However, beyond making the technical processes more accessible, there are social and technical abstractions which will need to be addressed to integrate functional fabrication into existing ubicomp designs.\r\n\r\n4 Physical, as in ‘Obeys the Laws of Physics’\r\n\r\nThe notion of a user interface which resides ‘above’ such physical systems contributes to the conceptual separation between digital and physical, visible and invisible, tangible and intangible, embodied and disembodied. The term physical literally implies that the system obeys the laws of physics, and therefore includes the behaviour of ‘unseen’ physical systems. For example, computer behaviour may be physical but perceptually invisible due to carrier frequency such as wireless transmission via radio signals; or due to miniaturisation such as the nano-scale transistors that make up modern memory and processors which have invisible electrical switching behaviours characteristic of semiconductor-based computer architectures. We have become accustomed to the idea of digital design, but invisibility often leads us to forget how information itself is physically transmitted, transformed, encoded and represented, and that this may obscure new design opportunities.\r\n\r\nWhen we imagine ‘the digital’, we often resort to a disembodied model of ‘data’ or ‘information’. Suchman [18] draws on Katherine Hayles’ How Information Lost its Body to explore the need to reverse the immateriality of information, suggesting it should be inseparable from its material and social instantiation in the everyday world. A key point of Suchman\'s thesis is that the engineering challenges and labour involved in making technologies are masked by current design approaches which use highly abstracted notions of intelligence and autonomy to hide the work on the ground required to make technologies work. This challenge requires that we return to the foundations of computing to understand how the physical body of digital information has been obscured in our current models of computing design. Clearly the computers themselves are still there; so why does their manifestation remain so abstracted from our consciousness, and how do these physical systems remain so well hidden in plain sight?\r\n\r\n5 FABRICATION DISRUPTS ABSTRACTION\r\n\r\nAlthough abstractions exist for good historical reasons, they can create inertia in computer designs which would otherwise be open to the diverse ideas increasingly recognised in fabrication, for example cultural or artistic values; or efficiency in material consumption rather than computational efficiency.\r\n\r\nComputing history is characterised by abstraction of designs to increase efficiency, share standards and manage complexity. Abstractions help reduce the need to monitor or understand how computers work, inserting layers of complexity encased within veneers of simplicity to make computers more widely accessible. The computer science literature of the mid-20th century provides ample evidence that computational architectures themselves were already becoming ‘unassailable’. In 1962, Doug Engelbart wrote:\r\n\r\nSophisticated capability results from clever organizational hierarchy so that pursuit of the source of intelligence within this system would take one down through layers of functional and physical organization that become successively more primitive. A programmer could take us down through perhaps three levels. Then a machine designer could show us how the different hardware (e.g., random-access storage, arithmetic registers, adder, arithmetic control) are organized. The logic designer could then give us a tour of how pulse gates, flip-flops and AND, OR, and NOT circuits can be organized, a circuit engineer could show us how transistors, resistors, capacitors, and diodes can be organized. Device engineers and physicists could take us down through more layers. Soon we have crossed the boundary between what is man-organized and what is nature-organized, and are discussing the way in which a given physical phenomenon is derived from the intrinsic organization of sub-atomic particles, with our ability to explain succeeding layers blocked by the exhaustion of our present human comprehension. (abridged from [5])\r\n.\r\n\r\nIn the 1960s, machine architectures were already considered complex and the labour required to design them was starting to be distributed across different roles from physicists through to software engineers. Nonetheless, Engelbart remained the product of a generation which closely understood the nature of these machine architectures. Although machines of the 1960s were established in a hierarchy very similar to today\'s computers, they were not of the same scale of miniaturisation nor the same level of abstraction as current computers, for example even in the 1970s machines such as DEC\'s PDP-11 still closely tied programming operations to machine architecture, using assembly languages and physical switches which directly corresponded to and represented processor and memory instructions. Nonetheless, even these direct architectural interfaces were displaced proxies for the physical processes which took place on silicon designs.\r\n\r\nThe subsequent success of the next generation of high level programming languages, operating systems and the GUIs they coded meant that almost two decades would pass before researchers began again to ask serious questions about the physical design of computing interfaces. Work emerged from a demand to re-introduce physical design to the digital interface, and that has happened in a variety of ways, whether physicality came in the form of the ‘real world’ contrasted with virtual reality as in mixed reality, physical objects contrasted with graphical objects as in tangible computing, or social forms of physicality contrasted with cognitive forms of digital information as in embodied computing [4]. Ishii and Ullmer\'s vision of Tangible Bits [9] is an important example, which contrasted digital-only interfaces with physical-digital interfaces that combine the best of both ‘materials’, re-emphasising the design of hands-on devices and their interoperation with information. Tangible interfaces reach across the interface to identify correspondences between ‘bits’ and ‘atoms’. The tangible computing paradigm has formed the basis of a programme which re-respects physical interface material and people\'s engagement with it.\r\n\r\nHowever, the fabrication perspective suggests that the bits are also being stored, manipulated and calculated using atoms, in addition to any other interface design correspondences between these supposedly different mediums. Counterintuitively, tangible interfaces also reinforce the notion of a digital interface by giving it equal status to the physical interface, only diverging from digital-only (graphical user) interfaces. Ishii et al have expanded their vision to include Radical Atoms [8] – actuated and miniaturised interfaces which exhibit physical actuation and material dynamics. Nonetheless, this vision still accepts primacy of digital material as a concept by using actuation to present digital behaviours in highly material ways. Embracing functional fabrication requires that we fully reconsider digital design.\r\n\r\n6 FABRICATION CHALLENGES DESIGN\r\n\r\nDespite early examples, significant work in personal fabrication is still needed to move the audience for functional fabrication from materials scientists and engineers towards software engineers, product and interaction designers. The lack of ‘high level’ design innovation is not a weakness in the materials science itself, but rather in the kind of work that would naturally fall within the HCI remit – forming freely available platforms and standards, comparable to Arduino-like approaches, which are agnostic to the shifting scientific landscape.\r\n\r\nOne specific challenge is to understand how to balance and combine the materials that give a product form and the materials that give it function. Should form follow function, or function follow form? Could we compose functional building blocks such as thin film devices into layers which then build up into desired tactile, structural and mechanical properties? Is it better to use algorithms which automate the layout and placement of functional materials within a designed form, similar in approach to the automatic routing of circuit boards? Whichever design approaches emerge, there are reasons for believing that local functional fabrication could enhance current design processes. Ubicomp abstractions although highly efficient and complex, can create undesirable personal and societal effects, and some positive effects could be encouraged by considering local design, not least the re-emergence of traditional craft in bespoke product design processes. Some motivations are to enhance holistic design opportunities, some to allow better reuse of materials or designs, and some to enhance human values like agency and creativity.\r\n\r\nWe would expect to see potential advantages in helping users understand, manage and creatively manipulate how systems work. Abstraction of technical complexity often reduces expertise in the behaviour of the abstracted layers. Even among expert computer scientists it is rare that a single person understands in detail the design of an entire modern computer at all layers. This challenge leads to many ‘high level’ design problems such as Wirth\'s Law [23], which suggests that increases in hardware speed driven by Moore\'s Law are effectively compensated by parallel decreases in software and operating system efficiency, because these layers are coded with minimal understanding of physical architectures and compilation processes.\r\n\r\nThere may be economic effects of local functional fabrication, for example undermining the separation of silicon design and manufacture in computing. Intel made a single investment of 9 billion dollars in its 22 nanometre fabrication process in 2011, a process already made redundant by 14 nanometre and subsequent architecture roadmaps. The fact that there are limited sources of transistor manufacture and very high barriers to entry means that most chip design companies are ‘fabless’, leading to slow design cycles, long lead times, and disengagement of the electrical and electronic design community from its target materials and manufacturing processes.\r\n\r\nA key outcome will be environmental impacts: typically we cannot reuse old electronic components in new designs because the integration of materials at the silicon or even circuit board component level are so bespoke to the individual product that we have little sense of how to extract and reuse them. Clearly modular reuse of electronic components would be an order of magnitude more energy efficient than attempts to recycle them as base materials. However, reduction of waste and shortening supply chains is not a panacea. Functional fabrication will also require engagement with the circular economy and material recycling communities, as well as understanding how to design for reuse when the hands-on shaping of a range of physical materials is also the shaping of functional digital behaviours. Where physical and digital design converge in material design, new opportunities are presented, but new threats are also envisaged.\r\n\r\n7 CONCLUSIONS\r\n\r\nThis paper has described the emergence of functional fabrication, and the idea that this enables physical materials and computer architectures to be accessible as interfaces. This approach is to some degree a development of hybrid physical/digital design programmes such as tangible computing and mixed reality in the way that they understand digital material sceptically as an abstracted allegory rather than as ‘real’ design material. However, it will go further to place the design of form and function together back into the product designers\' hands. For HCI, functional fabrication makes us question the value of mixed reality approaches in ubicomp design. This paper has argued that the reification of the digital in ubicomp frameworks has given legitimacy to disempowering and obfuscating social and cultural effects of digital abstractions. Therefore, fabrication in HCI presents an opportunity more than just making ‘things’, but rather to re-make our conceptual relationship with technology in society.\r\n\r\nACKNOWLEDGEMENTS\r\n\r\nThis work was funded by EPSRC grant EP/M021882/1, Interaction Design with Functional Plastics.\r\n\r\nREFERENCES\r\n\r\nPatrick Baudisch and Stefanie Mueller. 2017. Personal Fabrication. Foundations and Trends in Human Computer Interaction 10, 3-4(2017), 165–293. https://doi.org/10.1561/1100000055  \r\nMagnus Berggren, David Nilsson, and Nathaniel D. Robinson. 2007. Organic Materials for Printed Electronics. Nature Materials 6, 1 (2007). https://doi.org/10.1038/nmat1817  \r\nCalvin K. Chan, Lee J. Richter, Brad Dinardo, Cherno Jaye, Brad R. Conrad, Hyun Wook Ro, David S. Germack, Daniel A. Fischer, Dean M. DeLongchamp, and David J. Gundlach. 2010. High-Performance Airbrushed Organic Thin Film Transistors. Applied Physics Letters 96 (2010), 929–938. https://doi.org/10.1063/1.3360230  \r\nPaul Dourish. 2001. Where the Action is: The Foundations of Embodied Interaction. MIT Press.  \r\nDouglas C. Engelbart. 1962. Augmenting Human Intellect: A Conceptual Framework. SRI Summary Report AFOSR-3223, for Director of Information Sciences, Air Force Office of Scientific Research(1962).  \r\nStephen R. Forrest. 2004. The path to ubiquitous and low-cost organic electronic appliances on plastic. Nature 428(2004), 911–918. https://doi.org/10.1038/nature02498  \r\nDaniel Groeger and Jurgen Steimle. 2018. ObjectSkin: Augmenting Everyday Objects with Hydroprinted Touch Sensors and Displays. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 4 (2018), 134. https://doi.org/10.1145/3161165  \r\nHiroshi Ishii, David Lakatos, Leonardo Bonanni, and Jean-Baptiste Labrune. 2012. Radical atoms: beyond tangible bits, toward transformable materials. Interactions 19(2012), 38–51. https://doi.org/10.1145/2065327.2065337  \r\nHiroshi Ishii and Brygg Ullmer. 1997. Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems (CHI\'97). 234–241. https://doi.org/10.1145/258549.258715  \r\nTommie W. Kelley, Paul F. Baude, Chris Gerlach, David E. Ender, Dawn Muyres, Michael A. Haase, Dennis E. Vogel, and Steven D. Theiss. 2004. Recent Progress in Organic Electronics: Materials, Devices, and Processes. Chemistry Materials 16(2004), 4413–4422. https://doi.org/10.1021/cm049614j  \r\nBoriana Koleva, Ian Taylor, Steve Benford, Mike Fraser, Chris Greenhalgh, Holger Schnadelbach, Dirk vom Lehn, Christian Heath, Ju Row-Farr, and Matt Adams. 2001. Orchestrating a mixed reality performance. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’01).  \r\nStefanie Mueller. 2017. 3d printing for human-computer interaction. Interactions 24, 25 (2017), 76–79. https://doi.org/10.1145/3125399  \r\nStefanie Mueller, Bastian Kruck, and Patrick Baudisch. 2013. LaserOrigami: Laser-Cutting 3D Objects. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems (CHI\'13). 2585–2592. https://doi.org/10.1145/2470654.2481358  \r\nSimon Olberding, Michael Wessely, and Jurgen Steimle. 2014. PrintScreen: fabricating highly customizable thin-film touch-displays. In Proceedings of the 27th annual ACM symposium on User Interface Software and Technology (UIST\'14). 281–290. https://doi.org/10.1145/2642918.2647413  \r\nRebecca Onion. 2008. Reclaiming the Machine: An Introductory Look at Steampunk in Everyday Practice. Neo-Victorian Studies 1, 1 (2008), 138–163.  \r\nMichael L. Rivera and Scott E. Hudson. 2019. Desktop Electrospinning: A Single Extruder 3D Printer for Producing Rigid Plastic and Electrospun Textiles. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems (CHI\'19). https://doi.org/10.1145/3290605.3300434  \r\nJurgen Steimle. 2015. Printed Electronics for Human-Computer Interaction. Interactions 22, 3 (2015), 72–75. https://doi.org/10.1145/2754304  \r\nLucy Suchman. 2011. Restoring Information\'s Body. http://www.youtube.com/watch?v=Z3I-ndAXYWg. Verified: 2019-09-05, summarised in Hardin, S., Restoring Information\'s Body, in Bulletin of the American Society for Information Science and Technology, 37 (3), Feb/Mar 2011.  \r\nNattapong Tongrod, Teerakiat Kerdcharoen, Natthapol Watthanawisuth, and Adisorn Tuantranont. 2010. Low-Cost Data-Glove for Human Computer- Interaction Based on Ink-Jet Printed Sensors and ZigBee Networks. In Proc. 14th IEEE International Symposium on Wearable Computers (ISWC\'10). https://doi.org/10.3109/17483107.2012.737540  \r\nJi Zheng Wang, Jian Gu, Frederic Zenhausern, and Henning Sirringhaus. 2006. Low-Cost Fabrication of Submicron All-Polymer Field Effect Transistors. Applied Physics Letters 88, 13 (2006). https://doi.org/10.1063/1.2191088  \r\nMark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (1993), 75–84. https://doi.org/10.1145/159544.159617  \r\nMikael Wiberg, Hiroshi Ishii, Paul Dourish, Daniela Rosner, Anna Vallgarda, Petra Sundstrom, Tobie Kerridge, and Mark Rolston. 2012. “Material interactions”: from atoms & bits to entangled practices. In CHI Extended Abstracts 2012. 1147–1150.  \r\nNiklaus Wirth. 1995. A Plea for Lean Software. Computer 28, 2 (1995), 64–68. https://doi.org/10.1109/2.348001 ',1,'Fraser','Mike Fraser, Jingqi Liu, Jenna Shapiro, Joshua Taylor, and Aluna Everitt','Mike Fraser *(Department of Computer Science, University of Bath, UK)*<br>\r\nJingqi Liu *(Department of Computer Science, University of Bath, UK)*<br>\r\nJenna Shapiro *(Bristol Interaction Group, University of Bristol, UK)*<br>\r\nJoshua Taylor *(Bristol Interaction Group, University of Bristol, UK)*<br>\r\nAluna Everitt *(Bristol Interaction Group, University of Bristol, UK)*',NULL,0,'10.1145/3363384.3363472','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,45,10,NULL,NULL,0,28),(14,'lange-blending-into-the-white-box-of-the-art-museum','2019-09-02 15:24:57','2019-11-14 14:02:51','2019-09-02 15:24:57',NULL,1,'published','[]','Blending into the White Box of the Art Museum','Mixed reality applications can enrich museum exhibits and make them more attractive to an audience of adolescents. However, in the design of such applications, we face a myriad of possibilities and little guidance on how to choose between (early) alternatives. In this paper, we explore the notion of experience blend - which could act as an aesthetic governing the design of mixed reality experiences. We present an effort to operationalize experience blend and illustrate its use in the design and evaluation of an application for an art museum. Stakeholders in the project assumed that in order to reach out to adolescents an exciting experience was needed, deviating from education and breaking with the hidden rules of the art-museum, our user study showed that adolescents favored a blended experience. This suggests experience blend may be a helpful aesthetic in the design of other mixed reality experiences.','Vera Lange, Marleen van Beuzekom, Michel Hansma, Jasper Jeurens, Willemiek van den Oever, Marjolein Regterschot, Jille Treffers, Koen van Turnhout, Tonguc Ibrahim Sezen, Ido Iurgel, and René Bakker. 2019. Blending into the White Box of the Art Museum. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 9 pages. [https://doi.org/10.1145/3363384.3363469](https://doi.org/10.1145/3363384.3363469 \"DOI for the article \'Blending into the White Box of the Art Museum\'\")','1 Introduction\r\n\r\nThis paper is the result of a design project focusing on mixed reality experiences for museums. Museums see potential in mixed reality to attract younger audiences. Clearly, well-designed experiences in museums can be interesting for adolescents; but designing for the context of a museum also comes with specific challenges. Museums are typically information-rich spaces, with (implicit) rules about how to behave and demanding communicative goals. Considering such a context, it seems apparent that novel experiences need to ‘blend in’; they need to be designed to form an integral part of the museums’ experience-scape.\r\n\r\nThe design case we focus on is part of the larger RheijnLand.Xperiences project. In this project, eight museums in the Rhine region in the Netherlands and Germany are connected through an over-arching storytelling framework [9, 15] accompanied by mixed reality experiences aiming to create a better museum visiting experience for adolescents. Our focus in this paper is on Museum Kurhaus Kleve, a modern art museum close to the Dutch-German border. Art museums have difficulties reaching out to a young audience [6, 19]. They face what Idema [8] frames as the problem of the white box. Art museums offer little context to the art on display and leave it up to the visitors to form their own judgment. Visitors, in turn, can feel intimidated [7] and insecure about the hidden rules of enjoying art [4]. This image of the museum as an intimidating white box is particularly affecting adolescents. They fear being judged for not understanding the museum\'s content or expect to be bored by it. In response, the museums take the position that to attract adolescents, an exciting experience is needed that deviates from educational (informational) purposes entirely and focuses mainly on pushing the limits of what is considered a museum visit.\r\n\r\nAt face value, the ideas of a novel user experience ‘blending in’ to the existing museum and the idea of ‘pushing the limits of the museum visit’ are at odds with each other, and this is a tension we experienced throughout this design case. We wanted to deliver something that would engage the intended audience, but we wanted to do so in such a way that depended heavily on the existing museum context. This tension forced us to rethink the notion of ‘blending in’ and to operationalize it in such a way that it could be used to generate design alternatives and to evaluate (early) concepts. More specifically, we needed to come up with an operationalization that supported the formative evaluation of our first design.\r\n\r\nAccordingly, this paper focusses on the following contributions:\r\n\r\nA design case of a mixed reality experience for an art museum and its evaluation.\r\nOperationalizing the notion of experience blend into a qualitative framework that could be used in a generative and evaluative manner and an illustration of its use to illuminate the design tensions in our case.\r\nIn the remainder of this paper, we will first highlight related work and show how it informed our operationalization of experience blend. Next, we will describe the design of ‘the Cluefinder’, a mixed reality scavenger hunt within the museum, followed by a discussion of the user test and its results. In this evaluation study, we made use of the experience blend framework. We will close the paper with a critical examination of the pros and cons of the experience blend framework and future work.\r\n\r\n2 Related Work\r\n\r\n2.1 Other frameworks\r\n\r\nOur departure point in the design of the Cluefinder (and other design cases in the larger RheijnLand.Xperiences project) was the intuitive notion that these new digital experiences should fit into the existing museum context and utilize and enrich the existing, visiting experience. All too often when we visit museums, we encounter designs that are rather loosely related to the museum context. However, it is non-trivial to conceptualize this intuition in a way that is actionable for design, and that can be evaluated in the end.\r\n\r\nSeveral authors have expressed a similar viewpoint and have offered conceptualizations already. Van Turnhout et al. [17] for example, propose the notion of experience blend as a way to approach the relations between existing contexts and the digital experiences, designed for those contexts. The two forms of experience blend identified by van Turnhout et al. [17] are experience stacks and contextualized experiences. With experience stacks, they express the idea that a novel experience - such as a treasure hunt in a theme park - can be seen as a new layer on top of the existing experience which could demand too much attention and therefore detract from the current theme park attractions. With contextualized experiences, they refer to the idea that an experience could derive much of its meaning from the context in which it is placed - much in the way an indicator light derives its meaning from the device it is placed on. We find this notion of experience blend to be elegant and to the point, but the forms of blend it highlights are too general and loosely defined to be useful in design and evaluation of a project like ours. We believe the proposed forms of experience blend are two extremes on a more elaborate scale that deserves operationalization.\r\n\r\nThe related concept of blended spaces was proposed by Benyon et al. [3]. Benyon builds the notion of conceptual blending, and then suggests designing mixed reality experiences as blended spaces, thus creating one experience from the intertwinement of a real and digital space. This concept of an experience as a blended space suggests elements that can be designed: ontology, topology, volatility, and agency. Benyon demonstrates this notion can be used to design novel experiences [13]. The strength of the blended spaces framework is that it identifies a set of essential elements that could act as a structure to think about the division of labor of the real and digital components of a mixed reality experience and that act as a condensation point for design decisions. However, we think there is more to user experiences than space, and we find the space metaphor limiting in this respect. Moreover, the notions of ontology, topology, volatility, and agency are difficult to grasp, and this hinders their application as a generative framework.\r\n\r\nA third proposal is the trajectories framework, which builds upon the storytelling aspect of mixed reality experiences. Benford et al. [1] conceptualize mixed reality experiences as a trajectory through multiple hybrid elements: space, time, interfaces, roles. The trajectories framework has been used in the design of a sizable set of mixed reality experiences [2] and was used in multiple ways (e.g., as a descriptive, generative and evaluative framework [20]). To us, the main strength of the trajectories framework is its acknowledgment of a narrative, time-based component in a user experience. However, despite its recognition of hybrids, the framework focusses mainly on the design of the novel experience and does not specifically address the difficulty of blending novel experiences into an existing environment. Moreover, the framework is quite elaborate, which makes it challenging to make a step from mapping out a trajectory to coming to a global judgment of its qualities - in our case in terms of experience blend.\r\n\r\n2.2 Synthesis\r\n\r\nAs different existing frameworks touch upon various aspects of the experience, a synthesis was required. We strived for a framework that would offer concrete condensation points for design decisions (like the trajectories and the blended spaces frameworks), but also one that would focus directly on combining the existing experiences with new ones. Moreover, we strived for simplicity and comprehensiveness so the framework could also be used in a generative way. At the same time, it needed to offer enough structure to be used as an evaluative framework. The resulting framework provides a layered protocol of four experience design layers: motivations, location, narrative, and actions, for which the interplay of the existing, and the novel experiences can be examined.\r\n\r\nAt the top level of abstraction, we propose to consider motivations. Motivations describe the preexisting reason for a visit – why does the visitor want to partake or visit and what are their expectations for the experience. According to Falk [7] motivations for visiting a museum come forth out of a complex dynamic between personal and/or sociocultural needs and the knowledge of a museum that could potentially fulfil said needs. The target audience described in this paper often does not get an active say in the decision of visiting a museum. The adolescents are often brought to museums in the context of a school excursion or by their families. For many members of the target audience a visit to an art museum does not align with their personal needs. This misalignment is furthered by prior experiences that have created the image of art museums to be stuffy and boring [7].\r\n\r\nThe designed experience can add new reasons and expectations for the visit. This new motivation could be either complementary or disruptive. An application that invites participants to share art with friends [16] blends with this existing motivation of the museum, while a game that awards points by quickly scanning all art pieces would blend less. The motivations layer can be compared to the notion of experience stacks as van Turnhout et al. [17] describe them.\r\n\r\nThe next level is location. Our notion of location is similar to Benyon\'s [3] idea of space and encompasses all objects and physical surroundings. In the case of museums, this means this may be the architecture, the different rooms an object in the space such as benches to rest on and the artwork itself. Newly designed experiences may add new (virtual) objects or spaces for the experience. The new and the existing location may, again, be strongly or poorly aligned. An application that adds information to existing art objects through augmented reality is better aligned with the existing location than a generic application like Pokémon Go, whose virtual content would not be related to the existing museum location.\r\n\r\nThe third layer is narrative. Every location has its own stories to tell. Some sites have a higher story density than others - art museums tend to be relatively thin regarding narratives, while history museums are more dependent on stories. A tour guide that helps reveal the existing narrative with background information of a curator\'s justification for the placement of a piece of art aligns well. For a history museum in the same project, we designed an experience in which a historic character decides to leave her painted portrait and move to the digital realm out of boredom of being trapped in an old painting. This is an example of a new narrative that does not particularly connect to the existing (historical) narrative but does offer a different visiting experience for the particular location. The trajectories framework provides a more elaborate dissection of the narrative level [1].\r\n\r\nThe final action layer deals with the level of the interaction design, specifying the actual user actions that may be prompted or guided by a narrative. The existing actions may be quite basic in the case of a traditional art museum, like positioning yourself in front of a painting to look at it more closely or moving towards the nameplate for additional information. In short, alignment at the levels of actions would mean that the actions make sense and are appropriate in both the existing and novel experience. An augmented view that reveals footsteps of previous visitors may offer new actions in the line of looking to the ground and following a trail but may also prompt or reinforce existing actions of standing in alternate locations that may offer a different view on the artwork. This layer is not explicitly centralized in the related frameworks but touched upon in both the trajectories [1] and the blended spaces [3] framework.\r\n\r\nWithin the design process, we suggest to first define the contents of each layer of the existing experience. Each layer of the new experience can be designed in conjunction with the corresponding layers of the existing experience. Apart from this comparison within layers, the framework also allows examining how different layers of an experience are aligned. It can be used as an evaluative framework by clustering user comments relating to the (absence of) blend in the eight cells of the table. We must stress here that we consider this framework to be a first version which may have face-validity but must be put to the test both as a generative and as an evaluative framework and subsequently reiterated.\r\n\r\nFigure 1 provides an overview of the framework with examples from the Rider Spoke experience [2]. In Rider Spoke, the audience is invited to explore the city by bike. The user is asked questions and asked to record their reflection on life through an audio message at one of the ‘hiding spots’ at specific locations throughout the city. A mounted screen on the bike shows your location and hiding spots of other users that offer audio content. The density of diagonal lines is used to indicate the level of blend present between the existing and new layers.\r\n\r\nFigure 1:\r\nFigure 1: Proposed blend framework illustrated by the example of the Rider Spoke experience\r\n3 Design\r\n\r\n3.1 Context: Museum Kurhaus Kleve\r\n\r\nOne of the museums that we designed for in the RheijnLand.Xperiences project is Museum Kurhaus Kleve (see Figure 2). The museum houses a standard collection of classical and contemporary art as well as room for several temporary exhibitions. The museum feels very ‘museum-like’; a building whose stately classical architecture itself almost demands respect. You become fully aware of any sounds you make as they are amplified and echoing in the large, otherwise silent, solemn halls. The artwork presents itself to you without much context, information, or guidance, while the security guards present make you feel cautious about not doing anything inappropriate.\r\n\r\nFigure 2:\r\nFigure 2: Images of Museum Kurhaus Kleve [10, 11, 12]\r\nWe can expect that adolescent visitors are not attracted by the formal atmosphere of the museum with its implicit rules. Idema [8] would most certainly classify this as a white box experience. It was our goal to redesign the museum visiting experience to be more approachable for the target audience, while still respecting the existing experience and audience.\r\n\r\n3.2 Design approach\r\n\r\nBecause we realized the intended design goal of creating an exciting experience for adolescents seemed to mismatch with the currently visiting experience so much, we felt we had to break open the design space, and discuss solutions that were likely to lie far outside of the usual frame of reference of the stakeholders.\r\n\r\nTo this end, we used the design method 1:10:100 [18], an approach to involve stakeholders in an open-ended design project. In 1:10:100, a design challenge is tackled in 3 iterations with increasing timespans (1, 10 and 100 days respectively, or equivalents). In each iteration, traditional design user-centered design activities like research, specification, ideation, prototyping, and testing are being used to come to an intermediate solution. Especially in the earlier design iterations of the 1:10:100, we actively involved end-users. Cultural probes and interviews were used to gather insights about our target users. From this, we learned adolescents might feel intimidated and bored by the art museums when there is no clear idea or guidance on what to do. Also, the way their peers see them plays an essential role in their user experiences in general – hence, if the new experience would make them look bad or silly in front of other visitors, they would not go through with it. Furthermore, the results of the probes illuminated that giving the adolescents a clear goal during their museum visit would make them feel more self-assured. These insights helped inform our design decisions and were used to improve, build upon, or completely change the direction of the final designs. The designed artifacts were tested regularly with small groups of end-users to validate the chosen design decisions.\r\n\r\nIn 1:10:100 after each iteration, insights from the design project and intermediate solutions are discussed with the stakeholders, which will lead to a reframing of the solution space and challenge [18]. In this case, during these meetings, the design focus gradually shifted from giving the adolescents tools to help them interpret the art better, to the idea of giving a fundamental twist to the museum visit. We wanted to create an environment in which the adolescents felt welcome to break some of the rules that usually apply in art museums. The new experience had to get the adolescents into an active and exploring mindset – in an activity that was unexpected in the context of an art museum and more fun. This goal suggested a design that was, by its very definition, not blended well with the existing museum visit; the assumption at this point of the design process was that engagement of the adolescents and creating an enjoyable activity was far more important than blending the new experience well with the existing one.\r\n\r\n3.3 Final design\r\n\r\nWithin this new framing, we developed the Cluefinder. Instead of wandering in the museum admiring art, the Cluefinder puts adolescents into the role of a detective who must solve the mystery of a stolen painting. The adventure starts at a specific location in the museum, where an empty spot on the wall next to a nameplate is lined off with police tape, hinting the theft of the painting. Here, players are invited to download the app and use a physical extension named ‘the Cluefinder’, which holds the users’ phones, to find augmented reality clues that are scattered throughout the museum. Finding the clues will allow players to solve the mystery of the location and identity of the thief.\r\n\r\nWe will describe the experience of the Cluefinder in detail according to the four layers of the experience blend framework: motivation, location, narrative, and actions. The framework will show the design to not be very blended as was intended.\r\n\r\n3.3.1 Motivations. The scavenger hunt motivates players to solve a mystery: where is the stolen painting? This motivation does not blend well with the existing motivations of a typical museum visit, such as enjoying art. We felt it was necessary to alleviate some of the negative preconceptions of the museum visit.\r\n\r\nThe scavenger hunt puts the adolescents in charge and allows them to work together. We felt this would create a safe space wherein they were not expected to be quietly wandering the halls, but to play and talk. One positive alignment between the existing motivations of the art museum and the scavenger hunt motivation was that a scavenger hunt stimulates inquisitive behavior, which is also part of enjoying art.\r\n\r\n3.3.2 Location. To support the detective story, we created a fictional crime scene in the museum, by setting up an empty space where an artwork once hung alongside other artworks including a plaque describing the stolen artwork. Augmented reality ‘clues’ were then placed as a route throughout the museum. These clues were: 1) a heist plan the thief had left behind, 2) a runic graffiti made by the thief to provoke the detectives, 3) a decoder to help solve the runic graffiti, and 4) a virtual sculpture inspired by the existing sculptures of Ewald Mataré present in the museum, which had the current location of the painting scribbled all over its surface. These clues aligned with the detective story and were thematically somewhat related to the museum. But this content was created to suit the scavenger hunt and not as an extension of the existing content of the exhibition.\r\n\r\nPart of the game was a tangible device in the form of a physical handheld device in which a smartphone was inserted, to create the general aesthetic and affordances of a detective\'s magnifying glass. This device aligned with the detective story but also with the inquisitive attitude needed in a normal museum visit.\r\n\r\n3.3.3 Narrative. The museum\'s own location plays a central role in the game narrative of a stolen painting. However, there are also misalignments. First, the narrative style is very different from the art museums natural way of presenting its work. Art museums typically use thin and open narratives. Although there is information and clues about the choices a curator made in the exhibition, much is left to the visitors’ imagination– in particular how to appreciate the art. The story in the Cluefinder was much more closed and denser – there was a specific outcome, enforced by the clues in the storyline. Second, the scavenger hunt story did not extend the existing narratives in the museum about the history of the location (a bathing place) or the exhibits. The Cluefinder story would fit any art museum, not just Kurhaus Kleve.\r\n\r\n3.3.4 Actions. The user\'s actions change from wandering through the museum and looking at artworks to searching for the virtual clues. This shift in objective and thus behavior introduces an urgency of action and a new tempo to the experience. Whereas visitors normally set their own speed in a museum, the new goal of finding the stolen painting and catching the thief made them more selective in where in the museum they would allow themselves to pause and when to hurry.\r\n\r\nMoreover, the introduction of the interactive Cluefinder interface breaks with the passivity of the existing experience.\r\n\r\n4 Evaluation\r\n\r\n4.1 Experiment setup\r\n\r\nTo test the Cluefinder experience, we set up an experiment. Apart from testing the technology and obtaining formative feedback on the designed clues and interfaces, we were anxious to test the design solution that resulted from the “100” iteration more rigorously. We wanted to assess whether the designed solution succeeds in delivering the primary design goal of providing a more approachable visiting experience for adolescents. Moreover, we were interested in the notion of experience blend, at least in the sense that the designed experience would interfere with the existing one in an undesirable (or desirable!) way. We used the experience blend framework as a post-hoc structure to analyze the results; we did not structure our data collection according to the framework.\r\n\r\n4.2 Prototype\r\n\r\nWe developed a prototype to allow for field tests with the target audience. The prototype consisted of a mobile application built in the Unity framework that was installed on the users’ mobile phones running Android OS. The app used the phone camera to deliver an augmented reality view that overlaid virtual objects over the real world near specific places of interest. These places of interest were detected through beacons. Feedback regarding proximity towards these places was shown in coarse granularity through blinking lights on the screen. The player\'s progression was shown through a collection of discovered clues with information that provided hints towards the next location. We placed the beacons throughout the museum in specific locations suited to the designed clues. The beacons themselves were hidden from sight.\r\n\r\n4.3 Data gathering\r\n\r\nFor our test audience, we recruited 170 first-year students from our faculty between 16-23 years old (see Figure 3). We chose first-year students so they would still have little knowledge of media technology, design, or usability. Compared to the general target group, this group may thus be skewed towards higher education levels and more positive attitudes towards technology or design. The excursion to the museum and participation in the test procedure was presented to the participating students as an educational experience, part of their studies to become a media professional. Before the evaluation students were told that they would be asked to evaluate an application that was intended to get adolescents interested in visiting the museum. They were not briefed or educated on the concept of blend.\r\n\r\nFigure 3:\r\nFigure 3: Adolescent during user test in museum holding the Cluefinder\r\nWe ran tests in 4 consecutive days, which meant testing with roughly 50 students each day. Each day, the students were randomly divided into groups with five specific roles:\r\n\r\nField Testing: this person would be the prime test subject and visit the museum using the Cluefinder\r\nObserver 1: interaction & route: tasked with observing the tester and documenting interaction with the Cluefinder and the route throughout the museum\r\nObserver 2: (human) eye-tracking: tasked with observing the tester and documenting where the tester\'s focus of attention lies; we differentiated for example between the virtual focus (in the app) and real-world focus (outside the app)\r\nObserver 3: attitude and emotion: tasked with observing the tester and documenting the tester\'s attitude and emotion\r\nObserver 4: thinking-out-loud: tasked with prompting the tester to think out loud and record his/her thoughts\r\nOf the 170 students recruited, 45 took the role of ‘tester’, while the rest were divided among the different types of observers. Although only the testers operated the application, the students with the observing roles experienced the museum visit ‘by proxy’ and were therefore still able to provide valuable personal feedback themselves. While this division of labor into \'players\' and \'observers\' may have been artificial, our impression during the experiment was that students took the activity on as a group activity in which the different roles got backgrounded - at least during play time. In the analysis students resumed their assigned roles. We do not expect this setup has influenced the experiment a whole lot. Still, an individual evaluation would perhaps have been more authentic.\r\n\r\nFor each of the roles, we provided detailed instructions and templates to help guide them in how, when, and what to document. We structured the templates to include all significant steps in the user experience, such as receiving the mission, searching and finding each of the clues, and solving the mystery. As an example of further guidance, we provided a template with the Geneva Emotions wheel for observer 3 [14]. We moderated and assisted all activities when needed.\r\n\r\nBecause we wanted to compare our newly designed experience to the existing experience, we let each group run two separate tests; one as the regular, existing museum visit, and one with the Cluefinder experience.\r\n\r\nThe test runs would take about 20 to 30 minutes. Afterward, the groups engaged in discussions with each other about the observed results. This discussion allowed the groups to interpret their findings more accurately by asking each other questions about the observed behavior and triangulating results. For example, observers focusing on where the attention of the tester lied, could ask further questions regarding what made them change their focus of attention.\r\n\r\nNext, the observers of each group were asked to interview the field tester, guided by a questionnaire we provided. The questionnaire had questions about the test participants general attitude towards museums, and the perceived experience before, and after the visit. Finally, the groups were asked to map all their findings on a user journey, marking the most important findings.\r\n\r\n4.4 Analysis\r\n\r\nWe analyzed both the interviews and the observer data in an interpretive manner. We first organized all data to compare observations and comments. This way, we were able to evaluate the data in the context of each group of testers. Furthermore, this helped us detect recurring and unexpected comments, which we then clustered into categories. In this second analysis phase, the four blend layers proved to be a useful means of organizing much of the qualitative data. The layers covered all user comments on the topic of blend and thus allowed us to reflect on our design decisions for each layer. Considering they could comment on anything they encountered during the visit, both the high amount of comments regarding blend and the good coverage of the four layers of this diverse set of blend comments surprised us. In the post-test questionnaires the 45 testers gave a total of 191 suggestions on the improvement of the experience, of which 28 suggestions were regarding blend.\r\n\r\nThe user journeys required a two-step analysis. We averaged the general trajectory and grouped the data according to their corresponding points in the user journey. Recurring comments were added to one summarized user journey that included both the user experience of the Cluefinder test and the existing museum visit for comparison (see Figure 4).\r\n\r\nFigure 4:\r\nFigure 4: User journeys of the Cluefinder experience including a selection of user quotes\r\n5 Results\r\n\r\nIn this section, we discuss the results of the user test and relate them to our proposed theoretical framework for blended experiences. The results are collected in the blend framework (see Figure 5). Different levels of blend or lack thereof are visualized within the table. The right column highlights our improvement plans after receiving the users’ feedback.\r\n\r\nFigure 5:\r\nFigure 5: Evaluation of test results within the proposed framework\r\n5.1 Motivations\r\n\r\nIn this layer of our blend framework, we saw perhaps the biggest conflict between the two experiences. The designed experience begins by introducing the test participants to their new mission, without any connection to their existing goals and expectations of the museum visit. Contrary to our expectations, the adolescents experienced this sudden change of purpose as disturbing in the flow of the existing experience. For example, one adolescent questioned the experience; wondering: “What is better [for the museum], youngsters who come here to play a game, or visitors who come here for the art?”\r\n\r\nAlthough we specifically designed the Cluefinder experience to clash with the existing experience, our target users were rather negative about it. They felt frustrated by the unexpected introduction of a game into their own expectations of the museum visit. A mismatch in motivation without a design in place to bridge this gap has consequences for the blended experience in the layers below.\r\n\r\n5.2 Location\r\n\r\nAs mentioned earlier, the AR-clues were designed to have minimal connections to the artworks in the museum. Furthermore, the architecture of the museum was used only to create a fitting route through the museum. We expected that the adolescents would become immersed in the game but still feel free to look around and enjoy the artworks around them. However, the adolescents felt like the scavenger hunt made them focus mainly on the smartphone and the ground which they had to scan for the clues. While they still noticed the artworks around them, a recurring comment was that the new experience distracted too much from the existing content – for the adolescents turned out to have more interest than expected. When asked whether the adolescents would recommend the experience to friends and family, for example, many adolescents said that they would not recommend it, “because you see very little of the museum or the artworks.”\r\n\r\n5.3 Narrative\r\n\r\nBecause of the thin nature of the existing narrative environment, we were curious about how the testers experienced the newly introduced narrative and how they related it to the context of the museum.\r\n\r\nMany users asked for a more extensive narrative introduction. For example, one tester said that it felt odd to them that the user “gets suddenly dropped into the role of the detective” and that “a bit of an introduction would make it more exciting.”\r\n\r\nThe new experience creates a clash in the Motivations layer between the expectations of the adolescents and the newly introduced detective role they need to assume to play the game. This clash could be resolved with a narrative bridge blending the role of visiting a museum and the new detective role the adolescents are taking on. The misalignment between the two kinds of narratives seems to have a bigger impact than we expected. The storyline of the Cluefinder is much denser than the rather undefined narratives the exhibition itself. By interweaving the detective story more with the history of the museum and the stories told by the artworks, the blended narrative can enrichen and shed light on parts of the existing experience that are currently invisible.\r\n\r\n5.4 Actions\r\n\r\nThe testers commented on problems in the functionality of the prototype. Instabilities of the beacons and the app led to a few early terminations of the scavenger hunt, either from frustration or not being able to find the clues needed. While we assisted where possible to ensure a smooth user experience, these technical problems influenced data collected on this layer of blend.\r\n\r\nFurthermore, students liked that “the Cluefinder led them through the whole museum”, and that it adds to the museum visit by introducing “puzzles that one needs to figure out.” The students found these two activities to work well together. However, the virtual clues on the Cluefinder distracted the students from looking at art, which is the essential action expected for the existing experience. Thus, we may conclude that, while the basic user actions of both experiences are integrated, they are not yet blended well. Further fine-tuning is needed to have the two enhance each other.\r\n\r\n5.5 Other findings\r\n\r\nStudents reported similar journeys during the Cluefinder test and the museum visit test – when averaged, both journeys stayed relatively close to neutral for the first half of the test and then declined into a negative experience. However, the adolescents reported quite different dynamics between the experience without and with the Cluefinder. The journey with the Cluefinder revealed a pattern with more extreme positive and negative peaks coinciding with the moments the testers were finding and searching clues respectively. The testers experienced pride, happiness, and surprise whenever they found a clue, while they felt frustrated, bored, or confused when they didn\'t. The emotional range of the museum visit without the Cluefinder consisted mostly of interest, boredom, and confusion.\r\n\r\n6 Discussion\r\n\r\n6.1 Design of the Cluefinder\r\n\r\nMuch to our surprise, our strategy to break with the experience blend aesthetic that formed a basis of the project turned out to be invalid. Most of the comments of the students who tested the experience pertained to a lack of blend at all levels of the experience. A wish for a blended experience may hold for many museums. When visiting a museum, users hope to experience something that they couldn\'t experience anywhere else. In retrospect, we should not have abandoned the blend aesthetic so quickly, but we should have tried to achieve the goals of a surprising engaging experience for adolescents while maintaining blend. Our redesign of the Cluefinder focusses on achieving this.\r\n\r\n6.2 The utility of the blend framework\r\n\r\nWe operationalized the notion of a blended experience as a layered protocol of motivations, location, narrative, and actions in the evaluation of our work. The framework also lend itself for structuring data for analysis. We found in this study that user comments about blend in some way were easy to cluster into these different blend layers. As such, the framework can support a qualitative analysis of a user test, and at first sight, it seems to cover the full breadth of experience design. At least the user comments did not ‘suggest’ other layers of blend that we overlooked. A quantitative evaluation of blend at each layer is one of our future goals.\r\n\r\nWe feel the layers in this framework can also be a valuable asset earlier on in the design process of mixed reality applications. By first analyzing the existing experience, the new experience can be designed according to the design goals – either thoroughly blended and interlocking or (purposely) not blended in one or multiple layers. We now possess a tool that aids in decisions about experience blend, allowing ample room for the nuances that exist between extremes of a fully blended or unblended experience. Since all layers are connected and dependent on each other, designers can develop a grasp of the effects their decisions have on the overall experience. We found that potential misalignments between each layer of the existing and newly designed experiences can be identified easily and discussed accordingly.\r\n\r\nA disadvantage of the framework may be that the layers were quite broad, and within each layer, different arguments could be formulated that positioned a particular design choice as more – or less – blended. Other frameworks, such as blended spaces [3] or trajectories [1] may be more precise. If the framework is used as a generative tool, this need not be a problem. It still stimulates a focused design discussion and a clear design rationale [5]. However, for its evaluative role, this openness is less desirable. One way forward is extending the framework with an identification of different blend ‘forms’ for each layer and guidance on identifying these forms.\r\n\r\n6.3 Future work\r\n\r\nAs many of the qualitative comments of the students in the test pertained to the notion of blend, we believe it is a concept that could be used to compare and evaluate different user experiences in the cultural sector. The larger team of the RheijnLand.Xperiences project is currently creating eight different experiences for eight museums in the Rhine-Waal region. We think the experience blend framework would be a valuable way to compare these different designs. To this end, we are currently revisiting and reiterating the different layers to see how they could be quantified in user questionnaires. In the future, this quantitative version of the framework could help in empirically evaluating whether a higher level of blend leads to a better user experience.\r\n\r\nREFERENCES\r\n\r\nSteve Benford, Gabriella Giannachi, Boriana Koleva, and Tom Rodden. 2009. From interaction to trajectories: designing coherent journeys through user experiences. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \'09). ACM, New York, NY, 709-718. DOI: https://doi.org/10.1145/1518701.1518812  \r\nSteve Benford and Gabriella Giannachi. 2011. Performing mixed reality. The MIT Press, Cambridge, Massachusetts.  \r\nDavid Benyon, Oli Mival, and Serkan Ayan. 2012. Designing blended spaces. In Proceedings of the 26th Annual BCS Interaction Specialist Group Conference on People and Computers (BCS-HCI \'12). British Computer Society, Swinton, UK, 398-403.  \r\nMarc Calmbach, Silke Borgstedt, Inga Borchard, Peter Martin Thomas, and Berthold Bodo Flaig. 2016. Wie ticken Jugendliche 2016?Springer, Wiesbaden.  \r\nJohn M. Carroll, and Mary Beth Rosson. 2003. Design rationale as theory. In HCI models, theories and frameworks: Toward a multidisciplinary science. Morgan-Kaufmann, San Francisco, 431-461. DOI: 10.1016/B978-155860808-5/50015-0  \r\nVanessa Cesário, António Coelho, and Valentina Nisi. 2018. Design patterns to enhance teens\' museum experiences. In Proceedings of the 32nd International BCS Human Computer Interaction Conference. BCS Learning and Development Ltd., Belfast, UK, 159. DOI: 10.14236/ewic/HCI2018.160  \r\nJohn H. Falk, Lynn D. Dierking. 2016. The Museum Experience Revisited. Routledge, New York, USA.  \r\nJohan Idema. 2014. How to Visit an Art Museum. BIS Publishers, Amsterdam.  \r\nMarjolein Jacobs, Jasper Jeurens, Marjolein Regterschot, Koen van Turnhout, and René Bakker. 2016. Two countries, eight museums: aiming for cross-cultural experience blend. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct. ACM, New York, 1498-1502.  \r\nMuseum Kurhaus Kleve. n.d. Artus Quellinus d. Ä., Pallas Athene in der Säulengalerie des Museum Kurhaus Kleve, 1660. Retrieved from https://www.museumkurhaus.de/  \r\nMuseum Kurhaus Kleve. n.d. Die Wandelhalle des Museum Kurhaus Kleve. Retrieved from https://www.museumkurhaus.de/  \r\nMuseum Kurhaus Kleve. n.d. Die Treppe in der Wandelhalle des Museum Kurhaus Kleve. Retrieved from https://www.museumkurhaus.de/  \r\nBrian O\'Keefe and David Benyon. 2015. Using the blended spaces framework to design heritage stories with schoolchildren. In International Journal of Child-Computer Interaction 6 (2015). Elsevier B.V., Amsterdam, 7-16. DOI: 10.14236/ewic/hci2014.10  \r\nVera Shuman, Katja Schlegel, and Klaus R. Scherer. 2012. Geneva Emotion Wheel rating study (Report). University of Geneva, Swiss Center for Affective Sciences, Geneva, Switzerland.  \r\nTonguc Ibrahim Sezen, Ido Iurgel, Nicolas Fischöder, René Bakker, Koen van Turnhout, and Digdem Sezen. 2018. A Top-Down Narrative Design Approach for Networked Cultural Institutions. In Proceedings of the 11th International Conference on Interactive Digital Storytelling (ICIDS 2018). Springer, Berlin, Germany.  \r\nJocelyn Spence, Benjamin Bedwell, Michelle Coleman, Steve Benford, Boriana N. Koleva, Matt Adams, Ju Row Farr, Nick Tandavanitj, and Anders Sundnes Løvlie. 2019. Seeing with New Eyes: Designing for In-the-Wild Museum Gifting. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI \'19). ACM, New York, NY, USA, Paper 5, 13 pages. DOI: 10.1145/3290605.3300235  \r\nKoen van Turnhout, Sander Leer, Emiel Ruis, Lambert Zaad, and René Bakker. 2012. UX in the Wild: Experience Blend & Embedded Media Design. In The Web and Beyond 2012 16th Chi Nederland conference. Amsterdam, Netherlands.  \r\nKoen van Turnhout, Stijn Hoppenbrouwers, Paul Jacobs, Jasper Jeurens, Wina Smeenk and René Bakker. 2013. Requirements from the Void: Experiences with 1: 10: 100. In Proceedings of the 3rd Workshop on Creativity in Requirements Engineering. Essen ICB, Essen, Germany.  \r\nVasiliki Tzibazi. 2013. Participatory Action Research with young people in museums. Museum Management and Curatorship 28, 2, 153-171. DOI: 10.1080/09647775.2013.776800  \r\nRaphael Velt, Steve Benford, and Stuart Reeves. 2017. A survey of the trajectories conceptual framework: investigating theory use in HCI. In Proceedings of the 2017 CHI conference on human factors in computing systems. ACM, New York. ',1,'Lange','Vera Lange, Marleen van Beuzekom, Michel Hansma, Jasper Jeurens, Willemiek van den Oever, Marjolein Regterschot, Jille Treffers, Koen van Turnhout, Tonguc Ibrahim Sezen, Ido Iurgel, and René Bakker','Vera Lange *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nMarleen van Beuzekom *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nMichel Hansma *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nJasper Jeurens *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nWillemiek van den Oever *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nMarjolein Regterschot *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nJille Treffers *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nKoen van Turnhout *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nTonguc Ibrahim Sezen *(Hochschule Rhein-Waal, Germany)*<br>\r\nIdo Iurgel *(Hochschule Rhein-Waal, Germany)*<br>\r\nRené Bakker *(Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*',NULL,0,'10.1145/3363384.3363469','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,55,10,NULL,NULL,0,25),(15,'lalone-a-vision-of-augmented-reality-for-urban-search-and-rescue','2019-09-02 15:24:57','2019-11-14 14:05:50','2019-09-02 15:24:57',NULL,1,'published','[]','A Vision of Augmented Reality for Urban Search and Rescue','Search and rescue (SAR) operations are often nearly computer-technology-free due to the fragility and connectivity needs of current information communication technology (ICT). In this design fiction, we envision a world where SAR uses augmented reality (AR) and the surplus labor of volunteers during crisis response efforts.\r\n\r\nUnmanned aerial vehicles, crowdsourced mapping platforms, and concepts from video game mapping technologies can all be mixed to keep SAR operations complexity-free while incorporating ICTs. Our scenario describes a near-future SAR operation with currently available technology being assembled and deployed without issue. After our scenario, we discuss socio-technical barriers for technology use like technical fragility and overwhelming complexity. We also discuss how to work around those barriers and how to use video games as a testbed for SAR technology. We hope to inspire more resilient ICT design that is accessible without training.','Nicolas LaLone, Sultan A. Alharthi, and Z O. Toups. 2019. A Vision of Augmented Reality for Urban Search and Rescue. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363466](https://doi.org/10.1145/3363384.3363466 \"DOI for the article \'A Vision of Augmented Reality for Urban Search and Rescue\'\")','Figure 1: In this design fiction for future search and rescue operations: On the left is the view of where a house of interest is located through the goggles of a search and rescue team member. On the right is a painted target from the perspective of the team that is marking areas of interest with color-coded tags (e.g. green for potential human residents, yellow for areas with potential danger such as packs of animals, red for remains in the open).\r\n1 INTRODUCTION\r\n\r\nThis design fiction establishes a near-future scenario within which augmented reality (AR) is used in search and rescue (SAR1) operations in concurrence with an assemblage of currently separate, yet existing technologies. We say existing technologies because current information technology is not typically seen as resilient to the types of conditions a SAR operation experiences [20, 22]. As a result, SAR operations tend to use more robust and reliable technologies like radios, paper maps, handheld GPS maps, and paper documentation [1, 9, 27]. This technology is juxtaposed against the rapid development of information communication technology (ICT) in society writ large [8].\r\n\r\nThe resulting expectation that crisis response should embrace the use of ICTs in addition to digital mapping technologies, cellular technology, and connectivity that can connect to crowdsourcing platforms [11, 20, 22]. We are inspired by video games, crowdsourcing disaster, and current technology needs in crisis response [2, 7, 22, 29]. Our spaces of inspiration lead us to urge mobile ICT (e.g., smartphones, wearables) developers to use extended battery life and the ability to withstand the physical rigors as selling points\\rlap.2 This will foster more robust ICT design and use in SAR operations. Once ICT use is common in SAR, the connection between existing crowdsourcing efforts [23] in crisis response to AR is inevitable, as one of the most significant barriers to this new design trend is access. By working toward this common goal\\rlap,3 the resilience of humankind within, during, and after disaster will be increased.\r\n\r\n2 DESIGN FICTION\r\n\r\nThe first footage of the aftermath of the hurricane4 began to creep into social media and online community feeds shortly after the rains had weakened enough for unmanned aerial vehicles (UAVs or drones) to take flight [12, 14, 17]. Drone operators – recently outsourced and certified by FEMA\\rlap,5 much like NASA6 began to rely on SpaceX [5, 13] – began to fly over and photograph the impacted areas. The image feed was examined in nearly real-time as these satellite-connected drones sent images to public mapping platforms [25]. Members of this certificate-gated community (see: [7]) began to pour over the assembled map of a vast metropolitan region that had been devastated by flooding, winds, and intense rain [12, 17, 25]. It was the biggest hurricane anyone had seen that year; the hurricane, combined with mandatory evacuations, had made this coastal city seem post-apocalyptic.\r\n\r\nHurricanes’ courses can be somewhat predicted, so, in advance of the incident\\rlap,7 SAR teams were stationed outside the expected area of impact. As the drone operators did their work, their first task was to identify an area for the base of operations (BOO8). With candidate locations tagged by the community, the incident commander identified an appropriate location. The convoy of tractor trailers and personnel began to move in and establish the BOO.\r\n\r\nThe drone operators continued their work by starting to identify areas of interest. Online mapping communities also began processing and preparing information for the SAR teams for their initial deployment. They deployed a connectivity balloon – a lightweight drone equipped to provide wireless network communication – over the center of the area of interest to provide a direct data feed from the mapping drones to the BOO [3, 15].\r\n\r\nAs they did, those same drone contractors and their respective communities painted 75 targets. These targets would be areas that needed investigation by teams on the ground. Their targeting and connectivity was dependent on the connectivity balloon. The contractors and communities used a set of heuristics to develop targets, including:\r\n\r\nhow changed the area was from its most recent aerial photograph (e.g., buildings that had collapsed or been washed away);\r\nplaces that looked like they had been particularly flooded (e.g., collections of cars and other debris, buildings surrounded by water);\r\nlocations that appeared to no longer be reachable by safe paths (e.g., places where someone might have sheltered, but would now no longer be able to leave);\r\nlocations with messages from people trapped (e.g., with “HELP!” painted in an obvious place);\r\nlocations with human or animal bodies in the open; and\r\nlocations that seem to be sheltering humans or large numbers of animals.\r\nThose 75 targets covered 400 square miles of what used to be an urban area. Both workers in the BOO and search and rescue operatives are able to make use of the marked targets.\r\n\r\nThis aerial perspective is not perfect, however, and a ground search still needed to be carried out. In some cases, areas are obscured from drones’ views; in other cases, connectivity is insufficient to support moving the necessary data around. In the latter case, observations were delayed until the drone could move back into a connected area.\r\n\r\nThe BOO consists of a set of tents, mobile bases, and equipment depots that support operations and planning. A command base serves as the main gathering point within the BOO; out of this building, command decisions and plans are made, incorporating information from the field and from the incident command post, a permanent installation that is remote from the incident. This vehicle has been equipped with a light table [9], in addition to antennae that could accept the signal from the balloon. The light table displays all 75 targets, in addition to the signals for each of the SAR team gathered at the edge of the territory waiting for the go ahead to begin their activity.\r\n\r\nJudging from the expected coverage circle, it seemed like there would be few dead areas as the SAR teams attempted to get to each of the investigation sites. Each SAR team member would note and triage other objects of interest along the way.\r\n\r\nEach member of the team wore their standard gear; the targets would be visible at the BOO as well as in the real world through specialized goggles that the SAR team used. Each had personal protective gear (e.g., helmet, rescue boots), radio, and backpack with a first aid kit, rain gear, a shovel, some rope, and enough water for them and any potential rescues they might find [10]. In addition to their kit, each member of the team wore a pair of goggles that could display any signal within a mile of their location. These signals looked like giant pillars of color in the horizon (Figure 1) and, as the SAR member got closer, thinned until it pointed at the ground. As each team member got to the point, they could use their small tablet to mark the target as either A). clear or B). one of eleven possible response scenarios, along with their priority. Each of these scenarios would change the icon of the paint at the table as well as any SAR team member within a mile of the target; high-priority scenarios would be pushed to nearby responders immediately, to provide situation awareness and provoke action, if needed.\r\n\r\n3 DISCUSSION\r\n\r\nIn this design fiction, we presented a SAR scenario that is just barely a fantasy. Everything within our fiction is separately available, but not for SAR...yet. What we blended together was:\r\n\r\nSAR operations as they are organized now;\r\nconcepts from map interfaces in video games;\r\ncrowdsourced mapping technologies;\r\ndrone operations;\r\nand crisis informatics.\r\nThe most surprising inclusion here, we feel, is using concepts from game design to explore how wearables and AR can be used in the context of disaster response. Video games at present often feature large, highly detailed virtual worlds that require resource gathering. These SAR-compatible systems are often well-designed and meant to provide a bridge between places where things are and those who are searching for them. Yet they are often ignored due to being for entertainment purposes.\r\n\r\nOur discussion expands on the implications of our design fiction. Specifically, we want to address the barriers to use these technologies simultaneously. Next, we want to discuss workarounds for getting these technologies over their barriers. Finally, we point toward the value of video games as a means for testing emergency response interfaces.\r\n\r\n3.1 Socio-Technological Barriers to Use\r\n\r\nWe already know from our preliminary data that there is resistance to the incorporation of technology that is not yet reliable and robust. Until human-carried battery capacities enable such designs to work seamlessly all-day and until such gear can survive the rigors of search and rescue (e.g., water-, shock-, heat-, dust- proof), such devices are unlikely to find a home in search and rescue practice [16]. This barrier could also be referred to as the barrier of time or the barrier of capitalism. Hearty, low-power, single-purpose devices with long battery life could be available but there is simply no incentive to do develop or sell them yet.\r\n\r\nIn addition, there are issues within design trends. Crisis informatics, the study of human information behaviors during disaster, has been attempting to use current computational techniques without much success over its fifteen-year existence [20, 22]. The reason for this is that there is an imbalance between the usefulness of computer technology and the knowledge required to use it. While related to the physical fragility of ICT, this relates more to when the technology is functioning. The knowledge of and endless packages necessary to install to make data useful requires a skillset that very few people in the crisis response world possess.\r\n\r\n3.2 Seamful Workarounds\r\n\r\nThere are numerous workarounds for these issues of fragility, access, and training. First, technological resilience can be increased by decreasing certain kinds of seams – breaking points in technological systems caused by combinations of events, sensor capabilities, network coverage, etc. [4, 6]. In our scenario we imagined removing as many of these as we could.9\r\n\r\nThe SAR team all had goggles that could do one thing: show potential areas of interest within a mile. Everything else in our scenario is outside of the crisis zone and outsourced to people who will either be sitting in the comfort of their homes or within an EOC in a stable, bunker-like room with robust protections for infrastructure. Our scenario reflects an approach to seamful design [6] that advocates for avoiding seams.\r\n\r\nIn other cases, the seams created by the fragility of the technology are worked-around. The connectivity balloon only needs to float where it is deployed. The transponder and broadcast of the signal is still delicate, but deploying it above a zone after an event with potential power needs being partially offset by solar power will increase the lifetime of these balloons; they can be replaced as needed. Areas of dead connectivity are filled in by drones using local storage and deployed responders, who use their alternative viewpoint and personal gear to gather nearby data.\r\n\r\nThe most imaginary piece of technology for this design fiction are the goggles. We based this concept off of the video game The Legend of Zelda: Breath of the Wild [18]. This game actually places the functionality we want to see put to use in crisis within a tablet that the main character carries around. By placing this on goggles, a more hearty piece of technology than a tablet, power, heat, and connectivity needs can be minimized. This minimization is necessary as the battery needs for a tablet will force the tablet to be a bit larger than necessary. Additionally, a tablet would allow designers to cram more potential technology inside of it and this is unnecessary.\r\n\r\n3.3 Games as Testbeds\r\n\r\nVideo games are a rich source of inspiration that is oft-ignored. In this case, The Legend of Zelda: Breath of the Wild [18] contains a feature for placing digital pins through a tablet that the character carries around. This feature continues to inspire us and, based on our experience as disaster-response researchers, we connected this component of game design to work practice [9, 27], developing new designs. While this game has inspired us, we believe that this moment of inspiration points to the value of using games as not only a way to inspire designs, but also to consider the ways in which certain designs do and do not work. This too, is a form of a workaround in that, while these technologies are expensive to create and difficult to deploy due to physical and training limitations, they can still be examined from a use perspective within their digital environments.\r\n\r\n4 CONCLUSION\r\n\r\nIn this design fiction, we presented a near-future setting for SAR operations. By using developments from drone-technology spaces, crowdsourcing, wearables, and video games, this assemblage of technologies could almost be pieced together now if it were not for their individual fragilities. The consideration of more hearty and robust technologies for consumers is urgently needed. By fostering more resilient technology, emergency response can better integrate these technologies into their toolkit. Additionally, we further urge designers to look to virtual exercises like resource gathering in video games as an inspirational space for future development. By looking to the present with an eye on how easily it could be destroyed by natural forces, the resilience of humans everywhere will increase.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nWe thank the creativity of game designers and emergency responders for always pushing use scenarios beyond everyday use. These worlds always give us important somethings to think about. This material is based upon work supported by the National Science Foundation under Grant No. IIS-1651532.\r\n\r\nREFERENCES\r\n\r\nSultan A. Alharthi, William A. Hamilton, Igor Dolgov, and Z O. Toups. 2018. Mapping in the Wild: Toward Designing to Train Search & Rescue Planning. In Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing(CSCW ’18). ACM, New York, NY, USA, 137–140. https://doi.org/10.1145/3272973.3274039  \r\nSultan A. Alharthi, Ruth C. Torres, Ahmed S. Khalaf, Z O. Toups, Igor Dolgov, and Lennart E. Nacke. 2018. Investigating the Impact of Annotation Interfaces on Player Performance in Distributed Multiplayer Games. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 314, 13 pages. https://doi.org/10.1145/3173574.3173888  \r\nS. H. Alsamhi, F. A. Almalki, Ou Ma, M. S. Ansari, and M. Angelides. 2019. Performance optimization of tethered balloon technology for public safety and emergency communications. Telecommunication Systems(2019), 1–10.  \r\nSteve Benford, Andy Crabtree, Martin Flintham, Adam Drozd, Rob Anastasi, Mark Paxton, Nick Tandavanitj, Matt Adams, and Ju Row-Farr. 2006. Can You See Me Now?ACM Trans. Comput.-Hum. Interact. 13, 1 (March 2006), 100–133. https://doi.org/10.1145/1143518.1143522  \r\nNiño Cabatingan. 2019. SpaceX Dragon Successfully Delivers NASA Cargo To ISS. International Business Times (7 May 2019).  \r\nMatthew Chalmers and Areti Galani. 2004. Seamful Interweaving: Heterogeneity in the Theory and Design of Interactive Systems. In Proceedings of the 5th Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques(DIS ’04). ACM, New York, NY, USA, 243–252. https://doi.org/10.1145/1013115.1013149  \r\nDharma Dailey, Robert Soden, and Nicolas LaLone. 2017. Crisis Informatics for Everyday Analysts: A Design Fiction Approach to Social Media Best Practices. In Proceedings of the 2018 ACM Conference on Supporting Groupwork. ACM, Florida, USA, 230–243.  \r\nAlan Dix. 2017. Human–computer interaction, foundations and new paradigms. Journal of Visual Languages & Computing 42 (2017), 122–134.  \r\nJoel E. Fischer, Stuart Reeves, Tom Rodden, Steve Reece, Sarvapali D. Ramchurn, and David Jones. 2015. Building a Birds Eye View: Collaborative Work in Disaster Response. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems(CHI ’15). ACM, New York, NY, USA, 4103–4112. https://doi.org/10.1145/2702123.2702313  \r\nBud Force. 2011. Texas Task Force 1: Urban Search & Rescue. Texas A&M University Press, College Station, Texas, USA.  \r\nAmanda Hughes and Leysia Palen. 2014. Social Media and Emergency Management. In Critical issues in disaster science and management: a dialogue between researchers and practitioners, Joseph E. Trainor and Tony Subbio (Eds.). FEMA Higher Education Project, Washington D.C., USA, Book chapter 11, 348–391.  \r\nAmelia Hunt and Doug Specht. 2019. Crowdsourced mapping in crisis zones: collaboration, organisation and impact. Journal of International Humanitarian Action 4, 1 (2019), 1.  \r\nChristopher Ketcham and Jai Galliott. 2016. Outsourcing space. In Commercial Space Exploration: Ethics, Policy and Governance. Routledge, New York, NY, USA, 299.  \r\nMd. Nafiz Hasan Khan and Carman Neustaedter. 2019. An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 272, 14 pages. https://doi.org/10.1145/3290605.3300502  \r\nWynand Lambrechts and Saurabh Sinha. 2019. Successful Implementations of Last Mile Internet Solutions in Emerging Markets. In Last Mile Internet Access for Emerging Economies. Springer, New York City, NY, USA, 185–207.  \r\nBruno Latour. 2011. Love your monsters. Breakthrough Journal 2, 11 (2011), 21–28.  \r\nPatrick Meier. 2015. Digital humanitarians: how big data is changing the face of humanitarian response. Taylor & Francis, Boca Raton, Fl, USA.  \r\nNintendo EPD. 2017. The Legend of Zelda: Breath of the Wild. Game [Switch]. Nintendo, Kyoto, Japan.  \r\nOxford English Dictionary. 2019. ”hurricane, n.”. Dictionary Definition. Retrieved June 6, 2019 from http://www.oed.com/view/Entry/89594.  \r\nLeysia Palen and Kenneth M Anderson. 2016. Crisis informatics–New data for extraordinary times. Science 353, 6296 (2016), 224–225.  \r\nStuart Reeves, Murray Goulden, and Robert Dingwall. 2016. The future as a design problem. Design Issues 32, 3 (2016), 6–17.  \r\nChristian Reuter, Amanda Lee Hughes, and Marc-André Kaufhold. 2018. Social media in crisis management: An evaluation and analysis of crisis informatics research. International Journal of Human–Computer Interaction 34, 4(2018), 280–294.  \r\nFlorian Roth and Timothy Prior. 2019. Utility of virtual operation support teams: An international survey. The Australian Journal of Emergency Management 34, 2(2019), 53.  \r\nMostafa Sabbaghi, Willie Cade, Sara Behdad, and Ann M Bisantz. 2017. The current status of the consumer electronics repair industry in the US: A survey-based study. Resources, Conservation and Recycling 116 (2017), 137–151.  \r\nRobert Soden and Leysia Palen. 2016. Infrastructure in the Wild: What Mapping in Post-Earthquake Nepal Reveals About Infrastructural Emergence. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). ACM, New York, NY, USA, 2796–2807. https://doi.org/10.1145/2858036.2858545  \r\nOlivia Solon. March 6, 2017. A right to repair: why Nebraska farmers are taking on John Deere and Apple. The Guardian. https://www.theguardian.com/environment/2017/mar/06/nebraska-farmers-right-to-repair-john-deere-apple  \r\nZ O. Toups, William A. Hamilton, and Sultan A. Alharthi. 2016. Playing at Planning: Game Design Patterns from Disaster Response Practice. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play(CHI PLAY ’16). ACM, New York, NY, USA, 362–375. https://doi.org/10.1145/2967934.2968089  \r\nU.S. Department of Homeland Security. 2008. National Incident Management System. U.S. Department of Homeland Security, Washington, DC, USA.  \r\nJason Wuertz, Sultan A. Alharthi, William A. Hamilton, Scott Bateman, Carl Gutwin, Anthony Tang, Z O. Toups, and Jessica Hammer. 2018. A Design Framework for Awareness Cues in Distributed Multiplayer Games. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 243, 14 pages. https://doi.org/10.1145/3173574.3173817  \r\nKaige Yan, Jingweijia Tan, and Xin Fu. 2019. Bridging mobile device configuration to the user experience under budget constraint. Pervasive and Mobile Computing 58 (2019), 101023.  \r\nFOOTNOTE\r\n\r\n1The abbreviation is commonly read as a word “sar” by responders in the USA.\r\n\r\n2We want to mention the growing competition surrounding battery life [30], answers to common repair needs for mobile devices [24], and the current socio-political climate around the right-to-repair movement [26] as ways in which this goal is currently manifesting.\r\n\r\n3We specifically use the term “goal” here with reference to Reeves et al.[21] within which we cite an idealized future that you can help be created.\r\n\r\n4“...cyclones of diameter of from 50 to 1000 miles, wherein the air moves with a velocity of from 80 to 130 miles an hour round a central calm space, which with the whole system advances in a straight or curved track...” [19].\r\n\r\n5The United States Federal Emergency Management Agency, which manages disaster response at the federal level.\r\n\r\n6The United States National Aeronautics and Space Administration (NASA), which handles government space flight.\r\n\r\n7“An occurrence, natural or manmade, that requires a response to protect life or property. ...” [28].\r\n\r\n8Pronounced as “bee-oh-oh”.\r\n\r\n9By seams, we begin by referring to the physical weaknesses of technology. We then refer to the skill set and expertise needed to use computer software, computer hardware, and multi-device, multi-platform, multi-tool collaboration. By stripping SAR technical needs to their essential components, we attempt to interweave design and theory [6] to an accessible foundation for all stakeholders to engage. SAR team members can suggest new tools they need without worrying about invisible systems.',1,'LaLone','Nicolas LaLone, Sultan A. Alharthim, and Z Toups','Nicolas LaLone *(University of Nebraska Omaha, USA)* <br>\r\nSultan Alharthim *(New Mexico State University, USA)* <br>\r\nZ O. Toups *(New Mexico State University, USA)*','https://www.researchgate.net/profile/Nicolas_Lalone/publication/336312638_A_Vision_of_Augmented_Reality_for_Urban_Search_and_Rescue/links/5d9b431da6fdccfd0e7fc5bb/A-Vision-of-Augmented-Reality-for-Urban-Search-and-Rescue.pdf',1,'10.1145/3363384.3363466','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,65,5,NULL,NULL,0,22),(16,'marshall-the-limitations-of-reality','2019-09-02 15:24:57','2019-11-14 14:05:57','2019-09-02 15:24:57',NULL,1,'published','[]','The Limitations of Reality','Existing conceptualisations of mixed reality technologies embody a fundamental assumption, that they are a tool to simulate consistent ‘realities’. We present three examples of how this assumption constrains designers:\r\n\r\n* Systems stimulate only a subset of senses. Aiming for consistent simulation ignores exciting potential to use externally stimulated senses in new ways.\r\n* Deliberately breaking convincing simulated reality can create new, thrilling experiences.\r\n* Compelling experiences can be create when people interacting in ways which break boundaries of conceptual realities.\r\n\r\nOne way to avoid these issues is to define such ‘immersive technologies’ purely as motion tracked sensory stimulation devices. This offers a basic building block for design, however in the the future a range of higher level concepts will be required to enable new and exciting uses of VR and AR equipment. Convincing simulation of realities is only a small subset of the potential uses.','Joe Marshall and Paul Tennent. 2019. The Limitations of Reality. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363475](https://doi.org/10.1145/3363384.3363475 \"DOI for the article \'The Limitations of Reality\'\")','Figure 1: Three systems which go beyond simulation of consistent reality: (a) VR Playground overlays misaligned 3D visuals onto physical sensations of riding a playground swing. (b) Bolt Spinner tips the player\'s view to make them lose balance.(c) In The Baby Game, players wearing a VR headset interact with real objects with help from outside players.\r\n1 INTRODUCTION\r\n\r\nThe term virtual reality (VR) was popularised during the 1980s to refer to systems which used head-mounted displays or surround projection in order to present a visual illusion to a user of being present in a different ‘reality’. This was followed by augmented reality (AR), referring to systems such as see-through heads up displays, which rather than enclosing the user in a different reality, visually overlay digital content, bringing that digital content into their world. In an influential 1994 article, Milgram and Kishino [6] presented a definition of mixed reality (MR), as a continuum, with virtual reality at one end, real reality at the other, and systems such as augmented reality placed in the middle. Whilst MR is often used to mean a range of different things, the definition and terminology used by Milgram and Kishino remains dominant [9]. Commercially, we also see Cross/Xtended Realities (XR) used as an umbrella term for all MR technologies.\r\n\r\nThese terms for describing systems and hardware all share the word ‘reality’. In this article we argue that conceptual models based on ‘realities’ produce constraints on design which mean that the creative potential of the underlying technologies is not being fulfilled. For design to fully realise the potential of current and future hardware, we need to drop the concept of ’realities’ entirely, and roll back to fundamental descriptions of what such technologies do to our senses and what they can sense; we believe such low level descriptions can be built upon with a wide range of possible conceptualisations, of which simulation of convincing mixed or virtual realities is only one narrowly focused possibility.\r\n\r\n2 WHAT IS WRONG WITH REALITY?\r\n\r\nIn this section, we present three problems with the assumption that a key aim of this technology is simulation of realities, along with three prototype systems which illustrate ways in which each problem can in fact become an opportunity when we drop the need to attempt consistent simulation.\r\n\r\n2.1 Complete simulation of digital realities is not possible, as other senses are still physically stimulated\r\n\r\nVR headsets are often referred to as ‘immersive’ technology. One take on this is to consider this as sensorial immersion, for example from Witmer & Singer:\r\n\r\nA VE that effectively isolates users from their physical environment, thus depriving them of sensations provided by that environment, will increase the degree to which they feel immersed in the VE [12].\r\nIn Milgram and Kishino [6], ‘virtual reality’ is a system with full sensory immersion. However they primarily focus on visual and auditory senses. Whilst virtual reality headsets can effectively isolate these senses, the other senses are almost always open to stimulation from their physical environment; in practice full sensory immersion is an impossible goal. The traditional response to this is to control the environment heavily (e.g. passive haptics [3]) and/or to build ways of stimulating more senses (e.g. feelings of heat [8]). Recent work however suggests that full sensory immersion may not always even be a desirable goal, that rather than try and reduce non-digital sensory stimulation, we can instead embrace the knowledge that some sensory input will always come from physical reality and treat the combination of physical and digital sensory stimulation as an opportunity for design [11]. An example of a way to do this is in overlaying digital visual stimulation on top of exciting physical experiences. Figure 2 shows VR Playground, a ride based around a playground swing. VR playground makes use of the swing to create exciting kinaesthetic and tactile sensations as the rider feels themselves flying through the air, whilst using a VR headset to create visual stimulation of exciting motions which are different to the real world swinging [11].\r\n\r\n\r\nFigure 2: In VR Playground people ride a playground swing whilst a VR headset overlays 3D worlds.\r\n2.2 Better simulation of consistent realities is not the same as better experience\r\n\r\nMeasures of presence are considered key to understanding the user experience of virtual reality systems [5, 10]. Conventionally, presence relates to the user\'s feeling of being present in a virtual world. Similarly, in augmented reality, presence relates to users’ perception that AR objects are ‘present’ in their world [7]. Concepts of presence are fundamentally related to the idea that a key aim is to create convincing simulated realities, as can be seen from the example questions in Table 1.\r\n\r\nRecent work suggests that deliberately breaking simulation, by creating of deliberately and sometimes obviously ‘misaligned’ sensory experiences [4] can create new and thrilling sensations; we built a simple isolated illustration of this called Bolt Spinner (Figure 3). In Bolt Spinner, the user sits on an office chair, whilst a headset presents visuals of an environment containing a number of gigantic bolts, including one directly below. As they rotate on the chair, the bolt turns and unscrews, until a climax where the bolt comes out completely and the user\'s view falls sideways. This breaks simulation, creating a sudden moment of disconnect between the user\'s visual and vestibular senses of balance, which is thrilling and disorientating (and typically leads them to fall to one side as seen in Fig. 3).\r\n\r\n\r\nFigure 3: In Bolt Spinner, tipping the view creates a thrilling moment of disorientation and makes the rider fall sideways.\r\nTable 1: AR and VR presence questions [7, 12].\r\nQuestion    Weighting\r\nHow natural did your interactions with the environment seem    POSITIVE\r\nHow much did your experiences in the virtual environment seem consistent with your real-world experiences?    POSITIVE\r\nHow inconsistent or disconnected was the information coming from your various senses?    NEGATIVE\r\nWas watching the virtual objects just as natural as watching the real world?    POSITIVE\r\nDid the virtual objects appear to be (visualized) on a screen, or did you have the impression that they were located in space?    POSITIVE\r\n2.3 Breaking boundaries between people in different realities may be a desirable design strategy\r\n\r\nThe concept that mixed reality technology is for immersing users in some kind of reality is also problematic because it ignores valid design strategies which break the walls between users who are experiencing a different combination of sensory stimulations (or different ‘realities’). Perhaps the most basic example is how when introducing users to VR, we often remove headphones and have an external supporter talk them through. Even in experiences where the underlying design is ‘virtual reality’, direct communication with outside helpers can improve user experience. This is a deliberate design tactic in our third prototype; In The Baby Game, a player (the baby) wears a virtual reality headset which shows a highly distorted version of their surroundings - initially, the baby only sees a blur of light and dark. Spoken instructions give the baby tasks (’find the toy’). Halfway through the experience, the vision of the baby improves, and they can see their surroundings more clearly; however, they are reversed and zoomed in, to create an effect of tunnel vision, and to confuse the baby\'s proprioception, while they must do some simple motor tasks (’can you stack the blocks up!’). Key to the Baby Game experience is that the audio is played on a speaker, and as well as game audio, spectators can join in and give advice, encouragement and help (Figure 4). The Baby Game is at least as entertaining for the spectators enjoying the struggle of the baby to complete simple tasks as it is for the baby themselves. This design does not fit traditional examples of mixed reality, in that in while the baby is mostly visually isolated from the other players, and their experience is opaque, spectators in the real world are an active and important part of player experience. A similar approach has been taken in the game You Better Eat to Survive[1] where players wearing headsets are fed food by players in the physical world.\r\n\r\n\r\nFigure 4: Spectator helping baby find some stacking blocks.\r\n3 DISCUSSION\r\n\r\nAs the examples above show, taking as a fundamental assumption that we are trying to create some kind of consistent reality for users is problematic, as many design possibilities exist which break that assumption. So what is the future for design of systems using current and future ‘immersive’ technology; we propose two things:\r\n\r\nBegin with descriptions of technologies in terms of underlying sensory stimulation capabilities, how they isolate physical senses, and how they track motion.\r\nTo support practical design, we can then build a range of conceptual models on top of this, of which simulation is only one possibility.\r\n3.1 Technology as tracked sensory stimulation devices\r\n\r\nFollowing Marshall et al.[4], we argue that rather than put high level interpretations on what hardware is for, a good initial model is to look at what the hardware is capable of. One simple way of modelling this is to consider what sensory stimulation a piece of hardware provides, which sensory inputs from the outside world are blocked, and what the hardware can sense. For example in Table 2, we can see the differences between 3 commercial headsets - at one extreme, the HTC Vive Pro VR headset has over-ear headphones which block out external sound, and also blocks out external visual stimulus, whereas the Microsoft Hololens overlays visual and auditory stimuli without blocking external sensory input. Recent Oculus devices such as the Quest and Go use purely digital visual stimulation whilst using speakers near the ear to allow external physical sounds to mix with the digital sound. Different headsets also differ in terms of whether they can sense hands or controllers, and whether they have position tracking versus purely orientation. Interestingly, even this simple table exposes the differences in auditory blocking between similarly marketed ’virtual reality’ headsets.\r\n\r\nAs an example of this, the baby game makes use of the fact that the baby\'s visuals are blocked and can be manipulated, and treats the fact that kinaesthetic and auditory senses are exposed to external stimulation as a design opportunity.\r\n\r\nTable 2: Sensory and tracking characteristics of selected commercial headsets.\r\nDevice    Digitally stimulated senses    Physical senses blocked    Tracking capability\r\nHTC Vive Pro    Vision, sound    Vision, sound    Head & hand controllers\r\nOculus Quest    Vision, sound    Vision    Head & hand controllers\r\nOculus Go    Vision, sound    Vision    Orientation\r\nHololens    Vision, sound    None    Head & hands\r\n3.2 Experience-Led Design for sensory stimulation\r\n\r\nIn future, we believe designing for different sensory stimulation mixtures and tracking capabilities will enable a range of new and exciting experiences which are currently hard to envisage with our focus primarily on simulation of convincing virtual worlds or convincingly bringing virtual content into our world. The low-level, system driven descriptions of technology we describe above, whilst vital to understanding the fundamental technological capabilities, are not sufficient to enable experience focused design using these technologies.\r\n\r\nSuch design will instead require building on the fundamental underlying capabilities of technologies we have access to with higher level design frameworks or knowledge. Rather than working purely with the relatively fixed ideas of the current conceptualisation of mixed reality, we can instead build a range of things on top of the wide variety of available hardware.\r\n\r\nGiven the limitations of mixed reality as a concept, we believe that no one overarching theoretical basis for design will be adequate to explore the possibilities of diverse new sensory stimulation and body sensing technologies. Some systems may even create altered reality whilst not providing a 3D modelled world at all - see for example Byrne et al.’s work using tracking of body posture and balance alteration to alter perceived reality [2]. This uses the digital to alter reality in ways far outside what we currently know of as mixed reality.\r\n\r\nFuture work will require picking and choosing from a wide range of new design approaches. As an example, our current work takes a sensory focused approach to experience design - looking at how stimulation in each of the senses can come from digital stimuli, what deliberately presented physical stimuli are part of the experience, and how senses are blocked or left open to stimulation from the external world. A small number of ways of doing this already exist in the literature such as sensory misalignment [4], abstract machines [11], and exploiting gaps in sensory blocking to enable communication between people in and out of technology [1]. A key focus for HCI researchers interested in such technologies will be to explore and map the many ways in which such sensory stimulation technology may be used and develop the conceptual tools to enable the full exploitation of new and existing MR technologies.\r\n\r\n4 CONCLUSION: THE FUTURE OF REALITY\r\n\r\nThe idea that MR technologies can be pinned down onto a linear continuum of realities has outlived its usefulness. In this article we describe 3 ways in which the focus on simulation of realities fails to keep up with the potential of MR technologies:\r\n\r\nComplete simulation of realities is an impossible ideal as some senses are not stimulated.\r\nConsistent simulation may not equal optimum user experience.\r\nBreaking the boundaries between people in different ‘realities’ may in fact be a desirable design strategy.\r\nInstead we believe that by beginning with lower level descriptions of the fundamental capabilities of technology to stimulate the user\'s senses and track their bodies, and building on these with a diverse set of higher level concepts, possibilities will be exposed which go far beyond the potential of current, simulation based models of ‘realities’. Future HCI research in this area must address the challenge of mapping and exploring these new high level concepts.\r\n\r\nREFERENCES\r\n\r\nPeter Arnold, Rohit Ashok Khot, and Florian\'Floyd’ Mueller. 2018. You Better Eat to Survive: Exploring Cooperative Eating in Virtual Reality Games. In Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction. ACM, 398–408.  \r\nRichard Byrne, Joe Marshall, and Florian\'Floyd’ Mueller. 2016. Balance ninja: towards the design of digital vertigo games via galvanic vestibular stimulation. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play. ACM, 159–170.  \r\nBrent Edward Insko, M Meehan, M Whitton, and F Brooks. 2001. Passive haptics significantly enhances virtual environments. Ph.D. Dissertation. University of North Carolina at Chapel Hill.  \r\nJoe Marshall, Steve Benford, Richard Byrne, and Paul Tennent. 2019. Sensory Alignment in Immersive Entertainment. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 700.  \r\nAlison McMahan. 2003. Immersion, engagement and presence. The video game theory reader 67 (2003), 86.  \r\nPaul Milgram and Fumio Kishino. 1994. A taxonomy of mixed reality visual displays. IEICE TRANSACTIONS on Information and Systems 77, 12 (1994), 1321–1329.  \r\nHolger Regenbrecht and Thomas Schubert. 2002. Measuring presence in augmented reality environments: design and a first test of a questionnaire. Porto, Portugal (2002).  \r\nEmily Shaw, Tessa Roper, Tommy Nilsson, Glyn Lawson, Sue VG Cobb, and Daniel Miller. 2019. The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation. arXiv preprint arXiv:1902.04573(2019).  \r\nMaximilian Speicher, Brian D. Hall, and Michael Nebeling. 2019. What is Mixed Reality?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 537, 15 pages. https://doi.org/10.1145/3290605.3300767  \r\nKaty Tcha-Tokey, Emilie Loup-Escande, Olivier Christmann, and Simon Richir. 2016. A questionnaire to measure the user experience in immersive virtual environments. In Proceedings of the 2016 Virtual Reality International Conference. ACM, 19.  \r\nPaul Tennent, Joe Marshall, Patrick Brundell, Brendan Walker, and Steve Benford. 2019. Abstract Machines: Overlaying Virtual Worlds on Physical Rides. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 581.  \r\nBob G Witmer and Michael J Singer. 1998. Measuring presence in virtual environments: A presence questionnaire. Presence 7, 3 (1998), 225–240. ',1,'Marshall','Joe Marshall and Paul Tennent','Joe Marshall *(Mixed Reality Lab, University of Nottingham, UK)*<br>\r\nPaul Tennent  *(Mixed Reality Lab, University of Nottingham, UK)*',NULL,0,'10.1145/3363384.3363475','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,70,5,NULL,NULL,0,31),(17,'lundstroem-the-disappearing-computer-science-in-healthcare-vr-applications','2019-09-02 15:24:57','2019-11-14 14:06:05','2019-09-02 15:24:57',NULL,1,'published','[]','The Disappearing Computer Science in Healthcare VR applications','One growing area of research in the field of interaction design concerns new applications of filmed VR, or what is sometimes referred to as 360 video. We have studied this new semi-interactive medium in two applied use settings: in clinical psychotherapy sessions for agoraphobia and in elderly care. The systems used in both projects were effective and well received by patients and practitioner and are now taken into continued use at the studied organisations. As researchers in HCI, we were surprised that these small experiments could be so successful in the wild, while only loosely connected to the discourse of VR as we knew it. Based on our design process, and experiences from real use settings, we discuss the future role of the historically strong field of computer science in the domain of applied VR.','Anders Lundström and Ylva Fernaeus. 2019. The Disappearing Computer Science in Healthcare VR applications. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 5 pages. [https://doi.org/10.1145/3363384.3363398](https://doi.org/10.1145/3363384.3363398 \"DOI for the article \'The Disappearing Computer Science in Healthcare VR applications\'\")','1 Introduction\r\n\r\nVirtual Reality (VR) is a well-established research area in HCI, concerned with methods that let people take part of three-dimensional visual material using different types of stereoscopic displays, a topic that has been explored from an artistic and technical standpoint ever since the 1950s [42]. Thus, there is a large amount of research covered in this area, with whole conferences and journals, and a growing number of examples where VR has been successfully used not only for entertainment but also for e.g. industrial and perhaps most significantly, in the area of health and various forms of clinical therapy.\r\n\r\nIn the medical domain, there are several dedicated centres and programs for VR-based treatment methods, such as the VR Medical Center1 and the VR treatment program at Duke University2 . Examples of applications include pain management for adults [1,16,24,31] and children [3], post-stroke rehabilitation [22], treatment of stress-related disorders [4], tinnitus [23], balance impairment [30], intellectual disabilities [8], dementia [15], exposure-based cognitive behaviour therapy (CBT) [29] for self-treatment of spider phobia [9,27], rehabilitation of neck injuries [11], fear of heights [12,34], social phobia [17], fear of flying [28], and PTSD for war veterans [35]. Studies also show that VR can save time and lead to more effective exposure therapy [25] in safe and controlled environments [32]. There is also evidence that cognitive behaviour therapy using VR is an attractive entry to real environments [20]. \r\n\r\nMost of the above examples are based on systems where 3D graphics have been produced specifically for a clinical case. Similar to such 3D graphics-based VR, 360 videos [21] are experienced via head-mounted displays (HMDs), but are based on real recorded video footage instead of computer-generated graphics. Recently, several research groups have, like us, experimented with this new media format in various applied interactive settings [7,18,43]. Examples from the healthcare domain include VR as a resource for preparing patients for anaesthesia [41], MRI scanning [2] and exposure therapy [13]. \r\n\r\nAs many other researchers in the more practice- and socially oriented discourse of HCI, we were initially sceptical to the concept of using HMDs, as we saw it like socialising with blindfolds. But given several thought-provoking productions concerned with various socially responsible topics such as bullying3, being a refugee4, and empathy with hunted pray5, we became increasingly curious about the potentials of 360 video. Below we present two clinical 360 video use cases, followed by a short discussion on the future role of the historically strong field of computer science in the domain of applied VR.\r\n\r\n2 Use Cases\r\n\r\nWe will here report from two projects based on easily accessible, scalable, and affordable consumer technology. The driving force was to explore how 360 videos may lead to more efficient and better care. The first setting concerned exposure treatment of agoraphobia in cognitive-behavioural psychotherapy, while the second project aimed to enhance wellbeing in elderly care through co-located co-watching of 360 videos. \r\n\r\n2.1 360 Video in Phobia Treatment\r\n\r\nIn collaboration with a psychotherapy clinic, we tested CBT treatment of agoraphobia using existing practices and protocols but where all exposure sessions take place directly at the clinic through 360 videos in VR HMDs instead of in reality (Figure 1). The purpose is to improve the efficiency of the care and to be able to offer treatment to groups that otherwise do not receive treatment. People with agoraphobia usually suffer from severe social and mobility hindrances in everyday life. A common case in our area is avoiding public transport hence affecting their social life and work capabilities. Project outcomes have been very successful and all patients (N = 12) who have undergone 12 weeks of VR-KBT have had significant long-term effects (6 and 12-month follow-up) using standard CBT measurements (primary outcome mobility inventory, panic disorder severity scale, PHQ-9 depression measurements). All patients have been positive to the experience and most have explicitly stated that approaching these filmed environments was an attractive entry point after many years of avoiding feared environments. Several patients had not used the subway for 10+ years despite other treatments and are now active advocates of 360 video CBT. The project has been widely reported in the media, especially since it was awarded Innovation of the Year 2019 by the Stockholm county innovation fund.\r\n\r\n2.2 Shared Screenings at Retirement Homes\r\n\r\nIn collaboration with Film Stockholm, who staged a series of activities via Norrtälje municipality and the Tiohundra organization, we studied the application of 360 video in elderly care where the residents in smaller groups were co-watching synchronized 360 videos from the local area (Figure 2). The videos were produced by Film Stockholm who has a societal mission to work with video and culture in the healthcare sector.\r\n\r\nMental health issues in the form of perceived solitude and isolation is great in the group older than 65 years. To prevent these issues elderly care centres typically arrange activities, social events and housing activities. The purpose of this project was to further add value and raise the quality of life for the elderly through shared experiences. Examples of videos featured were a boat trip in fishing waters visited in their youth, a visit to the home town that is now being rebuilt, a modern dance performance and the fascinating lemurs at a nearby zoo. In that sense, this case has conceptual similarities to The Photostroller [14], though their design exploration concerned navigation of Flckr images rather than 360 video content. As part of the project, a new display model was developed, in which the staff themselves could show 360 videos for a small group of elderly as a social activity.\r\n\r\nIn total, nurses have so far facilitated sessions with over 100 elderly. The caregivers have reported various positive effects among the elderly, such as increased mental presence, more spontaneous movements, general excitement and most of all smiles and laughter. The elderly were openly positive to both the content of the videos and the fact that they got to try something new. Two studies (N = 19, N = 19) with different participants has also showed that the experience was much appreciated, but similar to [43] we could see that there is more to do with regard to the social co-watching setup, regarding technology as well as in terms of the structure of the sessions. The staff has also shown great commitment to trying out different 360 videos with the elderly. Many testify that they got to know the elderly better and some believe that it can lead to better and more meaningful work. This project has also received substantial attention in national media and many people have heard of the project, which caused a widespread interest at other elderly care centres.\r\n\r\n3 Discussion\r\n\r\nDespite our own initial scepticism to virtual reality in general, and to the concept of using HMDs in particular, we now see that this technology has the potential to enable increased quality of care, quality of life, accessibility, and reduced human resources and more cost-effective treatment. In the phobia treatment project, there are today three psychologists using 360 videos and with the shared screenings, five retirement homes have used it so far and we also have a demand from other organisations, for example in special schools and special housing, interested in using the setup. Based on the current results, it is clear that 360 video seems mature and useful in existing practices. The latter is especially important for treatment in so called evidence-based care, which needs to follow established protocols and procedures based on a scientific foundation. We should also emphasise that we, as researchers in HCI, initially had little technical expertise in VR technology but still found the development easy and accessible.\r\n\r\nIn comparison to 3D graphics-based VR systems, we see in particular two main strengths with using 360 videos in settings such as ours. First, key concepts typically addressed in VR research are so-called presence [36,45] and immersion [39,40], which are major challenges for computer-generated VR. These topics, and especially the question of realism and the problem of ‘uncanny valley’ becomes less of a problem in 360 videos as they already portray real environments and people. It should be acknowledged though that the importance of realism has been questioned in relation to clinical outcomes [33]. Secondly, despite the constant progress in tools for making attractive 3D graphics, producing a 360 video is a lot less resource-intensive in terms of skills and time needed and as a result, associated with much lower production costs. This makes it an attractive and viable option for healthcare facilities, compared to 3D graphics productions.\r\n\r\nSimilar to the orchestration of a mixed reality performance [19], we see the challenge in contemporary VR applications, both such based on 3D graphics and 360 video, to be more a matter of media production, foregrounding crafts of design, content, and aesthetic considerations, rather than engineering research.\r\n\r\nOne of the remaining key research challenges in VR environments is how to realistically treat body movement (locomotion) [37,38,44]. Not being able to walk around and interact in the environment is indeed a major drawback in 360 video applications, where the camera limits mobility to a greater extent than in computer-generated scenes. In our work we have deliberately chosen scenarios where less movement is demanded or expected, e.g. videos that the caretaker can progress and choose from. Potential future remedies to this limitation include using stop motion techniques [6], photogrammetry [5], 360 hypervideo [10,26], and hybrid 3D and 360 video compositions6 . There are also several aspects such as the lock-in/lock out experiences of HMDs, as well as technical aspects of interacting within stereoscopic headsets, that could use more attention, perhaps most successfully using designerly approaches. Again, making attractive interactions in this domain rely fundamentally on the orchestration of professionally produced experiences. \r\n\r\nSo far, the two projects reported on here have been treated separately and the main focus has been on resident or patient experiences. But we see a need to take a broader approach to applications of 360 video in our use settings, and in particular to deepen the knowledge about the care providers\' perspectives on the introduction of 360 video in the practice. Examples of issues are whether the use of the technology leads to a more attractive workplace and how the technology can be improved in order to better fit other needs, e.g. for follow-up, documentation, sense of coexistence in the digital environment, as well as aspects regarding the concrete handling. These are all interaction design aspects, requiring no or little advanced ‘computer science’ either to study or to implement, nor a special focus on 3D graphics.\r\n\r\nAlthough we foresee that many computer science research motives will remain in the years ahead, it is reasonable to believe that this maturity and accessibility will cause a much larger body of research to emerge outside computer science departments. For instance, we note that several recent research papers concerning 360 video in medical settings [e.g. 1, 24], are not only published outside of the HCI or computer science discourse, they also do not include any authors from these fields, and they appear to have been conducted without such expertise. In addition to the lower threshold for development and usage, the new affordable platforms cause new groups to explore and study what was previously expensive equipment tied to computer science departments. An emerging question, given our fields historical connection to, and typical affiliation with, computer science departments, is how, or to what degree, computer science motives will be relevant in the future to knowledge contributions in the area of applied VR. \r\n\r\nACKNOWLEDGMENTS\r\n\r\nThe work presented in this paper was funded by several grants from SLL, under the project name “VR i Vården”.\r\n\r\nREFERENCES\r\n\r\nNaseem Ahmadpour, Hayden Randall, Harsham Choksi, Antony Gao, Christopher Vaughan, and Philip Poronnik. 2019. Virtual Reality interventions for acute and chronic pain management. International Journal of Biochemistry and Cell Biology 114, June: 105568. https://doi.org/10.1016/j.biocel.2019.105568 \r\nJonathan Ashmore, Jerome Di Pietro, B A Hons, Kelly Williams, Anna Symons, Martina Smith, Louise Clegg, and Cormac Mcgrath. 2019. A Free Virtual Reality Experience to Prepare Pediatric Patients for Magnetic Resonance Imaging : Cross-Sectional Questionnaire Study. JMIR PEDIATRICS AND PARENTING 2, 1. https://doi.org/10.2196/11684  \r\nBarbara Atzori, Laura Vagnoli, Andrea Messeri, and Rosapia Lauro Grotto. 2018. Virtual reality for pain management among children and adolescents: Applicability in clinical settings and limitations. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)10908 LNCS: 15–27. https://doi.org/10.1007/978-3-319-92052-8_2  \r\nR. M. Baños, V. Guillen, S. Quero, A. García-Palacios, M. Alcaniz, and C. Botella. 2011. A virtual reality system for the treatment of stress-related disorders: A preliminary analysis of efficacy compared to a standard cognitive behavioral program. International Journal of Human Computer Studies 69, 9: 602–613. https://doi.org/10.1016/j.ijhcs.2011.06.002  \r\nL. Barazzetti, M. Previtali, and F. Roncoroni. 2018. Can we use low-cost 360 degree cameras to create accurate 3D models? International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives 42, 2: 69–75. https://doi.org/10.5194/isprs-archives-XLII-2-69-2018  \r\nMark Bolas, Ashok Kuruvilla, Shravani Chintalapudi, Fernando Rabelo, Vangelis Lympouridis, Christine Barron, Evan Suma, Catalina Matamoros, Cristina Brous, Alicja Jasina, Yawen Zheng, Andrew Jones, Paul Debevec, and David Krum. 2015. Creating near-field VR using stop motion characters and a touch of light-field rendering. ACM SIGGRAPH 2015 Posters, SIGGRAPH 20155: 2787640. https://doi.org/10.1145/2787626.2787640  \r\nAndy Brown, Jayson Turner, Jake Patterson, Anastasia Schmitz, Mike Armstrong, and Maxine Glancy. 2017. Subtitles in 360-degree Video. In Adjunct Publication of the 2017 ACM International Conference on Interactive Experiences for TV and Online Video - TVX ’17 Adjunct, 3–8. https://doi.org/10.1145/3084289.3089915  \r\nRoss Brown, Laurianne Sitbon, Lauren Fell, Stewart Koplick, Chris Beaumont, and Margot Brereton. 2016. Design insights into embedding virtual reality content into life skills training for people with intellectual disability. Proceedings of the 28th Australian Computer-Human Interaction Conference, OzCHI 2016: 581–585. https://doi.org/10.1145/3010915.3010956  \r\nAlbert S. Carlin, Hunter G. Hoffman, and Suzanne Weghorst. 1997. Virtual reality and tactile augmentation in the treatment of spider phobia: A case report. Behaviour Research and Therapy 35, 2: 153–158. https://doi.org/10.1016/S0005-7967(96)00085-X  \r\nTeresa Chambel, Maiur N. Chhaganlal, and Luís A.R. Neng. 2011. Towards immersive interactive video through 360° hypervideo. ACM International Conference Proceeding Series: 2–3. https://doi.org/10.1145/2071423.2071518  \r\nNyberg Daniel. 2015. StarGazer: A Virtual Reality exergame for neck pain rehabilitation.  \r\nPaul M.G. Emmelkamp, Mary Bruynzeel, Leonie Drost, and Charles A.P.G. Van Der Mast. 2001. Virtual Reality Treatment in Acrophobia : A Comparison with Exposure in Vivo. Cyberpsychology & Behaviour 4, 3: 335–339.  \r\nEivind Flobak, Jo D Wake, Joakim Vindenes, Smiti Kahlon, Tine Nordgreen, and Frode Guribye. 2019. Participatory Design of VR Scenarios for Exposure Therapy. 1–12.  \r\nWilliam Gaver, Andy Boucher, John Bowers, Mark Blythe, Nadine Jarvis, David Cameron, Tobie Kerridge, Alex Wilkie, Robert Phillips, and Peter Wright. 2011. The photostroller: Supporting diverse care home residents in engaging with the world. Conference on Human Factors in Computing Systems - Proceedings: 1757–1766. https://doi.org/10.1145/1978942.1979198  \r\nJames Hodge, Madeline Balaam, Sandra Hastings, and Kellie Morrissey. 2018. Exploring the design of tailored virtual reality experiences for people with dementia. Conference on Human Factors in Computing Systems - Proceedings 2018-April: 1–13. https://doi.org/10.1145/3173574.3174088  \r\nHunter G. Hoffman, David R. Patterson, Gretchen J. Carrougher, and Sam R. Sharar. 2001. Effectiveness of virtual reality-based pain control with multiple treatments. Clinical Journal of Pain 17, 3: 229–235. https://doi.org/10.1097/00002508-200109000-00007  \r\nIsabel L Kampmann, Paul M G Emmelkamp, Dwi Hartanto, Willem-paul Brinkman, Bonne J H Zijlstra, and Nexhmedin Morina. 2016. Behaviour Research and Therapy Exposure to virtual social interactions in the treatment of social anxiety disorder : A randomized controlled trial. Behaviour Research and Therapy 77: 147–156. https://doi.org/10.1016/j.brat.2015.12.016  \r\nSam Kavanagh, Andrew Luxton-Reilly, Burkhard Wüensche, and Beryl Plimmer. 2016. Creating 360° educational video. In Proceedings of the 28th Australian Conference on Computer-Human Interaction - OzCHI ’16, 34–39. https://doi.org/10.1145/3010915.3011001  \r\nB. Koleva, I. Taylor, S. Benford, M. Fraser, C. Greenhalgh, H. Schnädelbach, D. Vom Lehn, C. Heath, J. Row-Farr, and M. Adams. 2001. Orchestrating a mixed reality performance. Conference on Human Factors in Computing Systems - Proceedings, 3: 38–45.  \r\nMary Ann Liebert, Azucena Garcia-palacios, D Ph, Hunter G Hoffman, D Ph, Sheree Kwong See, D Ph, A M Y Tsai, Cristina Botella, and D Ph. 2001. Redefining Therapeutic Success with Virtual Reality Exposure Therapy. CYBERPSYCHOLOGY & BEHAVIOR 4, 3: 341–348.  \r\nYen-Chen Lin, Yung-Ju Chang, Hou-Ning Hu, Hsien-Tzu Cheng, Chi-Wen Huang, and Min Sun. 2017. Tell Me Where to Look. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17, 2535–2545. https://doi.org/10.1145/3025453.3025757  \r\nCarlos Luque-Moreno, Alejandro Ferragut-Garcías, Cleofás Rodríguez-Blanco, Alberto Marcos Heredia-Rizo, Jesús Oliva-Pascual-Vaca, Pawel Kiper, and Ángel Oliva-Pascual-Vaca. 2015. A Decade of Progress Using Virtual Reality for Poststroke Lower Extremity Rehabilitation: Systematic Review of the Intervention Methods. BioMed Research International 2015, February. https://doi.org/10.1155/2015/342529  \r\nD. Malinvaud, A. Londero, R. Niarra, Ph Peignard, O. Warusfel, I. Viaud-Delmon, G. Chatellier, and P. Bonfils. 2016. Auditory and visual 3D virtual reality therapy as a new treatment for chronic subjective tinnitus: Results of a randomized controlled trial. Hearing Research 333, January: 127–135. https://doi.org/10.1016/j.heares.2015.12.023  \r\nBrian Mallari, Emily K Spaeth, Henry Goh, and Benjamin S Boyd. 2019. Virtual reality as an analgesic for acute and chronic pain in adults: a systematic review and meta-analysis. Journal of Pain Research Volume 12: 2053–2085. https://doi.org/10.2147/jpr.s200498  \r\nJessica L Maples-keller, Brian E Bunnell, Sae-jin Kim, O Barbara, and Behavioral Sciences. 2018. The Use of Virtual Reality Technology in the Treatment of Anxiety and Other Psychiatric Disorders. Harv Rev Psychiatry 25, 3: 103–113. https://doi.org/10.1097/HRP.0000000000000138.The  \r\nTeresa Matos, Rui Nóbrega, Rui Rodrigues, and Marisa Pinheiro. 2018. Dynamic annotations on an interactive web-based 360◦ video player. Proceedings - Web3D 2018: 23rd International ACM Conference on 3D Web Technology. https://doi.org/10.1145/3208806.3208818  \r\nAlexander Miloff, Philip Lindner, William Hamilton, Lena Reuterskiöld, Gerhard Andersson, and Per Carlbring. 2016. Single-session gamified virtual reality exposure therapy for spider phobia vs. traditional exposure therapy: Study protocol for a randomized controlled non-inferiority trial. Trials 17, 1. https://doi.org/10.1186/s13063-016-1171-1  \r\nAndreas Mühlberger, Anne Weik, Paul Pauli, Georg Wiedemann, Andreas Mühlberger, Anne Weik, Paul Pauli, and Georg Wiedemann. 2007. One-session virtual reality exposure treatment for fear of flying : 1-Year follow-up and graduation flight accompaniment effects. Psychotherapy Research 16, 1: 26–40. https://doi.org/10.1080/10503300500090944  \r\nDavid Opriş, Sebastian Pintea, Azucena García-Palacios, Cristina Botella, Ştefan Szamosközi, and Daniel David. 2012. Virtual reality exposure therapy in anxiety disorders: A quantitative meta-analysis. Depression and Anxiety 29, 2: 85–93. https://doi.org/10.1002/da.20910  \r\nLars-Göran Öst. 2008. Cognitive behavior therapy for anxiety disorders: 40 years of progress. Nordic Journal of Psychiatry 62, sup47: 5–10. https://doi.org/10.1080/08039480802315590  \r\nAli Pourmand, Steven Davis, Alex Marchak, Tess Whiteside, and Neal Sikka. 2018. Virtual Reality as a Clinical Tool for Pain Management. Current Pain and Headache Reports 22, 8.  \r\nAlbert Skip Rizzo. 2005. A SWOT Analysis of the Field of Virtual Reality Rehabilitation. Presence 14, 2: 119–146.  \r\nAlbert Skip Rizzo and Sebastian Thomas Koenig. 2017. Is Clinical Virtual Reality Ready for Primetime ? Neuropsychology 31, 8: 877–899.  \r\nBarbara Olasov Rothbaum, Larry F. Hodges, Rob Kooper, Dan Opdyke, and James S. Williford. 1995. Virtual Reality Graded Exposure in the Treatment of Acrophobia : A Case Report. Behavior Therapy 26: 547–554.  \r\nBarbara Olasov Rothbaum, Matthew Price, Tanja Jovanovic, Seth D Norrholm, Maryrose Gerardi, Boadie Dunlop, Michael Davis, Bekh Bradley, Erica J Duncan, Albert Rizzo, and Kerry J Ressler. 2014. A Randomized, Double-Blind Evaluation of D-Clycoserine or Alprazolam Combined with Virtual Reality Exposure Therapy for Posttraumatic Stress Disorder in Iraq and Afghanistan War Veterans. Am J Psychiatry 171, June: 1–9. https://doi.org/10.1176/appi.ajp.2014.13121625  \r\nMaria V Sanchez-vives and Mel Slater. 2005. From presence to consciousness through virtual reality. Nature reviews Neuroscience 6, 4: 332–339. https://doi.org/10.1038/nrn1651  \r\nAdalberto L Simeone, Ifigeneia Mavridou, Wendy Powell, and Senior Member. 2017. Altering User Movement Behaviour in Virtual Environments. IEEE Transactions on Visualization and Computer Graphics 23, 4: 1312–1321. https://doi.org/10.1109/TVCG.2017.2657038  \r\nMel Slater and Anthony Steed. 1995. Taking steps : The influence of a walking technique on presence in virtual reality. CM Transactions on Computer-Human Interaction 2, 3: 201–219. https://doi.org/10.1145/210079.210084  \r\nMel Slater and Martin Usoh. 1993. Representations Systems, Perceptual Position, and Presence in Immersive Virtual Environments. Presence: Teleoperators and Virtual Environments 2, 3: 221–233. https://doi.org/10.1162/pres.1993.2.3.221  \r\nMel Slater and Sylvia Wilbur. 1997. A framework for immersive virtual environments (five): Speculations on the role of presence in virtual environments. Presence: Teleoperators and Virtual Environments 6, 6: 603–616.  \r\nBenjamin O Sullivan, Fahad Alam, and Clyde Matava. 2018. Creating Low-Cost 360-Degree Virtual Reality Videos for Hospitals : A Technical Paper on the Dos and Don\'ts. 20. https://doi.org/10.2196/jmir.9596  \r\nIvan E Sutherland. A head-mounted three dimensional display *. 5–10.  \r\nAnthony Tang and Omid Fakourfar. 2017. Watching 360° Videos Together. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17, 4501–4506. https://doi.org/10.1145/3025453.3025519  \r\nSam Tregillus and Eelke Folmer. 2016. VR-STEP: Walking-in-Place using Inertial Sensing for Hands Free Navigation in Mobile VR Environments. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16: 1250–1255. https://doi.org/10.1145/2858036.2858084  \r\nBob G. Witmer and Michael J. Singer. 1998. Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoperators and Virtual Environments 7, 3: 225–240. https://doi.org/10.1162/105474698565686  \r\nFOOTNOTE\r\n\r\n1 http://www.vrphobia.com/\r\n\r\n2 http://psychiatry.duke.edu/divisions/general-psychiatry/virtual-reality-therapy-phobias/\r\n\r\n3 https://vimeo.com/212007651\r\n\r\n4 https://player.vimeo.com/video/208655948\r\n\r\n5 https://www.imdb.com/title/tt5680410/\r\n\r\n6E.g. https://www.viar360.com/',1,'Lundström','Anders Lundström and Ylva Fernaeus','Anders Lundström *(Media Technology and Interaction Design, KTH Royal Institute of Technology, Sweden)*<br>\r\nYlva Fernaeus *(Media Technology and Interaction Design, KTH Royal Institute of Technology, Sweden)*',NULL,0,'10.1145/3363384.3363398','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,75,5,NULL,NULL,0,14),(18,'yoo-service-design-in-hci-research-the-extended-value-co-creation-model','2019-09-02 15:24:57','2019-10-11 14:36:44','2019-09-02 15:24:57',NULL,1,'published','[]','Service Design in HCI Research: The Extended Value Co-creation Model','In this paper, we discuss what it means to practice service design in an academic research setting. For a long time, the primary focal point of design research has been the users—of their experiences, needs, desires, and values. By contrast, designers have been relatively anonymous and unlocatable. In shift to the service-centric design paradigm, we argue that it is important to recognize design researchers as distinct stakeholders, who actively interact with systems and services with a goal to fulfill their own values and achieve desired outcomes. In practice, typically the role of designer is that of a design consultant working for (or rather on behalf of) the client. By contrast, in academic research settings, the role of designer is that of a design researcher working with their own research agenda.\r\n\r\nWe provide a case study of a service design research project aimed at developing new digital services for public libraries. We encountered a series of issues with a complex set of values at play, in which design researchers emerged as distinct stakeholders with specific sets of research questions, goals, and visions. The main contribution of this paper is a model that (a) clarifies the position of design researchers within the sociocultural context in which they practice design, and (b) visualize how their positions impact the value co-creation, and in turn, the design outcome.','Daisy Yoo, Anya Ernest, Eva Eriksson, Sofia Serholt, and Peter Dalsgaard. 2019. Service Design in HCI Research: The Extended Value Co-creation Model. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 8 pages. [https://doi.org/10.1145/3363384.3363401](https://doi.org/10.1145/3363384.3363401 \"DOI for the article \'Service Design in HCI Research: The Extended Value Co-creation Model\'\")','1 INTRODUCTION\r\n\r\nWith the third wave of human-computer interaction (HCI), as defined by Bødker [5], come new research challenges. One of the major trends in the third wave of HCI is to move away from optimizing efficiency by turning the focus onto experience and meaning-making [6, 24]. Another major trend is the evolving role of interaction designer from a product designer to a service designer. Forlizzi and Zimmerman argue that product-centric approaches to interaction design are insufficient to appropriately take on complex sociotechnical challenges, and propose service design as a complement [13, 15]. They argue that “a service framing offers a systemic approach that better address the complex stakeholder relationships, yields outcomes in the form of product-service systems, and focuses on how value can be co-produced between customers and stakeholders” [15, p. 1]. Responding to Forlizzi and Zimmerman\'s call, we ask: What does it mean to engage in service design in an HCI research setting? We explore this question by reflecting on a case study in which we adopted service design models and methods developed in practice settings and tried to apply them in a collaborative research project aimed at developing new digital services for public libraries.\r\n\r\nThe development of service design has been mainly driven by practitioners. Service design originally emerged from the domains of marketing and management, and over time, developed into a design discipline. Through practice and reflection on what practitioners do, many useful process models and design methods have been developed such as service blueprint [38], customer journey map [40], impact mapping [30], and touchpoints matrix [9] to name a few. However, as Sangiorgi [35] pointed out, service design currently lacks a strong sense of research direction, which is reflected by the limited number of academic publications. According to Roto et al. [33], as of 2017, there were only five CHI papers in the ACM digital library that included “service design” as a keyword.\r\n\r\nWhile practice and research complement each other, we would like to acknowledge a key difference. Design practice focuses on producing new artifacts (e.g., devices and services). Design research, in contrast, is primarily concerned with producing new knowledge. In Research through Design (RtD), for example, the knowledge that comes from the process of bringing a new artifact into being or from studying a designed artifact in use is the contribution, while the resulting artifact (e.g., prototype) is considered more as a means than an end [12, 16, 46]. In design practice, outcomes are often evaluated based on economic value, whereas in design research, outcomes are often evaluated based on intellectual merit. In short, design practice and design research are driven by different agendas. The models and methods developed in practice settings sometimes do not work in research settings, and vice versa.\r\n\r\nThis work contributes to discourses of the designer\'s roles and positions with a specific focus on value tensions and value co-creation between academic researchers and their partner organizations in a collaborative research project. We do so by providing a model that clarifies the position of design researchers in service design and visualizes how their position impacts the value co-creation process, and in turn, the design outcome. Given a strong commitment for knowledge production and a further commitment for sociotechnical innovation, we argue that HCI design researchers play a distinct role in relation to service design practitioners.\r\n\r\nThe paper is structured as follows: First, we offer a brief introduction to service design and the concept of value co-creation. Next, we review how designers have been positioned in various HCI literature. We then introduce the case in question, an international library research project, focusing on key stakeholder values and tensions. We describe the shortcomings of the conventional value co-creation model and service blueprint developed in practice settings and, in turn, suggest an extended value co-creation model adapted to an academic research setting.\r\n\r\n2 BACKGROUND\r\n\r\n2.1 Value Co-creation in Service Design\r\n\r\nService design is distinct from product-centric design in that it is systemic [14]. While product-centric design focuses on the design of artifacts, service design turns the focus onto design of interactive systems comprised of multiple resources and stakeholders [19]. In other words, service design extends beyond the traditional product-centric design paradigm by taking into account a complex set of social relations and technological ecologies surrounding the artifact that we build [23]. In particular, Ramirez and Mannervick [31] described service design as the design of “value-creating systems,” meaning that to design a service is to organize a system of value creation by redistributing capabilities across a complex network of stakeholders. Such capabilities are “not resources per se, but the ability to access, deploy, exchange, and combine them that lies at the heart of value creation” [26, p. 409].\r\n\r\nTraditionally, service providers were primarily charged with responsibility for planning, manufacturing, and delivering services to their customers, who in turn could demand, consume, and evaluate them [29]. Thus, service has been understood as a delivery of value that is predetermined and embedded in the service (see Figure 1). This traditional formulation of service, however, has been critiqued and evolved through the recent development of service-dominant logic [44]. According to service-dominant logic, the value of a service is co-created in use rather than delivered in exchange. As Meroni and Sangiorgi [25] argue, the key to engage in value co-creation is to understand “the fundamental inability of design to completely plan and regulate services, while instead considering its capacity to potentially create the right conditions for certain forms of interactions and relationships to happen” (p. 10). Service professionals can only propose potential value by creating the right conditions for a positive experience, which users later turn into real value-in-use. Such a process of value co-creation is dialogical (see Figure 2). Users engage in value co-creation by actively interacting with the service and by assessing their subsequent experience of the service. By expressing their expectations and combining resources for their own benefits, the role of users shifts from a mere consumer to a co-creator of value. Service professionals (rather than service providers), in turn, propose potential values based on understanding of what users expect and how users combine resources.\r\n\r\n\r\nFigure 1: Service as delivery in traditional service design model.\r\n\r\nFigure 2: Our interpretation of value co-creation in service-dominant logic.\r\n2.2 Design Researchers as Distinct Stakeholders\r\n\r\nDesign is never from nowhere and a designer is never unbiased [39]. Drawing from Haraway\'s concept of situated knowledge [18], Suchman [42] called for professional designers to take “located accountability” to become responsible for explicitly positioning themselves within the social relations that comprise technical systems. Echoing Suchman\'s perspective, the HCI community has become increasingly aware of the importance of locating and disclosing the designer\'s own sociocultural position in the world. Reflective design [36] is one compelling example, which argues for a more rigorous, critical approach to reflecting on what values, attitudes, and worldviews designers bring into the design practice. In Participatory Design (PD) literature, Iversen, Halskov, and Leong [21] focused on designers’ use of appreciative judgment of values: “the capacity to understand, or appreciate a situation through the discernment of what is to be considered as a background and what is to be considered as foreground in the formation of a project” (p. 92). Iversen and colleagues encouraged designers to be aware of their personal values so as to understand how those values guide their choice of design methods and resources and how it impacts their interpretation of stakeholders’ values. Furthermore, in value sensitive design (VSD) literature, Borning and Muller [7] criticized the publication norms in HCI, in which researchers are instructed to anonymize their work and to use a disembodied voice in reporting their investigations. Borning and Muller called for design researchers to disclose their researcher stance and make their voice salient in the writing about their socio-cultural background, their relation to the participants in the study, and their personal values at play that impacted their design judgment.\r\n\r\nBuilding on the above discourses on designer\'s positions and values, in this paper we will specifically examine the role of design researcher in collaborative research with non-academic partners. Borrowing from Nelson and Stolterman [27]’s model of the ideal service design relationship, we visualized service design research partnership as shown in Figure 3. Like Yin and Yang, such a relationship is a dynamically balanced relationship, but it is not a relationship without tensions. As Nelson and Stolterman described: “The model implies that tension lies at the core of the interconnection. It is the complexity of this interconnection, and in the tension between its different qualities, that imaginative and innovative design work takes place” (p. 49). While specific qualities of the stakeholders may differ greatly from case to case, one of the common qualities shared by many design researchers engaging in service design is the intention to drive sociotechnical innovation and to generate new knowledge. Partner organizations, on the other hand, join a research partnership with a desire for service innovation at the very least. Attending to inconsistent conceptions of value and value tensions among diverse partners is one of the most crucial yet challenging tasks in collaborative research [4] – especially when the partner organization\'s understanding of value is skewed towards narrow economic measures [45].\r\n\r\n3 CASE STUDY: DESIGNING DIGITAL SERVICES FOR PUBLIC LIBRARY\r\n\r\n3.1 Project Synopsis\r\n\r\nIn this project, we make use of a computational alternative research agenda [22]. Computational alternatives are not designed to showcase a new technical solution to a well-known problem, but rather to systematically question the technological status quo and peak into a possible future. At the same time, they are not speculative fictions detached from real-world practice. Computational alternatives aim to elucidate sociotechnical issues otherwise taken for granted, through critical technical development in a concrete use case.\r\n\r\n\r\nFigure 3: Model of service design research partnership adapted from Nelson and Stolterman [27].\r\nSpecifically, we conducted our investigation around the case of exploring computational alternatives for public libraries, namely the PLACED project. Public libraries are undergoing transitions from a quiet study space to a vibrant “third place” [1, 11, 28]. Libraries are taking up a new role to become urban innovation hubs by offering a range of activities that bring together local communities from different neighborhoods and backgrounds. The PLACED project aims to support community events and cultural activities taking place in public libraries by developing digital services to effectively capture knowledge co-created by local residents participating in these events and activities. Furthermore, the project aims to explore how to turn such local knowledge into an integral part of the library collection.\r\n\r\nThe PLACED project consortium consists of partners from three European countries: Denmark, France, and Sweden. Each country is represented by one research university and one public library. In addition, we have a partner from Sweden that assists in developing a business plan for ensuring the ongoing development and deployment of the digital services when the initial research project funding expires.\r\n\r\n\r\nFigure 4: Traditional service blueprint of the PLACED project.\r\n3.2 Method\r\n\r\nWe provide a design reflection on value tensions and value co-creation between two key stakeholders of this project: the partner libraries and the design researchers. By partner libraries, we refer to three public libraries participating in this project. By design researchers, we refer to academics who are leading this project, including the authors. First, we will reflect on each stakeholder\'s values. Next, we identify key tensions that may be of particular interest to the HCI design community.\r\n\r\nThe stakeholder values have been identified in two ways. First, in order to identify values of the partner libraries, one of the authors conducted a thematic analysis on empirical data collected from co-design sessions and ethnographic investigations from the first year of the project. For collecting data, we used a qualitative multi-site approach [3], where we studied three public libraries, each in a different country, over the course of six months. The primary research carried out included (1) ethnographic studies and semi-structured individual and group interviews, (2) co-design workshops with library personnel, and (3) a focus group with library personnel. Secondary research included analysis of the different websites and social media used by the libraries, and the ways in which the libraries market themselves and their activities online. When applicable, statistics were also obtained through the library staff. Next, in order to identify values of the design researchers, another author analyzed the research funding application document using open coding [41] and thematic coding [17]. Among international researchers working across different academic institutions, the research funding application document served as the primary contract and a guide for conducting our design investigations.\r\n\r\n3.3 Identifying Stakeholder Values\r\n\r\nIn what follows, we discuss values of the key stakeholders in the project—the partner libraries and the design researchers—in order to surface intersections and tensions, as well as to describe the value co-creation process that we took when these values were brought into play in the project.\r\n\r\n3.3.1 Values of the Partner Libraries. As was reported in our previous work [37], the practice of the library staff is guided by value sentiments such as empowerment, freedom of expression, emancipation and democracy, and organized activities at the library are heavily influenced by such ideals. Public libraries have a sense of duty to maintain the status of libraries as free services open for anyone, not seeking to profit upon patrons, and where they can offer spaces for teaching and learning through activities, literature, and by means of the space itself.\r\n\r\nFurthermore, the library staff is committed to providing various services to respond to the needs of residents in local areas. For example, the library staff assists patrons in civic matters by helping them to fill out a form or guiding them in printing out necessary documentation. The library space also offers a safe haven for citizens who are in need of a place to stay during the day, such as homeless people. Such efforts, however, often go unnoticed by the public, in part, because of the difficulty measuring the broad impact. Many politicians, who supply the funding, would rather focus on the services that can be measured through statistics such as visitor count, putting a pressure on libraries to stay focused on more popular and highly visible activities.\r\n\r\n\r\nFigure 5: Extended service blueprint of the PLACED project, where (1) blue is where the partner libraries see most values, (2) green is where the design researchers see most values, (3) orange is where we see most tensions, (4) purple is a new service that does not currently exist but for which both the partner libraries and the design researchers see potential values and tensions.\r\n3.3.2 Values of the Design Researchers. The overarching research goal of the PLACED project is to develop new and dynamic digital services to help public libraries transform from a traditional knowledge institution into a vibrant urban hub. We aim to do so by building a web-based open source infrastructure supporting knowledge creation activities among citizens, and then turning this knowledge into an ever-growing part of the urban community\'s shared resources. Key design research values include: technological innovation (i.e., leveraging “cutting-edge academic expertise in participatory design, human-computer interaction, activity-based computing and visualization”), localization (i.e., ensuring “a strong rooting in the local challenges’ and increasing ‘the capacity of urban areas to answer local challenges”), participation (i.e., encouraging “active participation and co-creation of knowledge by citizens to enrich library collections”), dynamic knowledge (i.e., supporting the transformation of public libraries “from static to dynamic urban knowledge hubs,” creating a “growing, living library collection fueled by the activities of the citizens who actively use the library”), and sustainable dialogue (i.e., enabling public libraries to “support the evolving needs of urban residents on an ongoing basis through continuous dialogue after the project has ended”).\r\n\r\n3.4 Surfacing Value Tensions in the PLACED project\r\n\r\nThe partner libraries and the design researchers shared sensibilities around values of participation and sustainable dialogue. The partner libraries, on the one hand, aim to provide a social meeting place, free of charge and open for all, promoting citizen participation. The design researchers, on the other hand, are committed to take a participatory approach in the design process as well as in the use of technology. The partner libraries and the design researchers also shared sensibilities around the desire to meet local needs and engage in local issues. At the same time, there were different, and sometimes diverging, stakeholder values at play in the PLACED project. Here we describe key value tensions arising from: (a) technological innovation versus digital overhead and (b) dynamic knowledge versus traditional knowledge.\r\n\r\n3.4.1 Technological Innovation vs. Digital Overhead. Considering value of technological innovation, the partner libraries regarded technology as holding a lot of promise if it supports the underlying values such as accessibility and openness. However, a clear issue in contemporary libraries can be characterized as ”digital overhead” that is inevitable for most of the library staff who are not particularly tech savvy. While our partner libraries have indicated that they feel positive towards user-friendly, simple technologies in their everyday work (e.g., their book return robots), they were considerably less pleased when new (and, to them, complicated) digital systems were introduced, as this entails a shift in focus from the social engagement librarians want to take part in, towards occupying a substantial amount of their day dealing with technical issues.\r\n\r\n3.4.2 Dynamic Knowledge vs. Traditional Knowledge. The partner libraries viewed knowledge in a traditional sense, where they feature as guardians and providers of the social and cultural heritage of society by means of the expert knowledge that is the library collection. It was clearly important for librarians to maintain, preserve, and safe-guard what should be regarded as library content and what should not. Suggesting an emergent view on dynamic knowledge where anyone and everyone can become a contributor, therefore, might be perceived as a threat toward the legacy of the library and the duty of librarians. Any content that is not produced by the libraries themselves, or supplied through the collection whose legitimacy is ensured, necessitates moderation and curation by the library personnel. This makes the idea of the dynamic knowledge, with which we, the design researchers aim to support a “growing, living library collection fueled by the activities of the citizens who actively use the library,” inherently problematic.\r\n\r\n3.5 Engaging in Value Co-creation: Extending the Service Blueprint Method\r\n\r\nIn the PLACED project, we used service blueprints [38] to communicate stakeholder values and address value tensions. Initially, we generated a traditional version of a service blueprint focusing on interactions and touch points between the library staff and the patrons (see Figure 4). This service blueprint was effective in visualizing the overall work process of organizing a library event and identifying practical needs and pain points of the library staff. However, this service blueprint led us to only focus on well-known problems at hand experienced by the partner libraries within their existing practice (e.g., addressing logistical issues). This service blueprint did not reflect interests of the design researchers who sought to challenge the status quo. Taking the computational alternatives approach, we, the design researchers, were interested in exploring design opportunities that can transform the nature of participation and knowledge co-creation in library events.\r\n\r\nThus, we created an extended version of the service blueprint (see Figure 5). This service blueprint aims to (a) reflect values of the design researchers as well as the partner libraries, (b) surface value tensions, and (c) identify novel opportunities.\r\n\r\n\r\nFigure 6: Revised value co-creation model in an academic research setting.\r\n4 THE EXTENDED VALUE CO-CREATION MODEL FOR DESIGN RESEARCH SETTINGS\r\n\r\nWith the stakeholder value mapping and identification of tensions in the PLACED project, it became clear that the way design researchers work with their partner organization is different from the way service design practitioners work on behalf of their client organization. Design researchers have a direct stake in the project as they bring in a specific set of research questions, goals, and visions. Different conceptions of value between design researchers and their partner organizations need to be clearly communicated and explicitly negotiated in the design process.\r\n\r\nWe considered the traditional value co-creation model (see Figure 2) to be insufficient for describing how we worked with our partner organizations. Based on the above insights, we created an extended model of value co-creation (see Figure 6), highlighting the dynamics between design researchers and their partner organizations.\r\n\r\nIn our new model, design researchers and partner organizations collaboratively define the value proposition for the service system. Partner organizations join the project with desire for service innovation and potential economic value, whereas design researchers join the project with the agenda for sociotechnical innovation and knowledge creation. By recognizing their own values and making them explicit, design researchers become a distinct stakeholder in the value co-creation process. For partner organizations, it is important to understand what the design researcher\'s values are and how those will impact the value proposition.\r\n\r\nWe propose that PD can offer insights into how design researchers can engage with their partner organization in value co-creation. The principle of mutual learning prevalent in PD emphasizes the need for the development of processes and tools that enable more robust communication among those involved in the design process [32]. Through PD processes, design researchers and partner organizations can learn from each other by understanding each other\'s practices, values, and priorities. This leads to a more robust value proposition that reflects both the perspectives of design researchers and partner organizations, which leads, in turn, to outcomes that are more likely to be successful.\r\n\r\n4.1 Implications of the Extended Value Co-creation Model for the PLACED project\r\n\r\nThere are many implications of the extended value co-creation model in design research. It is beyond the scope of this paper to examine them all, but here we share some of the key implications we encountered in the case of the PLACED project.\r\n\r\nFirst, by reflecting on the traditional service blueprint (see Figure 4) and identifying gaps, we have become aware of the design researchers as a distinct stakeholder. Becoming aware of our own research agenda and values, we have learned to accept them and allowed those values to guide how the project develops. To do so, we have allocated time to explicitly identify and clearly communicate stakeholder values. Specifically, we analyzed key stakeholder values as described in Section 3 and generated an extended version of service blueprint (see Figure 5).\r\n\r\nIn the process of identifying values, we have also been able to identify tensions. By making the tensions explicit, we were able to explore ways to resolve tensions. Above all, we have learned the importance of trying to communicate an explicit research agenda in every meeting. We have strived to reflect on a shared project vision often, preferably in every contact with the partner organizations. We have organized multiple joint meetings with all the key stakeholders for building common ground and empathy. This is a process that occurs in many projects, but the focus of these meetings was not just about design researchers gaining better understanding of the stakeholders; we have focused on finding ways to make the stakeholders understand us, design researchers, to reach mutual learning. By doing so, the stakeholders can set the right expectations for the project outcomes.\r\n\r\nThis focus on mutual learning has led us to change our implementation process to that of participatory prototyping, where we as design researchers provide re-configurable alternatives in forms of design prototypes, with which the questions asked are carefully examined and the answers are digested in cooperation with stakeholders [5]. We have further taken on a computational alternative approach, meaning that we now communicate more explicitly to all stakeholders that the main approach in the project is not to solve well-known problems here and now, but rather to systematically question the technological status quo and peak into a possible future [22]. To mitigate the present-future gap that poses challenges to evaluation [34], we have chosen a situated evaluation approach [8].\r\n\r\nFurthermore, we aim to incorporate economics as a material for design, to understand the underlying economic model with a wider set of stakeholders [15]. Specifically, we plan to develop a viable business model as a result of the project, which will be reported on elsewhere.\r\n\r\n5 DISCUSSION AND CONCLUSION\r\n\r\nThe extended model of value co-creation clarifies the position of design researchers in service design projects, and contributes to broader discourses of the designer\'s positions and values in HCI. In ”When second wave HCI meets third wave challenges”, Bødker states: ”I am concerned with the possible lack of serious commitment of designers to users [...] As I have pointed out, this leads to a situation where mediators either make us break down or act transparently, but where our ability as human beings to learn and cooperate in communities of practice is largely ignored” [5, p. 6]. We propose that service design, in combination with PD, can serve as a frame for understanding and addressing mutual learning and cooperation in the design of services. Although several researchers have discussed the interplay of research and design as unfolding throughout a design process (e.g., [2, 10]), we have not yet seen this discussion in relation to service design and the HCI researchers as distinct stakeholders who bring their own agenda and values to the project.\r\n\r\nWe argue that a service design perspective can contribute to design-oriented HCI research since it offers insights on how to address complex sociotechnical systems. However, it also has limitations and embody certain perspectives that must be taken into consideration. Service design originally emerged from the domains of marketing and management, relies on a rather simplistic framing of customer and service provider, and seems timid in its approach to using technology as it often entails the adoption of well-known technology and commercial platforms [46]. In this sense, it embodies some of the traits that Bødker warns against: ”The emerging third wave seems strongly tied to a kind of consumerism that differs from the underlying co-determination framework of the Scandinavian societies” [5, p. 6]. One way to address this problem is to adopt an understanding of the notion of value that extends beyond pecuniary aspects and take into consideration a wider understanding of value related to the social and political contexts [45]. PD research such as that of Van der Velden and Mörtberg [43] and Iversen et al. [20] provides useful insights for doing so. In the case of design researchers entering the fray, this expanded understanding of value must also entail the value of sociotechnical innovation and new knowledge created in collaborative partnership between the researchers and the partner organizations.\r\n\r\nIn this paper, we have discussed how service design can be a complement to HCI research settings, and especially with focus on the role of design researcher. The contribution of this paper is a model of the value co-creation process with design researchers as distinct stakeholders who bring with them their own values and agenda into the project. We have placed our model in the ongoing discourse on how to practice service design in HCI research and how to address designer values. We hope that readers will borrow and appropriate this model in diverse service design research settings.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThanks to all who took part in this study. The work is funded by Vinnova 2017-01553, Innovation Fund Denmark 5123-00007B, Agence Nationale de la Recherche ANR-16-ENSF-0004, and JPI Urban Europe EU 693443. We also thank Erasmus+ 2018-1-SE01-KA203-039072.\r\n\r\nREFERENCES\r\n\r\nSvanhild Aabø and Ragnar Audunson. 2012. Use of library space and the library as place. Library & Information Science Research 34, 2 (2012), 138–149. https://doi.org/10.1016/j.lisr.2011.06.002  \r\nDitte Amund Basballe and Kim Halskov. 2012. Dynamics of Research Through Design. In Proceedings of the Designing Interactive Systems Conference(DIS ’12). ACM, New York, NY, USA, 58–67. https://doi.org/10.1145/2317956.2317967  \r\nPam Bishop. 2010. Multi-Site Case Study. In Encyclopedia of Case Study Research, A Mills, G Durepos, and E Wiebe (Eds.). SAGE Publications, Inc, Thousand Oaks, CA, USA, 588–591. https://doi.org/10.4135/9781412957397  \r\nMichael Mose Biskjaer, Aliakbar Kamari, Stina Rask Jensen, and Poul Henning Kirkegaard. 2019. Exploring blind spots in collaborative value creation in building design: a creativity perspective. CoDesign (2019), 1–18.  \r\nSusanne Bødker. 2006. When Second Wave HCI Meets Third Wave Challenges. In Proceedings of the 4th Nordic Conference on Human-computer Interaction: Changing Roles(NordiCHI ’06). ACM, New York, NY, USA, 1–8. https://doi.org/10.1145/1182475.1182476  \r\nSusanne Bødker. 2015. Third-wave HCI, 10 Years Later—participation and Sharing. interactions 22, 5 (Aug. 2015), 24–31. https://doi.org/10.1145/2804405  \r\nAlan Borning and Michael Muller. 2012. Next Steps for Value Sensitive Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’12). ACM, New York, NY, USA, 1125–1134. https://doi.org/10.1145/2207676.2208560  \r\nBertram Bruce, Andee Rubin, and Junghyun An. 2009. Situated Evaluation of Socio-Technical Systems. https://doi.org/10.4018/9781605669847.ch144  \r\nGianluca Brugnoli. 2009. Connecting the dots of user experience. Journal of Information Architecture 1, 1 (2009).  \r\nPeter Dalsgaard. 2010. Research in and Through Design: An Interaction Design Research Approach. In Proceedings of the 22Nd Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction(OZCHI ’10). ACM, New York, NY, USA, 200–203. https://doi.org/10.1145/1952222.1952265  \r\nJ. K. Elmborg. 2011. Libraries as the spaces between us: Recognizing and valuing the third space. Reference & User Services Quarterly 50, 4 (2011), 338–350.  \r\nDaniel Fällman. 2003. Design-oriented Human-computer Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 225–232. https://doi.org/10.1145/642611.642652  \r\nJodi Forlizzi. [n. d.]. Moving beyond user-centered design. Interactions 25([n. d.]).  \r\nJodi Forlizzi. 2010. All Look Same?: A Comparison of Experience Design and Service Design. Interactions 17, 5 (Sept. 2010), 60–62. https://doi.org/10.1145/1836216.1836232  \r\nJodi Forlizzi and John Zimmerman. 2013. Promoting service design as a core practice in interaction design. In Proceedings of IASDR13. 1–12.  \r\nWilliam Gaver. 2012. What Should We Expect from Research Through Design?. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’12). ACM, New York, NY, USA, 937–946. https://doi.org/10.1145/2207676.2208538  \r\nGraham R Gibbs. 2007. Analyzing qualitative data. Sage Publications, Inc., Thousand Oaks, CA, US.  \r\nDonna Haraway. 1998. Situated knowledges: The science question in feminism and the privilege of partial perspective. Feminist studies 14, 3 (1998), 575–599.  \r\nStefan Holmlid. 2007. Interaction Design and Service Design: Expending a Comparison of Design Disciplines. In Proceedings of NORDES’07.  \r\nOle Sejer Iversen, Kim Halskov, and Tuck Leong. 2012. Values-led participatory design. CoDesign 8, 2–3 (2012), 87–103.  \r\nOle Sejer Iversen, Kim Halskov, and Tuck Wah Leong. 2010. Rekindling Values in Participatory Design. In Proceedings of the 11th Biennial Participatory Design Conference(PDC ’10). ACM, New York, NY, USA, 91–100. https://doi.org/10.1145/1900441.1900455  \r\nHenrik Korsgaard, Clemens Nylandsted Klokmose, and Susanne Bødker. 2016. Computational Alternatives in Participatory Design: Putting the T Back in Socio-technical Research. In Proceedings of the 14th Participatory Design Conference: Full Papers - Volume 1(PDC ’16). ACM, New York, NY, USA, 71–79. https://doi.org/10.1145/2940299.2940314  \r\nRamia Maze and Johan Redström. 2008. Switch! Energy Ecologies in Everyday Life. International Journal of Design. 2, 3 (Nov. 2008). http://www.ijdesign.org/index.php/IJDesign/article/view/492/222  \r\nJohn McCarthy and Peter Wright. 2004. Technology As Experience. The MIT Press.  \r\nAnna Meroni and Daniela Sangiorgi. 2011. Design for services. Grower Publishing.  \r\nP. Moran and S. Ghoshal. 1999. Markets, firms, and the process of economic development. Academy of management review 24, 3 (1999), 390–412.  \r\nHarold G. Nelson and Erik Stolterman. 2012. The Design Way: Intentional Change in an Unpredictable World. The MIT Press.  \r\nR Oldenburg. 1989. The Great Good Place: Cafes, Coffee Shops, Bookstores, Bars, Hairsalons and Other Hangouts at the Heart of Community. Marlowe and Company.  \r\nS. P. Osborne, Z. Radnor, and K. Strokosch. 2016. Co-production and the co-creation of value in public services: a suitable case for treatment?Public Management Review 18, 5 (2016), 639–653.  \r\nIngrid Ottersten and Mijo Balic. 2010. Effektstyrning av IT : nyttan uppstår i användningen (2 ed.). Liber, Malmo, Sweden.  \r\nRafael Ramirez and Ulf Mannervik. 2008. Designing Value Creating Systems. In Designing for Services: Multidisciplinary Perspectives - Proceedings from the Exploratory Project on Designing for Services in Science and Technology Based Enterprises, Lucy Kimbell and Victor Seidel (Eds.). Said Business School, University of Oxford, Oxford.  \r\nToni Robertson and Ina Wagner. 2012. Ethics: engagement, representation and politics-in-action. In Routledge International Handbook of Participatory Design. Routledge, Chapter 4. https://doi.org/10.4324/9780203108543.ch4  \r\nVirpi Roto, Jung-Joo Lee, Tuuli Mattelmäki, and John Zimmerman. 2018. Experience Design Meets Service Design: Method Clash or Marriage?. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems(CHI EA ’18). ACM, New York, NY, USA, Article W26, 6 pages. https://doi.org/10.1145/3170427.3170626  \r\nAntti Salovaara, Antti Oulasvirta, and Giulio Jacucci. 2017. Evaluation of Prototypes and the Problem of Possible Futures. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems(CHI ’17). ACM, New York, NY, USA, 2064–2077. https://doi.org/10.1145/3025453.3025658 \r\nDaniela Sangiorgi. 2009. Building Up a Framework for Service Design Research. In 8th European Academy Of Design Conference. 415–420.  \r\nPhoebe Sengers, Kirsten Boehner, Shay David, and Joseph\'Jofish’ Kaye. 2005. Reflective design. In Proceedings of the 4th decennial conference on Critical computing: between sense and sensibility. ACM, 49–58.  \r\nSofia Serholt, Eva Eriksson, Peter Dalsgaard, Raphaëlle Bats, and Alix Ducros. 2018. Opportunities and Challenges for Technology Development and Adoption in Public Libraries. In Proceedings of the 10th Nordic Conference on Human-Computer Interaction(NordiCHI ’18). ACM, New York, NY, USA, 311–322. https://doi.org/10.1145/3240167.3240198  \r\nLynn Shostack. 1982. How to Design a Service?European Journal of Marketing 16 (1982), 49–63.  \r\nM. L. J. Söndergaard and L. K. Hansen. 2017. Designing with Bias and Privilege. Nordes 2017 7(2017).  \r\nMarc Stickdorn and Schneider Jakob. 2012. This is Service Design Thinking: Basics, Tools, Cases. Wiley, New York, NY.  \r\nAnselm Strauss and Juliet M. Corbin. 1990. Basics of qualitative research: Grounded theory procedures and techniques. Sage Publications, Inc., Thousand Oaks, CA, US.  \r\nLucy Suchman. 2002. Located Accountabilities in Technology Production. Scand. J. Inf. Syst. 14, 2 (Sept. 2002), 91–105. http://dl.acm.org/citation.cfm?id=782686.782694  \r\nM Van der Velden and Christina Mörtberg. 2015. Participatory design and design for values. In Handbook of Ethics, Values, and Technological Design: Sources, Theory, Values and Application Domains. 41–66.  \r\nS.L. Vargo and R.F. Lusch. 2004. Evolving to a new dominant logic for marketing. Journal of marketing 68, 1 (2004), 1–17.  \r\nRoger Whitham, Simon Moreton, Simon Bowen, Chris Speed, and Abigail Durrant. 2019. Understanding, capturing and assessing value in collaborative design research. CoDesign1(2019).  \r\nJohn Zimmerman, Jodi Forlizzi, and Shelley Evenson. 2007. Research Through Design As a Method for Interaction Design Research in HCI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’07). ACM, New York, NY, USA, 493–502. https://doi.org/10.1145/1240624.1240704 ',1,'Yoo','Daisy Yoo, Anya Ernest, Eva Eriksson, Sofia Serholt, and Peter Dalsgaard','Daisy Yoo *(Aarhus University, Denmark)*<br>\r\nAnya Ernest *(Chalmers University of Technology, Sweden)*<br>\r\nEva Eriksson *(Aarhus University, Denmark and Chalmers University of Technology, Sweden)*<br>\r\nSofia Serholt *(University of Gothenburg, Sweden)*<br>\r\nPeter Dalsgaard *(Aarhus University, Denmark)*',NULL,0,'10.1145/3363384.3363401','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,10,NULL,NULL,0,17),(19,'carcani-making-activities-visible-a-way-to-patient-empowerment-cscw-perspectives-on-the-cognitive-rehabilitation-process','2019-09-02 15:24:57','2019-10-25 16:29:25','2019-09-02 15:24:57',NULL,1,'published','[]','Making activities visible: a way to patient empowerment — CSCW perspectives on the cognitive rehabilitation process','Patient empowerment is a concept that has found an extensive discussion in health care. It is of significant interest, especially now when the number of people living with chronic diseases has increased. However, there is a stigma associated with being a patient, and contributing to empowerment becomes more challenging. In this paper, we present an empirical study of the cognitive rehabilitation process. We root the case analysis in Computer Supported Cooperative Work (CSCW) research field and further reflect on patient empowerment concept. Through our reflections, we contribute to the discussion of patient empowerment by highlighting some of the work structures that need to be in place in healthcare to make possible patient empowerment. Moreover, we contribute back to CSCW through a situated discourse of concepts in the context of rehabilitation care model. Rendering publicly visible the activities and facilitating the overseeing of events and activities, both in the level of the overall treatment as well as the micro-interactions among health care professionals and patients, are found relevant in building awareness among parts and leading to empowerment.','Klaudia Çarçani, Jo Herstad, and Harald Holone. 2019. Making activities visible: a way to patient empowerment: CSCW perspectives on the cognitive rehabilitation process. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 8 pages. [https://doi.org/10.1145/3363384.3363482](https://doi.org/10.1145/3363384.3363482 \"DOI for the article \'Making activities visible: a way to patient empowerment — CSCW perspectives on the cognitive rehabilitation process\'\")','1 Introduction\r\n\r\nPatient empowerment is a central subject in a rapidly changing health care system. It is recognized as an “essential element of high-quality healthcare systems tackling the expanding burden of chronic diseases” [7]. The European Patient Empowerment and Centeredness Committee [7] defines empowered patients as “people who are expected to take more control over their illnesses or treatments where possible, and doctors are expected to encourage or ‘empower’ them to do so by enabling patients to become equal partners in the team managing their health”. We refer to the European Patient Forum [8] definition of empowerment and look at empowerment as a compound of factors that together make a patient empowered. These factors are: meaningful involvement in the treatment, health literacy, shared decision making with healthcare professional and self-management [8, pp. 7-9]. While patient empowerment has been at the centre of discussions in healthcare in the latest decades and laws and regulations in several countries have supported it, there is still a long way to go before claiming that we have achieved patient empowerment.\r\n\r\nWe pose the question “How can a shared coordination mechanism that supports rendering treatment activities “publicly” visible for the patient and medical staff and gives an overall view of activities and events at the hospital influences patient empowerment?” We present our findings and reflections from an empirical study of the cognitive rehabilitation process. The data were gathered first through ethnographic explorations of the patient journey undergoing cognitive rehabilitation in a specialised hospital in Norway. Then, the patient\'s needs were explored through Participatory Design (PD) workshops for redesigning a goal-plan document used in rehabilitation. The goal-plan is a patient health record co-constructed by medical professionals involved in patient rehabilitation (formal caregivers), the patient, and the kin or others caring about the patient (informal caregivers). This document is essential for coordinating rehabilitation activities and helps supporting patient empowerment. The patient gets the document on paper.\r\n\r\nThe case of cognitive rehabilitation resembles a cooperative work setting where patient, formal and informal caregivers are mutually dependent in order to deliver the rehabilitation services. Hence, we ground our analysis of “patient empowerment” in Computer Supported Cooperative Work (CSCW) studies. We apply concepts and findings explored in other contexts in CSCW, but which result highly relevant for our case to disentangle the concept of patient empowerment. We discuss participation of the patient in articulation work – coined by Strauss and colleagues [23; 25] – and the construction of patient-healthcare professionals coordination mechanisms – coined by Schmidt and Simonee [20] – as relevant building blocks to empowerment. Further, we engage in discussing how the participation in articulation work and coordination mechanisms requires activities and events to be rendered publicly visible – coined by Heath and Luff [12; 13] – among each of the agents in rehabilitation, both on the treatment management level as well as the daily micro-interactions, in order to support the transition of patient toward becoming an expert in rehabilitation and consequently influencing empowerment. Moreover, we discuss how the micro-mobility – coined by Luff and Heath [17] – associated with the paper document and how the design of this paper document influences public and private spaces and should be considered once designing the empowering coordination mechanisms.\r\n\r\nWe contribute in CSCW with a situated discourse of the concepts mentioned above in the context of cognitive rehabilitation care model as a novel care model leaning toward cooperation. Moreover, we contribute to CSCW by discussing a situation where agents through rendering activities visible contribute to the construction of awareness. The transitional process of patients toward becoming aware of their rehabilitation contributes to patient empowerment. Hence, we conclude by proposing an enhanced patient empowerment discussion model.\r\n\r\n2 Patient empowerment\r\n\r\nPatient Empowerment is a complex concept which comprises broad use in different contexts [4; 14]. There are various definitions of patient empowerment [4]. However, Roberts [18] in a critique commentary states that the concept can be still classified as fuzzy and black-boxed. We root our understanding of patient empowerment in the insights derived from an EU-funded project called EMPATHIE (“Empowering Patients in the Management of Chronic Diseases” as reported in [8]) as akin to the context of cognitive rehabilitation. The European Patient Forum (EPF) [8] in their report expands on four related concepts on which to position the discussion and analysis of an empowered patient. This approach of patient empowerment as not a single entity but an umbrella term for other concepts is found as well in other research entities [1; 10; 14]. We will use these four areas described in the EPF report as the ground for discussing patient empowerment and build our reflections from there. The following areas of discussing patient empowerment has been largely recognized in the patient empowerment literature. However, the EPF document brings them together, and that is why we use that as our main reference.\r\n\r\nMeaningful involvement - relates to the right and duty “to participate individually and collectively in the planning and implementation of their healthcare” (Alma Ata Declaration – Principle IV. 1978, WHO as cited in [8, pp.7-8]. The patient holds the expertise in her/his life and daily challenges, so it should have a more determinant role in their treatment.\r\nHealth literacy means having sound knowledge of your condition which will lead to better health decisions in the context of everyday life – “at home, in the local community, at the workplace, the healthcare system, the market place and the political arena” [8, pp.7-8; 15].\r\nSelf-management stands for the support that the patient should get in order to live in the best way possible with the condition they have. The self-management support aims to build among patients the confidence, self-efficacy and skills to take control of their daily life and attain the highest possible quality of life. This also helps to make the best use of all available resources “by, for example, improving adherence, reducing hospitalisation and emergency visits, and improving health outcomes” [8, pp.9-10].\r\nShared decision-making stands for a partnership of equals among patient and healthcare professionals. The involvement of the patient should be accepted by the healthcare professionals, which would welcome the patient\'s participation in the decision making of her/his treatment [8, pp.10-11].\r\nWe contribute to the ongoing discussion of patient empowerment with insights from a study of cognitive rehabilitation in a specialised rehabilitation hospital in Norway with a model for operationalizing patient empowerment.\r\n\r\n3 Methods\r\n\r\nWorld Health Organization (WHO) defines rehabilitation as a “set of measures that assist individuals who experience, or are likely to experience, disability to achieve and maintain optimal functioning in interaction with their environment” [26, pp.96]. While there are several rehabilitation programs, we will present in this paper, our empirical study of cognitive rehabilitation. Cognitive Rehabilitation is that rehabilitation program which is offered to patients that have had an Acquired Brain Injury, caused mainly from stroke or accidents (Traumatic Brain Injury) and have to live with one or a set of cognitive impairments which make challenging their everyday life. Our study group were people with Mild Acquired Cognitive Impairments (MACI). MACI consists mostly on tiredness, anxiety, memory and attention problems persisting after a person has had an acquired brain injury. More about the study group has been described in a previous publication [5].\r\n\r\nThe study of the cognitive rehabilitation process and the patient journey was conducted in a specialist rehabilitation hospital in Norway in which there is a unit which is specialised in cognitive rehabilitation. The study we present refers to data collected over an extended period of study and involvement in a redesign project in this unit.\r\n\r\nThe first author conducted non-participant observations during a 6-months period. During this period, the researcher shadowed two occupational therapists, one nurse, one physiotherapist, one speech therapist, one social worker and one psychologist, providing 180 hours of observations. In addition, a semi-structured interview with each of the staff members shadowed was organised after the observation period to understand other activities they do with the patients.\r\n\r\nMoreover, we supplemented the observations with an analysis of routine documents for the workflow at the unit and went through five patient goal-plan documents and the respective weekly plan documents. The triangulation of data helped to gain a better understanding of the workflow. The limitation of our study consists of not having observed the patient journey from the patient\'s perspective. However, in collaboration with the medical staff at the hospital we judged that such a procedure would be the best setting for the research but not for the patients, whom usually have a tiredness syndrome and could be overwhelmed by the presence of the researcher.\r\n\r\nThe second data source comes from three Participatory Design workshops with ten patients. In the workshops, we investigated needs for redesigning the main patient health record document, called the goal-plan document, in a way that supports the patient to have a better understanding and take control of their rehabilitation. A detailed description of the PD process is presented in [5].\r\n\r\nThe research was approved by the Norwegian Centre for Research Data. Digital and physical data have been saved securely at the hospital premises. During observations and workshops, no personal data for the patient was recorded. Moreover, the patients\' consent prior to involvement in the research was required.\r\n\r\nWe use grounded theory and content analysis [24] to make sense of the ethnographic data with the help of NVIVO as our analysis tool. Moreover, we built on Schön\'s [21] reflection-on-action in sense-making of the PD workshops data as described in [5].\r\n\r\n4 Caring about the patient in rehabilitation\r\n\r\nWe describe how cognitive rehabilitation services are organised in the cognitive unit of a specialised rehabilitation hospital in Norway. However, the goal-planning care model used in the cognitive rehabilitation unit of the hospital we studied is used widely in other rehabilitative settings, and many of the things that we describe can be replicable in other rehabilitation programs.\r\n\r\n4.1 Participation in defining the treatment\r\n\r\nWilson defines cognitive rehabilitation as: “a process whereby people with brain injury work together with health service professionals and others to remediate or alleviate cognitive deficits arising from a neurological insult” [27, pp.97]. Rehabilitation is organised by defining a set of goals that the patient wants to achieve. These goals relate to activities and functioning of the patient in everyday life. The cognitive rehabilitation process in the specialised hospital that we studied in Norway is as follows.\r\n\r\nThe patient defines the goals in collaboration with a multidisciplinary team compounded by different formal caregivers [3] such as an occupational therapist, physical therapist, psychologist, social worker, nurse, doctor, and speech therapist if needed. The kin as the informal caregivers [3] are also involved in this work. After the goals have been defined, the patient, multidisciplinary team and the kin discuss possible recovery pathways for the patient. The treatment can be either in terms of compensatory strategies when the condition of the patient cannot be improved, and they need to live in the best way possible with their disability, or by implementing strategies that will improve the functional ability of the patient.\r\n\r\nOnce the treatment plan (goals, sub-goals, the specific measures that the patient will work during the stay at the hospital for each sub-goal, and who from the multidisciplinary team will be involved in helping the patient in each of the measurements) is defined, the rehabilitation starts.\r\n\r\nAs the rehabilitation at the hospital is only for five weeks, and the patient has to cope with the challenges coming from the disability at home, the caregivers try to educate the patient on how s/he will live with these challenges at home, thus aiming for health literacy and self-management.\r\n\r\nThe discussion of the goals and the treatment plan is done within the first week at the hospital in individual meetings among each of the multidisciplinary team members and the patient and as well in a joint meeting where all the care network agents are involved in finalising the goals and the treatment plan. Hence, the patient gets involved from the beginning of the discussion of the management of her/his treatment and is an active part in the decision making regarding her/his rehabilitation.\r\n\r\n4.2 The goal – plan document\r\n\r\nThe goals and the treatment plan are stipulated in a document called the goal-plan document. Here, the patient\'s goals and sub-goals are listed together with the set of measurements (referring to a specific activity that is part of the treatment) that the patient will have in order to reach the goals. The document also specifies who will be working together with the patient with each of the goals/sub-goals. The patient refers to this document throughout the whole stay at the hospital and is introduced to the document before coming to the hospital. This allows them to reflect on possible goals that they want to work on during their stay. Once the patient arrives, s/he is again shown and given a printed version of this document. The patient can annotate the document and discuss it with an occupational therapist (OT) or a nurse that will follow her/him throughout the rehabilitation.\r\n\r\nIn most cases, the patient talks about her/his needs and the OT or the nurse formulate the goals and write them down. There is a different dynamic when the OT or nurse uses a computer or a paper document to keep notes regarding goals where in most cases the OT or nurse or the patient write notes on the sides of the piece of paper. The paper document gives the possibility to the patient to see what is being written. The computer is more private for the health care professional. The screen can be shown to the patient, but it does not offer the same flexibility as the paper. However, in both cases, the OT reads what it has written in the document out loud, so the patient can comment, agree or disagree.\r\n\r\nIn the goal-plan meeting with the patient, the multidisciplinary team and the kin, the goal-plan is shown on a big screen, and one of the health care team members goes through each goal, sub-goal and measurement. After the meeting, the nurse prints a version of the document for the patient and gives it to her/him.\r\n\r\nThe goal-plan document is the central patient health record in rehabilitation and is saved in the hospital Electronic Patient Record (EPR) system. The patient does not have access to the hospital EPR system, so s/he does not have access to the electronic version of the document. The multidisciplinary team uses the electronic version of the document and keep their notes as a journal in the system.\r\n\r\nUsually, in an individual rehabilitation session, the patient is reminded of which of the goals/sub-goals s/he is working on in that session. So, the patient can have a clear understanding and remember why they are having a specific session. The goal-plan aims to help the patient to have an overview of the activities and the events that will come during rehabilitation. Moreover, it is useful in rendering visible to the patient why s/he needs to do a specific activity (For example showing that the morning walk is needed to “Get to know how much physical activity the patient can withstand”, sub-goal 2 of goal 1 – see Figure 1.)\r\n\r\nFigure 1:\r\nFigure 1: An example of the redesigned goal-plan document\r\nIn coordinating the activities that the patient should do daily at the hospital, a weekly-plan document is used, which is prepared and printed for the patient each week. The weekly-plan has the list of activities and meetings that the patient should do during their stay at the hospital. The activities are directly related to one of the goals or sub-goals in the goal-plan document. Changes in the weekly-plan schedule are discussed with the patient and among the multidisciplinary team members. The weekly-plan document includes scheduled activities that are organised at the hospital and activities that are individual for a specific patient. It serves as a coordination mechanism among the patient and a specific member of the multidisciplinary team and as a coordination mechanism among the multidisciplinary team members for a specific patient. The patient receives a paper version of the document, and the electronic version is saved in a common shared folder among the healthcare professionals.\r\n\r\nThe hospital invited us to be involved in discussing the goal-plan document with the patients and look into the possibility of redesigning it in a way that would help the patients to achieve more control of their rehabilitation and consequently feel empowered.\r\n\r\nThus, we used Participatory Design [22] approach to redesign the document [5]. Three workshops were conducted at the hospital during April - May 2018. Each workshop lasted one hour and was recorded. Together with the primary author in the role of the facilitator-designer, a member from the hospital that was not directly involved with the patients was included in co-facilitation. Figure 1 shows how a part of the redesigned goal plan looks. There is a clear tree structure of the patient\'s goals, subgoals and treatment for each subgoal. While goals are general and long-lasting, subgoals are SMART - Specific, Measurable, Attainable, Realistic, Timely. For each of the subgoals, there is a set of treatment measurements that the patient should follow during the hospital stay. In the pre-redesign goal-plan document the patient defined two main goals. The subgoals were grouped into three categories, e.g. subgoals of body function and structure, activities and participation, and environmental factors. This grouping is in line with the International Classification of Disease and the rehabilitation theories but appeared abstract to the patients. Moreover, the patients had difficulties understanding the connection between subgoals, goals and treatments. In the redesigned goal-plan, they could understand and be reminded how each activity they did during the week influenced the subgoal and consequently their main goal. Increasing the visibility of each part of the goal plan document in the redesigned version was a substantial contribution to what patients expressed in the workshops as perceived empowerment.\r\n\r\n5 Analysis and discussion\r\n\r\nIn this section, we analyse our case by building on concepts widely discussed within CSCW. Some of the concepts have been coined during the study of health care settings, and others have been discussed in other settings which might differ from our own, still relevant to the discussion and sense-making in our case. Furthermore, we discuss cooperative work elements found in the cognitive rehabilitation care model at the treatment level and micro-interactions and how they relate to patient empowerment, as described in section 2.\r\n\r\n5.1 Patient empowerment at the treatment level\r\n\r\nComputer Supported Cooperative Work has been defined by Bannon and Schmidt [2, pp.360] as \"an endeavour to understand the nature and characteristics of cooperative work with the objective of designing adequate computer-based technologies\". Fitzpatrick and Ellingsen [9] present a twenty-five-years review of CSCW research in healthcare. They show how CSCW has contributed continuously to provide better healthcare services. Moreover, they emphasise the need to address new integrated models of care in upcoming CSCW systems. The rehabilitation care model implies new ways of working in healthcare. Thus, we contribute to CSCW by applying its concepts in the context of the rehabilitation care model.\r\n\r\nWe determine patient empowerment as a cooperative work arrangement among the patient and the healthcare professionals which sustains the meaningful involvement, health literacy, shared decision making and self-management. Therefore, we analyse patient empowerment by adopting CSCW lessons and terminology regarding cooperative work arrangements.\r\n\r\nWe extracted three elements from our findings special to the rehabilitation care model.\r\n\r\nFirst, in comparison to more paternalistic health care models, the patient was not just getting treatment but was involved in defining the treatment. Together with the team, the patient would decide who were the team members s/he would work with and on which activities. So, the patient was involved in the division of labour of her/his treatment. The patient was involved in what Strauss [25] calls the articulation work of her/his treatment. Strauss [23; 25] defines “articulation work” as the supra-type of work that is needed in order to make possible the division of labour in a cooperative work setting where the actors are mutually dependent on each other and need to work together in order to get the job done. The goal-plan meeting and everything that leads to it are activities that the multidisciplinary team does in terms of articulation work.\r\n\r\nSecond, we identified the goal-plan document and the weekly-plan documents as cooperative artefacts among the patient and the multidisciplinary team in order to facilitate the division of labour and consequently the articulation work. Coordination mechanisms [20, pp.27] refer to “a specific organisational construct, consisting of a coordinative protocol imprinted upon a distinct artefact, which, in the context of a certain cooperative work arrangement, stipulates and mediates the articulation of cooperative work to reduce the complexity of articulation work of that arrangement”. Thus, as both documents are imprinted artefacts of a coordinative protocol, we can state that they are coordination mechanisms as defined by Schmidt and Simonee [20]. Coordination mechanisms have been used extensively in the medical setting to coordinate the work of health care professionals in order to deliver better services for the patients. However, in the case of the goal-plan and the weekly-plans, the patient was not only the carrier of the document but was among the actors in the division of labour associated with these shared artefacts. The goal-plan as a coordination mechanism among the multidisciplinary team has expanded its reach to involve also the patient, thus becoming a relevant element in empowering the patient.\r\n\r\nThird, the aim of participation in articulation work and of the goal-plan document as a coordination mechanism was to support visibility and overview of the patient toward the rehabilitation process and activities. This increased visibility contributed to building patient awareness toward their rehabilitation, which would result in more control of the process and consequently, empowerment. The work of Heath and Luff [12] about the London Underground (LU) Control Room is relevant to the understanding of our case. Heath and Luff [12] have described rendering activities publicly visible to the others in the local milieu and overseeing the local environment of events and activities as necessary in making possible the coordination of work among the controller and Divisional Information Assistant (DIA). They describe several mechanisms and behaviours that support the public display of activities and events in a way that is visible to others that rely on that information as well in the local milieu. Moreover, they discuss how even when the work of the individual cooperative workers requires different skills and expertise, they “monitor each other\'s activities to gather relevant information with which to coordinate their conduct” [12]. The public display of activities as described by Heath and Luff [12] is compatible with the treatment plan display in our case. Moreover, the public visibility of activities and the overseeing of the patient in the treatment plan will influence patient conduct in rehabilitation. However, there are some elements that differ. They describe a situation in the control room where the agents involved are roughly equally competent parties with a shared commonsense understanding of the work in hand. Moreover, what is described are current contingent selected activities and events rendered visible to the common space which can encourage others to take actions. In other publications, the analysis of the LU control room is defined as “awareness” [6; 11; 13; 19]. The LU case describes awareness in an established cooperative setting. In our case both the patient and the multidisciplinary team have just entered the cooperation space. The patient has high expertise in being themselves in the current situation. However, she/he is still in the process of building awareness around their condition and activities related to her/his treatment. The healthcare specialist on the other side have to build what Kuziemsky and Varpio [16] calls patient awareness, consisting of goal awareness and status and treatment plan awareness; getting to know the patient. Thus, both are novices in the cooperative space just created. The public visibility of the activities in our case supports the transition toward becoming experts in this common space of rehabilitation and create a common shared understanding of the activities, a transitioning towards awareness. This transition leads to patient empowerment.\r\n\r\nWe use EPF for understanding an empowered patient. By being involved in articulation work for the rehabilitation, having a coordination mechanism which supports the articulation work and the public visibility of the activities at the treatment level, the patient:\r\n\r\nhas a more meaningful involvement in the treatment by participating in articulation work.\r\ncreates health literacy by understanding the reasoning behind goals, sub-goals and activities and\r\ncan replicate the same strategies once s/he goes home, leading to self-management.\r\ncan discuss more equally with healthcare professionals, enabling shared decision making.\r\nWe investigated the issues described above in the Participatory Design workshops together with patients. They expressed increased experience of empowerment by participation in goal definition, the existence of the goal-plan document and the overview and visibility of during rehabilitation at the hospital.\r\n\r\n5.2 Visibility and micro-mobility in micro-interactions\r\n\r\nWhat we discussed in 5.1 relates to the management of the whole rehabilitation process. We refer to this as the macro-scale of rehabilitation – the level of defining the treatment plan for the rehabilitation. In this subsection, we focus on single activities of rehabilitation where the patient is involved with members in the multidisciplinary team during specific treatment measurements. We refer to these as micro-interactions.\r\n\r\nOn the macro-scale, we found that rendering private activities publicly visible were relevant to empower the patient. We discuss how this is highly relevant also in the micro-interactions.\r\n\r\nIn healthcare, there is a tradition of making private spaces of the patient publicly visible to the healthcare professionals. However, this usually works only one way. The decisions of the healthcare professionals are closed, and the patient has to read between the lines. The patient has to navigate material written for health professionals. This undermines the process of empowerment. Rendering private activities of healthcare professionals visible to the patient support patient\'s health literacy and the process of shared decision making. Mechanisms like the goal-plan support this visibility and contribute to the patient\'s understanding of their rehabilitation. This visibility is necessary both on the macro- and micro-levels.\r\n\r\nHere is an example from our ethnographic study where the patient had an individual meeting with the physiotherapist to have a balance test.\r\n\r\n“...We moved from the patient room downstairs to the gym of the hospital to redo the balance test. The physio always motivates the patient by giving some positive feedback. The physio initially shows the task and reinforce how it should be done by explaining thoroughly. When the patient is not paying attention, the physio carefully asks for attention and spends time on explaining the activity…the patient tries to do the exercises after the physio. The physio asks the patient to say it “loud and clear” when something is difficult, e.g. having shaky moves with the left leg.”\r\n\r\nWe noticed that both the physio and the patient do not just perform the activity but give information to each other during the activity. This increases mutual awareness, and consequently, each of them adapts their conduct. These micro-interactions influence patient empowerment. In the example, the patient has a meaningful involvement in the activity by giving very relevant feedback to the physio. By articulating the exercises and how each of the moves relates to specific muscles, the physio helps the patient to build health literacy. Hearing the explanation of exercises and repeating them, the patient gains knowledge that s/he can use in self-management, allowing the patient to perform the test at home. Moreover, the physio and the patient share the decision on the level of exercises that the patient should perform. The patient sets the limit of her/his own abilities, and the physio tries to motivate her/him to do more if the patient is capable.\r\n\r\nIn the presentation of the case, we described how the usage of laptops or paper for note-taking changes the dynamics in the individual sessions among the patient and the rehabilitation specialist. Luff and Heath [17, pp.2-3] introduced ‘micro-mobility’ as “the way in which an artefact can be mobilised and manipulated for various purposes around a relatively circumscribed, or ‘at hand’, domain.” The paper note-taking is associated with micro-mobility and can be adapted to different situations based on patient needs while the laptop is rigid, thus making notetaking more private for the health care professional. In rehabilitative settings where the patient is considered a mutual partner and both parts need to cooperate to do the activity, the artefacts involved should embody the requirement for micro-mobility. The micro-mobility of shared artefacts plays a significant role in supporting:\r\n\r\nmeaningful involvement as the patient will have the flexibility to interact with the artefacts, for example crossing out things in the paper goal-plan or writing notes on the sides.\r\nhealth literacy as the patient can follow the sense-making of goals and enable writing of goals by the patient\r\nshared decision making – by enabling the patient to influence how the goals are written. The process is very private and undermines the shared decision making when only healthcare professionals can write the goals.\r\nself-management as the patient has the possibility to adapt the shared artefacts to individual needs.\r\nThus, we conclude that micro-interactions in rehabilitation renders activities publicly visible for the parties, which is highly relevant for the empowerment of the patient. Moreover, the design of cooperative artefacts that embody micro-mobility [17] contributes to empowerment.\r\n\r\n1.1 “Patient empowerment” a “How to” model\r\n\r\nWe have described the care model in cognitive rehabilitation. Due to the cooperative work nature of the rehabilitation, we made sense of the work arrangements in our case with concepts from CSCW. We further discussed how these elements of the rehabilitation care model relate to patient empowerment by discussing patient empowerment using the four related concepts as suggested in EPF report [8].\r\n\r\nWe concluded with a set of operationalized activities that influence patient empowerment:\r\n\r\nPatient participation in articulating work [23] in their treatment\r\nThe development of a coordination mechanism [20] that supports the articulation work\r\nThe design of these coordination mechanisms should embody micro-mobility [17]\r\nPublicly render visible [12] activities that the patient will go through during treatment and offer the possibility to the patient to oversee events [12] and activities. This should be applicable both at the treatment level and in micro-interactions.\r\nFigure 2 presents an operationalized model of patient empowerment, seeing patient empowerment as an umbrella term for meaningful involvement, health literacy, self-management and shared decision making.\r\n\r\nFigure 2:\r\nFigure 2: Patient Empowerment operationalized model\r\nThe proposed model is a starting point for a wider discussion on operationalization of patient empowerment. Naturally, involvement of the patient and visibility of activities will vary based on the clinical condition of the patient.\r\n\r\n6 Conclusions and future agendas\r\n\r\nPatient empowerment has been discussed and implemented in the legal frame of many countries. However, changing paternalistic healthcare into a culture where the patient works together with the medical staff in collaboration requires more knowledge. Above we presented the case of rehabilitation and lessons learned from the rehabilitation care model. We conclude that participation by the patient in articulation work and the establishment of coordination mechanisms with the patient are useful measures to empower the patient. However, they do not guarantee that the patients would be meaningfully involved in their treatment and would feel empowered. In our redesign of the coordination mechanisms paper document, we concluded that the medical staff should render the activities visible to the patients, and the patient should understand and influence events and activities in their rehabilitation treatment. In this way, they can build health literacy and thus participate on equal terms in shared decision making and be able to self-manage their life. Hence, the discussion of making activities of the healthcare personnel “public” [12] to the patient and vice versa appears of increased importance in patient empowerment. Rendering activities visible is a recursive process that should start on the macro-scale of the management of the whole treatment and scale down into the micro-interactions that the patient has with healthcare professionals. Moreover, the issue of designing artefacts that support micro-mobility was discussed by Luff and Heath [17] two decades ago and needs to be explored more through the lenses of patient empowerment.\r\n\r\nREFERENCES\r\n\r\nANDERSON, R. M. AND FUNNELL, M. M. 2010. Patient empowerment: myths and misconceptions. Patient education and counseling,79, 277-282.  \r\nBANNON, L.J. AND SCHMIDT, K. 1989. CSCW: Four characters in search of a context. In ECSCW 1989: Proceedings of the First European Conference on Computer Supported Cooperative Work. Computer Sciences Company, London. .  \r\nBRATTETEIG, T. AND WAGNER, I. 2013 Moving Healthcare to the Home: The Work to Make Homecare Work. 2013 London. Springer London, 143-162.  \r\nBRAVO, P., EDWARDS, A., BARR, P. J., SCHOLL, I., ELWYN, G. AND MCALLISTER, M. 2015. Conceptualising patient empowerment: a mixed methods study. BMC health services research,15, 252.  \r\nÇARÇANI, K. AND HOLONE, H. 2019. Participatory Design “Method Story”: The Case of Patients Living with Mild Acquired Cognitive Impairments. ACHI 2019, The Twelfth International Conference on Advances in Computer-Human Interactions, 2019 Athens, Greece. IARIA, 210 to 217.  \r\nDOURISH, P. AND BELLOTTI, V. 1992. Awareness and coordination in shared workspaces. CSCW, 1992. 107-114.  \r\nEHP 2015. Patient Empowerment and Centredness. Brussels: European Health Parliament.  \r\nEPF 2015. EPF Background Brief: Patient Empowerment. Available: http://www.eu-patient.eu/globalassets/campaign-patient-empowerment/briefing_paperpatient-empowerment_final_external.pdf [Accessed 1/10/2018].  \r\nFITZPATRICK, G. AND ELLINGSEN, G. 2013. A review of 25 years of CSCW research in healthcare: contributions, challenges and future agendas. Computer Supported Cooperative Work (CSCW),22, 609-665.  \r\nFUMAGALLI, L. P., RADAELLI, G., LETTIERI, E. AND MASELLA, C. 2015. Patient empowerment and its neighbours: clarifying the boundaries and their mutual relationships. Health Policy,119, 384-394.  \r\nGROSS, T. 2013. Supporting effortless coordination: 25 years of awareness research. Computer Supported Cooperative Work (CSCW),22, 425-474.  \r\nHEATH, C. AND LUFF, P. 1992. Collaboration and controlCrisis management and multimedia technology in London Underground Line Control Rooms. Computer Supported Cooperative Work (CSCW),1, 69-94.  \r\nHEATH, C., SVENSSON, M. S., HINDMARSH, J., LUFF, P. AND VOM LEHN. D. 2002. Configuring awareness. Computer Supported Cooperative Work (CSCW),11, 317-347.  \r\nHOLMSTRÖM, I. AND RÖING, M. 2010. The relation between patient-centeredness and patient empowerment: a discussion on concepts. Patient education and counseling,79, 167-172.  \r\nKICKBUSCH, I., MAAG, D. AND SAAN, H. 2005. Enabling healthy choices in modern health societies. Eighth European Health Forum, Bad Gastein, Austria, 5–8 October, 2005.  \r\nKUZIEMSKY, C. E. AND VARPIO, L. 2011. A model of awareness to enhance our understanding of interprofessional collaborative care delivery and health information system design to support it. International journal of medical informatics,80, e150-e160.  \r\nLUFF, P. AND HEATH, C. 1998. Mobility in Collaboration. CSCW, 1998. 305-314.  \r\nROBERTS, K. J. 1999. Patient empowerment in the United States: a critical commentary. Health Expectations,2, 82-92.  \r\nSCHMIDT, K. 2002. The problem withawareness\': Introductory remarks onawareness in CSCW\'. Computer Supported Cooperative Work (CSCW),11, 285-298.  \r\nSCHMIDT, K. AND SIMONEE, C. 1996. Coordination mechanisms: Towards a conceptual foundation of CSCW systems design. Computer Supported Cooperative Work (CSCW), 5(2-3), pp.155-200.  \r\nSCHÖN, D. A. 2017. The reflective practitioner: How professionals think in action, Routledge.  \r\nSIMONSEN, J. AND ROBERTSON, T. 2012. Participatory Design: an introduction. Routledge international handbook of participatory design.Routledge.  \r\nSTRAUSS, A. 1985a. Work and the division of labor. Sociological quarterly,26, 1-19.  \r\nSTRAUSS, A. AND CORBIN, J. M. 1997. Grounded theory in practice, Sage.  \r\nSTRAUSS, A. L. 1985b. Social organization of medical work, Chicago, University of Chicago Press.  \r\nWHO 2011. World report on disability. Geneva: WHO.  \r\nWILSON, B. A. 2002. Towards a comprehensive model of cognitive rehabilitation. Neuropsychological rehabilitation,12, 97-110. ',1,'Carcani','Klaudia Çarçani, Jo Herstad, and Harald Holone','Klaudia Çarçani *(Faculty of Computer Science, Østfold University College, Norway)*<br>\r\nJo Herstad *(Institute of Informatics, University of Oslo, Norway)*<br>\r\nHarald Holone  *(Faculty of Computer Science, Østfold University College, Norway)*',NULL,0,'10.1145/3363384.3363482','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,10,10,NULL,NULL,0,38),(20,'murray-rust-entangled-ethnography-towards-a-collective-future-understanding','2019-09-02 15:24:57','2019-10-11 14:41:10','2019-09-02 15:24:57',NULL,1,'published','[]','Entangled Ethnography: Towards a collective future understanding','In this work, we develop a vision for entangled ethnography, where constellations of people, artefacts, algorithms and data come together to collectively make sense of the relations between people and objects. This is grounded in New Materialism\'s picture of a world understood through entanglement, through resonant constellations, through a multiplicity of unique individual viewpoints and their relationships. These perspectives are especially relevant for design ethnography, in particular for research around smart connected products, which collect data about their environment, the networks they are a part of, and the ways they are used. However, we are concerned about the current trend of many connected systems towards surveillance capitalism, as data is colonised, machinations are hidden, and a narrow definition of value is extracted. There is a key tension that while design, particularly of networked objects, attempts to go beyond human centeredness, the infrastructures that support it are moving towards a less than human perspective in their race to accumulate and dispossess. Our work tries to imagine the situations where participants in networked systems are richly engaged, rather than exploited. We hope for a future where human agency is central to a respectful and acceptable collaborative development of understanding.','Dave Murray-Rust, Katerina Gorkovenko, Dan Burnett, and Daniel Richards. 2019. Entangled Ethnography: Towards a collective future understanding. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 10 pages. [https://doi.org/10.1145/3363384.3363405](https://doi.org/10.1145/3363384.3363405 \"DOI for the article \'Entangled Ethnography: Towards a collective future understanding\'\")','1 INTRODUCTION\r\n\r\nIn this paper we explore the concept of entangled ethnography—an avenue for design research into human practices that involves people more deeply in making sense of their interactions with connected products. We aim to support research that contributes design insight while avoiding intrusion, surveillance and disempowerment. We build on developments in New Materialism, a philosophical movement which reconsiders the position of human amongst non-human actants, weaving a connected picture of the entanglements between humans and things [7, 23, 26]. This leads to a vision where the unfolding relations between people and things build a vibrant picture of human and non-human activity. There are two hopes here:\r\n\r\n1. Consensual understanding is more powerful than data acquisition: By acknowledging that data without grounding is unreliable, that there are crucial subtleties of experience that need to be interrogated in concert with those involved, we see a world where participation is a more common option than data extraction and dispossession.\r\n\r\n2. Objects and situations are as useful as modelling individuals: where surveillance uses things to record the actions of people, we can turn this so that people\'s biographies of objects carry equal weight, shifting the weight of surveillance from humans to constellations [13]. Having those directly engaging with objects in the wild involved in collaborative sensemaking with researchers about understanding situations – rather than behavioural models of people – gives them more power, pushing back against surveillance.\r\n\r\nThis paper engages with the New Approaches to Research & Design and Public & Private Spaces themes of the Halfway to the Future conference. Our work picks up on some of the challenges discussed for third wave HCI, modulated through the current socio-technical climate [6]. This work also explores how technology can support collaborative sense-making in a similar way to the work of Heath and Luff [25]. Issues arise of scale, surveillance, reductionism and the impacts of a data-driven capitalist appropriation of design principles. There are key concerns around the flows of data, and how these practices can be scaled up to fit alongside the massive deployments that characterise modern IoT infrastructures.\r\n\r\nPhilosophically, we are interested in the intersection of ethnographic practice and critical HCI theory, with an attempt to create a space where thick description and richness is privileged as a foil to reductionism, and engagement with human actors is a counter to dispossession. Practically, we are also concerned with how we can generate usable design insights, at scale, without compromising the agency or privacy of the people.\r\n\r\nThis paper contributes a theory driven exploration of more-than human centred ethnography, which we call entangled ethnography. It acknowledges that objects will increasingly capture and share data about their use, and that computational intelligence will increasingly be used to make sense of this data. In response, it posits a practice for research and design where:\r\n\r\nThe relations between humans and things are paramount, both for the design of new or better objects and the understanding of human practices surrounding these objects.\r\nData is the start of the process, not the end. Human truth is sought to make sense of data collected, so that meaning is constructed collaboratively between researchers, algorithms and the networks of people and objects in the world.\r\nHumans act as biographers of objects just as much as the other way round: where Thing Ethnography uses objects to understand human behaviour, in an entangled approach, the humans understand the object behaviour and requirements.\r\nHuman attention is extremely valuable, and any work carried out should be sensitive to this, aiming to use technology to make the most use out of people\'s limited time.\r\n2 BACKGROUND\r\n\r\nBy surveying critical theory and ethnography literature we develop a vision for new ways of understanding behaviour. While traditional ethnographic and anthropological techniques allow us to understand the rich complexities of human behaviour and motivation across cultures and demographics through direct observation and long term immersion, new methodological and theoretical developments promise to facilitate observation of both human and non-human actors at the intersection of their interaction.\r\n\r\n2.1 Object Oriented Ontology\r\n\r\nHarman\'s Object Oriented Ontology (OOO) [23, 24], a part of the New Materialism school of thought, seeks to redefine the treatment of humans, objects and their relations. In particular OOO creates a ‘flat ontology’ where humans are not seen as privileged or distinct from other objects, and object represents anything from material things, to individuals, properties, actions or abstract notions. The essence of these objects is inaccessible to us and unknowable, but we can understand the relations and observe the entanglements between them. Building on this work Bogost develops a philosophical practice of alien phenomenology [7], which attempts to understand these intrinsically unknowable experiences of objects through the use of unavoidably anthropomorphic metaphors. The practical implications of these ideas are that it is important to recognise the agency of objects to shape the world around them (in line with earlier work around Actor Network Theory, e.g. [11]). Rather than being passive, the things around us have power, and understanding how this power works is necessary for understanding complex situations. Bennet [3, p.20–29] illustrates this mode of thinking by exploring how the various components of the electricity grid, from electrons and waves through transmission lines up to legislature and laws, can collectively fail and produce blackouts. Foregrounding the individual perspectives of objects, their unique relations to each other, creates a more vibrant picture of the world, with a deeper understanding of the networks and relations that increasingly support our daily lives. From a design point of view, products can be seen not as isolated objects, but the end result of a coming together of designers, manufacturers, materials and their producers, supply chains, regulatory bodies, the imaginaries of retail and marketing and so on. This is especially relevant in the context of ‘smart’ or connected objects, where their functioning is distributed to include cloud servers and communications networks. Similarly, as objects can sense and respond to the world more, their perspectives become more clearly articulated, and can be explored by humans investigating their data streams. When attempting to understand human experience, accounting for the interconnected relations between things—both material and immaterial, both human and non-human—creates a multitude of points to probe and question.\r\n\r\n2.2 Contemporary Ethnography\r\n\r\nIn parallel, there has been a trend within ethnographic practice to broaden the scope of enquiry. In particular, George Marcus develops multi-sited ethnography [28, 29] to grapple with issues of interconnectedness: ”Strategies of quite literally following connections, associations, and putative relationships are thus at the very heart of designing multi-sited ethnographic research.” [28].\r\n\r\nThe philosophical developments in OOO and speculative realism discussed above, have directly inspired the development of thing ethnography, that explores the use of things as co-ethnographers that give a new perspective into human behaviour [19, 20]. Data collected through sensors and cameras attached to domestic products, can help develop an understanding of the minutiae of people\'s engagements [12, 19, 20]. An ethnographic exploration of everyday home activity conducted by Giaccardi et al. [19] used home appliances, including kettles and mugs instrumented with cameras, in order to record and reveal the situated nature of home activity.\r\n\r\nOther ethnographic practices also leverage the value of a thing perspective through the collection of data. Ethnomining continuously gathers data generated by a smart device about human activity and uses it as a resource for sensemaking [1, 4]. Anderson et al. [1] used data logging from an array of personal computing devices to generate detailed visualisations of activity, which were used in contextual inquiry interviews, enabling co-creation of data and insight [1]. Using a similar log based data capture ethnomethodological approach, Fischer et al. [17] used temperature and humidity sensors placed in people\'s homes as a support tool for energy advisors, who in collaboration with homeowners made sense of the data and provided advice.\r\n\r\nMeanwhile, the Ethnobot project [43] uses a chat-bot to interact with participants, simultaneously collecting data and guiding activity, through the anthropomorphisation of human-computer interaction. By adopting new thing-led perspectives, we are developing research practices that can examine the rich entanglements of human behaviour with things. This use of ethnographic research practice comes under the umbrella of design ethnography, which aims to gain rich insight into the lives of people in order to find design solutions that cater to their needs [37].\r\n\r\nThe development of software has also been examined through ethnographic research practices. Here, the Biography of Artefacts perspective, developed by Pollock and Williams [32], emphasises the value of strategic ethnography for research into technology design development. They are critical of the use of short ethnographic studies with small groups at places of work, which privilege local interactions and produce inadequate accounts of technological and organisational change. To address this Pollock and Williams [32] propose the development of strategic ethnography, which broadens its research scope across wider time-scales, addressing technology at different moments in its life-cycle, across different organisational users, with a broader view of technology development in order to develop holistic biographies of artefacts.\r\n\r\nWe share in the concerns raised by Pollock and Williams [32] and George Marcus [28] regarding the traditionally limited scope of ethnographic deployments. We address them by examining some of the opportunities afforded by the use of technology as co-ethnographers in order to work across a large number of people within dispersed geographies.\r\n\r\n2.3 More-Than Human Centred Design\r\n\r\nThe design of products and interfaces within Human Computer Interaction (HCI) has largely focused on simplifying the human experience by creating intuitive and cognitively undemanding interactions [21]. Within design these aims have largely overlapped with Human Centered Design (HCD), which caters to the needs of users and creates seamless interactions [21]. While reducing complexity has been a key trend within design it is juxtaposed with the increasingly complex networks of IoT products and digital services available to users across their working and home environments [6]. Susanne Bødker [5] identifies different ’waves’ of evolution of the field of Human Computer Interaction, the first wave was characterised by a model-driven study of human factors, the second wave was characterised by human-centered techniques focused on ”cooperation, learning, and participation”, while the third wave of HCI broadens notions of contexts and applications to include ’artifact ecologies’ that exist within a complicated network of activity [6].\r\n\r\nCoulton and Lindley [13] argue that HCD approaches are limited by their focus on the immediate user and that third wave HCI approaches need to address challenges around this increasing complexity where ”the notion of human centred ceases to be useful”, they call this new approach more-than human centred design. In order to untangle some of this complexity researchers have developed the use of metaphors as a design thinking tool [13, 31], in a similar fashion to Ian Bogost\'s alien phenomenology metaphors [7]. These metaphors often take on the form of visual speculative designs that focus on the behaviors of IoT devices and how they connect, communicate and act as part of a network [31]. Pierce and DiSalvo [31] use metaphors to address network anxieties by making data-flows and abstract notions explicit and visible, Pschetz et al. [33] use speculative devices to embody ideas of autonomy and control. Meanwhile, Coulton and Lindley [13] have developed the metaphor of constellations to describe the independent-but-interdependent perspectives of objects. They ground their work within OOO philosophy in order to extend human-centered design thinking [13]. Within their metaphor IoT objects, hardware, software, algorithms and networks come together to create a constellation of star-like entities, that although at times invisible, exert tangible forces on each other [13]. Within this paper we have adopted the use of the constellations metaphor as a way to ground our work within OOO theory and embrace the entangled complex nature of design ethnography within the connected devices context.\r\n\r\n2.4 HCI in the Wild\r\n\r\nIn the wild HCI research methods vary widely and include diary studies, experience sampling, field studies, and observations [8, 14, 27, 30]. In a similar fashion to developments within contemporary ethnographic practice, in the wild research methods are also utilising data collection and capture from technology. Contingent experience sampling in particular, relies on data and algorithms to facilitate real-time responses from uses based on triggers from data streams [16, 40, 46, 49]. By eliciting participant responses close to the time of the activity of interest, this approach ameliorates issues around retrospective recall [46]. However, contingent ESM tends take the researcher out of the context of real-time research and instead rely on data and algorithms to trigger real-time participant feedback. Furthermore, contingent ESM is known to disrupt participant activities, which can affect the quality of responses and question the validity of findings. [46]. With particular relevance to our research is the use of research products and technology probes, which are research artefacts deployed in the wild to explore people\'s experiences around technology in situ [27, 30]. While qualitative data about participant experiences has traditionally been gathered through post-hoc interviews or the traces left on the artefacts [30, 45], the development of ever smarter and more connected IoT products has raised questions about the potential of live data to support situated research. Recently the work of Burnett et al. [10] investigated the potential of supervisory digital twins, virtual rendered representations of products that respond to live data about the way they were being used, to be used as a resource for design led research.\r\n\r\n2.5 Ethics of Data-Gathering for Design\r\n\r\nData gathering through products in the wild is subject to an array of thorny ethical issues such as the potential exploitation of human labor and time. Coulton and Lindley [13] argue that today manufacturers defend data gathering through the promise of better user experience, but by not making the ways that data creates further value for them explicit, they are diminishing user agency, a form of data colonialism [44]. The use of data-gathering for the development of products is part of a wider trend called prosumption, which utilises user labour for financial benefit [34]. Prosumption is characterised by the trend of companies to engage consumers in the process of production [34]. Traditionally prosumption capitalism has been seen to exploit its customers by requiring them to take an active part in the creation of the products that they consume, for example the invention of fast food restaurants where people are expected to serve themselves thus diminishing the need for hired staff. However prosumption associated with the Web 2.0 is more ambiguous in the way that value is produced [34]. Users are often motivated to take an active part in production because they see it is personally beneficial, they are more critical of the process and often expect to pay little for services [34]. For example, while YouTube and Facebook rely on people to continuously create and consume content in order for them to make advertisement revenue, those engaged in producing content for these platforms may feel that they benefit by feeling more connected to friends or progressing their career as a vlogger. In a similar fashion Jennifer Whitson [48] postulates that everyday surveillance tied into gamification elements of the quantified self can be seen as enjoyable and acceptable. Surveillance entangled in play can encourage behaviour change that can be seen as fun and even beneficial by users. While not addressing questions of profit creation, she is keen to highlight that ”the black box of the software that hides the rules from us” may create unrewarding experiences, highlighting a one directional power dynamic.\r\n\r\nAlthough people willingly participate in surveillance and prosumption when they see a personal benefit, it is unclear to what extent they understand how the data collection process they are part of creates value for corporations and even universities. As Shoshana Zuboff highlights in her work on surveillance capitalism, our experiences are rendered as behavioural data combined with machine intelligence to create predictions about our behaviour, which are sold on the marketplace, for example Google selling data to target advertisements [50]. While it began with predicting click through behaviour, this model is increasingly being used within physical designs.\r\n\r\nThe ethics of data collection is a highly contextual issue, especially with connected products. While the question of what data is being collected is a starting point, it quickly becomes important to understand what is being done with that data, who can see it, what inferences are drawn from it and what levels of control the users have. Many devices today use data flows as a core part of their functioning - the Nest thermostat collecting data about it\'s users in order to predict their behaviour and turn the heating on at the right time. Devices that collect information on their own performance as a means of predicting failure or scheduling maintenance are much less problematic [39], for example, predictive maintenance is a vital part of servicing Rolls-Royce jet-engines, which capture vast amounts of telemetry data about their functioning [2]. In contrast devices that collect data in order to better understand their users are much more ethically ambiguous [50]. Shoshana Zuboff highlights that data collection through smart devices does not necessitate surveillance capitalism and that these ethical issues can be tackled by avoiding the creation of black boxes and giving exclusive ownership and management rights of personal data to the user [51].\r\n\r\nThese issues and potential solutions can be explored through a critical approach to design. For example, the ’Living Room of the Future’ explores the future of media production and smart devices where ”media content adapts in response to user data collected from IoT devices situated in the living room and the adaptation, in turn, actuates connected devices (e.g., speakers, lights, window blinds, heating, etc.) in order to enable the media experience to reach beyond the screen into the living room” [36]. The project makes explicit the acts of requesting and collecting data about the users, but then stores it on a ’Databox’ [15] that physically situates the data with the user, giving them control over access to it and responding to concerns regarding privacy, trust and control within data-driven media.\r\n\r\n\r\nFigure 1: An overview of the Entangled Ethnography process, showing how real-time visualisation (a) leads to real-time conversations with users of objects (b) that can result in directed capture of data surrounding a situation. This can then be understood through a sensemaking process (c) where machine learning supports deriving meaning from the data. As more is understood, machine learning algorithms can contribute to the contextual enquiry (d), e.g. by triggering conversations and giving context to the researchers.\r\n3 ENTANGLED ETHNOGRAPHY\r\n\r\nOur vision for Entangled ethnography builds on these research themes and practices in order to develop an understanding of human behaviour through data collection from products in the wild, intertwining behaviour, experience, objects and environment. Our core notion here is that entanglements between people and things can help us make sense of the ways that they each carry out their existences. More properly, this might be called entangled design ethnography, as we are primarily focusing on the kinds of ethnographic questions that support designers in their work. The central driving force is to understand how to create assemblages of people, algorithms, devices and networks that allow us to understand the ways that objects are used in practice, and develop design insights that help to make better, more appropriate artefacts that both address the needs of users and the needs of the wider environment they are a part of.\r\n\r\nEntangled ethnography aims to create a broad more-than human centred ethnographic approach by combining the object orientation of thing ethnography [19, 20] with the interconnected constellations of Coulton and Lindley [13] and the extensiveness of critical ethnography [32].\r\n\r\nData is clearly fundamental to this kind of work, but it is important to take data in a broad sense, to include collection of qualitative responses, notes, images, and video, as well as simply quantitative data generated by sensors. It is important to bring the participants into this—a camera on a device is a surveillance device, but asking a user to take a photo of how they are using things can be a collaborative act. Equally important is developing a nuanced and connected understanding of what data is used for and what the benefits are.\r\n\r\nEntangled ethnography is an argument that by working with rather than against users, devices can develop more insightful pictures of their use. While thing ethnography fruitfully uses objects as co-ethnographers, entangled ethnography is the engagement of both participants and things in a continuous co-ethnographic practice. For the people that want to engage with the sensemaking of their relationship with the things around them, having a voice in the process can be empowering. Similarly, understanding the nuances of behaviours and interactions across the increasingly vast network of human and non-human agents can help inspire design.\r\n\r\nWe build on the following criteria:\r\n\r\nSome forms of ethnomining and data analysis are necessary to work at today\'s scales, making sense of data from multiple sites, over significant periods of time, with the involvement of a broad range of participants or users of technology.\r\nData on its own is limited in its ability to provide rich insights into people or their relations to objects. Interpretation from human participants is crucial to making connections outside of the narrow view of data, whether to internal states, enriching context or understanding some of the complex networks of action and relation that occur in modern life. This interpretation is expensive both for researchers and participants in terms of time and mental energy, and should be focused on areas of interest.\r\nIf we want to interrogate what has happened in a moment, the closer we can get to that moment the better, both for human recall and for the ability to uncover, articulate and develop extra contextual information.\r\nSimilarly, algorithmic analysis on its own is unlikely to provide a solid basis for insight or action. Collaborative sensemaking processes are necessary that continually ground truth the output of algorithms with both an ethnographic understanding of the situation and participants reflections.\r\nThe acceptability of the process is key; at a surface level, this means making sure that participants are willing and engaged, but can be taken further to ensure an alignment of values between the designers and the users of objects, and to develop a sense of participation in the design process that extends well into the lifetime of the objects being designed.\r\n\r\nFigure 2: Constellation of actors in the Chatty Factories project, showing the situation under consideration. It consists of connections between people and products, communication and data sharing with designers and ethnographers, then a connection through the different design stages, through the manufacturing process and supply chain to create the actual product under investigation.\r\n3.1 Entangled Ethnography in practice\r\n\r\nIn practice, an entangled ethnographic approach could be enacted as follows (see Figure 1 for an overview).\r\n\r\nSensors are attached to objects that capture information about how they are used. This is a broad and potentially deeply problematic statement, which we will come back to later (see Acceptable Sensing section below). In short, we would emphasise the object\'s point of view: what environment is it experiencing? is it being dropped, vibrated, turned upside down? To some extent, what does it know about how it is being used?\r\nEthnographers use this live data feed to look for moments of interest. The sphere of interest can change over time, as a nuanced view of interaction is built up, and research questions develop.\r\nThe ethnographers communicate with the participants based on these moments of interest. In line with contingent experience sampling, the aim is to target interactions at particularly interesting moments. The communication can include discussions with participants through a chat system, including requests for photos or videos, or pre-defined contingent experience sampling questions automatically sent based on triggers from the live data, such as the object accelerating beyond a certain value. This contextual inquiry would build up a carefully aligned picture of what is happening combining sensor data, photo and video capture and interpretation close to moments of interest.\r\nInsights generated from these contextual inquiry activities will be used to annotate the data and add supplementary field notes.\r\nThis forms the basis for analytic work, where a combination of visualisation and machine learning is brought together to support sensemaking. Through future research we hope to develop techniques that would allow us to work with algorithms in collaborative ways, negotiating the territory between human and machine understanding, such as:\r\nUsing human annotation to train models, then extending the models to additional participants or sites, testing examples and hypotheses.\r\nUsing unsupervised techniques to spot novel behaviour, and directing human attention to those moments.\r\nAllowing designers to develop hypotheses and test them against data coming in, working towards tests for particular occurrences.\r\nThere is a hope here that by setting up the right collaborations, maintaining human engagement, even imperfect and limited algorithms will be of use.\r\nAs this analysis comes together, it can be fed directly back into the conversation between ethnographers and participants, by prompting conversation at particular moments, and supplying the current interpretation of the situation for discussion, making sure that any conversation is a chance to influence the picture that is being built up, and to reflect back the context of enquiry.\r\nTaken together, this works to create a constellation of investigating that involves the object under investigation but extends out to entangle researchers, algorithms, datastores and eventually manufacturers, suppliers, other users and beyond.\r\n\r\n4 CASE STUDY: CHATTY FACTORIES\r\n\r\nAn initial method based on these principles has been tested through deploying sensorized Bluetooth speakers in the wild with participants who used them in their daily lives, in their homes and beyond [22]. This study is situated within a project that seeks to generate design insight from product data in a manner that supports rapid redesign and manufacture in response to the way that products are used—a form of use sovereignty[9]. This kind of design process requires us to make sense of the complex constellations of actors, both human and non-human involved in the design, production and use of these artefacts (Figure 2).\r\n\r\nEach of the speakers we developed sends out a continuous stream of sensor data in addition to its normal operation with data about orientation, movement, temperature, connectivity etc. as well as reporting on its intended function of playing music - track titles, volume, playback status and so on. This data is presented along with a digital twin of the object to the researcher through a dashboard [10]. This realtime visualisation of live data streams allows the ethnographer to monitor activity and engage the participants at key times about interesting activity they are seeing through direct messaging, prompting for explanation, context and image or video capture. We have seen that directly communicating with participants lets us collect rich insights that ground truth the quantitative data, encourage reflection on events that could otherwise be missed, and sensitively collect images and video showing a context of use—for full details, see [22].\r\n\r\nWe have taken several measures in order to increase the acceptability of the research process, as discussed by Rooksby et al. [35]. Unlike thing ethnography and ethno-mining which often rely on the collection of video footage and GPS data [1, 19, 20], we do not collect location, audio, or video from the IoT devices used in research. Currently data collection and storage is centralised to two university institutions working in collaboration. However the ownership of the raw data belongs to the participants, who have the right to withdraw or withhold data in perpetuity. Yet, as we scale the use of our ethnographic practice beyond the university setting, we believe that there are further considerations regarding not just data ownership but also the creation of value through data collection.\r\n\r\n5 FUTURE VISION OF ENTANGLED ETHNOGRAPHY\r\n\r\n5.1 Ethical Sensing\r\n\r\nThere are a raft of ethical and privacy issues around data collection. Our concerns centre on ethics and privacy, but also extend out to include the care we take with people\'s time and attention or the power balances between designers, researchers and users of objects. In an ideal world, a sense of entanglement would provide a guide for carrying out studies by supporting participants agency. Practically, a more concrete framework is useful, and the Theoretical Framework for Acceptability can be brought to bear [38]. While intended to make sense of health interventions, it has been applied to personal data [35] and identifies a set of concerns that underpin many interventions into people\'s lives. Distinct from working with ethical issues, this considers more broadly how acceptable a process is to users, and works on several dimensions. Excluding Self efficacy, which is aimed at personal health interventions and does not translate directly here, we will relate the considerations from the framework below:\r\n\r\nAffective Attitude: how do people feel about the intervention. Developing the right relationships with participants is important here, emphasising participation and choice over covert surveillance and acquisition. Valuing participants contribution and time is key to creating an ongoing, mutually supportive context for research.\r\nBurden: perceived effort of participating. Our preliminary findings indicate that user-researcher communication is at times taxing to participants [22]. We feel that similarly to ESM, some level of disturbance is warranted in order to limit retrospective recall and gather contextually grounded thick descriptions of moments of interest. For long term deployments, it is clear that an increasingly sensitive approach to asking ground-truthing questions is required. We aim to decrease the burden on participants by limiting interactions through the use of algorithmically generated triggers, such as those used in contingent experience sampling, alongside the identification of key moments by training machine learning models. This would limit interactions to a handful of moments that are truly interesting. This is a site where computational support can help, as data is quickly labelled, and moments of uncertainty or novelty highlighted as the basis for a conversation.\r\nEthicality: of the process as a whole. In particular, how does any data collection and analysis line up with the participant\'s value systems; does it affect their autonomy or control. Building a model of human behaviour through the use of data collection is susceptible to thorny ethical issues. This is a place where giving users control of their data is crucial, and supporting an engagement with the interpretation of their data can be meaningful. In addition, it is vital to carefully select the ways data is collected: less personally identifying data can often still give useful insight, and bringing participants into the capture process can ensure that they both know what is captured and consent to it.\r\nCoherence: how well do people understand the process and their role within it? While some of this can be dealt with by explanation, much is down to the way the participatory process is handled. Some of the key questions that need to be explored are what is the ultimate objective of data collection, who benefits and in what ways, and how are users/participants engaged in the process.\r\nOpportunity costs: what is given up to participate. Apart from the burden of participation, the main issues are that any object with sensors and intelligence attached is likely to be more unwieldy, expensive and power hungry than its non-sensorised cousin. However, in a world of increasingly networked products, cheaper sensors and data, this is likely to be increasingly negligible.\r\nPerceived effectiveness: how much do participants believe the work makes a difference? In this case, the primary focus is on how much effect participants believe that their contributions will have to design and understanding. This again lines up with values of transparency and entanglement - as participants are brought into the sensemaking process, they can see and shape the ways they are understood, and have a deeper connection to the research effort as a whole. Part of this may also come through connecting people to the fruits of their labour - finding ways to give them updated versions of products, containing the changes derived from their actions and sensemaking.\r\nOverall, there is a strong correspondence between the direction of the Theoretical Framework for Acceptability and cultivation of human agency within the context of data collection and sensemaking. Conversely if we are to argue for a more-than human centred ethnographic practice, a human-centred acceptability framework may be limiting in the way we evaluate its effects on the broader constellation of objects. As discussed in the Ethics of Data-Gathering for Design section, key considerations for the use of entangled ethnography are the ways that value is created and for whom. We strongly agree with Shoshana Zuboff\'s guidelines for avoiding surveillance capitalism by avoiding black boxing and giving ownership and management rights over personal data to users/participants in a clear, understanding and empowering way [51]. One way that this can be facilitated is through the use of Databox type systems that store and process data locally, only exporting data with exclusive permission from the owner [15]. Alternatively, if the data is not stored locally users should still have full control over the ways in which it is used, sold, analysed, and by whom it is seen. Future considerations for ways that data gathering and collaborative sense-making may affect a constellation of interconnected objects, may include environmental, political, and societal impact, although it is currently unclear how those can be evaluated.\r\n\r\n5.2 Expanding Moments\r\n\r\nData and time have a nuanced relationship. In particular, data extends the present moment, as viewpoints on it can be refined and developed after the fact. On the one hand, this can be coercive and corrosive: As discussed at a presentation at a Singularity University event by Brad Templeton, a privacy expert, things that are currently being recorded could have significant implications for our privacy and rights in the future when AIs would be able to look into your past and see what you were doing at any point in your life [47]. However, if it can be constructed properly, an entangled approach to understanding can bring together the various perspectives and sources of data to create understanding that was not available in the moment, connecting chains of action between people and the objects around them. This shapes the way that data is collected, as research questions emerge and can be rapidly asked using digital tools, continually shaping the way that data is collected and the situation is conceptualised. These conceptualisations extend both forward in time by shaping new data collection, and backwards by shaping the analysis of data already captured and processed.\r\n\r\nAt the same time, this expands across space, by connecting moments with other participants. Nuanced similarities between activities in multiple sites allow for a somewhat strategic ethnography [32] albeit in an ad-hoc manner. As suggested by Pollock and Williams [32] in their strategic ethnography practice, entangled ethnography should look at the whole lifespan of products and systems, creating biographies of each part of the constellation of entangled things, users, researchers and organisations. As a result an ethnographer would be able to examine the minutiae of qualitative and qualitative data associated with a single product and they would be able to describe how user behaviours change over time. Moreover they would be able to have a holistic view of effects that exceed questions of human behaviour and needs, such as the relationship between the materials used in products and their potential to be recycled or reused, in order to support mindful research and industry practices. In essence entangled ethnography has the potential to make visible the ways IoT objects, users, networks, ethnographers, designers and manufacturers affect each other over time.\r\n\r\n5.3 Data, Matter and Constellations\r\n\r\nMore and more, the products around us are born digital, with identifiers and histories, provenance and models. They increasingly resemble Bruce Sterling\'s [42] Spimes: futuristic manufactured objects, ”material instantiations of an immaterial system”. Within our vision, the entangled non-human things are becoming more ‘spimey‘ [42]. As well as having an increasing animacy and ability to affect their environment or interact with the world around them. Part of this work is to support these new vibrant constellations [13], where networks of people and objects come together to shape matter and data. By broadening the scope of ethnographic practice it is able to address the issues of complexity raised by third wave HCI [6].\r\n\r\nIn the same way that ambiguity can highlight issues and perspectives that can enrich design practice [18], we are interested in a vision for entangled ethnography that can create a new interpretative relationship between designers, people, things, needs and perceptions. There are connections to be found all the way from a designers annotation on a digital file, through the process of manufacture, into the momentary interaction with a particular user, then back through sensors and data analysis to a contextualised response to the original question. By understanding and supporting these long range entanglements, the constellations created can emphasis valuing people for their viewpoints and understanding, as reflective, relational collaborators, connected to the results of their participation. They also allow the things more space for agency, and more of a say in their design process, moving towards a sense of designing by data [41]. In a similar way to Fischer et al.’s use of data gathered from IoT home sensing systems, where energy advisors and homeowners collaboratively interpret data logs and create actionable insight [17], we feel that actionable insight can be collaboratively created between researchers, users, and things. Overall, this is a development of human-machine inter-agencies around ethnographic processes: how can we enlist humans and AI alike in the task of developing rich, nuanced understanding.\r\n\r\nThere is a shift away from any pure sense of ethnography here, in that this kind of investigation is fundamentally disruptive—participation in reflective activities and sensemaking is very different from going about one\'s business naturally. This goes beyond the burden of participation, and changes the nature of the relations between researchers and participants. If we were developing techniques for understanding the world as it is, this disruption and divergence from natural practice would likely be a step too far. However, as the aim here is to bring end users into the design process in pursuit of creating beneficial changes, the desire for purity can be weighed against the immediate responses and increased agency of the participants. Entanglement affects systems, and this approach will be more appropriate for some situations than others.\r\n\r\n6 CONCLUSION\r\n\r\nThrough this paper, we have tried to make the case that a practice of digitally entangled ethnography is emerging, bringing together emerging theory about how we understand the interconnected world around us with (and for) networked and sensitized infrastructures. The challenge is to navigate towards a shared, vibrant, participatory understanding, finding ways to engage in data collection and interpretation while avoiding the pull of surveillance capitalism and its attendant will to capture and control flows of data. In the context of third wave HCI, this offers routes to really centre on the interactions [6] while embracing the current key challenge facing HCI work: how to work at scale without losing the vibrancy of human experience. By finding acceptable, entangled ways to collaborate between computational and human intelligence, we can work towards a vision of connected human-machine inter-agencies that develop broad contextual understandings to support human activities.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis research was funded by the EPSRC under the New Industrial Systems theme through the Chatty Factories project (EP/R021031/1).\r\n\r\nREFERENCES\r\n\r\nKen Anderson, Dawn Nafus, and Ryan Rattenbury. 2009. Numbers have qualities too: experiences with ethno-mining. In In Ethnographic Praxis in Industry Conference Proceedings(EPIC 2009). 123–140. https://doi.org/10.1111/j.1559-8918.2009.tb00133.x  \r\nJim Austin, Tom Jackson, Martyn Fletcher, Mark Jessop, Peter Cowley, and Peter Lobner. 2004. Chapter 5 - Predictive Maintenance: Distributed Aircraft engine diagnostics. In The Grid 2 (Second Edition)(second edition ed.), Ian Foster and Carl Kesselman (Eds.). Morgan Kaufmann, Burlington, 69 – 79. https://doi.org/10.1016/B978-155860933-4/50009-2  \r\nJane Bennet. 2010. Vibrant Matter: a political ecology of things. Duke University Press. 200 pages.  \r\nYash Bhavnani, Kerry Rodden, Laura Cuozzo Guarnotta, Margaret T. Lynn, Sara Chizari, and Laura Granka. 2017. Understanding Mobile Phone Activities via Retrospective Review of Visualizations of Usage Data. In Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services(MobileHCI ’17). ACM, New York, NY, USA, Article 58, 10 pages. https://doi.org/10.1145/3098279.3119841  \r\nSusanne Bødker. 2006. When Second Wave HCI Meets Third Wave Challenges. In Proceedings of the 4th Nordic Conference on Human-computer Interaction: Changing Roles(NordiCHI ’06). ACM, New York, NY, USA, 1–8. https://doi.org/10.1145/1182475.1182476  \r\nSusanne Bødker. 2015. Third-wave HCI, 10 Years Later—participation and Sharing. interactions 22, 5 (Aug. 2015), 24–31. https://doi.org/10.1145/2804405  \r\nIan Bogost. 2012. Alien phenomenology, or, what it\'s like to be a thing. Univ Of Minnesota Press.  \r\nBarry A. T. Brown, Abigail J. Sellen, and Kenton P. O\'Hara. 2000. A Diary Study of Information Capture in Working Life. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’00). ACM, New York, NY, USA, 438–445. https://doi.org/10.1145/332040.332472  \r\nBranson D. Murray-Rust D. Preston J. Richards D. Burnett D. … Thorp J. Burnap, P.2019. Chatty Factories: A vision for the future of product design and manufacture with IoT. In Living in the IoT: PETRAS/IET Conference.  \r\nDan Burnett, James Thorp, Daniel Richards, Katerina Gorkovenko, and Dave Murray-Rust. 2019. Digital Twins As a Resource for Design Research. In Proceedings of the 8th ACM International Symposium on Pervasive Displays(PerDis ’19). ACM, New York, NY, USA, Article 37, 2 pages. https://doi.org/10.1145/3321335.3329685  \r\nMichel Callon. 1986. Some elements of a sociology of translation: domestication of the scallops and the fishermen of St Brieuc Bay. In Power, Action, and Belief: A New Sociology of Knowledge?, John Law(Ed.). Routledge & Kegan Paul, 196–223.  \r\nWen-Wei Chang, Elisa Giaccardi, Lin-Lin Chen, and Rung-Huei Liang. 2017. ”Interview with Things”: A First-thing Perspective to Understand the Scooter\'s Everyday Socio-material Network in Taiwan. In Proceedings of the 2017 Conference on Designing Interactive Systems(DIS ’17). ACM, New York, NY, USA, 1001–1012. https://doi.org/10.1145/3064663.3064717  \r\nPaul Coulton and Joseph Galen Lindley. 2019. More-Than Human Centred Design: Considering Other Things. The Design Journal 22, 4 (2019), 463–481. https://doi.org/10.1080/14606925.2019.1614320 arXiv:https://doi.org/10.1080/14606925.2019.1614320  \r\nAndy Crabtree, Alan Chamberlain, Rebecca E. Grinter, Matt Jones, Tom Rodden, and Yvonne Rogers(Eds.). 2013. Introduction to the Special Issue of “The Turn to The Wild”. ACM Trans. Comput.-Hum. Interact. 20, 3, Article 13 (July 2013), 4 pages. https://doi.org/10.1145/2491500.2491501  \r\nAndy Crabtree, Tom Lodge, James Colley, Chris Greenhalgh, Kevin Glover, Hamed Haddadi, Yousef Amar, Richard Mortier, Qi Li, John Moore, Liang Wang, Poonam Yadav, Jianxin Zhao, Anthony Brown, Lachlan Urquhart, and Derek McAuley. 2018. Building accountability into the Internet of Things: the IoT Databox model. Journal of Reliable Intelligent Environments 4, 1 (01 Apr 2018), 39–55. https://doi.org/10.1007/s40860-018-0054-5  \r\nBob Evans. 2016. Paco–Applying Computational Methods to Scale Qualitative Methods. In In Ethnographic Praxis in Industry Conference Proceedings(EPIC 2016). 348–368.  \r\nJoel E. Fischer, Andy Crabtree, James A. Colley, Tom Rodden, and Enrico Costanza. 2017. Data Work: How Energy Advisors and Clients Make IoT Data Accountable. Computer Supported Cooperative Work (CSCW) 26, 4 (01 Dec 2017), 597–626. https://doi.org/10.1007/s10606-017-9293-x  \r\nWilliam W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity As a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 233–240. https://doi.org/10.1145/642611.642653  \r\nElisa Giaccardi, Nazli Cila, Chris Speed, and Melissa Caldwell. 2016. Thing Ethnography: Doing Design Research with Non-Humans. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems(DIS ’16). ACM, New York, NY, USA, 377–387. https://doi.org/10.1145/2901790.2901905  \r\nElisa Giaccardi, Chris Speed, Nazli Cila, and Melissa L. Caldwell. 2016. Things As Co-ethnographers: Implications of a Thing Perspective for Design and Anthropology.  \r\nJoseph Giacomin. 2014. What Is Human Centred Design?The Design Journal 17 (12 2014). https://doi.org/10.2752/175630614X14056185480186  \r\nKaterina Gorkovenko, Dan Burnett, Dave Murray-Rust, James Thorp, and Daniel Richards. 2019. Supporting Real-Time Contextual Inquiry Through Sensor Data. In In Ethnographic Praxis in Industry Conference Proceedings(EPIC 2019).  \r\nGraham Harman. 2012. The Well-Wrought Broken Hammer: Object-Oriented Literary Criticism. New Literary History 43 (03 2012), 183–203. https://doi.org/10.2307/23259371  \r\nGraham Harman. 2016. Immaterialism: Objects and Social Theory. Cambridge: Polity Press.  \r\nChristian Heath and Paul Luff. 1992. Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms. Computer Supported Cooperative Work - CSCW 1 (03 1992), 69–94. https://doi.org/10.1007/BF00752451  \r\nIan Hodder. 2012. Entangled: An Archaeology of the Relationships between Humans and Things. https://doi.org/10.1002/9781118241912  \r\nHilary Hutchinson, Wendy Mackay, Bo Westerlund, Benjamin B. Bederson, Allison Druin, Catherine Plaisant, Michel Beaudouin-Lafon, Stéphane Conversy, Helen Evans, Heiko Hansen, Nicolas Roussel, and Björn Eiderbäck. 2003. Technology Probes: Inspiring Design for and with Families. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 17–24. https://doi.org/10.1145/642611.642616  \r\nGeorge E. Marcus. 1995. Ethnography in/of the World System: The Emergence of Multi-Sited Ethnography. Annual Review of Anthropology 24, 1 (1995), 95–117. https://doi.org/10.1146/annurev.an.24.100195.000523 arXiv:https://doi.org/10.1146/annurev.an.24.100195.000523  \r\nGeorge E Marcus. 2012. Multi-sited ethnography: Five or six things I know about it now. In Multi-sited ethnography. Routledge, 24–40.  \r\nWilliam Odom, Ron Wakkary, Youn-kyung Lim, Audrey Desjardins, Bart Hengeveld, and Richard Banks. 2016. From Research Prototype to Research Product. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). ACM, New York, NY, USA, 2549–2561. https://doi.org/10.1145/2858036.2858447  \r\nJames Pierce and Carl DiSalvo. 2018. Addressing Network Anxieties with Alternative Design Metaphors. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 549, 13 pages. https://doi.org/10.1145/3173574.3174123  \r\nNeil Pollock and Robin Williams. 2010. e-Infrastructures: How Do We Know and Understand Them? Strategic Ethnography and the Biography of Artefacts. Computer Supported Cooperative Work (CSCW) 19, 6 (01 Dec 2010), 521–556. https://doi.org/10.1007/s10606-010-9129-4  \r\nLarissa Pschetz, Kruakae Pothong, and Chris Speed. 2019. Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 387.  \r\nGeorge Ritzer and Nathan Jurgenson. 2010. Production, Consumption, Prosumption: The nature of capitalism in the age of the digital ’prosumer’. Journal of Consumer Culture 10, 1 (2010), 13–36. https://doi.org/10.1177/1469540509354673 arXiv:https://doi.org/10.1177/1469540509354673 \r\nJohn Rooksby, Alistair Morrison, and Dave Murray-Rust. 2019. Student Perspectives on Digital Phenotyping: The Acceptability of Using Smartphone Data to Assess Mental Health. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 425, 14 pages. https://doi.org/10.1145/3290605.3300655  \r\nNeelima Sailaja, Andy Crabtree, James Colley, Adrian Gradinar, Paul Coulton, Ian Forrester, Lianne Kerlin, and Phil Stenton. 2019. The Living Room of the Future. In Proceedings of the 2019 ACM International Conference on Interactive Experiences for TV and Online Video(TVX ’19). ACM, New York, NY, USA, 95–107. https://doi.org/10.1145/3317697.3323360  \r\nTony Salvador, Genevieve Bell, and Ken Anderson. 1999. Design Ethnography. Design Management Journal (Former Series) 10 (10 1999), 35 – 41. https://doi.org/10.1111/j.1948-7169.1999.tb00274.x \r\nMandeep Sekhon, Martin Cartwright, and Jill J. Francis. 2017. Acceptability of healthcare interventions: An overview of reviews and development of a theoretical framework. BMC Health Services Research 17 (01 2017). https://doi.org/10.1186/s12913-017-2031-8  \r\nRuben Sipos, Dmitriy Fradkin, Fabian Moerchen, and Zhuang Wang. 2014. Log-based Predictive Maintenance. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining(KDD ’14). ACM, New York, NY, USA, 1867–1876. https://doi.org/10.1145/2623330.2623340  \r\nAnnelien Smets and Bram Lievens. 2018. Human Sensemaking in the Smart City: A Research Approach Merging Big and Thick Data. In In Ethnographic Praxis in Industry Conference Proceedings(EPIC 2018).  \r\nChris Speed and Jon Oberlander. 2016. Designing from, with and by Data: Introducing the ablative framework. In Proceedings of the International Design Research Society Conference.  \r\nBruce Sterling. 2005. Shaping Things. MIT Press.  \r\nElla Tallyn, Hector Fried, Rory Gianni, Amy Isard, and Chris Speed. 2018. The Ethnobot: Gathering Ethnographies in the Age of IoT. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 604, 13 pages. https://doi.org/10.1145/3173574.3174178  \r\nJim Thatcher, D OSullivan, and Dillon Mahmoudi. 2016. Data colonialism through accumulation by dispossession: New metaphors for daily data. Environment and Planning D: Society and Space 34 (03 2016). https://doi.org/10.1177/0263775816633195  \r\nWenn-Chieh Tsai, Po-Hao Wang, Hung-Chi Lee, Rung-Huei Liang, and Jane Hsu. 2014. The Reflexive Printer: Toward Making Sense of Perceived Drawbacks in Technology-mediated Reminiscence. In Proceedings of the 2014 Conference on Designing Interactive Systems(DIS ’14). ACM, New York, NY, USA, 995–1004. https://doi.org/10.1145/2598510.2598589  \r\nNiels van Berkel, Denzil Ferreira, and Vassilis Kostakos. 2017. The Experience Sampling Method on Mobile Devices. ACM Comput. Surv. 50, 6, Article 93 (Dec. 2017), 40 pages. https://doi.org/10.1145/3123988  \r\nPaul Watson. 2015. Privacy expert: Time travelling robots could punish ’future crimes’. (2015). https://www.infowars.com/privacy-expert-time-traveling-robots-could-punish-future-crimes/  \r\nJennifer Whitson. 2013. Gaming the Quantified Self. Surveillance & Society 11 (05 2013), 163–176. https://doi.org/10.24908/ss.v11i1/2.4454  \r\nShaozeng Zhang, Bo Zhao, and Jennifer Ventrella. 2018. Towards an Archaeological-Ethnographic Approach to Big Data: Rethinking Data Veracity. Ethnographic Praxis in Industry Conference Proceedings 2018 (10 2018), 62–85. https://doi.org/10.1111/1559-8918.2018.01197  \r\nShoshana Zuboff. 2015. Big Other: Surveillance Capitalism and the Prospects of an Information Civilization. Journal of Information Technology 30 (2015), 75–89. https://doi.org/10.1057/jit.2015.5 \r\nShoshana Zuboff. 2018. The Age of Surveillance Capitalism : the Fight for the Future at the New Frontier of Power. Profile Books. ',1,'Murray-Rust','Dave Murray-Rust, Katerina Gorkovenko, Dan Burnett, and Daniel Richards','Dave Murray-Rust *(University of Edinburgh, UK)*<br>\r\nKaterina Gorkovenko *(University of Edinburgh, UK)*<br>\r\nDan Burnett *(Lancaster University, UK)*<br>\r\nDaniel Richards *(Lancaster University, UK)*',NULL,0,'10.1145/3363384.3363405','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,20,10,NULL,NULL,0,21),(21,'bates-the-future-of-techno-disruption-in-gig-economy-workforces-challenging-the-dialogue-with-fictional-abstracts','2019-09-02 15:24:57','2019-10-02 14:12:53','2019-09-02 15:24:57',NULL,1,'published','[]','The future of techno-disruption in gig economy workforces: challenging the dialogue with fictional abstracts','In this article we explore near-future of the pervasive computing, AI, and HCI in the context of the disruptive potential of technologies on workers in the on-demand gig economy. Using fictional abstracts, the authors muse on dystopian case studies of: independent contractors, last-mile couriers, teachers, and creative professionals. This article serves as base for critical reflections on: 1) the need for multidisciplinary approaches when tackling broader and far-reaching societal implications of digital technology in the gig economy, and 2) the potential role of fictional abstracts in the design process of future digital technologies.','Oliver Bates, Christian Remy, Callum Nash, and Ben Kirman. 2019. The future of techno-disruption in gig economy workforces: challenging the dialogue with fictional abstracts. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363476](https://doi.org/10.1145/3363384.3363476 \"DOI for the article \'The future of techno-disruption in gig economy workforces: challenging the dialogue with fictional abstracts\'\")','1 INTRODUCTION\r\n\r\nIn HCI, design fictions [4, 5, 6, 19, 21], speculative research visions [3], futures studies [12, 16, 17], and workshops using fictions [11, 14] considering the societal consequences of technologies are becoming increasingly popular. The narratives and fictional scenarios presented in this literature have facilitated discussions of alternative presents and futures, helping recognise and steer the development of digital technology away from unforeseen consequences on society. Pargman et al. utilised a so-called ‘fictional abstract’ where attendees authored 250 word fictional abstracts used to facilitate discussion and debate focusing on “futures of computing and wisdom” [14]. Building on Pargman et al., Light et al. [10], and Blythe [5], the authors see fictional abstracts as an effective medium for illustrating the potential effects on technologies and services in gig economy work, collaboratively embracing tensions of being a responsible designer, and recognising the needs for multidisciplinary approaches to technology design in complex social systems. This article focuses specifically on dystopian visions of the ‘gig economy’, which should be understood as “the exchange of labour for money between individuals or companies via digital platforms that actively facilitate matching between providers and customers, on a short-term and payment by task basis” [9].\r\n\r\nHCI and related studies of digital technology have focused on: protecting gig workers [18]; algorithmic bias and data in the futures of work [13, 22]; developing tools to support workers in gig and crowd work [2, 8]; configurations of piecemeal work [1]; and, studies of on-demand, gig economy work [7, 20]. Whilst gig work is facilitated by technology, the authors also recognise the potential of digital technology to disrupt the labour of work in the UK where the gig economy facilitates casual work for 2.8 million workers [9]. Within this context, we see fictional abstracts as a tool to develop narratives and a diversity of multidisciplinary collaborations, leading to discussions and designs which more deeply considering the role of digital technology in key societal issues surrounding current and future labour laws, human security, employment rights, automation, access and bias, worker categorisations (e.g. gig economy workers vs. employees), and regulatory reform.\r\n\r\nThe purpose of this article is three-fold: 1) introducing fictional abstracts to the ‘Halfway to the Future’ community; 2) develop critical reflections on the near future of gig economy work in the UK; and, 3) use fictional abstracts to enable a discussion with the community about the broader implications of technology and its far-reaching consequences.\r\n\r\n2 METHODS OVERVIEW\r\n\r\n“We used fictional abstracts for two different purposes. The first purpose was to encourage researchers to write abstracts that speculate about possible futures of (in this case) computing and wisdom. The second purpose was to put these abstracts to work as a tool to drive conversations about the futures of computing and wisdom at the workshop itself.” [14]\r\nThe theme of the abstracts presented here is “The future of techno-disruption in gig economy workforces.” This theme builds on previous work highlighting how HCI and design can (and should) work for workers, not just consumers, to help fight issues of unjust labour practice and shift the power of the gig economy to the hands of workers [2, 8]. The abstracts are positioned in the near-future (2025-2035) (cf. Design Fiction), and challenge notions of AI, HCI, labour, work, and automation. The authors followed writing guidelines developed by Pargman et al. [15].\r\n\r\n3 FICTIONAL ABSTRACTS\r\n\r\nA case study of gig workers as responsible moral centres of semi-automated systems.\r\n\r\nInternational Institute for Responsible Automation\r\n\r\nRecent high-profile incidents involving improper use of automated work-allocation systems demonstrate a misunderstanding of corporate responsibility. In this case study of the recent cyber-terrorist attack (“The Gig Gig”), where a group of extremists exploited a corporate payroll server to steal funds (e.g., Argyll, 2022), we explore how the public misattributed blame and restate the vital role gig workers play as moral centres. The dominant argument on social media that preceded was that the terrorist groups were enabled and supported by corporations in their acts, using a series of instructional content on digital platforms to develop the skills necessary to carry out these attacks, and that the attackers were radicalised by systems that suggested increasingly extreme content based on their interaction history.\r\n\r\nWe explore this misunderstanding and demonstrate that responsibility rests with independent contractors, hired on extreme short contracts (“gig workers”), who are used to efficiently classify and categorise content on these platforms. This is done through a series of tagging tasks with excerpts of content, through a game interface where contractors compete to classify accurately and quickly for financial reward. Since these contractors independently made the decision to classify material used in preparation for the attack, it therefore follows that they ultimately be held responsible for the resulting misuse. Although platforms host the content, it would neither be accessible, or semantically linked, if not for the work performed. We propose design recommendations that ensure that such contractors are correctly held accountable for the effects of their actions.\r\n\r\nEveryday Datafied Digital Service Design: Embracing resistance when designing for the productive societal contributions of ex-workers\r\n\r\nAlternative Cybernetics Research Cooperative, UK\r\n\r\nCollective action against the automation of last-mile logistics and “The Death of the Highstreet” is rising; “Sky-net” attacks against parcel drones in airspaces have quadrupled in the last decade (BBC Sept. 2032), and hacktivist groups repeatedly reroute empty AVUber taxis into Thames estuary (CNN, Oct. 2030). To maintain the flow of goods and services, the underbellies of our cities are used as ‘secure testbeds’, leading to the rapid development of fatberg cutting parcel drones and AV (Wired, Jan 2029). As an impact of basic income in the UK, free time is no longer a premium, perpetuating increased digitally mediated “civil disobedience” (e.g., anti-drone drones, the “Sky-net”). Work and labour became increasingly datafied between 2020 - 2025, leading to worker exploitation in these ubiquitous digital platforms, through holistic tracking of worker movements, practices, and behaviours. It has been hypothesised that business further leveraged this data (cf. surveillance capitalism) leading to the agency, work patterns, and intellectual property of the workers from this period becoming deeply ingrained in the autonomous society we now serve under. This paper aims to reconcile the role of technologists who “sit at a [slightly] higher plain of innovation and opportunity” [@HCI_technocrat_2F8cA, Twitter 12/23/33] by beginning to heal the broken social contract between the economy and the worker. Building on the framework of “Everyday Datafied Design” [Norman_bot and AI_xcF234, 2032] this paper presents qualitative deep learning study of ex-workers (n=328), presenting three new principles for designing resistance into digital services as a productive societal role.\r\n\r\n‘No Teacheroober!? How would I make time to get a job?’ The augmented and ‘naked’ final year experience compared.\r\n\r\nSchool of Critical Higher Education Design (CHED)\r\n\r\nThe 2024 Abacus Revolution\'s market deregulation policies has seen innovation in the ‘gig lecturer’ market, with 98% of UK students using learning support apps (Think and Sketch 2028) in dissertation writing.\r\n\r\nAuto-writing and deep-research software enables app-tutors (normally academic staff and unemployed graduates) to co-write up to 400 student dissertations simultaneously, costing between £250 - £1100 per essay (Stuart & Shatner 2028, Teacheroober 2026). Academic support apps were banned for final year students at Sony TRUMP University in 2028. Research showed that these students have worse post-grad employment outcomes in the first month (Teacheroober et al. 2029). Here, we examine the impact of the ban on staff.\r\n\r\nWe surveyed 75% of the teaching staff (£50 reward card given) with 1 hour, semi-structured chatbot interviews. The paper presents three key finding truth insights: Disruption to academic research teaching staff piggy-backed their contract research through their student base and the app; Workload increase - the student\'s ‘writing and research ability is crippled’. Tutors are having to ‘take students back to first year basics’; Decrease in income - ‘my bread and butter was gig lecturing’ ...‘I am saving for a private rented flat, I think I\'ll be based in my car for another year at least.’\r\n\r\nUK HE cannot ban learning support apps without large scale investment. At this point, it\'s now the backbone of the education market-place. Forcing students to learn is an affront to their freedom.\r\n\r\nThe grand challenge revisited: protecting creativity professional\'s workers’ rights\r\n\r\nCentre for Creativity and Innovation in Economics\r\n\r\nTwenty years have passed since HCI researchers were tasked with the grand challenge to develop creativity support tools (Shneiderman 2009), and since then the landscape has radically changed. With the advent of adaptive interfaces that automatically adjust tools to the designers’ needs, recent development focus has shifted towards the tools that automate creative task assessment (e.g., creativityindexer.org). While those tools simplify the work of researchers seeking to support creative practices, the transformation of the entire industry has led to a worrisome state of the worker\'s rights. Specifically, the flourishment of crowdsourcing design platforms in the last decade see now 63% of creative professionals to be in temporary, freelance, or self-employed positions (Deloitte 2028), without appropriate protection and security for their future.\r\n\r\nIn this paper, we report on an interview study with thirteen design professionals in non-permanent contract situations and shed light on how the subtle change of the creative process over the past decade has changed their work practice. Analysing the results, we reframe the initial grand challenge of building creativity support tools as a challenge to incorporate considerations of workers’ rights and protection for creative practice. Based on our review how the increased automation of creative tasks, their support tools, and the evaluation of creative work has changed this practice, researchers can no longer be agnostic of the political and economic implications that their work has on the affected workforce; an insight that was overlooked a decade ago.\r\n\r\n4 REFLECTION AND CONCLUSION\r\n\r\nThrough the creation of these abstracts, we the authors have been drawn to ideas of daring and unknown futures for gig workers that could be very threatening, both in terms of dystopian and utopian visions. As we are only halfway to the future we see this venue to discuss themes of gig economy work in the next 15 years, to come to terms with the impact of technology design, seeking to avoid the undesirable negative impacts that technology may have on and for workers.\r\n\r\nAs co-authors with different backgrounds (e.g., Computer Science, HCI, Design, Interactive Media), a variety of disciplinary approaches and clashing values, the fictional abstracts offered us an interface for discussing (and documenting) issues of complex, global, and sociotechnical systems that are often out of scope of the research projects due to epistemological boundaries and limitations in our lenses and approaches. Through reflecting on our own experiences and assumptions in fictional abstracts we were able to identify gaps and grey areas in our collective knowledge of the impact of digital technologies in the gig economy. In the context of the gig economy this exercise helped the authors critically reflect on issues that are often not tackled as part of a software engineering or digital design process, such as, legal and regulatory issues, disruption of work and society, consumerism, legislative and legal issues, human security, access to work, and justice.\r\n\r\nAs such, we leave the community with the following questions: How can fictional abstracts be used as tools in multidisciplinary projects to highlight different perspectives? How can we make research more responsible and consider societal issues that arise in potential future scenarios? And how do we use methods such as fictional abstracts and futures studies to help wrestle with the gaps in our disciplinary approaches and understandings of the world?\r\n\r\nBeyond provoking discussions between different disciplines, these fictions also serve as a reminder that our futures are latent, and are already in becoming. It is crucial, therefore, that we recognise the wider implications of evolving technologies and services, and in doing so, challenge the current dialogue in particular spheres. Whilst independent contractors, last-mile couriers, university lecturers and creative professionals are all professions in which technology has been positioned as being a capable aide, we have played with more dystopian futures to challenge such conceptions about gig economy work. We feel that it is critical for all designers and researchers in HCI and Ubicomp to engage with the ideas of technology having profound impacts on societal issues, and see that fictional abstracts are an effective tool for this.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis work is made possible the invisible labour of multiple colleagues, friends and incidental research subjects who inspire and help get these ideas from heads to paper. We thank Carolynne Lord for her input and support throughout the writing process. This work is funded in part by the EPSRC (EP/N02222X/1, EP/S027726/1), Lancaster University FST Research Grant: “Co-creating digital tools for the gig economy logistics workforce”, The Velux Foundations grant: Digital Tools in Collaborative Creativity (grant no. 00013140), and the Aarhus University Research Foundation grant: “Creative Tools”. Finally, we thank our reviewers for their insightful comments that have aided in strengthening our contribution.\r\n\r\nREFERENCES\r\n\r\nAli Alkhatib, Michael S. Bernstein, and Margaret Levi. 2017. Examining Crowd Work and Gig Work Through The Historical Lens of Piecework. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems(CHI ’17). ACM, New York, NY, USA, 4599–4616. https://doi.org/10.1145/3025453.3025974  \r\nOliver Bates, Adrian Friday, Julian Allen, Tom Cherrett, Fraser McLeod, Tolga Bektas, ThuBa Nguyen, Maja Piecyk, Marzena Piotrowska, Sarah Wise, and Nigel Davies. 2018. Transforming Last-mile Logistics: Opportunities for More Sustainable Deliveries. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 526, 14 pages. https://doi.org/10.1145/3173574.3174100  \r\nEric P.S. Baumer, June Ahn, Mei Bie, Elizabeth M. Bonsignore, Ahmet Börütecene, Oğuz Turan Buruk, Tamara Clegg, Allison Druin, Florian Echtler, Dan Gruen, Mona Leigh Guha, Chelsea Hordatt, Antonio Krüger, Shachar Maidenbaum, Meethu Malu, Brenna McNally, Michael Muller, Leyla Norooz, Juliet Norton, Oguzhan Ozcan, Donald J. Patterson, Andreas Riener, Steven I. Ross, Karen Rust, Johannes Schöning, M. Six Silberman, Bill Tomlinson, and Jason Yip. 2014. CHI 2039: Speculative Research Visions. In CHI ’14 Extended Abstracts on Human Factors in Computing Systems(CHI EA ’14). ACM, New York, NY, USA, 761–770. https://doi.org/10.1145/2559206.2578864  \r\nJulian Bleeker. 2009. A short essay on design, science, fact and fiction.  \r\nMark Blythe. 2014. Research Through Design Fiction: Narrative in Real and Imaginary Abstracts. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’14). ACM, New York, NY, USA, 703–712. https://doi.org/10.1145/2556288.2557098  \r\nAnthony Dunne and Fiona Raby. 2013. Speculative everything: design, fiction, and social dreaming. MIT press.  \r\nMareike Glöss, Moira McGregor, and Barry Brown. 2016. Designing for Labour: Uber and the On-Demand Mobile Workforce. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). ACM, New York, NY, USA, 1632–1643. https://doi.org/10.1145/2858036.2858476 \r\nLilly C. Irani and M. Six Silberman. 2013. Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’13). ACM, New York, NY, USA, 611–620. https://doi.org/10.1145/2470654.2470742  \r\nKatriina Lepanjuuri, Robert Wishart, and Peter Cornick. 2018. The characteristics of those in the gig economy. UK Department for Business, Energy and Industrial Strategy. Accessed 10 (2018).  \r\nAnn Light, Irina Shklovski, and Alison Powell. 2017. Design for Existential Crisis. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems(CHI EA ’17). ACM, New York, NY, USA, 722–734. https://doi.org/10.1145/3027063.3052760  \r\nConor Linehan, Ben J. Kirman, Stuart Reeves, Mark A. Blythe, Joshua G. Tanenbaum, Audrey Desjardins, and Ron Wakkary. 2014. Alternate Endings: Using Fiction to Explore Design Futures. In CHI ’14 Extended Abstracts on Human Factors in Computing Systems(CHI EA ’14). ACM, New York, NY, USA, 45–48. https://doi.org/10.1145/2559206.2560472  \r\nJennifer Mankoff, Jennifer A. Rode, and Haakon Faste. 2013. Looking Past Yesterday\'s Tomorrow: Using Futures Studies Methods to Extend the Research Horizon. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’13). ACM, New York, NY, USA, 1629–1638. https://doi.org/10.1145/2470654.2466216  \r\nSanna Ojanperä, Neave O\'Clery, and Mark Graham. 2018. Data science, artificial intelligence and the futures of work. https://doi.org/10.5281/zenodo.1475162  \r\nDaniel Pargman, Elina Eriksson, Rob Comber, Ben Kirman, and Oliver Bates. 2018. The Futures of Computing and Wisdom. In Proceedings of the 10th Nordic Conference on Human-Computer Interaction(NordiCHI ’18). ACM, New York, NY, USA, 960–963. https://doi.org/10.1145/3240167.3240265  \r\nDaniel Pargman, Elina Eriksson, Rob Comber, Ben Kirman, and Oliver Bates. 2018. Guidelines for fictional abstracts. https://futuresnordichi.wordpress.com/2018/05/22/guidelines-for-fictional-abstracts/  \r\nDaniel Pargman, Elina Eriksson, Mattias Höjer, Ulrika Gunnarsson Östling, and Luciane Aguiar Borges. 2017. The (Un)Sustainability of Imagined Future Information Societies. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems(CHI ’17). ACM, New York, NY, USA, 773–785. https://doi.org/10.1145/3025453.3025858  \r\nDaniel Sapiens Pargman, Elina Eriksson, Oliver Bates, Ben Kirman, Rob Comber, Anders Hedman, and Martijn van den Broeck. 2019. The Future of Computing and Wisdom: Insights from Human-Computer Interaction. Futures (2019).  \r\nPaolo Parigi and Xiao Ma. 2016. The Gig Economy. XRDS 23, 2 (Dec. 2016), 38–41. https://doi.org/10.1145/3013496  \r\nBruce Sterling. 2009. COVER STORY: Design Fiction. Interactions 16, 3 (May 2009), 20–24. https://doi.org/10.1145/1516016.1516021  \r\nWill Sutherland and Mohammad Hossein Jarrahi. 2017. The Gig Economy and Information Infrastructure: The Case of the Digital Nomad Community. Proc. ACM Hum.-Comput. Interact. 1, CSCW, Article 97 (Dec. 2017), 24 pages. https://doi.org/10.1145/3134732  \r\nJoshua Tanenbaum, Karen Tanenbaum, and Ron Wakkary. 2012. Steampunk As Design Fiction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’12). ACM, New York, NY, USA, 1583–1592. https://doi.org/10.1145/2207676.2208279  \r\nAlex J Wood, Mark Graham, Vili Lehdonvirta, and Isis Hjorth. 2019. Good gig, bad gig: autonomy and algorithmic control in the global gig economy. Work, Employment and Society 33, 1 (2019), 56–75. ',1,'Bates','Oliver Bates, Callum Nash, Christian Remy, and Ben Kirman','Oliver Bates *(Lancaster University, UK)*<br>\r\nCallum Nash *(Northumbria University, UK)*<br>\r\nChristian Remy *(Aarhus University, Denmark)*<br>\r\nBen Kirman *(University of York, UK)*','https://eprints.lancs.ac.uk/id/eprint/136924/',1,'10.1145/3363384.3363476','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,30,5,NULL,NULL,0,32),(22,'webb-human-robot-relationships-and-the-development-of-responsible-social-robots','2019-09-02 15:24:57','2019-10-23 09:11:17','2019-09-02 15:24:57',NULL,1,'published','[]','Human-robot relationships and the development of responsible social robots','The contemporary development of social robots has been accompanied by concerns over their capacity to cause harm to humans. Our RoboTIPS study sets out to design and trial an innovative design feature that will advance the safe operation of social robots and foster societal trust. The Ethical Black Box (EBB) collects data about a robot\'s actions in real time and in context; when an incident occurs, this data can be used within a wider investigation process to determine what went wrong and prevent similar adverse events. In this paper we draw on Lucy Suchman\'s groundbreaking work on human-machine relationships to elucidate the goals, practices and potential impact of our study. We align with Suchman\'s positioning of safety as an accomplishment of situated action and draw on her analysis to describe the actions of the EBB-enhanced social robot as contingent on context and the robot\'s status as a social agent. We also describe shared priorities in our methodological approaches. We close with observations on how participatory design and an ethnomethodologically-informed stance towards data collection and analysis can contribute to the field of responsible innovation (RI), which seeks to ensure that innovations are undertaken in the public interest and provide societal value.','Helena Webb, Marina Jirotka, Alan F.T. Winfield and Katie Winkle. 2019. Human-robot relationships and the development of responsible social robots. In *Proceedings of Halfway to the Future (HTTF 2019), November 19-20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 7 pages. [https://doi.org/10.1145/3363384.3363396](https://doi.org/10.1145/3363384.3363396 \"DOI for the article \'Human-robot relationships and the development of responsible social robots\'\")','1 Introduction: social robots, plans and the practical accomplishment of safety\r\n\r\nOver the last decade, advances in robotics and Artificial Intelligence (AI) have led to a rapid rise in the development and use of social robots – those which interact with humans to perform particular tasks in particular contexts [1]. The commercial sector has made significant investments into the production of robots with autonomous capacities that can perform social functions and interact with humans in order to fulfil roles in the home and workplace, as well as in settings connected to leisure, education, healthcare and social care. Perhaps the most well-known example is the driverless car, with over 50 companies approved by the California Department of Motor Vehicles to test autonomous vehicles on the road [2]. Further examples include personal companion robots, which interact socially with humans for the purpose of education or overcoming isolation [3], and nursing care robots, which assist patients in healthcare environments [4].\r\n\r\nWhilst commercial [5], government [6] and media discourses [7] often highlight the opportunities afforded by social robots, this positivity has sometimes been dimmed by the occurrence of negative events. Perhaps inevitably, the growing presence of social robots has been accompanied by a rise in incidents and accidents in which humans are harmed during their interactions with these technologies. Again, the most famous of these have involved driverless cars. In March 2018 during tests in Arizona, an Uber car in autonomous mode failed to identify a pedestrian crossing the road. The car hit the pedestrian, who subsequently died [8]. As of April 2019, there had been 6 recorded human fatalities in connection to driverless cars [9]. At times an atmosphere of fear and anger has developed in counterpoint to more optimistic viewpoints. Members of the public in Arizona have – in response to the fatality of 2018 – attacked self-driving cars being tested in Phoenix [10], and some public and media rhetoric constructs dystopian scenarios in which social robots cause mass unemployment and the usurpation of human autonomy, safety and authority [11].\r\n\r\nGiven this sometimes negative climate, it is also perhaps inevitable that public and policy discourses around social robots have increasingly called for processes and mechanisms to investigate, mitigate and prevent incidents and accidents. As described by Winfield and Jirotka [12], 10 different sets of ethical principles for robotics and AI, devised in academia and/or industry, had been published by December 2017, and more have been devised since. In addition, the UK government ran inquiries into Robotics and Artificial Intelligence [13], and Autonomous Vehicles [14] in the 2016-2017 parliamentary session. This demonstrates a clear commitment to good practice. However, we can question the extent to which guidelines and formal reports will assure the safer development and operation of these innovations. As Winfield and Jirotka state in [12] ‘principles are not practice’ (page 3); the existence of the former does not guarantee standards of behaviour in the latter. Winfield and Jirotka call instead for a more agile and inclusive approach to the ethical governance of social robots by drawing on the field of Responsible Innovation (RI) [15]. The RI approach emphasises the value of seeking the viewpoints of multiple stakeholders in order to ensure that innovations are undertaken in the public interest, and of verification and validation processes to ensure that systems are safe and fit for purpose when they move into real world application.\r\n\r\nTaking an ethnomethodological stance [16] helps us to move away from an over-reliance on abstracted principles and guidelines. Instead we can view the safe operation of a driverless car or other social robot as a lived practice. This position is expertly set out in the AI context in the pioneering work of Lucy Suchman [17] [18]. As Suchman describes, plans of action are not synonymous with purposeful action; they are “constituent as an artefact of reasoning about action, not as the generative mechanism of action.” [18] (page 60). We can understand principles and guidelines for the safe development and operation of social robots as plans and thereby see that they do not generate practice. The safe conduct of a given encounter involving robot and human is not predetermined through any kind of plan but is rather the result of the orderliness constituted in and through the interactions occurring between them. Furthermore, the plans – in the form of the principles and guidelines – are artefacts open to interpretation and may be contested. This may particularly occur when plans are designed to be abstracted and generalised away from practical action and local order.\r\n\r\nFollowing this logic, we argue that understanding and optimising safety in the interactions between humans and social robots requires a contextualised and in-depth understanding of how those interactions occur. When this is achieved, it becomes possible to embed mechanisms into social robots and the local order that can enhance safety in a practical way. In this paper, we describe a novel study of work that sets out to achieve this through the development and application of an innovative design feature. This is the ‘RoboTIPS’ project1 [15]. In this study, we develop an ‘Ethical Black Box’ (EBB) for social robots. Similar to the flight recorders used in aviation, the EBB collects data about a robot\'s actions in real time and in context. When incidents and accidents occur this data forms a vital resource to work out what has happened as part of a wider investigation process. This work moves away from dependence on abstract frameworks and guidelines in favour of eliciting a detailed understanding of the everyday practices of those involved in the development, use and governance of social robots.\r\n\r\nSuchman\'s groundbreaking analysis provides a means to conceptualise and examine human-robot relationships in the context of our study. In the remainder of this paper, we describe how we draw on Suchman\'s arguments in our own work and how her understandings of human-machine interactions are reflected in our vision of the EBB-enhanced social robot. We start with a more detailed description of our RoboTIPS study and its aims. We then foreground context in our understanding of social robots and describe them as social agents, with consequences for agency and accountability. Our methodological approach, again mirroring Suchman, emphasises in-depth, context-based analysis and also incorporates participatory design. We argue that this approach has valuable synergies with Responsible Innovation (RI). In particular, work with stakeholders makes the notion of responsibility explicit and ethnomethodologically-informed analyses of accidents and accident investigation processes can serve to foster responsibility in innovation as practical action. Our paper illustrates the continuing relevance of Suchman\'s work, and ethnomethodology more broadly, to the increasing focus on AI in contemporary sociotechnical research and discussions of best practices in innovation.\r\n\r\n2 The Ethical Black Box (EBB) for Social Robots\r\n\r\nThe RoboTIPS study forms part of the UK Engineering and Physical Sciences Research Council\'s Digital Economy programme. It takes up the challenge of exploring how issues of responsibility might be embedded into processes of technological design and development. The field of social robotics is used as a spotlight example to explore this question in detail and Responsible Innovation (RI) is drawn on as a resource to identify suitable activities for analysis and application. RI proposes anticipatory governance whereby the potential positive and negative consequences of an innovation may be anticipated and brought to developers’ attention in order to influence the development trajectory of that innovation. The process of anticipation in RoboTIPS [19] identified the potential for harmful encounters between humans and social robots, and highlighted that these encounters would damage societal trust. The process also led us to look to a more trusted industry to see what might be learnt from it. The industry we considered was aviation.\r\n\r\nThe aviation industry has well-established safety procedures developed over time that help to generate (but of course cannot guarantee) trust with users of various kinds of aviation technologies [20]. At the centre of these procedures is the ‘black box’ flight recorder. This typically consists of a flight data recorder, which records the recent history of a flight in the form of key data parameters collected several times per second, and a cockpit voice recorder, which preserves the conversation in the cockpit between pilots as well as other sounds occurring. When an incident or accident occurs the flight recorder provides valuable evidence that can be accessed and interpreted. The data from the flight recorder is drawn on as part of a wider accident investigation process involving human experts and witnesses. These investigations establish the cause of individual accidents, help to rule out systematic failure modes, and produce lessons to maximise safety across a particular model or the entire industry. The development of the flight recorder has been described as one of the most crucial inventions in the history of safety engineering [21] and its role as a data source in the wider process of investigation helps to preserve trust in aviation.\r\n\r\nIn RoboTIPS we take the aviation context as a starting point and seek to translate this trust-enabling process into the domain of social robots. We do not assume that all the specifics of this process – several of which have developed over periods of time – can be transferred with immediacy but we are interested to see what we can learn from the practices involved and how they might be adopted and adapted in a new context. With this mind, the study will develop a recorder for social robots. We call this recorder the Ethical Black Box (EBB). The EBB collects data about a robot\'s actions in real time and in context. This will include the AI decision-making of the robot and the environmental factors occurring in situ. When problematic incidents occur, the EBB provides a mechanism for the robot to produce an account of its own actions. The inclusion of a natural language explainer system will enable the robot to explain its own behaviour; eventually we want to allow the robot\'s users to be able to ask ‘why did you just do that?’ or even ‘what would you do if…?’ and the robot to give a simple, intelligible explanation. Of course the robot\'s own account will not be considered a neutral one to be straightforwardly taken at face value. Crucially, it is not the black box on its own that forms the safety mechanism; it is the inclusion of the black box within a social process of investigation. An investigation will draw upon EBB information amongst other information, including that of human witnesses and experts, to determine the reason for an incident and any lessons to be learnt from it. Hence, alongside the technical parameters of what to record within an EBB, our research will also consider how the interpretation of those recordings fits into the conduct of an investigation. We will devise a series of scenarios in which a robot with an EBB functions and then ‘malfunctions’ or ‘misbehaves’ in some way. We will then constitute a mock investigation with witnesses to reconstruct what happened and produce findings and recommendations as a real inquiry might. This mock scenario process forms a vital way for our study to trial the practical use of a safety mechanism for social robots in context and is, we believe, the first of its kind.\r\n\r\nIn order to develop a viable EBB and workable mock investigation procedures, the study will be grounded in understandings of the everyday practices and lived experiences of designers and developers, as well as the users of social robots themselves, plus those involved in investigation procedures. This approach builds on a rich tradition of sociological work that recognises the social side of technological risk. Most influential in this tradition is the work of Perrow [22], who provides a detailed analysis of complex systems and a framework for analysing the risks that emerge from them. Like Perrow, we explore the interweaving of the social and the technical in the occurrence of incidents and accidents, and their prevention. We also benefit from substantial bodies of work conducted in the fields of human-robot interaction [23] and human-computer interaction [24]. Since our focus is on ‘organisation’ in terms of local orderliness achieved moment by moment through social encounters involving human and machine, we find Suchman\'s work to be particularly illuminating. In the remainder of this paper we draw on her arguments to elucidate the goals, practices and potential impact of our study.\r\n\r\n3 RoboTIPS: understanding the EBB-enhanced social robot in interaction\r\n\r\nPublished in 1987, Suchman\'s ‘Plans and Situated Actions: The problem of Human-Machine Communication’ provided a pivotal critique of then established understandings and practices in AI and HCI. Suchman highlighted the fallibility of the dominant planning model, which was anchored in cognitive science and which treated actions as a form of problem solving and plans as a sequence of actions designed to achieve a particular, preset goal. She described how this model fails to take into account the highly context specific and contingent nature of human action. Drawing on ethnomethodology, Suchman argued – and demonstrated through empirical analysis - that the situatedness and localness of practical action enables interactants to accomplish tasks and activities, often in collaboration with each other and with the use of different kinds of tools and technologies. We can therefore understand plans as resources for action, interpreted and drawn on by participants in their particular local contexts. The 2007 ‘Human-Machine Reconfigurations: Plans and Situated Actions’ reproduces the earlier text with added commentary and contains further chapters to expand and update Suchman\'s arguments. Suchman widens the focus of her research interests to encompass a range of artefacts in addition to plans. She also describes her ‘renewed interest in questions of machine agency…inspired by contemporary developments both in relevant areas of computing and in the discussion of human-nonhuman relations within social studies of science and technology’ [18] (page 2). She points to the need to avoid an essentialist machine human divide and is enthusiastic about bringing in new conceptual understandings to reconfigure human-machine relations, practices and projects.\r\n\r\nSuchman\'s analysis of the relationships between human and machine provides a lens through which we can conceptualise human and EBB-enhanced social robot interaction in our study. We have already described how her critique of plans allows us to recognise the limitations of guidelines and frameworks and move towards a focus on safety as the outcome of practical action. Next we go deeper into Suchman\'s work to draw out how our vision of the EBB-enhanced social robot corresponds with her analysis of human-machine relationships. We begin by following Suchman to foreground context in our understanding of the social robot.\r\n\r\n3.1 The contingencies of context\r\n\r\nThe actions of a driverless car, companion robot or robot nurse are contingent on the context in which they occur. They are not pre-set but emerge through interaction with others on the scene. Within any interaction with humans, the social robot will draw on its programming and information available in the local context – such as the utterances and visible actions made by humans – as resources to shape moment by moment its actions. Similarly, humans on the scene will draw on available contextual detail – such as the utterances and visible actions performed by the robots – and their own background experiences, perhaps including assumptions about how robots ‘do’ and ‘should’ behave. These will provide resources for the humans to draw on to shape their own actions. Since the way that a particular social robot interacts with humans when carrying out its ‘functions’ will be contingent on those interactions, as a consequence, so will the data the EBB collects. Therefore, we would expect the data collected by an EBB for a (mock) investigation to differ, even if the scenarios in which the robots were placed were formally designed to be identical. In turn, the ways in which the data provided by the EBB are drawn on in the investigation will be contingent on the context of that investigation and how those involved interact with each other. We can therefore see that understanding the meaningful actions of social robots relies on an appreciation of context, and that understanding how an EBB-enhanced social robot may function as a safety mechanism relies on an exploration of its actions and interactions as they occur within specific local contexts.\r\n\r\nWe also find it fruitful to take up Suchman\'s rejection of an essential human versus machine divide in the recognition that is through contextually grounded actions and interactions that ‘machine-ness’ and ‘robotness’ are constituted in any given encounter. The robot is a product of temporally and contextually grounded processes and the extent of its ‘robotness’ is not predetermined. For instance, in a scenario where a human user has a conversation with a companion robot, the category of ‘robot’, as relevant to their interaction, is a product of their interaction rather than merely the material features of the technology. In the 2007 edition of her work, Suchman takes up ideas from Actor Network Theory (ANT) [25] to argue that when we move away from the categorical human-machine divide, we also recognise that our unit of understanding (and analysis) is not the single machine, but the network that it exists within. If humans and machines are mutually constituted, we need to develop an understanding of their sociomaterial assemblages. Whilst acknowledging that significant differences do exist between them, we recognise that ANT and ethnomethodology share an interest in understanding the role of the non-human in interaction [26] and find this interest in networks of use to our own study to some extent. We can understand the EBB-enhanced robot as the product of a network of activities and as embedded within context-dependent networks encompassing human and machine. We particularly see the EBB-enhanced robot as belonging or potentially belonging to multiple strands of network simultaneously. When in use, the robot is embedded within a network that is related to and makes visible its particular function – for instance, a transport network, a hospital network and so on. It also carries within it the ‘hidden labours’ of the designers and developers who created it, and the way it functions is highly contingent on the work of those actors. At the same time, there also exists a potential future network of those involved in an incident or accident investigation scenario. This network includes witnesses, experts, regulators, adjudicators and perhaps other social robots or technologies. This potential network may be called into being at any time. Therefore, its potential to exist is of relevance to the ongoing activities in the other strands of the network; the robot\'s possible role within an investigation is of necessity embedded into its design and its use in everyday activities.\r\n\r\n3.2 The social robot as a social agent\r\n\r\nOnce we have drawn on Suchman to understand the social robot as existing within a network and its actions as contingent on context, we can then consider her arguments about machine agency. As noted above, the 2007 work includes a renewed interest in machine agency; she follows ANT to position it as neither inherent to, or located within, humans or artefacts. Instead it is distributed and enacted. Again we recognise that differences exist between ANT and ethnomethodological positions. However, it is crucial to acknowledge that contemporary developments in AI have created new forms of machine human relationships, in which machines are able to exercise a degree of autonomy. A social robot is a social agent. It is not capable of intersubjective reasoning in the way a human is but nevertheless it is able to make decisions, and these decisions plus the actions that follow it have social consequences. We can usefully conceptualise the social agency of the robot as mutually constituted with its materiality [27] but our chief interest here is empirical. We are interested to observe how the EBB-enhanced robot is constituted as having agency in its interactions with humans; or as Suchman states ‘how the effect of machines-as-agents is generated’ [18] (page 2).\r\n\r\nThe enacted agency of social robots is of central interest to the RoboTIPS study, with particular reference to how agency also confers accountability. As a social agent, a social robot might be oriented to by human interactants as accountable for its actions, with consequences for the ongoing encounter. Once again, this does not suggest that a social robot is capable of human-like reasoning, but that the humans in an encounter might treat a robot as accountable for some unexpected or disruptive behaviour and alter their own behaviours accordingly. For instance, a human might make a robot accountable for a nonsensical conversational turn by producing a quizzical response, or make a driverless car accountable for passing too close to a pedestrian through the conduct of evasive action and gesturing. The role of accounts lies at the heart of the EBB-enhanced social robot. When it is involved in an incident or accident, the robot is treated in the local context as accountable to produce an explanation for its actions by those investigating what happened. It is not regarded as the moral perpetrator of the adverse event and does not provide an explanation grounded in human reasoning. However, the robot does provide an account - in the form of information about its actions, the local context and the traces of its own design and development - that allows human investigators to piece together what happened. In this way the EBB serves to help map out where responsibility for an incident or accident lies. The specific processes through which this is achieved will be contingent on context. We note that the robot\'s role transforms as the situation develops. When conducting its first function as a social robot, the robot may be treated as accountable for its behaviours plus also accountable to collect information relevant to the immediate context and simultaneously to collect information to enable sense-making in the potential future context of an investigation scenario. Later, it may be treated as accountable to produce this information in a way that is meaningful to human participants in the investigation. This is an area of great fascination that draws parallels with the work of Garfinkel [28] and subsequent work in the ethnomethodological tradition on record keeping [29]. It is a necessary task of the social robot and the network of actors that develop and configure it to produce within the EBB a record of information that is ordered, orderly and intelligible in two separate contexts. At the empirical level we are interested in how the EBB-enhanced robot can produce an account that helps an ongoing investigation. As the project unfolds we will explore the interactions in which the robot produces these accounts and seek to identify how to best shape the development of the EBB so that the explanations the robot produces are locally coherent and aid the successful accomplishment of the investigation.\r\n\r\n3.3 Methodological Considerations\r\n\r\nSuchman\'s work is groundbreaking methodologically as well as conceptually. Her original study included detailed analyses of interactions between users and an ‘intelligent’ machine. These demonstrated the value of naturalistic and quasi-naturalistic research methods, in particular the use of quasi naturalistic experiments to expose and identify unexpected aspects of social organisation when users interact with a new technology [30]. Following ethnomethodolgical principles, Suchman emphasises: i) conducting empirical work grounded in recognition of context; ii) observing interaction to identify how categories of machine and human are enacted in and through actions occurring within the local sequential and material order; and iii) exploring how troubles are identified and dealt with in context. She also highlights the contribution of participatory design in technological development. Her own work demonstrates this value by capturing how the designers of expert systems came to consider their innovations more in terms of human-machine interaction and usability.\r\n\r\nWe similarly prioritise these elements and employ them in RoboTIPS to optimise our understanding of human -robot relationships and the operation of the EBB-enhanced social robot. Our empirical work begins with ethnographic studies of designers and developers of social robots. This will help us to understand their everyday activities and sense-making, as well as the constraints they operate under. In combination with the stakeholder engagement described below, this will also elicit a set of user-focused requirements for the EBB [31]. Our ethnographic work will focus on the particular domains in which the EBB will subsequently be tested, thereby ensuring we gather necessary context-relevant knowledge. The EBB will be trialled empirically. Our mock investigations will be quasi-naturalistic encounters beginning with interactions between the social robot and human users, and then involving the social robot in an investigation process that includes humans taking the roles of investigators, experts and other witnesses. Our emphasis throughout will be on understanding the configurations of human and EBB-enhanced social robot as the product of situated action. We will observe interactions between humans and the social robot within the specific context in which they occur and draw on these observations to understand the occurrence of adverse incidents and the process of investigation that follows them. This exploration of how troubles are identified and dealt is central to our study. In the first instance, we are interested to observe how the ‘misbehaviour’ or ‘malfunctioning’ of a social robot becomes visible and is dealt with in the moment by moment unfolding of interaction. Next we are then interested to observe how this misbehaviour or malfunction is addressed in the later interactional context of the investigation process, in particular the ways in which the EBB provides contextually relevant information to aid this investigation. This includes a keen interest in how accountability for the event, and accountability for the production of information relevant to the event, is established.\r\n\r\nWe will embed participatory design activities across the entire timescale of the project. These will encourage reflexive awareness amongst developers and others of their own role in the innovation process. We see great resonance between the aims of participatory design and Suchman\'s deployment of it, and the RI approach described earlier in the paper. The notion of responsibility for the development of an innovation is implicitly embedded into participatory design. RI makes this explicit and identifies steps to make recognising responsibility practically achievable [31]. We will include a wide range of relevant stakeholders - policy makers, regulators, researchers, and educators amongst others - alongside the designers and users of the technology in various workshops, roundtables, surveys and focus groups. At times these activities will focus on specific design issues connected to the EBB and/or the requirements of a particular domain. At other times they will be broader in scope, for instance eliciting and circulating issues associated with being responsible in the contemporary digital economy. Towards the end of the project, we will run ‘speculative design’ exercises where we re-imagine different sorts of novel institutions, technologies, and policy environments as a tool for fostering an appreciation of the issues and generate creative solutions amongst designers, innovators, policy makers and so on. These speculative designs will take a number of forms, including video material and demonstrator systems, and will be used across our networks of stakeholders to stimulate discussion and impact.\r\n\r\n4 Conclusions: fostering the development of responsible robots\r\n\r\nSuchman\'s groundbreaking work offers a vivid account of human-machine relationships. It also provides a resource to conceptualise and analyse sociomaterial arrangements in different contexts. We have drawn on Suchman\'s arguments to set out the work of our RoboTIPS study, which develops an innovative safety design feature, the Ethical Black Box (EBB) for social robots, and embeds social robots into the incident and accident investigation process. Suchman\'s description of plans ‘as an artefact of reasoning about action’ rather than the ‘generative mechanism of action’ [18] (page 60) helps us to move away from a focus on formalised safety and ethical principles for social robots and to understand that safety is a practical accomplishment, achieved within a local context. As human-robot encounters are contingent on the interactions that occur between them, so too the data collected by the EBB in the social robot, and the outcomes of the investigation process drawing on information provided by the EBB, will be context-dependent. The incident investigation process we describe is a safety and transparency mechanism that can serve to foster trust. The EBB-enhanced social robot plays a pivotal, and pivoting, role in this process. In its first function it serves as a driverless car, companion or nurse etc. in interaction with humans but later transforms to provide information about an event that it was itself part of.\r\n\r\nOur study will interrogate the technically constructed EBB from within a social frame of reference. We are very interested in the EBB-enhanced social robot as a social agent that may be oriented to as accountable to collect information in its EBB that is both coherent in real time and that can also be meaningfully interpreted during an investigation at any future time. This accountability is enhanced by the existence within the EBB of a natural language explainer, meaning that the social robot can produce a verbal account of its actions. By extension, we can also consider the developers of the robot as also accountable to some degree, and our study seeks to establish processes through which responsibility is mapped out following an adverse event. Our mock investigations play a key role here. It is when something goes wrong with a technology that we are able to see what the chains of responsibility are; we are able to do this by observing how these chains are made visible and are enacted across the networks of human-machine actors. Our aim isn\'t to develop the \'perfect\' explainer in an EBB, but to polish a state-of-the-art explainer and to explore how it fairs within the social context of a simulated incident and investigation process. It is to \'learn-by-doing\' what the parameters are for an explainer to be integrated into a social process and to learn what role it comes to play. Taking this further, our work can contribute to current debates about trust and transparency in Artificial Intelligence (AI). The EBB is a motivation for exploring how investigations around the failure of AI might be constituted as a future tool in the wider AI regulatory framework.\r\n\r\nSuchman highlights the methodological approaches needed to understand human-machine configurations in context and in depth. We agree that empirical work and observations of interaction provide a fruitful approach to ground understandings of human-machine relationships in context and to identify how categories of machine and human are enacted moment by moment. We also agree that the exploration of how troubles occur and are resolved provides great analytic value and share Suchman\'s enthusiasm for participatory design in technological development. We take this further by making the notion of responsibility explicit as part of an agile process that takes the viewpoints of societal stakeholders into account in order to develop and implement an innovative design feature. We regard this as an instance of responsible innovation (RI) in action. We close with some observations on the synergies between ethonomethodology and the vision of responsible innovation.\r\n\r\nThe RI agenda has been strongly promoted by the EU, and national funding institutions are also increasingly adopting RI principles and encouraging RI for their funded research2 . RI is positioned as an opening up the innovation space to a range of stakeholders and facilitating practices to engage with them. This in turn allows the opportunities and challenges inherent to the innovation process to become visible and to be addressed creatively. RI proposes a new approach to research and innovation governance and seeks to facilitate a more adaptive, human-centred, inclusive and sustainable research and innovation process. This is to be applied from fundamental research through to application design and beyond. RI work so far has produced frameworks that researchers and innovators can draw on as a resource to pursue responsibility in their work. The contribution of ethnomethodology can take this further. The ethnomethodological focus on the detailed observation and understanding of context aligns closely with RI as a deep understanding of context is necessary to achieve responsibility in innovation. Attention to situated action allows us to understand human and machine practices, gauge user needs, and observe how innovations are used in action, including how problems are emerged and resolved. Drilling down into context combines with the ethnomethodolgical focus on practical action. This provides a way to avoid broad, overarching plans such as guidelines etc. to govern innovation in favour of more flexible and responsive mechanisms, such as the EBB for social robots. In our RoboTIPS study, we draw on social robots as a spotlight example of how responsible innovation may be achieved in action; in doing so, we hope also to illuminate ways that RI can be informed by ethnomethodology.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThe ‘RoboTIPS: Developing Responsible Robots for the Digital Economy’ study is an EPSRC Established Career Digital Economy Fellowship awarded to Marina Jirotka. Project ref: EP/S005099/1.\r\n\r\nREFERENCES\r\n\r\nSatyandra K. Gupta (2015). Six recent trends in robotics and their implications spectrum,ieee.org, 8th Sep 2015, https://spectrum.ieee.org/automaton/robotics/home-robots/six-recent-trends-in-robotics-and-their-implications.  \r\nAndrea Miller (2018). Some of the companies that are working on driverless car technology. abcnews.go.com, 21st March 2018. https://abcnews.go.com/US/companies-working-driverless-car-technology/story?id=53872985.  \r\nThe Medical Futurist (2018). The Top 12 Social Companion Robots, medicalfuturist.com, 31st July 2018, https://medicalfuturist.com/the-top-12-social-companion-robots.  \r\nRiken (2015). The strong robot with the gentle touch, riken.jp, 23 rd February 2015, http://www.riken.jp/en/pr/press/2015/20150223_2/.  \r\nKPMG Advisory N.V. (2016). Social Robots, kpmg.home, https://assets.kpmg/content/dam/kpmg/pdf/2016/06/social-robots.pdf.  \r\nTom Kalil and Sridhar Kota (2011). Developing the Next Generation of Robots, obamawhitehouse.archives.gov, June 24th 2011, https://obamawhitehouse.archives.gov/blog/2011/06/24/developing-next-generation-robots.  \r\nMarc Ambasna-Jones (2016). How social robots are dispelling myths and caring for humans, theguardian.com, 9th May 2016, https://www.theguardian.com/media-network/2016/may/09/robots-social-health-care-elderly-children.  \r\nSam Levin and Julia Carrie Wong (2018). Self-Driving Uber kills Arizona woman in first fatal crash involving pedestrian, theguardian.com, 19th March 2018, https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe.  \r\nWikipedia]</number> (2019). List of self-driving car fatalities, wikipedia.org, accessed 24 th June 2019, https://en.wikipedia.org/wiki/List_of_self-driving_car_fatalities.  \r\nOliver Rudguard (2018). Arizona residents attack self-driving cars, telegraph.co.uk, 13th December 2018, https://www.telegraph.co.uk/technology/2018/12/13/arizona-residents-attack-self-driving-cars/.  \r\nDom Galeon (2017). Bill Gates: Benefits of robots, healthcare AI, will outweigh pitfalls, futurism.com, 16th November (2017), https://futurism.com/bill-gates-benefits-robots-healthcare-ai-outweigh-pitfalls/.  \r\nAlan F.T. Winfield and Marina Jirotka (2018). Ethical governance is essential to building trust in robotics and artificial intelligence systems, Phil. Trans. R. Soc. A. 376:20180085. doi.org/10.1098/rsta. 20180085.  \r\nParliament UK (2016). Robotics and artificial intelligence inquiry launched, parliament.uk, 24th March 2016, https://www.parliament.uk/business/committees/committees-a-z/commons-select/science-and-technology-committee/news-parliament-2015/robotics-and-artificial-intelligence-inquiry-launch-15-16/  \r\nParliament UK (2016). Driverless vehicles – where are we going?, parliament.uk, 15th September 2016, www.parliament.uk/business/committees/committees-a-z/lords-select/science-and-technology-committee/news-parliament-2015/autonomous-vehicles-inquiry/  \r\nRene Von Schomberg (2013). A vision of responsible research and innovation. Responsible innovation: Managing the responsible emergence of science and innovation in society (2013), 51–74.  \r\nHarold Garfinkel (1967). Studies in Ethnomethodology, Englewood Cliffs, N.J.: Prentice Hall.  \r\nLucy Suchman (1987) Plan and Situated Actions: the problem of human-machine communication, Cambridge, Cambridge University Press.  \r\nLucy Suchman (2007). Human-Machine Reconfigurations: Plans and Situated Actions, 2nd Edition, Cambridge, Cambridge University Press.  \r\nAlan F.T. Winfield and Marina Jirotka (2017). The Case for an Ethical Black Box. In: Gao Y., Fallah S., Jin Y., Lekakou C. (eds) Towards Autonomous Robotic Systems. TAROS 2017. Lecture Notes in Computer Science, vol 10454. Springer, Cham.  \r\nUK Civil Aviation Authority (2013). Global Fatal Accident Review 2002 to 2011, June 2013 http://publicapps.caa.co.uk/docs/33/CAP%201036%20Global%20Fatal%20Accident%20Review%202002%20to%202011.pdf. \r\nKrishna M. Kavi (2010) Beyond the Black Box, IEEE Spectrum, August 2010, https://csrl.cse.unt.edu/kavi/Research/Spectrum-Aug-2010.pdf.  \r\nCharles Perrow (1984). Normal Accidents, New York:Basic Books.  \r\nTakayuki Kanda and Hiroshi Ishiguro (2017) Human-Robot Interaction in Social Robotics, Boca Raton, CRC Press, doi:10.1201/b13004.  \r\nAlex Roney Mathew, A. Al Hajj and A. Al Abri (2011) Human-Computer Interaction (HCI): An overview, 2011 IEEE International Conference on Computer Science and Automation Engineering, Shanghai, 2011, pp. 99-100. doi: 10.1109/CSAE.2011.5953178  \r\nBruno Latour (1987). Science in Action: How to follow scientists and engineers through society Cambridge, MA.:Harvard University Press  \r\nEric Laurier et al. (2019) The \"Studies in Ethnomethodology\" Are a Way of Understanding and Handling Empirical Materials and Thoughts. Eric Laurier in Conversation With Hannes Krämer, Dominik Gerst and René Salomon. Forum Qualitative Sozialforschung / Forum: Qualitative Social Research, [S.l.],20,2, May 2019. ISSN 1438-5627.  \r\nMorana Alač (2016). Social robots: Things or agents? AI & Soc 31, 519, doi 10.1007/s00146- 015-0631-6.  \r\nHarold Garfinkel and Egon Bittner (1967). Good organizational reasons for bad clinic records. In Harold Garfinkel (Ed.) Studies in Ethnomethodology, Englewood Cliffs, N.J.: Prentice Hall, 186-207.  \r\nChristian Heath and Paul Luff (1996). Documents and Professional Practice: ‘bad’ organizational reasons for ‘good’ clinical records, Proceedings of the Conference on Computer Supported Cooperative Work, Boston, ACM Press 1996, 354-363  \r\nChristian Heath and Paul Luff (2017) The Naturalistic Experiment: Video and Organisational Interaction, Organizatuonal Research Methods, 21, 2, 466-488.  \r\nBarbara Grimpe, Mark Hartswood and Marina Jirotka (2014).Towards a closer dialogue between policy and practice: responsible design in HCI. In Proceedings of the 32nd Annual ACM Conference on Human Factors in Computing Systems (Toronto, Canada, April 26-May 01). ACM Press, New York, 2014, 2965-2974',1,'Webb','Helena Webb, Marina Jirotka, Alan F.T. Winfield, and Katie Winkle','Helena Webb *(Department of Computer Science, University of Oxford, UK)*<br>\r\nMarina Jirotka *(Department of Computer Science, University of Oxford, UK)*<br>\r\nAlan F.T. Winfield *(Bristol Robotics Lab, University of West of England, UK)*<br>\r\nKatie Winkle *(Bristol Robotics Lab, University of West of England, UK)*<br>',NULL,0,'10.1145/3363384.3363396','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,10,NULL,NULL,0,12),(23,'isbister-toward-suprahuman-technology-a-manifesto-in-support-of-computational-augmentation-of-mutual-physical-presence-and-colle','2019-09-02 15:24:57','2019-10-23 09:11:21','2019-09-02 15:24:57',NULL,1,'published','[]','Toward ‘Suprahuman’ Technology: A Manifesto in Support of Computational Augmentation of Mutual Physical Presence and Collective Action','Drawing upon the findings and experiences of my team’s Research-through-Design practice, I propose that we as a scholarly community pull together (harder) to steer future technological developments toward putting attention on the experiential space between people, deploying computation toward augmenting physical copresence and collective action. Despite long-standing research efforts in HCI and Ubicomp aimed at reorienting the ship, particularly in recent years, vast commercial internet and mobile-based services have rightfully been critiqued for encouraging some pretty isolating behavior patterns. In the spirit of Suchman’s reframing of our understanding of the human machine interface in her classic text, Human-Machine Reconfigurations: Plans and Situated Actions, and drawing upon the style of and some key ideas from Donna Haraway’s past and recent work, I put forward a manifesto that calls for a future of technology that enables the ‘suprahuman’—a productive reweaving of the social fabric between us in ways that include our bodies and the material world, and that privilege bolstering connection and shared action. I respectfully put forward this call to action as fodder for discussion at the Halfway to the Future event.','Katherine Isbister. 2019. Toward ‘Suprahuman’ Technology: A Manifesto in Support of Computational Augmentation of Mutual Physical Presence and Collective Action. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363468](https://doi.org/10.1145/3363384.3363468 \"DOI for the article \'Toward ‘Suprahuman’ Technology: A Manifesto in Support of Computational Augmentation of Mutual Physical Presence and Collective Action\'\")','Toward `Suprahuman\' Technology\r\nA Manifesto in Support of Computational Augmentation of Mutual Physical Presence and Collective Action\r\nKatherine Isbister\r\nComputational Media, University of California Santa Cruz, Santa Cruz, California, USA, katherine.isbister@ucsc.edu\r\nABSTRACT Drawing upon the findings and experiences of my team\'s Research-through-Design practice, I propose that we as a scholarly community pull together (harder) to steer future technological developments toward putting attention on the experiential space between people, deploying computation toward augmenting physical copresence and collective action. Despite long-standing research efforts in HCI and Ubicomp aimed at reorienting the ship, particularly in recent years, vast commercial internet and mobile-based services have rightfully been critiqued for encouraging some pretty isolating behavior patterns. In the spirit of Suchman\'s reframing of our understanding of the human machine interface in her classic text, Human-Machine Reconfigurations: Plans and Situated Actions, and drawing upon the style of and some key ideas from Donna Haraway\'s past and recent work [5,6], I put forward a manifesto that calls for a future of technology that enables the `suprahuman\'--a productive reweaving of the social fabric between us in ways that include our bodies and the material world, and that privilege bolstering connection and shared action. I respectfully put forward this call to action as fodder for discussion at the Halfway to the Future event.\r\nCCS CONCEPTS · Human Centered Computing · Human Computing Interaction · Interaction Paradigms\r\nKEYWORDS Physical copresence, collective action, suprahuman technology\r\n1 The Problem: Isolating Technological Drift\r\nAs a Ph.D. student entering the world of Human Computer Interaction research long ago, I remember reading an edited volume, The Art of Human Computer Interface Design [10], as a key inspiration for my choice of future profession. This book was brimming with positive visions for how computation would enhance so many aspects of our daily lives, from education to collaboration to play--it was an edited volume published in 1990, close on the heels of the personal computer revolution. At that time, the luminaries in this new space had intellectual and cultural ties to prior social movements that emphasized challenging social norms and precedence, toward freer and presumably therefore better forms of both individual living as well as collective engagement [14]. I found all this invigorating and inspiring--it seemed that HCI would be a fantastic field for adding value to the human experience, moving us toward the exciting (to me) cyborgian possibility space that Donna Haraway wrote about so eloquently around that time [5].\r\nNow that we\'re `halfway to the future\', and I\'m a full professor teaching my own Ph.D. students, I\'m sobered by recent accusations against our field triggered by the rise of internet and mobile-based services--I worry that the face of what we do has taken the shape of a somnolent, isolating, and disempowering model that aims to\r\n1\r\n\r\ncapture and manage individual attention by developing personalized services that adapt to pull each of us ever more deeply into daily, hourly solo consumption [7]. I would argue that these services have significantly shifted everyday peoples\' notion of what it means to be social together, from mostly being in the world, physically, together, using our bodies to be present to our surroundings, toward a notion of social engagement that is increasingly intermingled with and mediated by networked software that does not require use of our bodies, and that is deeply intertwined with the service model and the accompanying business model of extracting value from gathering and processing data about our behavior while using these services. When we do move our bodies through the physical world, we carry along powerful technology that offers us the ever-present ability to delve back into these services, resulting in a more ghostly presence of our attention to the physical places and social spaces that our bodies occupy. At this point, the health impacts of physical inactivity [15] and of social isolation [8] are documented, so there are very practical reasons to want to challenge this drift. And also, to me, it seems that some of the most pressing political and social challenges of the day--such as climate change and the global rise of populism--would deeply benefit from activation of inperson connection and collective action.\r\nIt\'s not that our research community has not been investigating and championing the augmentation of rich in-person interaction--some of the luminaries of our field who have envisioned and prototyped technology designed to support compelling inperson social experience are here at this event (e.g. Benford [1], Rogers [4], Gaver [12]). But somehow, this work is not making its way in a sustained fashion into the everyday fabric of technologically enhanced life, nor into the sustained public perception of what technology can do for us as human beings. How can we shift this? This manifesto is an examination of that question, and a call to mutual action.\r\n2 Toward the Suprahuman\r\nIn Donna Haraway\'s Cyborg Manifesto, she presents the image of the `cyborg\' as a guiding concept for reimagining what it means to be human while dodging the application of `universal, totalizing theory\' that `misses most of reality, probably always.\' [5, p. 67]. She paints a sinuous and compelling picture of the cyborg as a fluid blend between person and technology, linking this with her visions of future feminism, and declaring at the end of the essay \"I would rather be a cyborg than a goddess.\" [5, p. 68].\r\nIn this manifesto, I introduce the Suprahuman as an inspirational concept and frame for challenging assumptions latent in some dominant current commercial practices and consumption patterns with technology. What I mean by this, can perhaps be visualized with the famous figure-ground perception illustration in Figure 1. I believe we can gain a great deal by firmly fixing our designerly attention on the spaces between co-present people as a rich terrain for technological practice. That is to say, how can technology help to build webs of connection and coordination and co-action between human beings who are physically together?\r\n2\r\n\r\nHow can technology meld people into suprahuman co-present entities that can engage and act in ways than are not possible for each person in isolation?\r\nFigure 1. Figure-ground perception illustration. This image can be seen as either two faces looking at one another on a white background, or as a vase on a black background.\r\nTechnological imaginings have a longstanding relationship with science fiction. A piece that I found inspirational in crafting this manifesto is Theodore Sturgeon\'s classic Science Fiction novel, More than Human [13]. In this novel (spoiler alert), a disparate set of six human beings slowly come together, and are able to `blesh\'-- meaning that they can form a collective consciousness together and have fantastical powers acting as one collective being. Sturgeon paints each individual in his story as an unwanted and cast-off person, outside societal norms, but together they become a wise and transcendent being, with capacities far beyond those of everyday individuals. We may already envision networked communication as a form of `bleshing,\' but it leaves our performative social bodies behind in important ways. What might it be like for everyday technology to truly augment physical bodies and interactions in ways that encourage and support group engagement and action, in a way that is `larger than\' oneself? What could it mean to be suprahuman in this way?\r\n3 True Colors: A Prototyped Example of Suprahuman Support\r\nFigure 2. True Colors wearable (image taken from [11]).\r\nAs an example of striving toward the suprahuman, here I\'ll briefly describe an example of our research team\'s work to engage the social space between bodies. We created the True Colors wearable (shown in Figures 2 and 3) in a co-design process with live action role players (larpers), to augment players\' experience of a multi-day play session. Larp is a form of collective play in which a group of people comes\r\n3\r\n\r\ntogether and enacts roles in an improvisational way, with the guidance of designers, to have a compelling shared experience. Larpers enjoy using technology to enhance their experience, but will not use it if it is distracting to individuals at the expense of the group dynamic and engagement [11].\r\n\r\nFigure 3. True Colors wearable in action during Event Horizon\'s New Gyr larp in 2018 (pictures used with permission of Event Horizon).\r\nThe devices we designed had many features (see Figure 2), but the clear favorite was when a device would `overload\', requiring that other players come to the wearer\'s assistance. These moments of vulnerability and contact led to meaningful experiences for subgroups of players, and added strong value to the overall experience (as relayed in interviews and through observation [2]). Helping others in a technologically induced and enhanced way augmented the lived social and physical experience of the group as a whole, working well within the context of their interactions, and gracefully creating opportunities for connection that were valued for their addition to the overall social texture of the event.\r\n4 Designerly Values and the Suprahuman\r\nIn the example above, our design work was supported and scaffolded by the inherent values of the larp community [2, 11]. Perhaps a step that we can take as a research community, is to collectively craft and stand behind a set of suprahuman design values [9] that can be used to shape our work, and also to critique other extant visions of how technology inserts itself into our copresent physical/social reality. Here I propose some contrasts, as Haraway does in her Cyborg Manifesto, of values that seem latent in some present-day common technologies (most especially mobile phones), as opposed to directions we might take on the path toward the suprahuman:\r\n\r\nIsolating/Individualist The device is there to support me, at my convenience, and serve information perfectly\r\nadapted to me. The device can ask for as much of my attention as it wants, at any time. It can make me stare at it and\r\ntouch it, ignoring others.\r\n\r\nSuprahuman The device(s) are there to support us, collectively, toward a shared experience here in this place now.\r\nThe device(s) are deeply sensitive to not interrupting, and rather, enhancing, my experience\r\nwith other people around me, avoiding interruptions. Their signaling and input doesn\'t get in the way of my interaction with others, but rather\r\nmay add to their/our social experience.\r\n\r\n4\r\n\r\nMore devices is better; everyone needs their own, and each person should have all functionality.\r\nMy device can collect data about me toward forming aggregate patterns to sell better stuff to me as an individual, or to other individuals like me\r\n(wherever they are) at some future time.\r\n\r\nSharing devices is fine, maybe even to be desired. It is powerful to have interdependent, distinct and\r\nunique devices that work best when shared/combined.\r\nOur devices only use data they collect about us to improve our co-present experience together in the\r\nhere and now.\r\n\r\n5 Manifesting the Suprahuman Together\r\nOur research group has been working on a series of projects that attempt to build an aesthetic and design language of the suprahuman [e.g. 2,3]. We are seeking comrades in the revolution! Many of you at this event care deeply about designing technology that supports shared social presence--perhaps we can use this set of values (and/or iterate them while we are here together) as a rallying point to gather momentum in translating this work into everyday technologies of the future. Donna Haraway\'s recent book [6] is focused on how to `stay with the trouble\' and `make kin\' with one another in our quest to reground ourselves and our relationship to our environment. One challenge problem for our community in this second half of our journey toward the `future\' could be engaging and empowering co-present people to let go of fear and isolation in regard to climate change, to instead work creatively and collaboratively (supported by suprahuman technology) to enact sustained productive responses--to `stay with the trouble\' together.\r\nACKNOWLEDGMENTS\r\nThanks to my past and present students, postdocs, and other collaborators for informing and shaping these thoughts, in particular Elena Márquez Segura, Joshua McVeigh-Schulz, Ella Dagan, Ferran Altarriba Bertran, and Raquel Robinson. Thanks also to the reviewers for their excellent feedback, that greatly improved the final version of this manifesto.\r\nREFERENCES [1] Benford, Steve, and Giannachi, Gabriella (2011). Performing Mixed Reality, MIT Press. [2] Dagan, Ella, Márquez Segura, Elena, Bertran, Ferran Altarriba, Flores, Miguel, and Isbister, Katherine\r\n(2019). Designing \'True Colors\': A Social Wearable that Affords Vulnerability. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, Paper No. 33. [3] Dagan, Ella, Márquez Segura, Elena, Flores, Miguel, and Isbister, Katherine (2018). `Not too Much, Not too Little\': Wearables for Group Discussions. Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. [4] Gaver, William W., Bowers, John, Boucher, Andrew, Gellerson, Hans, Pennington, Sarah, Schmidt, Albrecht, Steed, Anthony, Villars, Nicholas, and Walker, Brendan (2004). The Drift Table: Designing for Ludic Engagement. CHI \'04 Extended Abstracts on Human Factors in Computing Systems, pp. 885900. doi: 10.1145/985921.985947 [5] Haraway, Donna (2011/1984). Cyborg Manifesto. In Cultural Theory: An Anthology, p. 454. [6] Haraway, Donna (2016). Staying with the Trouble: Making Kin in the Chthulucene. Duke University Press. [7] Harris, Tristan (2019). How Technology Hijacks Peoples\' Minds--From a Magician and Google\'s Design Ethicist. http://www.tristanharris.com/essays/ , accessed 20 June 2019. [8] Holt-Lunstad, Julianne, Smith, Timothy B., Baker, Mark, Harris, Tyler, and Stephenson, David (2015). Loneliness and Social Isolation as Risk Factors for Mortality: A Meta-Analytic Review. Perspectives on Psychological Science, doi: 10.1177/1745691614568352. [9] Knobel, Corey and Bowker, Geoffrey C. (2011). Computing Ethics: Values in Design, Communications of the ACM 54(7): 26-28. Doi: 10.1145/1965724.1965735.\r\n\r\n5\r\n\r\n[10] Laurel, Brenda (Ed.) (1990). The Art of Human Computer Interface Design. Addison-Wesley Publishing Co., Reading, MA, 1990\r\n[11] Márquez Segura, Elena, Isbister, Katherine, Back, Jon and Wearn, Annika (2017). Design, Appropriation, and Use of Technology in Larps. Proceedings of Foundations of Digital Games 2017, doi: 10.1145/3102071.3106360\r\n[12] Rogers, Yvonne (2006) Moving on from Weiser\'s Vision of Calm Computing: Engaging UbiComp Experiences. In: Dourish, Paul, and Friday, A. (eds) UbiComp 2006: Ubiquitous Computing. UbiComp 2006. Lecture Notes in Computer Science, vol 4206. Springer, Berlin, Heidelberg [13] Sturgeon, Theodore (1953). More than Human. Farrar, Straus & Young [14] Turner, Fred (2006). From Counterculture to Cyberculture: Stewart Brand, the Whole Earth Network,\r\nand the Rise of Digital Utopianism. University of Chicago Press. [15] Wilmot EG, Edwardson CL, Achana FA et al. (2012). Sedentary time in adults and the association with\r\ndiabetes, cardiovascular disease and death: systematic review and meta-analysis\', Diabetologia, vol. 55, no. 11, pp. 2895­2905. doi: 10.1007/s00125-012-2677-z\r\n6\r\n\r\n',1,'Isbister','Katherine Isbister','Katherine Isbister *(Computational Media, UC Santa Cruz, USA)*',NULL,0,'10.1145/3363384.3363468','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,10,5,NULL,NULL,0,24),(24,'todi-reimagining-the-role-of-the-expert-from-interface-design-to-interface-curation','2019-09-02 15:24:57','2019-10-23 09:11:28','2019-09-02 15:24:57',NULL,1,'published','[]','Reimagining the Role of the Expert: From Interface Design to Interface Curation','User Interface (UI) design has been a core topic of HCI research for several decades. Equipped with design skills and knowledge, the expert interface designer meticulously analyses a design brief, conceptualises design ideas, and constructs viable solutions. The intended outcome of this tedious process is a usable and aesthetically-pleasing UI. Classical approaches in HCI have relied upon providing designers with guidelines, heuristics, and best practices for realising good designs. In recent years, computational approaches have turned towards formalising and automating parts of the design process. In this provocation, I claim that the future expert will hand over the task of creating design solutions entirely to the machine, and instead take on the role of an interface curator who inspects a set of feasible designs and picks out the best possible solutions for a given problem. I discuss the current state of computational interface design, and suggest a path forward towards realising this vision.','Kashyap Todi. 2019. Reimagining the Role of the Expert: From Interface Design to Interface Curation. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 3 pages. [https://doi.org/10.1145/3363384.3363386](https://doi.org/10.1145/3363384.3363386 \"DOI for the article \'Reimagining the Role of the Expert: From Interface Design to Interface Curation\'\")','1 BACKGROUND AND INTRODUCTION\r\n\r\nThe scientific community has invested a lot of effort on the design of user interfaces and interactions. Researchers in fields of HCI and design have proposed tools, techniques, and methods to improve both the design process and the outcomes in terms of the resulting UIs or interactions. Initially, the focus was on better understanding how we could design interfaces to make them usable, or how graphical interfaces could use concepts familiar from the physical world. This led to design concepts such as affordances and natural mappings [19], design heuristics [18], and UX approaches such as skeumorphic design. Further, researchers and practitioners identified the need to involve users during early stages of design, thus leading to design processes such as user-centred [20] and participatory design [22]. Designers often adopted a “fail fast, fail often” ideology, and iterated over designs to improve them. The Design–Implement–Analyse (DIA) cycle is now a well-known approach towards iterative UI design [3].\r\n\r\nHowever, designing using these classical techniques come with their own pitfalls. Design principles are not generalisable, and often hard to keep track of. It seems infeasible to expect a designer to remember every design principle, guideline, or best practice, while they are designing interfaces. Even within user-centred design, it is challenging to include every category of user during the design process. This can lead to biases in the final outcomes, and could result in designs that do not meet the needs of marginalised user populations, or users with particular needs (e.g. accessibility). Further, iterative design is time-consuming, and the trial-and-error process does not lead to a better understanding of what encompasses “good interfaces”.\r\n\r\nAnother line of HCI research has investigated systematically modelling users, and applying these models towards improving interface design. Initially, the Human-Processor Model [4] explained different cognitive processes that take place when we interact, and provided us with a formal understanding of timing requirements. Fitts’ Law [9] has been one of the most well-investigated HCI models, and has been effectively applied towards evaluating and improving interface designs. Several predictive models of aspects relating to aesthetics, performance, and usability have been proposed and developed. These range from aspects such as visual search [14], which models eye movements, to colour harmony [5], which quantifies how different colour compositions can influence aesthetics of an interface. Recent works (e.g. [21, 26]) have used a combination of models of human perception and performance for generating design solutions. By mathematically formulating a good user interface, we can now overcome several drawbacks of completely manual interface design.\r\n\r\nIn this provocation, I look towards the future of user interface design, and propose that the future interface design expert will not be as much the interface designer, but rather an interface curator. Their fundamental task then will not be to turn a design brief single-handedly (and manually) into a fully-functional UI. Instead, they will now provide systems with concrete design tasks, which will automatically be converted to feasible design solutions by the machine. Much like a curator at an art gallery, they will use their expertise and insight to browse through a large set of feasible designs and select the most desirable solutions for a given problem. When talking about how we perceive machine agents, Suchman [24] discusses the distinction between the physical and social. Traditionally, the design tool has been seen as just an artefact that responds to a designer\'s actions by providing them with expected outcomes. In [17], Brad Myers hinted that ”tools might enforce or at least encourage user interfaces that were highly usable, rather than today\'s stance that tools should be neutral and leave the design mostly to the human designer”. With these as inspiration, I suggest that future tools will take this one step further, and act as social agents that take charge of fully generating design outcomes that are objectively good and usable. By doing so, the human expert and the artificial designer could find common ground to open up new lines of communication and collaboration.\r\n\r\n2 STATE-OF-THE-ART: WHERE ARE WE NOW?\r\n\r\nOver the previous years, several approaches have been proposed for machine-assisted interface design. There has been an extensive amount of research on methods, tools, and techniques towards computational design. While a full discussion of all works in this area is beyond the scope of this paper, I discuss some key aspects and evolution in the state-of-the-art.\r\n\r\nInitially, the focus of computational user interface design was on completely automating the generation of interfaces. Model-based methods typically accept a design-specification as input, and used this to construct full layouts (e.g. [2, 7, 10]). They could generate alternative layouts for different user needs [11], or for different screen resolutions [8], thus addressing issues such as accessibility and device compatibility. Automatic approaches could retarget the content of an interface to match an example design [16], or could adapt the interface based on a collection of previously seen interface designs [25]. However, these do not fit well with traditional design approaches. In retrospect, it seems like a majority of these techniques and tools were targeted towards engineers who lacked the skills or knowledge to create good user interfaces. This resulted in the necessity to over-specify the design problem, which seems to be incompatible with interface designers’ workflows.\r\n\r\nMixed-initiative computing [12] suggests that humans and machine work on a common task collaboratively, while distributing tasks that best suit them. In this spirit, recent interactive design tools (e.g. DesignScape [21], Sketchplore [26]) attempt to provide computational support without burdening the designer with task specification or problem engineering activities. They fit in with designer activities, and actively suggest design improvements and alternatives based on what the system can automatically infer about the design task. These tools apply different computational approaches that can, for example, generate entirely new designs using predictive models or design heuristics, or mimic existing designs through example-based retargeting [16]. Optimisation techniques have been proposed for keyboard layouts [13], menu designs [1], and for gestural interactions [23] too. These enable the system to find objectively good solutions from a large design space within a feasible time-span. Further, machine learning approaches such as multi-armed bandits can support exploration and exploitation of a large number of design alternatives.\r\n\r\n3 CREATING DESIGN TOOLS FOR INTERFACE CURATION\r\n\r\nTo support future interface curators, interactive design tools will have to organically integrate with the design curation process. There are some key components that would be required towards realising these goals;\r\n\r\nSpecifying the design task: The first step towards creating a design solution is to analyse the design brief, and concretise the problem at hand. Interactive tools will need to allow designers to flexibly provide concrete design requirements for the task at hand. This design task provides the starting point (input) for a system or algorithm that can find design solutions. Some possible techniques for specifying the input could be through sketching, textual descriptions, or conversational interfaces. The system should avoid requiring over-specification of the problem, which although beneficial for finding solutions, can be cumbersome or infeasible for the design expert.\r\nDeriving semantics of the target interface: Semantics provide meaning to an interface. They cover aspects such as relationship between elements and flow of user interactions. Current computational techniques that automatically generate design solutions often ignore the semantics of the interface. This can result in designs that might in theory perform well, but are not functional in practice. It will be beneficial for future tools to explore techniques that enable the designers to conveniently explicate the semantics of a desired interface, or to (semi-)automatically infer the intended semantics, for example, through data mining approaches [6, 15].\r\nFinding design solutions: The key responsibility of a system that supports interface curators is to find feasible design solutions for a given design task. In this step, the machine takes the design task and desired semantics as input, and detects suitable designs from a large design space. To do so, approaches such as generative design, retargeting, and design optimisation could be adopted and improved upon. An important consideration for an interactive tool would be to construct or find these solutions rapidly in real-time.\r\nPresenting the viable solutions: Another important aspect for a tool that enables curation is the actual presentation of found design solutions to the expert. Automated design approaches can often lead to the generation of several design solutions, which although theoretically unique, are practically quite similar in nature. The tool should not overwhelm the curator with a surmounting number of choices, especially several similar solutions. Instead, they should aid the curator in the process of discovering several diverse solutions that meet the design requirements. This could be achieved by systematically measuring the diversity between designs, applying approaches such as exploration-and-exploitation, and by using intelligent visualisation techniques.\r\nIterative improvement of solutions: As designers select desirable alternatives, they might detect the need to further refine the designs. Tools should thus support the iterative design approach, enabling quick improvements once an initial set of viable designs is found.\r\nProviding explanations and design rationale: To make the results interpretable to the curator, and to support the design choices made while finding solutions, tools should also strive towards providing explanations and rationale as to the selected designs are objectively good. By doing so, they can also highlight differences between several solutions. For instance, two designs might be quite different as they are intended towards two distinct user populations. It would be desirable to highlight such aspects to the curator, thus enabling them to make informed choices.\r\n3.1 Discussion\r\n\r\nIn this provocation, I have proposed a new role for the UI design expert within the interface design process: one of the interface curator. While interacting with future design tools, these experts will now, instead of spending valuable time constructing new designs from scratch, utilise their skills towards recognising the best design solutions from a set of feasible designs that are generated or selected by a machine. The dialogue between the curator and the proactive design tool will enable rapid generation of final designs that are justifiably and objectively usable. Further, they will enable the detection of multiple good solutions, each catering to different needs and requirements of user populations. By reconfiguring the roles of the human and the machine as proposed in the paper, the next generation of interface and interaction design can ensure better use of available resources and better outcomes for the end-user.\r\n\r\nREFERENCES\r\n\r\nGilles Bailly, Antti Oulasvirta, Timo Kötzing, and Sabrina Hoppe. MenuOptimizer: interactive optimization of menu systems. In Proceedings of the 26th annual ACM symposium on User interface software and technology - UIST ’13 (2013). ACM Press, 331–342. http://dx.doi.org/10.1145/2501988.2502024  \r\nC. M. Beshers and S. Feiner. Scope: Automated Generation of Graphical Interfaces. In Proceedings of the 2Nd Annual ACM SIGGRAPH Symposium on User Interface Software and Technology (1989) (UIST ’89). ACM, 76–85. http://dx.doi.org/10.1145/73660.73670event-place: Williamsburg, Virginia, USA.  \r\nWilliam Buxton and Richard Sniderman. 1980. Iteration in the Design of the Human-Computer Interface. (1980).  \r\nStuart K. Card, Thomas P. Moran, and Allen Newell. 1986. The model human processor: An engineering model of human performance. John Wiley & Sons.  \r\nDaniel Cohen-Or, Olga Sorkine, Ran Gal, Tommer Leyvand, and Ying-Qing Xu. Color Harmonization. In ACM SIGGRAPH 2006 Papers (2006) (SIGGRAPH ’06). ACM, 624–630. http://dx.doi.org/10.1145/1179352.1141933event-place: Boston, Massachusetts.  \r\nBiplab Deka, Zifeng Huang, Chad Franzen, Joshua Hibschman, Daniel Afergan, Yang Li, Jeffrey Nichols, and Ranjitha Kumar. Rico: A Mobile App Dataset for Building Data-Driven Design Applications. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology (2017) (UIST ’17). ACM, 845–854. http://dx.doi.org/10.1145/3126594.3126651event-place: Québec City, QC, Canada.  \r\nJacob Eisenstein, Jean Vanderdonckt, Jean Vanderdonckt, and Angel Puerta. Applying Model-based Techniques to the Development of UIs for Mobile Computers. In Proceedings of the 6th International Conference on Intelligent User Interfaces (2001) (IUI ’01). ACM, 69–76. http://dx.doi.org/10.1145/359784.360122event-place: Santa Fe, New Mexico, USA.  \r\nJ. Falb, R. Popp, T. Rock, H. Jelinek, E. Arnautovic, and H. Kaindl. Fully-automatic generation of user interfaces for multiple devices from a high-level model based on communicative acts. In 2007 40th Annual Hawaii International Conference on System Sciences (HICSS’07) (2007-01). 26–26. http://dx.doi.org/10.1109/HICSS.2007.236  \r\nPaul M. Fitts. 1954. The information capacity of the human motor system in controlling the amplitude of movement. 47, 6 (1954), 381–391. http://dx.doi.org/10.1037/h0055392  \r\nKrzysztof Gajos and Daniel S. Weld. SUPPLE: Automatically Generating User Interfaces. In Proceedings of the 9th International Conference on Intelligent User Interfaces (2004) (IUI ’04). ACM, 93–100. http://dx.doi.org/10.1145/964442.964461  \r\nKrzysztof Z. Gajos, Daniel S. Weld, and Jacob O. Wobbrock. 2010. Automatically generating personalized user interfaces with Supple. 174, 12 (2010), 910–950. http://dx.doi.org/10.1016/j.artint.2010.05.005 \r\nEric Horvitz. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conference on Human factors in computing systems the CHI is the limit - CHI ’99 (1999). ACM Press, 159–166. http://dx.doi.org/10.1145/302979.303030  \r\nAndreas Karrenbauer and Antti Oulasvirta. Improvements to keyboard optimization with integer programming. In Proceedings of the 27th annual ACM symposium on User interface software and technology - UIST ’14 (2014). ACM Press, 621–626. http://dx.doi.org/10.1145/2642918.2647382  \r\nDavid E. Kieras and Anthony J. Hornof. Towards Accurate and Practical Predictive Models of Active-vision-based Visual Search. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (2014) (CHI ’14). ACM, 3875–3884. http://dx.doi.org/10.1145/2556288.2557324event-place: Toronto, Ontario, Canada.  \r\nRanjitha Kumar, Arvind Satyanarayan, Cesar Torres, Maxine Lim, Salman Ahmad, Scott R. Klemmer, and Jerry O. Talton. Webzeitgeist: Design Mining the Web. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(2013) (CHI ’13). ACM, 3083–3092. http://dx.doi.org/10.1145/2470654.2466420  \r\nRanjitha Kumar, Jerry O. Talton, Salman Ahmad, and Scott R. Klemmer. Bricolage: Example-based Retargeting for Web Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (2011) (CHI ’11). ACM, 2197–2206. http://dx.doi.org/10.1145/1978942.1979262event-place: Vancouver, BC, Canada.  \r\nBrad Myers, Scott E. Hudson, Randy Pausch, and Randy Pausch. 2000. Past, Present, and Future of User Interface Software Tools. 7, 1 (2000), 3–28. http://dx.doi.org/10.1145/344949.344959  \r\nJakob Nielsen. 1994. 10 Heuristics for User Interface Design. (1994). https://www.nngroup.com/articles/ten-usability-heuristics/  \r\nDonald A. Norman. The Design of Everyday Things. Basic Books, Inc.  \r\nDonald A. Norman and Stephen W. Draper. User Centered System Design; New Perspectives on Human-Computer Interaction. L. Erlbaum Associates Inc.  \r\nPeter O\'Donovan, Aseem Agarwala, and Aaron Hertzmann. DesignScape: Design with Interactive Layout Suggestions. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI ’15 (2015). ACM Press, 1221–1224. http://dx.doi.org/10.1145/2702123.2702149  \r\nDouglas Schuler and Aki Namioka. 1993. Participatory Design: Principles and Practices. (1993).  \r\nSrinath Sridhar, Anna Maria Feit, Christian Theobalt, and Antti Oulasvirta. Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (2015) (CHI ’15). ACM, 3643–3652. http://dx.doi.org/10.1145/2702123.2702136event-place: Seoul, Republic of Korea.  \r\nLucy A. Suchman. 2006. Human-Machine Reconfigurations: Plans and Situated Actions. Cambridge University Press, New York, NY, USA.  \r\nKashyap Todi, Jussi Jokinen, Kris Luyten, and Antti Oulasvirta. Familiarisation: Restructuring Layouts with Visual Learning Models. In 23rd International Conference on Intelligent User Interfaces (2018) (IUI ’18). ACM, 547–558. http://dx.doi.org/10.1145/3172944.3172949  \r\nKashyap Todi, Daryl Weir, and Antti Oulasvirta. Sketchplore: Sketch and Explore with a Layout Optimiser. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems (2016) (DIS ’16). ACM, 543–555. http://dx.doi.org/10.1145/2901790.2901817 ',1,'Todi','Kashyap Todi','Kashyap Todi *(Department of Communication and Networking, Aalto University, Finland)*',NULL,0,'10.1145/3363384.3363386','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,15,5,NULL,NULL,0,2),(25,'housley-natural-action-processing-conversation-analysis-and-big-interactional-data','2019-09-02 15:24:57','2019-10-23 09:11:34','2019-09-02 15:24:57',NULL,1,'published','[]','Natural Action Processing: Conversation Analysis and Big Interactional Data','This position paper identifies a crucial opportunity for the reciprocal exchange of methods, data and phenomena between conversation analysis (CA), ethnomethodology (EM) and computer science (CS). Conventional CS classification of sentiment, tone of voice, or personality do not address what people do with language or the paired sequences that organize actions into social interaction. We argue that CA and EM can innovate and substantially enhance the scope of the dominant CS approaches to big interactional data if artificial intelligence-based natural language processing systems are trained using CA annotated data to do what we call natural action processing.','William Housley, Saul Albert, and Elizabeth Stokoe. 2019. Natural Action Processing: Conversation Analysis and Big Interactional Data. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363478](https://doi.org/10.1145/3363384.3363478 \"DOI for the article \'Natural Action Processing: Conversation Analysis and Big Interactional Data\'\")','1 Background\r\n\r\nDevelopments in computational methods have been applied to the data and phenomena of discourse analysis with promising results. Computer-assisted transcription systems [25,34], topic and category search functionality across data corpora [9], and the identification of turn-taking patterns across heterogeneous data sets [4] demonstrate the viability of this interdisciplinary engagement. However, despite a rich history of ethnomethodological (EM) studies of human-computer interaction and computer-supported collaborative work [8,43], there has been relatively little application of developments within conversation analysis (CA) and ethnomethodology to the core methods, data and phenomena of computer science [46]. This is particularly puzzling given that spoken and text-based interactions are becoming primary sites for networked human-computer interaction. They also form crucial modes of interaction that often serve as both the medium and milieu for real time ‘big’ and ‘broad’ social data extraction [18].\r\n\r\nThis separation is in part due to the continued conflation of computational rules and conversational norms [7]. This category mistake re-issues long-broken promises about the development of ‘general AI’ every few decades [12], although scholars are becoming less optimistic about when, if ever, this may occur [27]. While domain-specific speech recognition and synthesis systems are now used in basic service interactions, fundamental questions about users’ and designers’ conceptualization of these systems are still largely unresolved [30]. Despite vast increases in computing power, and EM\'s increasing impact in user experience design [26], nothing has so far achieved the kind of ‘speech understanding system’ that early collaborations between conversation analysts and computer scientists anticipated arriving by the early 90s [14]. This may, on the one hand, be attributable to irreconcilable differences in the way both sides understand social action and human behavior [11:12–13], leaving little common ground for mutual interdisciplinary engagement. On the other hand, and more optimistically, these early explorations of the space between conversation analysis and computer science (CS) may simply have come too early to configure their meeting as a methodologically coherent interdisciplinary engagement.\r\n\r\n2 Three potential collaborative framings\r\n\r\nIn the following sections of this article we consider three prospective avenues for collaboration between CS and CA. Our purpose is not to advocate one position over the other. Rather, our intention is to identify three epistemological and techno-methodological frames through which CA and CS might harness the deluge of big interactional data through a shared analytical focus on social action.\r\n\r\n2.1 Automatic annotation of big interactional data?\r\n\r\nIn order to make interactional data (i.e., video and audio recordings of talk, gesture, and embodied and material conduct) computationally analyzable, researchers must find principled ways to operationalize CA\'s inductive observations [35], which focus on social actions, rather than clusters of words or other granular linguistic ‘features’. Although CA has tended to defer quantification in favour of detailed procedural descriptions [37], recent developments of Sacks\'s [36] methods have included early-stage experiments using speech recognition for automated CA transcription [25], as well as interactionally grounded approaches to categorization [13,41] and coding [39], The methodological viability of these developments are still under debate within CA [5,38]. However, transcription tools and coding schema that are empirically configured for CA can capture routinely structured generic social practices in everyday talk such as question/answer sequences, specific forms of repair, or task-oriented activities produced within specific institutional contexts such as service call settings [1,42].\r\n\r\nCA transcription [16] is not only a means for communicating analyses in research publication, it is a highly developed and well-theorized form of interaction analysis in itself [5,28]. Machine-readable CA transcripts provide interactional detail at orders of magnitude greater than the corpora that are commonly used for machine learning, and will provide the basis for unanticipated discoveries for both fields. What is required is the development of new annotation tools for collaborative transcription enable ‘crowdsourcing’ of large scale CA data for open access corpora such as in the CABNC [3].\r\n\r\nSince CA coding schemes describe actions discovered in real-time interaction, the ecologically-grounded annotated data they produce should, we argue, underpin AI. A large, manually-coded data corpus could be used to train supervised learning classifiers to pick out interactional features in new data. Where algorithms misclassify cases or fail to identify them, collections of these ‘edge cases’ could inspire new detailed, qualitative analyses [38] and provide useful data for testing and refining new iterations of the system. For example, in a recent study of antagonistic language on social media, twitter threads and stand-alone examples were identified from a large corpus of tweets. These data sets were annotated via a form of inductive inspection that identified a series of interactional features based on CA findings, such as turn taking, recipient design and routine membership categorization practices [19,20]. These data can also be reused to discover more examples, new variations and deviant cases for further inductive inspection [38]. We argue that automatic annotation will create a virtuous research cycle where CA methods for identifying action and automated action classification systems can work together to identify patterns in interactive text and talk.\r\n\r\n2.2 Augmenting model and hypothesis construction?\r\n\r\nHypothesis construction and modelling are key aspects of computational social science. However, the ways in which interactional and text-based data are understood, classified and operationalized are a crucial, but often unreported, determining factor in the research process [6]. The same problems of reproducibility that have been plaguing social psychology [29] pose similar threats to machine learning research [24]. The recent experimental turn in CA [21], and calls for theoretical interfaces between CA\'s inductive methods and the deductive logic of falsifiability [35] offer some practical responses to this unfolding reproducibility crisis [2]. CA and its sister field of Discursive Psychology (DP) have been critical of the widespread tendency to rely on models of interaction that are “largely stipulative or intuitive rather than based on detailed empirical work” [32:18], or that perform only cursory pre-hypothetical qualitative phases of research [31]. Despite long-held skepticism within CA and DP about the viability of hypothetico-deductive reasoning in interaction research, interaction analysts are finding practical solutions to long-standing problems with ecological validity in experimental design [22] where CA and video analysis provide the methodological basis for naturalistic experiments [15] and a ‘natural laboratory’ [40] for a principled approach to interaction research.\r\n\r\nThis approach also lends itself to studies of big interactional data on social media, gaming and ‘born-digital’ text-based mediated interaction. For example, current work on social media analytics has enabled an examination of clustering, homophily and differentiation at the interactional level in relation to Twitter-based activism and online campaigns [45]. This allows us to associate dimensions of a twitter thread with the likelihood of differentiation and ‘off topic’ conversation and a move towards more explicit forms of ‘identity’ work and claims management. Such observational findings may be transposed into hypotheses that relate to thread length and counter speech, for example, in modelling the spread of hateful content via social media networks. It remains to be seen whether related concerns can shed light onto the relatively recent emergence and proliferation of voice based big interactional data. This new ‘data deluge’ is being driven by ‘digital assistants’ in the home, the workplace and ‘artificially intelligent’ conversational technologies associated with contemporary marketing strategies. We argue that any movement towards a conversation analytic approach to voice-based big interactional data requires a radical reconsideration of the way we conceptualize features associated with ‘voice data’ and the framework in and through which such data is understood and classified.\r\n\r\n2.3 Natural action processing: Automating CA?\r\n\r\nThe state of the art in consumer voice interfaces still only allows systems like Amazon\'s Alexa to respond to variations on a single request-formatted phrase [30]. Far more sophisticated ‘natural language processing’ (NLP) systems are needed than the kind of ‘sentiment analysis’ often used to process social media [33] or transcribed dialogues, which usually associate simple word and phrase frequencies with meanings via limited statistical models of lexical semantics [10]. For example, in Extract 1 Salesperson (S) has called a prospective Customer (C). One common measure of customer satisfaction may be coded by a customer\'s ‘thank you’.\r\n\r\nExtract 1:\r\nExtract 1: Part of a call during which a salesperson (S) ‘cold calls’ a customer (C).\r\nThe salesperson re-issues the question of when the customer\'s contract is due on three occasions at lines 1, 7 and 12. Each time, the customer\'s response demonstrates that they are not treating what the salesperson says as a question to answer, but as an offer to refuse. Furthermore, the customer designs their refusals as assessments of their existing service, rather than make explicit refusals.\r\n\r\nThese mismatched turn-and-action formats highlight the arbitrariness of mapping between lexical semantics and social action in conversation. The customer\'s “Thank you” in the midst of the salesperson\'s last turn in line 13 highlights the dangers of operationalizing fixed words or phrases as communicative measures. How often the words “thank you” appear in a dialogue is as absurd a measure of gratitude as laughs-per-minute are a measure of amusement [37]. Out of place, these utterances can be rude since their meaning depends on precisely where and how they are used within a sequence of action. If CA and computer science researchers work together, they could explore new approaches to natural action processing (NAP) that take the centrality of social action into account.\r\n\r\nIn order to have an impact in machine learning and related approaches in CS, CA needs to work at a larger scale, with new software tools and protocols for data collection, transcription, and for sharing annotations for interactional features. CA has developed a bottom-up inductive research cycle [17] for refining analysis and identifying future cases by studying collections of individual cases in detail. However, if CA were equipped with computer-readable annotations, enabling work on large scale corpora, this ongoing research activity would allow CS access to detailed data for training machine learning systems and algorithm development.\r\n\r\nWe propose NAP as a critical and practical approach to automation using conversation analysis and related methods for interaction-based feature identification. Replacing the ‘L’ of NLP with ‘A’ underlines the importance of starting with action, not language (and interaction, not dialogue). This will involve building systems for scoping and annotating networked communications, as social media moves from an emphasis on text to incorporate speech and embodiment with the arrival of conversational and interactionally enhanced machines.\r\n\r\n3 Conclusion\r\n\r\nGreater interdisciplinary engagement between conversation analysis (CA) and computer science (CS) would enable CS to use CA data to build more sensitive systems for classifying patterns of behavior in real-time communications, the results of which could further inform understanding of key features and effects of large-scale social organization. The identification of common interactional features could then be re-deployed on data from spoken, multimodal and text-based interaction across a wide variety of social and institutional settings, online platforms and media environments. Successful uses of deep learning to deal with clearly defined problems such as automated translation [44] tend to arise from using new or better data. Using CA-based annotation and coding systems would not only provide new, more detailed data. CA\'s core focus on social action may help to define new research questions. Using CA at key points in the development of algorithms used for the automated scoping of big social data in real time would engender a move from a design ontology configured by hyper-individualized data points [23] to one that is nuanced and commensurate with social media as an interactional and relational environment.\r\n\r\nA final consideration is the extent to which the three approaches outlined above can act as a means of assisting the manual inspection of data streams, augmenting model building and ‘normal science’ or end up merely supporting the ‘dash for automation’. We suggest that all these workflows might be accommodated in a mutually reinforcing manner; albeit within the context of interdisciplinary, reflexive and collaborative work supported by new infrastructural requirements. However, it also represents engagement with ‘boundary objects’: processes and phenomena that are understood quite differently within computer science, conversation analysis and their cognate disciplines. This form of interdisciplinary engagement is fraught with difficulties and tensions; but it remains a creative and potentially rewarding process. To this extent the practice and process of interdisciplinarity remains key to exploring these avenues robustly, reflexively and with due care and attention.\r\n\r\nREFERENCES\r\n\r\nSaul Albert, William Housley, Rein Ove Sikveland, and Elizabeth Stokoe. frth. The Conversation Analytic Turing Test: Using Conversation Analysis to Evaluate Google Duplex. (frth.).  \r\nSaul Albert and J. P. De Ruiter. 2018. Improving Human Interaction Research through Ecological Grounding. Collabra: Psychology 4, 1 (July 2018), 24. DOI:https://doi.org/10.1525/collabra.132  \r\nSaul Albert, J. P. De Ruiter, and Laura De Ruiter. 2015. The CABNC. Retrieved from https://saulalbert.github.io/CABNC/  \r\nDaniel Angus, Sean Rintel, and Janet Wiles. 2013. Making sense of big text: a visual-first approach for analysing text data using Leximancer and Discursis. DOI:https://doi.org/10.1080/13645579.2013.774186  \r\nGalina B. Bolden. 2015. Transcribing as Research: “Manual” Transcription and Conversation Analysis. Research on Language and Social Interaction 48, 3 (July 2015), 276–280. DOI:https://doi.org/10.1080/08351813.2015.1058603  \r\nPhillip Brooker, William Dutton, and Christian Greiffenhagen. 2017. What would Wittgenstein say about social media? Qualitative Research (June 2017). DOI:https://doi.org/10.1177/1468794117713058  \r\nGraham Button. 1990. Going Up a Blind Alley: Conflating Conversation Analysis and Computational Modelling. In Computers and Conversation, Paul Luff, Nigel Gilbert and David Frolich (eds.). Academic Press, London, 67–90. DOI:https://doi.org/10.1016/B978-0-08-050264-9.50009-9  \r\nGraham Button and Paul Dourish. 1996. Technomethodology: paradoxes and possibilities. In Proceedings of the SIGCHI conference on Human factors in computing systems. Retrieved from http://dl.acm.org/citation.cfm?id=238394  \r\nSusan Conrad. 2002. Corpus Linguistic Approaches for Discourse Analysis. Annual Review of Applied Linguistics 22, (March 2002), 75–95. DOI:https://doi.org/10.1017/S0267190502000041  \r\nRobin Cooper. 2012. Type theory and semantics in flux. Handbook of the Philosophy of Science 14, (2012), 271–323.  \r\nJeff Coulter. 1989. Mind in action. Polity Press, Cambridge.  \r\nHubert L Dreyfus. 2012. A history of first step fallacies. Minds and Machines 22, 2 (2012), 87–99.  \r\nRichard Fitzgerald and William Housley. 2015. Advances in Membership Categorisation Analysis. Sage, London.  \r\nNigel Gilbert, Robin Wooffitt, and Norman Fraser. 1990. Chapter 11 - Organising Computer Talk. In Computers and Conversation, Paul Luff, Nigel Gilbert and David Frolich (eds.). Academic Press, London, 235–257. DOI:https://doi.org/10.1016/B978-0-08-050264-9.50016-6  \r\nChristian Heath and Paul Luff. 2017. The Naturalistic Experiment. Organizational Research Methods (December 2017), 1–23. DOI:https://doi.org/10.1177/1094428117747688  \r\nAlexa Hepburn and Galina B Bolden. 2017. Transcribing for social research. Sage, London.  \r\nE. M. Hoey and K. H. Kendrick. 2017. Conversation Analysis. In Research Methods in Psycholinguistics: A Practical Guide, A. M. B. de Groot and P.Hagoort (eds.). WileyBlackwell, Hoboken, NJ, 151–173.  \r\nW. Housley, R. Procter, A. Edwards, P. Burnap, M. Williams, L. Sloan, O. Rana, J. Morgan, A. Voss, and A. Greenhill. 2014. Big and broad social data and the sociological imagination: A collaborative response. Big Data & Society 1, 2 (July 2014). DOI:https://doi.org/10.1177/2053951714545135  \r\nWilliam Housley, Helena Webb, Adam Edwards, Rob Procter, and Marina Jirotka. 2017. Digitizing Sacks? Approaching social media as data. Qualitative Research (2017), 1468794117715063.  \r\nWilliam Housley, Helena Webb, Adam Edwards, Rob Procter, and Marina Jirotka. 2017. Membership categorisation and antagonistic Twitter formulations. Discourse & Communication 11, 6 (September 2017), 567–590. DOI:https://doi.org/10.1177/1750481317726932  \r\nKobin H. Kendrick. 2017. Using Conversation Analysis in the Lab. Research on Language and Social Interaction (January 2017), 1–11. DOI:https://doi.org/10.1080/08351813.2017.1267911  \r\nAlan Kingstone, Daniel Smilek, and John D. Eastwood. 2008. Cognitive Ethology: A new approach for studying human cognition. British Journal of Psychology 99, 3 (August 2008), 317–340. DOI:https://doi.org/10.1348/000712607x251243  \r\nRobert W Lake. 2017. Big Data, urban governance, and the ontological politics of hyperindividualism. Big Data & Society 4, 1 (June 2017). DOI:https://doi.org/10.1177/2053951716682537  \r\nZachary C. Lipton and Jacob Steinhardt. 2019. Troubling Trends in Machine Learning Scholarship. Queue 17, 1 (February 2019), 80:45–80:77. DOI:https://doi.org/10.1145/3317287.3328534  \r\nRobert J. Moore. 2015. Automated Transcription and Conversation Analysis. Research on Language and Social Interaction 48, 3 (July 2015), 253–270. DOI:https://doi.org/10.1080/08351813.2015.1058600  \r\nRobert J. Moore. 2018. A Natural Conversation Framework for Conversational UX Design. In Human–Computer Interaction Series. Springer International Publishing, 181–204. DOI:https://doi.org/10.1007/978-3-319-95579-7_9  \r\nVincent C. Müller and Nick Bostrom. 2016. Future Progress in Artificial Intelligence: A Survey of Expert Opinion. In Fundamental Issues of Artificial Intelligence. Springer International Publishing, 555–572. DOI:https://doi.org/10.1007/978-3-319-26485-1_33  \r\nE Ochs. 1979. Transcription as theory. In Developmental pragmatics, Elinor Ochs and B. B. Schieffelin (eds.). Academic Press, New York, 43–72.  \r\nOpen Science Collaboration. 2015. Estimating the reproducibility of psychological science. Science 349, 6251 (August 2015), aac4716–aac4716. DOI:https://doi.org/10.1126/science.aac4716  \r\nMartin Porcheron, Joel E Fischer, Stuart Reeves, and Sarah Sharples. 2018. Voice Interfaces in Everyday Life. In Proceedings of the 2018 ACM Conference on Human Factors in Computing Systems (CHI’18).  \r\nJonathan Potter. 2012. Re-reading Discourse and Social Psychology: Transforming social psychology. British Journal of Social Psychology 51, 3 (December 2012), 436–455. DOI:https://doi.org/10.1111/j.2044-8309.2011.02085.x  \r\nJonathan Potter and H te Molder. 2005. Talking cognition: Mapping and making the terrain. In Conversation and cognition, Jonathan Potter and Derek Edwards (eds.). 1–54.  \r\nMatthew Purver and Stuart Battersby. 2012. Experimenting with Distant Supervision for Emotion Classification. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL ’12), 482–491. Retrieved from http://dl.acm.org/citation.cfm?id=2380816.2380875  \r\nLuis Rodríguez, Francisco Casacuberta, and Enrique Vidal. 2007. Computer Assisted Transcription of Speech. In Pattern Recognition and Image Analysis (Lecture Notes in Computer Science), 241–248.  \r\nJ. P. de Ruiter and Saul Albert. 2017. An Appeal for a Methodological Fusion of Conversation Analysis and Experimental Psychology. Research on Language and Social Interaction 50, 1 (January 2017), 90–107. DOI:https://doi.org/10.1080/08351813.2017.1262050  \r\nHarvey Sacks. 1995. Lectures on conversation. Basil Blackwell, Oxford.  \r\nEmanuel A Schegloff. 1993. Reflections on Quantification in the Study of Conversation. Research on Language & Social Interaction 26, 1 (1993), 99–128. DOI:https://doi.org/10.1207/s15327973rlsi2601_5  \r\nJakob Steensig and Trine Heinemann. 2015. Opening Up Codings? Research on Language and Social Interaction 48, 1 (January 2015), 20–25. DOI:https://doi.org/10.1080/08351813.2015.993838  \r\nTanya Stivers. 2015. Coding Social Interaction: A Heretical Approach in Conversation Analysis? Research on Language and Social Interaction 48, 1 (January 2015), 1–19. DOI:https://doi.org/10.1080/08351813.2015.993837  \r\nE. Stokoe, R. O. Sikveland, and J. Symonds. 2016. Calling the GP surgery: patient burden, patient satisfaction, and implications for training. British Journal of General Practice (August 2016). DOI:https://doi.org/10.3399/bjgp16x686653  \r\nElizabeth Stokoe. 2012. Moving forward with membership categorization analysis: Methods for systematic analysis. Discourse Studies 14, 3 (June 2012), 277–303. DOI:https://doi.org/10.1177/1461445612441534  \r\nElizabeth Stokoe, Rein Ove Sikveland, Magnus Hamann, Saul Albert, and William Housley. frth. Can humans simulate talking like other humans? Comparing simulated clients to real customers in service inquiriesh. Discourse Studies (frth.).  \r\nLucy A Suchman. 1987. Plans and situated actions: the problem of human-machine communication. Cambridge University Press, Cambridge.  \r\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to Sequence Learning with Neural Networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2 (NIPS’14), 3104–3112. Retrieved from http://dl.acm.org/citation.cfm?id=2969033.2969173  \r\nHelena Webb, Pete Burnap, Rob Procter, Omer Rana, Bernd Carsten Stahl, Matthew Williams, William Housley, Adam Edwards, and Marina Jirotka. 2016. Digital Wildfires: Propagation, Verification, Regulation, and Responsible Innovation. ACM Trans. Inf. Syst.34, 3 (April 2016), 15:1–15:23. DOI:https://doi.org/10.1145/2893478  \r\nMalte Ziewitz. 2017. A not quite random walk: Experimenting with the ethnomethods of the algorithm. Big Data & Society 4, 2 (2017). DOI:https://doi.org/10.1177/2053951716682537  ',1,'Housley','William Housley, Saul Albert, and Elizabeth Stokoe','William Housley *(School of Social Sciences, Cardiff University, UK)*<br>\r\nSaul Albert *(School of Social Sciences, Loughborough University, UK)*<br>\r\nElizabeth Stokoe *(School of Social Sciences, Loughborough University, UK)*',NULL,0,'10.1145/3363384.3363478','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,20,5,NULL,NULL,0,34),(26,'mcmillan-against-ethical-ai-guidelines-and-self-interest','2019-09-02 15:24:57','2019-10-23 09:11:39','2019-09-02 15:24:57',NULL,1,'published','[]','Against Ethical AI: Guidelines and Self Interest','In this paper we use the EU guidelines on ethical AI, and the responses to it, as a starting point to discuss the problems with our community\'s focus on such manifestos, principles, and sets of guidelines. We cover how industry and academia are at times complicit in ‘Ethics Washing’, how developing guidelines carries the risk of diluting our rights in practice, and downplaying the role of our own self interest. We conclude by discussing briefly the role of technical practice in ethics.','Donald McMillan and Barry Brown. 2019. Against Ethical AI: Guidelines and Self Interest. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 3 pages. [https://doi.org/10.1145/3363384.3363393](https://doi.org/10.1145/3363384.3363393 \"DOI for the article \'Against Ethical AI: Guidelines and Self Interest\'\")','1 INTRODUCTION\r\n\r\nAs interest in the applications of artificial intelligence has grown, so have ethical guidelines for AI, and research around the ethics of computing systems. The list of guidelines curated by AlgorithmWatch is currently at 83 and growing[2]. These efforts are addressing a real problem: clearly, machine learning systems are being deployed in a host of settings where there is concern for the potential harm that such systems can cause. Moreover, the potential of such systems for even greater harm is prescient. Basic technologies such as facial recognition have such a broad range of applications, many of which are close to being inherently harmful — such as differentiating membership of an ethnic group [12].\r\n\r\nYet, as we argue in this short paper, there are aspects of ethical guidelines that are not about benefiting any actual user (or subject) of AI systems. Ethical guidelines can work as a mechanism to minimise institutional blame. As with research ethics, it is not clear that increased guidelines result in more ethical researcher behaviour. Indeed, McNamara et al. [10] showed that the ACM\'s ethical guidelines had little to no effect on the choices made by developers. In nearly all cases, guidelines stay at the level of pronouncements, statements of value that would take large (and undefined) effort to interpret in any actual situation. Moreover, these ethical guidelines often have contradictions or could have damaging unintended consequences.\r\n\r\nPart of the problem that we identify here is that there is little consideration of self-interest in the discussions and descriptions of ethics as proposed. Self-interest encompasses motivations, which cause direct benefits to oneself or one\'s immediate kin, family or companions. Organisations, companies and groups can act self-interested, and while we would not claim that this is the dominant motivation behind human action and activity, clearly it should not be ignored. We discuss here how self-interest manifests in the generation of ‘ethics work’ as a form of protectionism, how these resulting manifestos and guidelines by there unenforceable nature can foreshadow the dilution of human rights overall, and encourage the move beyond value statements to influencing and enforcing policy and law.\r\n\r\n2 ETHICS WASHING\r\n\r\nThe proposed Ethics guidelines for trustworthy AI from the EU was drawn up by a panel of 52 experts drawn from industry and academia, with a public consultation period which garnered input from over 500 other interested parties from the EU and beyond. The makeup of this panel of experts has been one initial source of criticism. Thomas Metzinger [11], an academic member of the panel himself, questioned the overwhelming number of industry-based or industry-funded members included. Metzinger reports how the pressure from industrial members removed text he championed, which included ‘red lines’ and ‘non-negotiable’ limits to AI and its impacts on subjects. This was done supposedly in favour of a ‘positive vision’ yet Metzinger himself points to this as one reason he now sees the whole exercise as one of ‘ethics washing’. As described by Wagner [16], ethics washing is the use of working groups, guidelines, and manifestos as a counterbalance to calls for legal and regulatory frameworks which would ensure the safety of the public.\r\n\r\nIn HCI some have suggested that there be some sort of removal of accreditation for those who break such guiding principles [3, 9], others have even called for AI practitioners taking something akin to the Hippocratic oath medical professionals are expected to swear [5, 15]. Yet swearing an oath as a programmer, data scientist, or AI operator does not bring the level of protection of those at the receiving end of the ‘digital treatment’. Indeed, the oath itself has been shown to be subservient, while complimentary, to the laws of the state [8] in ensuring the protection of rights. As pointed out by Sloan [13], discussions of ethics and technology have a tendency to position the harms as social while the solutions are technological. “That the social problem is deeply entangled with the existing fault lines of social stratification falls somewhat outsize the ontology of ‘ethical algorithms”’[13]. This narrowing of scope of ethical conversation can lead to something that has the potential to be a ‘dilution of rights’. The danger that in overlaying such unenforceable ‘digital’ rights on basic ‘human’ rights, the corresponding human rights will also become devalued or unenforced. Returning to the EU guidelines, it is notable that while they state that they are founded upon the EU declaration of Fundamental Human Rights, they only address a subset of those rights in the context of algorithmic harm. Wagner [16] notes that these regulations cover the rights to human dignity while ignoring rights such as the freedom of assembly or cultural rights.\r\n\r\nHow to manifest ethical guidelines in the work of actual design is usually left unspecified. Design requires trade offs and, in practice, it can be difficult to see how to balance conflicting ethical principles, or even how to respect these principles without producing designs that are poorer in some critical aspects. It is not clear that mandating websites to ask before setting a tracking cookie on a users machine has resulted in better outcomes for users, even if it fits better with the ethical principle of consent.\r\n\r\n3 SELF-INTEREST\r\n\r\nThis brings us to the concept of motivation and self-interest in the generation and application of ethical guidelines, manifestos, principles, and oaths. It is easy to be pessimistic and see all such action in the light of ‘ethics washing’, avoidance of regulation, and manipulation of public opinion. It can also be seen, on the other hand, as evidence that a large number of people in and around technology are interested, motivated, and hopeful that the future technology we build and deploy can be shaped to embody the best of our goals and principles.\r\n\r\nStarting on the side of pessimism, it is important to acknowledge and work with the self-interest that drives so much of human action. The corporations bankrolling the countless hours spent on generating and discussing these ethical guidelines are themselves not driven only by concerns of what is the most ethical action to take. There are any number of theories and models that point to understandings of how such corporate actors, and the individuals of which they comprise, align social good and business success. Freeman et al. ’s Stakeholder model [6] talks of decisions being made by weighing the good of those within and without the business, which is often criticised [4] for naive optimism on leaving the weighing and inclusion of such stakeholders to the individual. Friedman, on the other hand, puts decision making firmly for the benefit of shareholders [7] bound only by the necessity to stay within the law (although he later added that “basic rules of society...and ethical custom” should also be respected). For Friedman, a manager deciding to spend company resources on developing a set of ethical guidelines should see this as a direct benefit to the profits and, therefore, shareholders of the company. In the more optimistic Stakeholder model, the decision to spend employee time on creating ethical guidelines should balance the benefit of society with the benefit of the employees, shareholders, and customers. In either case, the self-interest of the companies involved is central. This does not have to manifest only in the avoidance of regulations [16], but could be seen as a form of lobbying to ensure even incrementally more favourable regulations towards their product, service, or sector at the expense of competitors [7]. Yet, as seen in the makeup of the EU\'s panel for ethical AI, even in a governmental setting, such confounding motivations are largely ignored.\r\n\r\nOn the positive side, this corporate self-interest provides a large number of highly skilled and experienced practitioners time and energy to devote to the discussion of these issues. Going further, it can be expected that for those who end up being involved at least one of the many motivations (from prestige, to corporate visibility, to ensuring the continued good fortunes of their employer) would be that they want, and in fact in many cases have pushed through internal structures and strictures, to be involved. Currently, the balance of these motivations has been left mostly to the moral and ethical fibre of the individual (harking back to the naivety of expectation in the Stakeholder model of governance), yet by through careful frameworks and regulation such expertise can be brought to bear. This is by no means an easy task, one dimension of political lobbying as the practice of providing ‘friendly’ experts to inform on policy is fraught with problems [14] — yet these are acknowledged and those accepting the opinions do so with some understanding of the competing motivations of those they are talking to. In future ethical consultations involving industry such actors should be seen in the same light, embracing that their self-interest may not align with the goals of society as a whole yet involving them (as members of that society) in the process.\r\n\r\n4 CONCLUSION\r\n\r\nMoving forward, we plan to explore in more depth the multiple relationships between guidelines and actual cases of technical practice. As Phil Agre wrote [1] – the relationship between technical practice, and attempts to guide that technical practice are complex. Agre wrote of the need for a “a split identity – one foot planted in the craftwork of design and the other foot planted in the reflexive work of critique”. We take this to mean that assessing ethical guidelines will require both close attention to practice and critique, at the intersection of academia, industry, and governance. In this short paper we have started to critically discuss and assess the role of ethical guidelines in AI. We point to the role of self interest in generating these discussions as a way of questioning why particular entities might produce guidelines, and to what likely use they might or might not be put.\r\n\r\nREFERENCES\r\n\r\nPhilip E. Agre. 1997. Lessons Learned in Trying to Reform AI. In Social Science, Technical Systems, and Cooperative Work, Geoffrey Bowker, Susan Leigh Star, and Les Gasser(Eds.). Routledge, Mahwah, N.J.  \r\nAlgorithmWatch. 2019. AI Ethics Guidelines Global Inventory.  \r\nBarry Brown, Alexandra Weilenmann, Donald McMillan, and Airi Lampinen. 2016. Five Provocations for Ethical HCI Research. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). ACM, New York, NY, USA, 852–863. https://doi.org/10.1145/2858036.2858313  \r\nThomas L. Carson. 2003. Self–Interest and Business Ethics: Some Lessons of the Recent Corporate Scandals. Journal of Business Ethics 43, 4 (April 2003), 389–394. https://doi.org/10.1023/A:1023013128621  \r\nOren Etzioni. 2018. A Hippocratic Oath for Artificial Intelligence Practitioners.  \r\nWilliam M. Evan and R. Edward Freeman. 1988. A Stakeholder Theory of the Modern Corporation: Kantian Capitalism.  \r\nMilton Friedman. 2009. Capitalism and Freedom. University of Chicago press.  \r\nLisa Hasday. 2013. The Hippocratic Oath as Literary Text: A Dialogue Between Law and Medicine. Yale Journal of Health Policy, Law, and Ethics 2, 2 (Feb. 2013).  \r\nDonald McMillan, Alistair Morrison, and Matthew Chalmers. 2013. Categorised Ethical Guidelines for Large Scale Mobile HCI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1853–1862. https://doi.org/10.1145/2470654.2466245  \r\nAndrew McNamara, Justin Smith, and Emerson Murphy-Hill. 2018. Does ACM\'s Code of Ethics Change Ethical Decision Making in Software Development?. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering(ESEC/FSE 2018). ACM, New York, NY, USA, 729–733. https://doi.org/10.1145/3236024.3264833  \r\nThomas Metzinger. 2019. Ethics washing made in Europe. https://www.tagesspiegel.de/politik/eu-guidelines-ethics-washing-made-in-europe/24195496.html.  \r\nS. Md. Mansoor Roomi, S. L. Virasundarii, S. Selvamegala, S. Jeevanandham, and D. Hariharasudhan. 2011. Race Classification Based on Facial Features. In 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics. 54–57. https://doi.org/10.1109/NCVPRIPG.2011.19  \r\nMona Sloane. 2019. Inequality Is the Name of the Game: Thoughts on the Emerging Field of Technology, Ethics and Social Justice. In Proceedings of the Weizenbaum Conference 2019 ”Challenges of Digital Inequality - Digital Education, Digital Work, Digital Life”. 9. https://doi.org/10.34669/wi.cp/2.9  \r\nBart Slob and Francis Weyzig. 2010. Corporate Lobbying and Corporate Social Responsibility: Aligning Contradictory Agendas. In Business, Politics and Public Policy: Implications for Inclusive Development, José Carlos Marques and Peter Utting (Eds.). Palgrave Macmillan UK, London, 160–183. https://doi.org/10.1057/9780230277243_7  \r\nBrad Smith and Harry Shum. 2018. Artificial Intelligence and Its Role in Society. In The Future Computed. Microsoft Corporation.  \r\nBen Wagner. 2018. Ethics as an Escape from Regulation: From Ethics-Washing to Ethics-Shopping?In Being Profiled, Emre Bayamlioğlu, Irina Baraliuc, Liisa Janssens, and Mireille Hildebrandt (Eds.). Amsterdam University Press, 84–89. https://doi.org/10.2307/j.ctvhrd092.18  \r\n',1,'McMillan','Donald McMillan and Barry Brown','Donald McMillan *(Department of Computer and System Sciences, Stockholm University, Sweden)*<br>\r\nBarry Brown *(Department of Computer and System Sciences, Stockholm University, Sweden)*',NULL,0,'10.1145/3363384.3363393','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,25,5,NULL,NULL,0,9),(27,'kraemer-exploring-communal-technology-use-in-the-home-uncovering-household-group-efficacy','2019-09-02 15:24:57','2019-11-14 14:12:24','2019-09-02 15:24:57',NULL,1,'published','[]','Exploring Communal Technology Use in the Home: Uncovering Household Group-Efficacy','Vacuum cleaners, dish washers, and computers have had a lasting impact on ordinary life, and the last wave of ubiquitous technology, smart home technology, once again alters social order and practices in the home. Increasingly pervasive and internet-connected, domestic technology has become a community concern. Communal use of technology poses complex challenges for research and practice, requiring new approaches. Our investigation (36 interviews) of perceptions and considerations of communal device use illustrates how ordinary life evolves facing known and newly evolving challenges. We report four main themes around living with and sharing technology by relating aspects of technology considerations to different social groups. Using these insights, we illustrate participant considerations of personal characteristics, and discuss self-efficacy as a way to look at technology considerations, social groups, and personal characteristics. We outline in three ways how the concept of group-efficacy can help shape further investigation.','Martin J Kraemer, Ivan Flechais, and Helena Webb. 2019. Exploring Communal Technology Use in the Home: Uncovering Household Group-Efficacy. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 8 pages. [https://doi.org/10.1145/3363384.3363389](https://doi.org/10.1145/3363384.3363389 \"DOI for the article \'Exploring Communal Technology Use in the Home: Uncovering Household Group-Efficacy\'\")','1 INTRODUCTION\r\n\r\nAs the current wave of technology for the homes evolves from “gadgets for enthusiasts” to dependable off-the-shelf solutions, technology once again disrupts ordinary, domestic life. Past generations of computing technology have had a lasting impact on household life and communal use, despite being intended to meet the needs of individuals [8]. The current wave of ubiquitous devices is increasingly pervasive and shared. While these devices proliferate in domestic environments, they are largely unfamiliar to their inhabitants. Families, flat shares, short and long term lets are all challenged with the intricacies of introducing, managing, and using internet-connected technology.\r\n\r\nA multitude of domestic roles and responsibilities exist in our homes, and devices will only ever align with some of them. Some devices, like thermostats or home security systems, are designed for administration by an individual while they provide functionality to all householders. Other devices were designed with a single user in mind but are indeed used by many [9]. Members of communal settings establish their own ways to share resources and responsibilities; ‘taking care of internet-connected devices’ is consequently not a responsibility assumed by each user equally [5, 9, 11, 16, 23]. Different household members do not share the same attitude, knowledge, and preferences, but they use and manage technology in their own ways. These differences influence the use (or non-use) of technology and can lead to tensions between householders  [9, 11, 14].\r\n\r\nThe use of ubiquitous technology in homes is inevitably communal, requiring an understanding of individual and communal practices to design adequately [2, 3, 4, 5, 6, 23]. Future smart homes should empower inhabitants communally “to take an active part in controlling their set up, evolution and destruction” [17]. We need to understand the intricate ways in which smart home technology can fit with communal everyday work practices [17, 22].\r\n\r\nThis paper presents an investigation of communal use of technology in the home. We interviewed   householders on their use of technology in ordinary life, their preferences and attitudes, and explored how their households shared and used devices. Four major themes evolved from our analysis: dealing with technology—old and new, sharing personal devices, using shared devices, and dealing with guests and visitors. We investigate these themes following considerations of technology (ownership, responsibility, interaction, benefits, disadvantages) and their effect on social groups (personal, communal, external) and find that participants considered attitudes, aptitudes, preferences, skills, and competencies of others when arranging for communal use. These findings resembled notions of self-efficacy, a concept that has been used successfully to unpack personal technology use. Inspired by this, we propose group-efficacy as a lens to understand communal use, and we illustrate its usefulness in three different ways.\r\n\r\nIn Section 2, we briefly review related work, and we introduce our research methodology in Section 3. We present our findings in Section 4 which we continue to discuss in Section 5. We conclude this paper with suggestions for future work in Section 6.\r\n\r\n2 RELATED WORK\r\n\r\nCommunal use of technology in our homes has been researched extensively. More than two decades of research on personal computers illustrate the influence of technology adoption on social structure and power relationships in the home [5, 8, 16, 21], and similar influences are reported in more recent research on ubiquitous and internet-connected technology in our homes, turning our homes into ‘smart homes’ [11, 12, 15, 22].\r\n\r\nResearchers allude to distributions of roles and responsibilities with regards to setup, use, and maintenance of smart home devices leading to tensions between household members [9, 14, 20]. Mennicken and Huang [14] find unfamiliarity among users caused a feeling of powerlessness and difficulties in getting high quality advice. They suggest future research into strategies of technically able household members that help shape the experience of their cohabitants. Tabassum et al. [20] also report on concerns expressed by those not setting up devices in the home which lead to abandoning a particular device. Geeng and Roesner [9] explored these tensions from a smart home administrator\'s perspective. They revealed tensions arising between different users and a ‘concentration of expertise, access and control’ with those setting up and maintaining devices.\r\n\r\nPrior work focuses on individual experiences, perceptions, and attitudes in relation to smart home technology use. Singh et al. [19] research individuals’ perceptions and attitudes toward smart home technology. Their participants perceive benefits of comfort, safety, and improvement of life but also raise concerns of autonomy and privacy. Forlizzi and DiSalvo [7] find some behavioural changes are intended or anticipated by participants, whereas other changes appear unintentional and incidental. The introduction of new technology challenges and changes traditional gender roles [10]. Hargreaves et al. [11] show how inhabitants negotiate the use of devices and navigate conflicts, while routines keep changing and evolving.\r\n\r\nWe approach the smart home considering householders’ experiences with technology in general, inclusive of those who already own smart home devices and those who do not. An analytic structure emerges from our thematic analysis which allows us to map technology considerations onto social groups. This helps us to unpack participants’ considerations of personal characteristics including attitudes, aptitudes, preferences, skills, and competencies. We shed light on understanding social negotiations, roles, and responsibilities in context of individual and communal technology use.\r\n\r\n3 METHODOLOGY\r\n\r\nTo understand how our participants lived and experienced communal technology use, we required a broad account of individual and household perspectives. We found semi-structured interviews appropriate to achieve this goal.\r\n\r\n3.1 Participants\r\n\r\nWe applied thematic analysis to a series of interviews with  participants in the UK from November 2017 to March 2018 (Table 1). Participants were recruited from our department, through community centres and various online channels. As compensation, participants were offered a £10 voucher. Interviews were generally conducted in public spaces, and a few were conducted at participants’ homes. The general public was invited to participate in interviews and, at first, we did not pre-screen participants. We started with focus on (a) general attitudes toward internet-connected technology in the home (n=18), (b) followed by a focus on newer smart devices, excluding entertainment and communication, (n=16) and (c) social negotiation asking partners of previous participants to participate (n=2).\r\n\r\nTable 1: Participants by age, gender, and self-reported technology competence.\r\nSkills\r\nAge    Gender        expert    competent    novice\r\n18-34    female        0    7    2\r\nmale        4    2    0\r\n35-64    female        1    12    1\r\nmale        5    2    0\r\nTable 2: Device ownership as reported by interviewees (n).\r\nn\r\nLaptop    32\r\nSmartphone    36\r\nTablet    20\r\nTV    21\r\nVoice Assistant    22\r\nAppliance    12\r\nSmart Lights    7\r\nEnergy Mgmt    22\r\nSecurity/Safety    13\r\nFitness    16\r\nHealthcare    3\r\n\r\n3.2 Data Collection and Analysis\r\n\r\nEach interview lasted between 30 and 45 minutes. Participants were asked about the different devices they owned (Table  2), their general attitude, the purpose of or the intention to purchase a device, experiences of using the device as part of their daily routine, changes in their own behaviour or that of their cohabitants, and how they thought and felt about these changes. Participants were invited to comment on anything related to products they already owned and those they had learned about.\r\n\r\nAll interviews were transcribed verbatim by the main researcher. At the end of the first and second iteration, we hosted a coding verification session with other researchers in our department. The analysis started with initial and selective coding of a full, verbatim transcript and an in-case analysis of each individual interview, supported by the qualitative research software NViVo. Categories and themes evolved as codes and quotes were compared while further interviews were conducted.\r\n\r\n4 INTERVIEW FINDINGS\r\n\r\nIn this paper, we report on the themes of Dealing with Technology, Sharing Personal Devices, Using Shared Devices, and Guests and Visitors from our thematic analysis. We report on these themes and supplement each theme by a diagram summarising relevant dimensions of technology consideration and social groups (see box:template).\r\n\r\n4.1 Dealing with Technology–Old and New\r\n\r\nWhen obtaining, using, and solving problems with technology, our participants reported largely relying on existing social and work relationships. Those providing advice expressed feelings of responsibility leading them to carefully consider their audience; and many of our participants to varying degrees provided advice to and sought help from others.\r\n\r\nSupport structures were based on participants’ relationships and the expertise they saw both in themselves and in other people. Participants 032 and 034 observed how their parents were generally able to use handheld devices, while they relied on their children to find out about new features; they were\r\n\r\nnot very comfortable at all with fiddling around. (034)\r\nThis difference in competence was also considered by participant 011 who found her mother incapable of using Microsoft Windows and hence opted for a Google Chromebook. 021 elaborated more broadly on his own expertise in providing technology support for family and friends. He found things like the internet or internet-connected kettles were too immature for many who lacked knowledge for setup and maintenance.\r\n\r\nBecause if anything then it\'s one more thing that they cannot manage by themselves. So myself, I have regularly to get to my father to help him out. It\'s almost once every fortnight. [...] And he is still running office 2003. Even though it\'s not security updated and everything else. Because I can not help him with the newest version of Microsoft Office. (021, emphasis added)\r\nA lack of support availability due to the novelty and immaturity of smart home devices were mentioned as particularly challenging.\r\n\r\nWith smart devices I probably wouldn\'t have anyone to go to. So I would look after them myself. [...] I would probably go to the local computer shop and ask somebody there. but they don\'t tend to know an awful lot more than I do. I think there\'s so much to know. (027, emphasis added)\r\nWe found the direction of technology advice in parent-child relationships could depend on expertise. While the adviser in the aforementioned cases was commonly younger than their receiving counterpart, we also learned about parents recommending the use of a particular smart home technology to their children. Two participants explained how they were motivated by their parents to install a home security system. It became apparent how benefits resulted on a personal (feeling safe), communal (looking after the dog), and close family (external) level (peace of mind); and how interacting with the system could be communal (looking after the dog) but was mainly personal.\r\n\r\nParticipant (015) talked about how catering for many different interests meant they were equipping their new house with many smart home devices. She had recently moved into a new house with her partner. As she was interested in “smart things” and her partner was “quite keen with security”, they installed a smart home security system. This was complemented by fire safety devices as her father insisted on these. The father used a similar system and was also a retired fire fighter.\r\n\r\nAnd I wanted to easily manage the utilities and hence the smart things. And my partner is quite keen with security. And then I guess we went kind of from the security system to the cameras for the dog. To the smoke alarm. Because my dad wanted it. (015)\r\nThe installation of new smart home technology could have unanticipated consequences for some household members. During the interview, the participant realised she now preferred doing online banking out of sight of the security cameras. The cameras covered the space in which she did online banking previously.\r\n\r\nI used to work in the sitting room downstairs at the dining table. I now only go to the desk. Especially to do online banking but also shopping or anything that has sensitive information. (015)\r\n\r\n\r\n\r\n\r\nSummary of Theme 1\r\n\r\nFeelings of responsibility by those external to a household emerged from providing/seeking advice but could also provide “peace of mind”; interaction with personal devices could become communal; and household members could be disadvantaged by unanticipated consequences\r\n\r\n4.2 Sharing Personal Devices\r\n\r\nSharing personal devices could extend benefits of use to others; in other cases, sharing was infeasible due to usage patterns or cohabitants’ aptitudes. Desktop computers, laptops, or mobile phones were largely considered as personal devices but could be shared under specific circumstances. Factors influencing the decision to share included the nature of the social relationship (e.g. parent child, spouses, close friends), the qualities of the device, and the perceived ability of the user. Several participants mentioned their partners accessing their laptops was permissible (e.g. 009, 017). Participant 032 explained how sharing access to laptops was fundamentally rooted in trust and intimacy. They had taken the decision to simply share everything, not distinguishing what was his and hers.\r\n\r\nNo not really. I mean we both have got logins to each others laptops. I mean.. I don\'t know if you are in a relationship or your friends are. But you know you sort of see couples that have been married for 50 years and still maintain separate bank accounts. (032)\r\nHowever, being in an intimate relationship didn\'t mean access to devices would always be handled in the same way. Smart phones could be “too individual” (017) or used “so often” (029) that sharing was considered infeasible. Participant 006 mentioned she would not be interested in using her partner\'s device as its qualities did not appeal to her.\r\n\r\nNo actually. In fact I don\'t even know his computer password; and that\'s how we like it; and I don\'t like it as he has BlackBerry phone. I\'ve got a nice phone. I don\'t need that. (006)\r\nAsked to reflect on sharing personal devices, participants 012 and 028 pointed towards their partners aptitude in handling devices. They preferred to keep their devices separate and to handle any arising issues on their own. Participant 001 emphasised that sharing their laptops would “beg for divorce” (001) having previously emphasised the devices were “almost like a third family member” (001) that needed attention and care taking. However, participant 001 found exceptions to the rule existed, and participant 012 acknowledged her partners skillfulness in problem solving.\r\n\r\nabsolutely not.. actually that would beg for divorce. [...]\r\n\r\nactually you are making me think. sometimes if he is out, I\'m using his computer to print and that\'s alright, that\'s okay. (001)\r\nbut he is very good in finding out how things not work like Google and so... no, we keep our devices separate. (012)\r\n\r\n\r\n\r\n\r\nSummary of Theme 2\r\n\r\nPersonal devices could be shared if considered sensible and desirable which could mean shared benefits\r\n\r\n4.3 Using Shared Devices\r\n\r\n4.3.1 Navigating communal use. The use of shared (entertainment or recreation) devices was commonly negotiated by considering each others’ needs and preferences, and sometimes simplified through redundancy of devices.Our participants commonly mentioned spending time with their partners or family watching television. They would agree on which programme to watch if there was no strong preference by any of them. If any one of them had a strong preference they would usually be given priority, but there was also the possibility to evade conflict by using a second device such as a tablet or a television in a different room.\r\n\r\nI thought it was the most horrible vibe ever at first. Because I don\'t want to watch what he\'s watching but I want to be in the same room as him. I tried reading books, but I can\'t read a book with the television on. (006, emphasis added)\r\nSimilarly, access to and use of the smart voice assistant owned by one flat mate was shared with a cohabitant. Participant 018 and her flatmate casually used their voice assistant while spending time together. The participant was also allowed to use the device without the owner (her flatmate) being present.\r\n\r\nWe use her [Alexa] for literally everything. Ask her what the weather is like, ask her if we ever have a conversation and we need to answer a question then we just ask her. (018)\r\nIn other situations, shared access was technically not possible although socially permissible.\r\n\r\nMy friend\'s Spotify and Amazon Prime is connected to it, so when he is driving and listens to Spotify and then I come home and start using it, it will cut his music out (018)\r\nAccess to a cross trainer and smart lights was shared and negotiated based on personal preferences and interest, leading to a stronger claim of those driving procurement and adoption in the first place. When both householders wanted to use the cross trainer at the same time, the two householders would trade the use of the TV as a reward (035). The cross trainer of participant 028 supported different profiles for different users, avoiding conflicts over personalisation. Similarly, participant 009 would leave usage decisions for smart lights in the living room to her partner because he was ‘a little bit annoying’ (009).\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nSummary of Sub-Theme 3.1\r\n\r\n(a) Joint-use of mature technology, e.g. television, were common; (b) strong individual preferences could influence usage practices of newer devices, e.g. home trainer and lights, and communal benefits emerged while individuals could feel disadvantaged; (c) benefits emerged from sharing smart voice assistants and connected services (music streaming) but participants debated disadvantageous technical limitations\r\n\r\n4.3.2 Usage Practices. Our participants observed how they and their cohabitants developed different usage practices such as the use of different features of, different interfaces for, or different devices as interfaces to control a device; some relied on others to control devices.\r\n\r\nWhen existing devices were replaced, not everyone used them to the same extent. Participant 019 observed how her daughter linked her phone to a smart speaker while she listened to internet radio only, and her husband did not want to use it, preferring his old stereo instead. Similarly, participant 016 recalled how his mother used a smart thermostat while his father preferred manual control over the heating, and participant 034’s smart kettle was used as a “normal” kettle by his partner.\r\n\r\nIf he is feeling cold, he is going to walk up and press the button on the thing. I mean he has an iPhone, but I can\'t even get him to pick up FaceTime because he doesn\'t understand it. (016)\r\nWhile participants in the aforementioned cases did not face any obvious drawbacks from their non-use of smart features, others reported disadvantages. For example, participant 026 reported how he used his smart phone to control the lights while his wife preferred their Google Home. However, it was not possible to control the smart plugs that way. A similar situation led participant 020 to an inconvenient work around to switch the lights on and off. While there were obvious solutions to both cases, the participants had not made use of them.\r\n\r\nNo, she uses the Google Home. She tells the Google Home to turn the lights on. I haven\'t done an action for the smart plugs yet (026)\r\nI then have to text or send a message to my boyfriend and go like. Can you turn the lights on? And that really frustrates me. (020)\r\nParticipant 020 had to use the lights as part of her daily routine and eventually installed the smart phone app to control them. She “made do” with the system as relying on her partner to act was infeasible. Participant 023 reported her mum chose to rely on her father to control the smart TV, only ever using it in his presence.\r\n\r\n\r\n\r\n\r\n\r\nSummary of Sub-Theme 3.2\r\n\r\nDifferent usage preferences, e.g. “unsmart” or manual use, meant benefits for the household were emerging, and these preferences could bring about disadvantages for the community\r\n\r\n4.3.3 Managing failure. Responsibilities to take care of the home network differed, but its use was commonly shared with some depending more on it than others.\r\n\r\nParticipant 001 split the work with her partner. While he was calling the provider, she would try switching the router off and on. Similarly, participant 012 explained how her partner would attempt to fix the problem but she would call the provider if “it reached crisis”. Again slightly different was participant 021’s approach. To analyse any home network issue, his wife would give him a call and follow his guidance because the network setup was “a little more complicated”.\r\n\r\nPersonal preference and expertise were also important factors for participants 010 and 020. 020 argued her partner did not like being on the phone and the internet was not a priority for him. It would be her calling the provider and sorting out the issue. Whereas he was more likely to fix the television in a timely manner.\r\n\r\nThe use of a smart home setup as described by participant 015 provided benefits to all inhabitants, it also increased her reliance on technology. The participant explained how her phone broke and how she had to go\r\n\r\nback to being more manual. (015)\r\nWhile reassured that the system was still workable, it made her realise how useful the smart system was and also how much she had gotten used to it.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nSummary of Sub-Theme 3.3\r\n\r\n(a) The home network was shared responsibility with stakes distributed by expertise (emerging); (b) ’spheres of expertise’ also extended to responsibility for personal devices and could disadvantage individuals in case of breakdowns\r\n\r\n4.3.4 Considering Cohabitants. When introducing internet-connected devices to the home, participants considered and involved their cohabitants to varying degrees.Responsibility, interaction, and benefit could be shared between householders if more experienced or interested individuals assumed responsibility of involving and educating others. For example, a smart home setup (e.g. lights and security cameras) was initially conceptualised and implemented by a single householder while influenced by all cohabitants. Being aware. Participant 020 and 024 were a couple and both were interviewed separately. Participant 024 initially purchased smart sockets to control lights over the winter months, aiming to protect the house from burglaries. At the time of interviewing, the sockets had been re-purposed by 024 as part of a more permanent light system, turning it from burglar protection into a more permanent and shared system. The comments suggested that while both participants initially agreed on the purpose and use of the system, participant 020 had struggled with using them. Two months after installation, she was still adjusting to its requirements. The male householder (024) who had been driving the technology adoption, appeared to have some knowledge of that situation.\r\n\r\nI then have to text or send a message to my boyfriend and go like. Can you turn the lights on? And that really frustrates me.[...]\r\n\r\nI have got the app now. But it\'s so. It\'s a little bit annoying. Because if you are already upstairs, and then you want to put the light on or off [without having the phone]. (020)\r\nShe likes [pauses briefly], she doesn\'t mind but she is not overly involved. She is quite happy with the lights and turning them on and off and how easy that is. (024)\r\nAt the time of the interview, the couple had only been living together for half a year. The smart lights were the first “smart home system” they owned.\r\n\r\nOngoing consultation. Considerations could become more articulated with growing expertise. Participant (032) blogged about smart homes devices in his free time, bringing a high level of knowledge and expertise to the table. He highlighted how the use of new smart devices was subject to ongoing consultation. He semi-professionally reviewed new devices he had been sent by companies or purchased. It was his responsibility to configure, investigate and discuss the use of such devices with his partner (participant 036). The partner also trusted him to act responsibly in protecting the household from any risks related to these devices.\r\n\r\nPart of it is the family acceptance factor. Can I get on with it. Can my wife get on with it. Can we get on with it when people come around. do they get one with it. And the other thing is how much effort it is. (032, emphasis added)\r\nYou don\'t really understand how this works either, do you. And he was like no I don\'t. So let\'s not do that that was a while ago and I can\'t really remember what it was. (036)\r\n\r\n\r\n\r\n\r\nSummary of Sub-Theme 3.4\r\n\r\nParticipants considered their cohabitants to varying degrees when introducing new technology to their household (emerging)\r\n\r\n4.4 Guests and visitors\r\n\r\nConsiderations of other users, their unfamiliarity with the system and the need for access control, expanded beyond the household to include guests and other visitors (e.g. contractors). Unfamiliarity with a system could inconvenience visitors, particularly without efforts of introduction by hosts. In turn, the lack of access control could potentially disadvantage the household and its individuals. Participants’ considerations ranged from hospitality for specific situations, e.g. accommodating parents (020, 036), to protecting systems from unwanted access (015). These considerations were driven by a range of factors including social norms of hospitality, intimacy, reliability, perceived ability, and personal preferences.\r\n\r\nIssues of access.\r\n\r\nTwo of our participants considered installing an Amazon Alexa in each bedroom. Participant 015 raised issues of access control, not wanting potential guests to have the same level of access to the device.\r\n\r\nDealing with unfamiliarity. Guests would not be expected to be familiar with the customs of and intricacies of “using” the home. Hence, participants found different ways to deal with their guests’ unfamiliarity. For the duration of a short stay, the household of participant 020 deemed appropriate explaining but not providing means of control over smart lights to the participant\'s father. Furthermore, the father was perceived as not being capable or open to using new technology.\r\n\r\nAnd he was like your light doesn\'t work. And we were like, no it does you just have to use the app. [...]\r\n\r\nI think he just doesn\'t understand. My dad is not very good with technology. So, he was just like. What\'s the point in that. (020, emphasis added)\r\nBecause their parents/in laws stayed with them for four weeks, participants 032 and 036 considered reconfiguring their system. Participant 036 explained that after consideration of their guests’ ability to control the smart home system using mobile phones, they reconfigured their smart home system to work independently of their mobile phones.\r\n\r\nWe actually had my parents living with us for four weeks [...] And that required quite a major reshuffle of everything that we had.[...] both of us work [...] [The system] just went into a sort of lock-down situation [when they left the house]. So a lot of stuff ended up getting disabled. (036)\r\n\r\n\r\n\r\n\r\nSummary of Theme 4\r\n\r\nParticipants debated access for visitors and guests, and touched on disadvantages arising from smart technology in their home (emerging)\r\n\r\n5 DISCUSSION\r\n\r\nUsers engage with technology within their situated contexts where features of their environments and their own sense making shape how they use and deal with technology. Differences in use and engagement occur between more mature internet-connected technologies and relatively ‘new’ smart devices, however, in all instances they are rooted in the communal context of the household. Technology design then needs to “[enable] people, themselves, to be smarter and proactive in their everyday working practices” [17]. Our findings emphasise the importance of considering the collective and the individual when doing so. We discuss our findings from a perspective of self-efficacy and illustrate how group-efficacy can help understand communal practices.\r\n\r\n5.1 Self-Efficacy\r\n\r\nAs experienced users of internet-connected devices, many of our participants demonstrated high levels of self-efficacy in seeking or providing advice, using, and maintaining devices. Self-efficacy is defined as “people\'s beliefs about their capabilities to produce designated levels of performance that exercise influence over events that affect their lives” [1]. Self-efficacy is a driver for how individuals approach technical challenges – those with higher levels of self-efficacy see difficulty as a challenge to be overcome and adopt effective strategies for achieving their goals. Those with lower levels of self efficacy avoid such difficult tasks, are more easily discouraged and can even view these as threatening [1]. According to Bandura [1], self-efficacy is affected by four main factors: experience (“enactive attainment”), modelling/observing others succeed (“vicarious experience”), social persuasion (e.g. encouragement), physiological factors (e.g. perceptions of signs of distress).\r\n\r\nMuch of our participants confidence in being able to navigate issues with internet-connected devices, e.g. their smart phones, computers, home networks, and televisions, was based on their own expertise and that perceived in others. Considerations of attitude, aptitude, and preferences were projected onto others’ when reflecting on their needs. With regards to smart home devices, our participants mentioned not having established support networks and an increased difficulty in navigating their communal use. They sought advice within their social networks, following established social relationships, and were guided by their own attitudes, preferences, and overall self-efficacy. Of particular interest was their consideration of not only their own, but other community members’ abilities and aptitudes. These considerations, to varying extents, influenced their willingness to share and the nature of their advice. As our participants continued to make their own experiences, they shaped their cohabitants experience, provided advice to others and sought help from those they trusted. These practices somewhat aligned with the four main factors affecting self-efficacy; while those more apt to using smart home devices increased their self-efficacy by experience (enactive attainment), they also served as role models in their social groups (vicarious experience).\r\n\r\nWe believe that a key part of this communal behaviour can be termed group efficacy – which in the manner of Bandura\'s definition of self-efficacy we can define as a group\'s capability to produce designated levels of performance that exercise influence over the events that affect the lives of its members.\r\n\r\n5.2 Group Efficacy\r\n\r\nIn the context of the home, group efficacy applies in a variety of different ways. The first revolves around the self-efficacy of each member of the group, and relates most to the use of communal devices. The second involves not the self-efficacy of every member, but the ability of the group to exercise influence over the technology that affects the lives of its members or has a communal impact. The third relates to the composition of the group, and considers that a household can have a relatively fluid group membership over time, which will affect its group efficacy. We explore each of these in turn below:\r\n\r\n5.2.1 Devices for communal use. When sharing personal devices, participants clearly considered the nature of social relationships, skills, traits, and expertise of others in their community. The decision to share smart phones, laptops, and the use of other gadgets was deeply rooted in these characteristics. Participants were less inclined to consider sharing when they described devices as too individual to be of convenient use for their partners. Also, their partners’ skills and aptitude influenced how comfortable they felt with sharing.\r\n\r\n“Using shared devices” was similarly influenced by personal relationships, skills, traits, and expertise. Moreover, cohabitants’ skills, traits, and expertise also surfaced as important factors in decisions to buy, configure, and use such devices as they had an impact on the whole household. The most common communal device among many participants was the television. Redundancy (more than one device) and communal interaction (jointly watching a movie) implied a broad range of technology considerations across all social groupings.\r\n\r\nIn cases where devices are used by many members of the household, group efficacy can help to frame and explain different situations. In the case where every member of the group is capable of using the technology, the goals of the group that pertain to using the technology are met too. However, in cases where the technology is too novel, complex, or where individual members of the group have lower self-efficacy, we can see that others within the group play a role in ensuring that the group achieves its objectives or, indeed, express concerns that lead to devices being abandoned (c.f. awareness of option to delete video recordings [20] or power imbalances resulting from device use [9]). From our interviews we have seen several examples where individuals specifically configure devices to be used by others, use smart technology on behalf of others, and even allow for alternative control options to enable those that do not wish to use smart technology. Without a consideration of the wider group in which smart technology is being used and its group efficacy, it can be difficult to determine how appropriate or effective the technology will be.\r\n\r\n5.2.2 Devices with communal implications. In other cases, smart devices were not necessarily intended for collective use but they have a communal impact, e.g. smart security systems, thermostats, or even smart coffee machines [13, 18, 20]. Different users had different demands for personal characteristics, and participants reported how they and their cohabitants had different usage practices [9]. These included the use of different features and different interfaces for the same devices, the use of different devices as interfaces to control another device, and the preference to not use a device at all. Personal characteristics and technology considerations plaid a decisive role in managing failure of technology. However, varying personal characteristics among cohabitants required more elaborate considerations by individuals of smart home technology on behalf of the household.\r\n\r\nAgain, we believe that group efficacy is key factor here, but where the communal use of technology focuses on the abilities of community members, more important for devices that can impact the community is the setting of clear goals that capture the needs of every community member, and the need for an individual who has the capability to translate these into reality. In practice, our interviews showed that typically the instigator of the purchase of a smart device is instrumental in its configuration [9, 20]. Our participants also took responsibility for ensuring the technology worked as intended and did not excessively impact members of the community. Exactly how the needs of the wider group were elicited and negotiated seemed highly variable and could be both implicit or explicit.\r\n\r\n5.2.3 Household communities are fluid. Social groups in the home were not limited to a household but included guests, visitors, and neighbours [9]. Similar considerations of personal characteristics and qualities of social relationship (level of intimacy with parents, family, friends) became influential for technology considerations.\r\n\r\nBy varying the scope of which members are part of the group, the concept of group efficacy is applicable here too. Participants considered adjustments to their systems catering for different levels of technology aptitude and social intimacy for guests, visitors and even neighbours, and they navigated issues of access control and unfamiliarity with technology.\r\n\r\n6 LIMITATIONS AND FUTURE WORK\r\n\r\nOur paper builds on participants’ self-reported behaviour and participants’ observations of other household members1. These other household members might hold different perceptions of these practices. While this allowed us to also learn about participants’ preferences, goals, and motivations, further observational research is needed. An enthnographic study of home technology use can help verify and expand our findings.\r\n\r\nIn future work, we aim to explore (1) group dynamics including roles and relationships to help understand levels of group efficacy; (2) how group efficacy can be useful and how it is related to self-efficacy; and (3) how group goals are elicited and enabled to help understand how motivation can be influenced.\r\n\r\nFurthermore, research should explore the implications of group efficacy on the design and use of technology, both inside and outside the home. Building from Bandura [1] four main self-efficacy factors, we can explore how these factors can develop self and group efficacy in a home context. Interventions through design, research, and education are also promising approaches.\r\n\r\n7 CONCLUSION\r\n\r\nTo enable users to be “smarter and proactive in their everyday working practices” [17], we need to better understand the social context in which they use technology, particularly the communal aspects of it. We reported findings from  interviews in which we asked our participants for their experience in using and managing devices. Along dimensions of technology considerations and social groups, thematic analysis provided four main themes for investigation: dealing with technology, sharing personal devices, using shared technology, and considering guests and visitors. Further analysis along these dimensions revealed participants’ considerations of characteristics including attitude, aptitude, preferences, skills, and competencies.\r\n\r\nDiscussing practices and experiences in light of reported characteristics, we found self-efficacy provided a useful perspective in the analysis. We further argued for group-efficacy as a useful lens to explain communal use, and we illustrate three possible applications of group-efficacy: (1) acceptance of devices for communal use; (2) managing devices with communal implications; and (3) understanding fluid household communities. In our future work, we plan to further explore the relationship of self-efficacy, group-efficacy, and household use of technology.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis work was funded by a Research Institute in Science of Cyber Security (RISCS) small grant. The first author was supported by an EPSRC grant (EP/P00881X/1).\r\n\r\nREFERENCES\r\n\r\nAlbert Bandura. 1994. Self-Efficacy. In Encyclopedia of human behaviour, V. S. Ramachaudran (Ed.). Vol. 4. Academic Press, New York, 71–81. https://doi.org/10.4135/9781483386874.n481  \r\nAndy Crabtree, Richard Mortier, Tom Rodden, and Peter Tolmie. 2012. Unremarkable Networking: The Home Network As a Part of Everyday Life. In Proceedings of the Designing Interactive Systems Conference(DIS ’12). ACM, New York, NY, USA, 554–563. https://doi.org/10.1145/2317956.2318039 \r\nAndy Crabtree, Tom Rodden, Peter Tolmie, Richard Mortier, Tom Lodge, Pat Brundell, and Nadia Pantidi. 2015. House rules: the collaborative nature of policy in domestic networks. Personal and Ubiquitous Computing 19, 1 (2015), 203–215.  \r\nAndy Crabtree, Peter Tolmie, and Will Knight. 2017. Repacking ’Privacy’ for a Networked World. Computer Supported Cooperative Work: CSCW: An International Journal 26, 4-6(2017), 453–488.  \r\nPaul Dourish and Ken Anderson. 2006. Collective Information Practice: Exploring Privacy and Security as Social and Cultural Phenomena. Human-Computer Interaction 21, 3 (2006), 319–342. https://doi.org/10.1207/s15327051hci2103_2  \r\nPaul Dourish and Genevieve Bell. 2011. Divining a Digital Future: Mess and Mythology in Ubiquitous Computing. The MIT Press.  \r\nJodi Forlizzi and Carl DiSalvo. 2006. Service Robots in the Domestic Environment: A Study of the Roomba Vacuum in the Home. In Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-robot Interaction(HRI ’06). ACM, New York, NY, USA, 258–265. https://doi.org/10.1145/1121241.1121286  \r\nDavid Frohlich and Robert Kraut. 2003. The Social Context of Home Computing. Springer London, London, 127–162. https://doi.org/10.1007/1-85233-854-7_8  \r\nChristine Geeng and Franziska Roesner. 2019. Who\'s In Control?: Interactions In Multi-User Smart Homes. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 268, 13 pages. https://doi.org/10.1145/3290605.3300498  \r\nTom Hargreaves, Michael Nye, and Jacquelin Burgess. 2010. Making energy visible: A qualitative field study of how householders interact with feedback from smart energy monitors. Energy Policy 38, 10 (2010), 6111–6119. https://doi.org/10.1016/j.enpol.2010.05.068  \r\nTom Hargreaves, Charlie Wilson, and Richard Hauxwell-Baldwin. 2017. Learning to live in a smart home. Building Research & Information 46, 1 (2017), 1–13. https://doi.org/10.1080/09613218.2017.1286882  \r\nRikke Hagensby Jensen, Yolande Strengers, Jesper Kjeldskov, Larissa Nicholls, and Mikael B. Skov. 2018. Designing the Desirable Smart Home: A Study of Household&#160;Experiences and Energy Consumption Impacts. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 4, 14 pages. https://doi.org/10.1145/3173574.3173578  \r\nJosephine Lau, Benjamin Zimmerman, and Florian Schaub. 2018. Alexa, Are You Listening?: Privacy Perceptions, Concerns and Privacy-seeking Behaviors with Smart Speakers. Proc. ACM Hum.-Comput. Interact. 2, CSCW (nov 2018), 102:1—-102:31.  \r\nSarah Mennicken and Elaine M. Huang. 2012. Hacking the Natural Habitat: An In-the-Wild Study of Smart Homes, Their Development, and the People Who Live in Them. In Pervasive Computing, Judy Kay, Paul Lukowicz, Hideyuki Tokuda, Patrick Olivier, and Antonio Krüger (Eds.). Springer, Berlin, Heidelberg, 143–160.  \r\nSarah Mennicken, Jo Vermeulen, and Elaine M. Huang. 2014. From Today\'s Augmented Houses to Tomorrow\'s Smart Homes: New Directions for Home Automation Research. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing(UbiComp ’14). ACM, New York, NY, USA, 105–115. https://doi.org/10.1145/2632048.2636076  \r\nHelen J. Richardson. 2009. A ’smart house’ is not a home: The domestication of ICTs. Information Systems Frontiers 11, 5 (2009), 599–608.  \r\nYvonne Rogers. 2006. Moving on from Weiser\'s Vision of Calm Computing: Engaging Ubicomp Experiences. In Proceedings of the 8th International Conference on Ubiquitous Computing(UbiComp’06). Springer-Verlag, Berlin, Heidelberg, 404–421. https://doi.org/10.1007/11853565_24  \r\nAlex Sciuto, Arnita Saini, Jodi Forlizzi, and Jason I. Hong. 2018. ”Hey Alexa, What\'s Up?”: A Mixed-Methods Studies of In-Home Conversational Agent Usage. In Proceedings of the 2018 Designing Interactive Systems Conference(DIS ’18). ACM, New York, NY, USA, 857–868. https://doi.org/10.1145/3196709.3196772  \r\nDeepika Singh, Ismini Psychoula, Johannes Kropf, Sten Hanke, and Andreas Holzinger. 2018. Users’ Perceptions and Attitudes Towards Smart Home Technologies. In Smart Homes and Health Telematics, Designing a Better Future: Urban Assisted Living, Mounir Mokhtari, Bessam Abdulrazak, and Hamdi Aloulou (Eds.). Springer International Publishing, Cham, 203–214.  \r\nMadiha Tabassum, Tomasz Kosinski, and Heather Richter Lipford. 2019. I don\'t own the data”: End User Perceptions of Smart Home Device Data Practices and Risks. In Fifteenth Symposium on Usable Privacy and Security (SOUPS 2019). USENIX Association, Santa Clara, CA. https://www.usenix.org/conference/soups2019/presentation/tabassum  \r\nAlladi Venkatesh. 1996. Computers and Other Interactive Technologies for the Home. Commun. ACM 39, 12 (1996), 47–54. https://doi.org/10.1145/240483.240491  \r\nCharlie Wilson, Tom Hargreaves, and Richard Hauxwell-Baldwin. 2015. Smart homes and their users: a systematic analysis and key challenges. Personal and Ubiquitous Computing 19, 2 (2015), 463–476. https://doi.org/10.1007/s00779-014-0813-0  \r\nEric Zeng, Shrirang Mare, and Franziska Roesner. 2017. End User Security & Privacy Concerns with Smart Homes. In Proceedings of the Thirteenth USENIX Conference on Usable Privacy and Security(SOUPS’17). USENIX Association, Berkeley, CA, USA, 65–80.  \r\nFOOTNOTE\r\n\r\n1We interviewed two couples as separate individuals to get both their perspectives.',1,'Kraemer','Martin J Kraemer, Ivan Flechais, and Helena Webb','Martin J Kraemer *(Department of Computer Science, University of Oxford, UK)*<br>\r\nIvan Flechais *(Department of Computer Science, University of Oxford, UK)*<br>\r\nHelena Webb *(Department of Computer Science, University of Oxford, UK)*','http://www.cs.ox.ac.uk/files/11128/Httf_exploing_communal_use-camera-ready.pdf',1,'10.1145/3363384.3363389','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,45,10,NULL,NULL,0,5),(28,'lee-smith-the-data-hungry-home-defining-populating-feeding-and-beyond','2019-09-02 15:24:57','2019-11-14 14:12:28','2019-09-02 15:24:57',NULL,1,'published','[]','The Data Hungry Home: Defining, Populating, Feeding, and Beyond','It\'s said that the pleasure is in the giving, not the receiving. This belief is validated by how humans interact with their family, friends and society as well as their gardens, homes, and pets. Yet for ubiquitous devices, this dynamic is reversed with devices as the donors and owners as the recipients. This paper explores an alternative paradigm where these devices are elevated, becoming members of Data Hungry Homes, allowing us to build relationships with them using the principles that we apply to family, pets or houseplants. These devices are developed to fit into a new concept of the home, can symbiotically interact with us and possess needs and traits that yield unexpected positive or negative outcomes from interacting with them. Such relationships could enrich our lives through our endeavours to “feed” our Data Hungry Homes, possibly leading us to explore new avenues and interactions outside and inside the home.','Matthew Lee-Smith, Tracy Ross, Martin Maguire, Fung Po Tso, Jeremy Morley, and Stephano Cavazzi. 2019. The Data Hungry Home: Defining, Populating, Feeding, and Beyond. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 10 pages. [https://doi.org/10.1145/3363384.3363390](https://doi.org/10.1145/3363384.3363390 \"DOI for the article \'The Data Hungry Home: Defining, Populating, Feeding, and Beyond\'\")','1 Introduction\r\n\r\n“Digital products – especially those for the home – do not have to reproduce our culture\'s preoccupation with work, consumption and entertainment. Instead, technology can encourage more exploratory engagements with life, providing evocative resources with which to discover new perspectives on ourselves and the world around us.” [28:5]\r\nAs in-home devices approach true ubiquity and are decreasingly seen as objects that should simply fulfil utilitarian or efficiency related needs and aspirations, there is an opportunity to explore alternative and experimental manifestations of, and interactions with, these devices. Three core theoretical pillars currently inform in-home ubiquitous computing (UbiComp), calm computing, engaging experiences, and sustainable homes [47]. The inceptive work of creating engaging experiences in UbiComp emerged as a critique and furcation of Weiser and Brown\'s vision of calm UbiComp [94] by Rogers [75]. Rogers calls for a proactive form of UbiComp that augments human intellect and enables them to “perform ever greater feats, extending their ability to learn, make decisions, reason, create, solve complex problems and generate innovative ideas” instead of diminishing the number of tasks required by humans to perform [75:411]. Rogers also argues for reviving the “excitement of interaction” that had been suppressed by the notions of calm technology [75:418]. This paper presents a theorisation and conceptual exploration of various in-home technologies that can be understood as existing within, or constituting, a home that requires data as a form of sustenance, the Data Hungry Home (DHH). The DHH draws upon both the calming and engaging pillars with a focus on creating engaging interactions that forge relationships between people, the data they (can) generate, the home, and its contents. In doing so, the DHH seeks to gain a foothold in the nurture or care driven aspects of the human condition currently occupied by animate objects, such as house plants and cats. The DHH seeks to form symbiotic relationships with humans by providing personality-imbued data-driven interactions through the consumption of varied data from the outside world. This paper represents the first step towards describing and creating a theoretical foundation for the DHH with the hope that, as the ideas develop, further design research contributions will help expand and refine our understandings of the nature of in-home UbiComp. It does so by creating and exploring a narrative and lexicon of collecting metaphorical “food” in the form of data, feeding it to the DHH, and eliciting an output/interaction, in four sections. The first provides an initial definition of the DHH. The second investigates ways in which the DHH can be populated by looking at the possibilities for buildings and devices. The third delves into possible “food” data for the home as well as ways of collecting it. Finally, potential needs, traits and outcomes that could be attributed to members of the DHH are explored. Together these sections seek to enrich the interaction and experience with the DHH and its contents enabling people to form bonds and relationships with the technology.\r\n\r\n2 Defining\r\n\r\nThe archetype of the DHH fundamentally describes a classification for certain homes, or their contents, that do not simply collect, create, use or transmit data but are hungry for it and require routine feeding for them to function. The hunger can be a need, craving, desire, dependency, reliance, even an addiction or simply seeking enough sustenance to plod along. The concept of the DHH alters the paradigm and shifts the hierarchy in the human-machine (or even machine-machine) relationship as it requires one component to maintain the other with regular feeding with curated and specific data in order to receive the desired outputs/interactions (Figure 1). It also sees the “members” of the DHH instilled with a certain amount of personality and agency that permits them to respond to their environment, communicate feelings and, quite macabrely, the ability to “die”. The term “Data Hungry Home” emerged initially as a grouping of concepts generated through a critical practice process in the preliminary stages of a research through design process by Lee-Smith et al. [55]. Currently, “smart” homes/devices unflinchingly procure, communicate or store data for use, are accessible at a moment\'s notice and fulfil our every request (if they can). Members of the DHH, on the other hand, will require a more symbiotic form of relationship. You scratch my back (with data/knowledge) and I will scratch your back (with an interaction), so to speak. This definition lends itself to prevailing technology phenomena, such as the Internet of Things (IoT) as the interconnectivity with other technologies (e.g. wearables and other in-home devices) which could facilitate activities such as conversations, trading and feeding. As with any framework that has the potential to create and handle (personal) data, anonymity and security must be considered. However, the data in this scenario need not follow the conventions we have come to expect with the near-permanent internet or mnemonist self-tracking tools. For example, the data can exist locally (i.e. only within the connected devices), be collected in a low-resolution manner, and/or be ephemeral in nature as it is consumed by the DHH, erasing it from existence. Aspects of the DHH, in many ways, already exist. The base concepts are an advance on various in-home projects such as the work undertaken and compiled by the Interaction Research Studio and others coined as “The Curious Home” [13,30]. Their work describes a variety of pieces of furniture [30] and “threshold devices” [32] that use various forms of data (from within and outside the home) to provide ludic interactions and situate and enrichen the understanding of the home and what surrounds it. However other “smart home” approaches have also been drawn upon. Jensen et al. [47] present three different smart home personas based on the desired characteristics identified by households. These are “the helper”, “the optimiser”, and “the hedonist” [47:4]. In the context of the DHH, the hedonist is the most relevant, described as creating a living space that is desirable to be in. They argue to achieve this the hedonist smart home must be nourishing, beautiful, unique and playful. Jansen et al.’s discussion of the hedonist home also ties in strongly with their exploration of Hygge in the house, which promotes cosiness and companionship, amongst other concepts [48].\r\n\r\nFigure 1\r\nFigure 1 The human, data, member interaction loop of the DHH.\r\n3 Populating\r\n\r\nIn order to make a home hungry for data, it must be designed and built to be able to receive and consume data or filled with artefacts (furniture, products, etc.) that are able to do the same. This section delves into populating the DHH with buildings and devices and examines informative theories and examples relevant to each. There are a plethora of design approaches, stances and theories that can be used to inspire the population of all parts of the DHH. These include design for slowness and reflection [21,33,34,36,63,68,69,81], ludic design [22,27,90], uncomfortable interactions [14], rich interactions [26,66], animism [3,58,59], tangible user interfaces [41,42,54] as well as many others.\r\n\r\n3.1 Buildings\r\n\r\nThere are many elements in an architectural structure that we interact with regularly, whether it is opening a window, shutting a door or switching on a light. Extending the reach and interactivity of space with technology has been explored and considered for decades. Some of the early and pivotal work in the realm of tangible interaction and the “tangible bits” movement [42] featured considerations of rooms (and therefore, logically, houses) that could interact with and display data [43,95]. The work considers how data could be communicated in a subtle or ambient manner that enabled the viewer to subconsciously pick up on and be aware of the it. Here, data is displayed through “ambient media” such as sounds, airflow and shadows. This is considered to be one of the early cases of ambient displays [71], however, the approach was more focused on the architectural elements than dedicated ambient display devices, referred to at the time as “ambient fixtures” [95]. These dedicated devices will be discussed further at a later point in this section. As research has progressed, ambient technology has been integrated into building architecture and used in behaviour change [76,83]. Others look at the culmination of the overlap of interaction design, UbiComp, architecture, urban design and the building industry and economy, known as human-building interaction [65]. More experimental forms of architecture look at how data, in this case, physiological data, can impact their size and form [44,79] or vice versa [45]. In the context of the DHH there are two main areas for consideration, the first being how can the structure of the home be designed to integrate the required technology, and the second being in what ways can the main elements of a building (walls, windows, doors, etc.) interact with people without creating safety or control issues (such as doors or windows leaving themselves open because of a lack of food/data).\r\n\r\n3.2 Devices\r\n\r\nMembers of the DHH can also take the form of devices, artefacts or products. These are perhaps the most suitable for widespread application as they are easily installed into any household, effectively retrofitting a DHH, and perhaps have the largest scope of conceptual and design flexibility as they are not constricted by as many requirements as a house. There are several different classifications and concepts for or relating to, devices that are used in the home. Peripheral [10,11] and ambient displays [71], for example, communicate information primarily through the peripheries of our attention instead of the centre. Whilst the initial concept of the peripheral display (of which the ambient display is considered a subset [71]) is linked to calm computing it can be used to actively engage with people. For example, the Physikit project [39] demonstrates how users can interact and change the data displayed by ambient display devices. Alternately, the Ambient Birdhouse uses an ambient display to help its users learn about common birds in their area [84]. Devices are also able to take advantage of data physicalisation [38,46], which involves converting data into physical/tangible outputs. Bookly, for example, is a device that communicates to its user their relation to the completion of their reading goals by changing its height, rotation and light output [50]. Outside of these larger areas of research, other forms of devices have been explored. For example, Berger et al. recently discussed their exploration of idiosyncratic smart objects for the home including an inflatable cat that fills itself when its real cat counterpart is meowing at the door [16]. In addition to smaller devices, furniture can be another medium to explore interactions (with data) [30,37,40,52,61,90]. Furniture is also a natural location to explore tangible interaction as we naturally touch or sit on them. Considering these and other data-dependent artefacts, devices of the DHH should seek to display data and interact with people in a varied and engaging manner.\r\n\r\n3.2.1   Himilco . With these devices in mind, we posit a classification of an in-home artefact, periplus, that we are currently exploring as part of our research. Periplus as a term relates to navigation, voyaging, and sailing and can be used to describe a documented list of ports, a voyage or journey (notably around a coast) or an account of a circumnavigation or journey. It is in the third part of the definition that is of particular interest as a potential metaphor for an in-home device that is an account, repository or archive of adventures beyond the home (perhaps to collect food for the DHH). Currently, a periplus named Himilco (after the Carthaginian navigator), that uses approaches such as data physicalisation and ambient displays to physicalise data, is being investigated. Himilco is a reconfigurable “data object” [85] and will use an approach known as composite physicalisation [35] where it will have multiple “dimensions” which it can use to display data, such as changing its height, colour or orientation. This device could be used to communicate or playback food/data in a direct or ambiguous manner, potentially prompting self-reflection [91]. Similar approaches have been taken to the physicalisation of activity that stimulates reflection on past activities and consideration on the execution of future ones [6,78,88,89]. Stusak\'s work on 3D printed activity sculptures, for example, demonstrates the potential for reflection on running activities as well as considering how the next activity might be different in order to manifest alternatively shaped sculptures [88:171]. In this case, the use of the term periplus would be attributed to the machine and system (i.e. the 3D printer and PC) that generated the sculptures, not the sculptures themselves. Non-3D printed approaches have also been used with concepts such as Loop which uses a set of rings to communicate an individual\'s daily step count relative to a goal [78]. In this case, the Loop artefact is a periplus. Of the examples of peripli found, there is a notable focus on activity data perhaps due to the increasing popularity and ease of access to data through products such as Fitbits. Himilco, on the other hand, will use data such as temperature, humidity, altitude and colour collected by its human companion to feed itself and produce its physicalisation.\r\n\r\n4 Feeding\r\n\r\nA hungry house (of hungry artefacts) needs food in the form of data. How, and with what, do you feed it/them? In this section, we unpack the nature of the possible interactions around the concept of feeding and harvesting data for the DHH. We do so by first taking a brief look at the types of “foodata”, a term that combines food and data as well as referencing the term and concept of “desiderata”, something that is needed or desired. Foodata encompasses a diverse range or groups of available (data) sustenance, similar to how humans eat a varied diet. Following on from this, ways in which foodata can be passively harvested for the home will be discussed. Finally, active forms of harvesting will be suggested. It is within this discussion of active harvesting that the concept of Carver, a wearable device specifically designed to harvest bundles of foodata is presented. It is through these devices that the members of the DHH are able to connect with, and be fed by, the outside world.\r\n\r\n4.1 Foodata Groups\r\n\r\nIt would be easy to plainly state that “the DHH will feed on various types of data” and move on. However, we will briefly describe the data that has been considered. In the paper thus far, activity data, such as heart rate, blood pressure and step count, weather data, such as temperature, atmospheric pressure and humidity and luminosity have been alluded to as possible foodata sources. Further inspiration can be taken from sources such as the data collected in geographic information systems (GIS) such as in the work of See et al. [80]. In the discussion of the sources of volunteered geographic information (VGI), they suggest biodiversity, crime, environmental (air quality, noise, etc.) and feature mapping amongst others. In addition to this, data such as WIFI/Mobile strength, surface textures, colour, electromagnetic wave strength and transcripts are all also viable foodata. With such a variety of data available, it is possible to imagine different groups of foodata (much like the food groups) that can sustain devices in different ways, i.e. a healthy diet of data.\r\n\r\n4.2 Passive Harvesting\r\n\r\nPassively collecting food for the DHH could function in a number of different ways. For example, connecting to certain types of online data, such as Twitter data or smart city data streams through application programming interfaces (API\'s). However, this would require little maintenance and, as such, is somewhat outside the main purpose of the DHH. On the other hand, other quasi-passive formats can be explored, such as sensors or devices that are placed outside the home and used to generate data for individuals and communities. Sethu-Jones et al., for example, discuss a project that involves the placing of four devices in a community garden [82]. The devices were equipped with luminosity sensors, cameras and a means to connect the devices to a tablet to access a “situated” or “overview” perspective of the devices and collect/view the generated data. Alternatively, the My Naturewatch project employs small camera devices that, when placed outside, can capture pictures of animals [29]. These devices can be accessed via WIFI to collect the photos or from an SD card that can be extracted. These projects demonstrate devices that passively store data but require some form of human interaction to collect, view or harvest those data. They are effectively “planted” in an outdoor context, allowed to “grow” with data and later “harvested” when they are ripe with data. This concept could be expanded to suggest an almost agricultural relationship with data. Devices (e.g. “data tomatoes”) could be designed to be planted out in the wild, tended and grown, harvested and fed to the DHH. The difference in value here, from actively harvesting the foodata is the prolonged engagement with, and nurturing of, foodata for the home.\r\n\r\n4.3 Active Harvesting\r\n\r\nActive harvesting of data is a much more engaged undertaking. This form of harvesting will require the user to seek out data in an involved interaction with the outside world. This would entail the user taking some form of collection device, such as a wearable or smartphone, with them on the excursions. Unlike the connotation of planting, growing and harvesting suggested in passive harvesting, active harvesting evokes thoughts of a form of data foraging/hunting or data botany/conchology. On the one hand, data can be sought out in a simple pragmatic or primal sense in order to collect a certain quantity, at any point, for the purpose of bringing it back to the DHH. This is the foraging or hunting approach. On the other hand, data can be carefully curated and selected to create a refined collection. This collection can form a creative expression through how the DHH responds to the data or a meticulous catalogue of unique foodata. Finally, as was briefly eluded to previously, the harvesting and feeding, as well as other, relationships in the DHH do not need to be exclusively human-machine in nature. In fact, they can take on an entire machine to machine structure with the human acting as overseer or maintenance provider. In this context, devices can be designed to venture out into the wider world and collect foodata. A similar interaction can be seen in projects such as PotPet which features a small four-wheeled robot that is able to drive itself and its plant outside for sun and water as well as communicating to a human that the plant requires watering [51]. The ability to view the interaction of machines collecting data for one another whilst maintaining the overall operation of the system could prove as pleasant and mesmerising as keeping fish.\r\n\r\n4.3.1   Carver . In this vein of thinking, we propose the use of the term vasculum as a possible class of wearables that can be used for active harvesting. In botany, a vasculum is a container used to collect botany samples. This type of wearable/carriable has existed for centuries and has appeared in many shapes, sizes and materials [2,12]. The variability in its design, connotations of sampling, collecting and storing and the relation to the explorative and informative practice of botany is why the term piqued our interest. We use the term to refer to the type of wearable that represents a counterpart to our periplus. The vasculum we designed, called Carver (after George Washington Carver, an avid botanist), combines a GPS and climate sensor with a colour sensor to create a wearable that collects passively and actively. The GPS and climate sensor will collect constantly whilst the colour sensor must be manually activated when an interesting colour is encountered. Carver, as a concept, has its origins in explorative navigation, specifically ways in which wearable/carriable devices can help us explore, and therefore potentially collect data from, space without the exact prescription of where one is going and/or how to get there. Specific inspiration can be found in projects such as Wandertroper [64], which uses a microphone and synthesising app to facilitate exploration by sampling sounds from the outside world, altering them with the synthesiser settings, and playing it back to the user through headphones. Another example, which isn\'t technically recognised as a navigation device, is the Datacatcher [31]. The Datacatcher concept was initially a carriable device to present and bring focus to matters such as socio-political issues and the power and breadth of big data. However, due to the location-based nature of the information, the device inadvertently prompts its users to explore their local space. What ties these two devices together is their ability to “augment” their user\'s capacity to engage with contextual data (in these cases sound and demographic data). Carver takes a similar approach and whereas with the other devices, one may alter their paths through space with thoughts such as “that sounds interesting” or “I wonder what life is like over there?”, Carver could lead to thoughts including “I like that colour” and “today is unseasonably cold, better get outside”. Whilst we consider the entire device to be a vasculum, the various sensors can be metaphorically seen as harvesting tools such as sickles or secateurs and the case, specific circuitry and code that deals with collecting, processing and storing the data to be the “true” vasculum. Both the Himilco and the Carver are members of the DHH, although they serve different purposes. However, peripli and vasculums are not exclusive to the DHH, they can exist as other devices with alternative objectives (Figure 2).\r\n\r\nFigure 2\r\nFigure 2 The relation of the DHH to peripli, vasculums, Himilco and Carver.\r\n5 and Beyond\r\n\r\nBy defining the DHH, populating it with various forms of buildings or devices and conceiving ways in which these members can be fed, the fundamental basis of the DHH has been established. To further develop these concepts and to embody the interactions between users and the DHH with weight and consequence, the addition of certain needs, traits and outcomes have been considered. It is the implementation of these factors into the functionality of members of the DHH that will permit them to appear more responsive, individual and alive (Figure 3). These enriched and nuanced interactions could lead to the formation of long-lasting relationships and bonds [7,93] as each member will effectively be “push[ing] our Darwinian buttons” [92:3]. This section attempts to create a semantical categorisation of various concepts considered within the context of the DHH. The first relates to various possible needs, as in what inputs or statuses each member could require to continue functioning. The second pertains to various traits the members could possess. These traits will impact how the entities will respond and consider inputs in terms of (dis)satisfying the needs. The third describes possible outcomes relating to the (dis)satisfaction of these needs in relation to the needs and personality of the entities. If certain internal criteria are met, different outputs or interactions are manifested. At this juncture, it is not vital to accurately distinguish between the three categories but to simply begin the discussion of what could be either a need, trait or outcome.\r\n\r\nFigure 3\r\nFigure 3 How a member of the DHH responds to inputs and generates outputs.\r\n5.1 Needs\r\n\r\nAt the core of the DHH paradigm is catering to, and the satisfaction of, needs manifested by each member. The preliminary need of members of the DHH is the supply of enough foodata but other needs are possible. This section briefly probes and describes some of the possible needs of the DHH.\r\n\r\n5.1.1   Foodata - Feeding Routines and Balance . As previously described, elements of the DHH require foodata. However, depending on the nature of the member, it may be able to sustain itself on a modicum of foodata for weeks/months (such as an alligator or cactus) or require several feedings a day (such as a human baby). As such, a great diversity in the interaction frequency with the DHH can be explored by experimentation. However, members should be fed with a given regularity and if a member is able to consume various types of data (see the omnivorous trait) then the member may also require a balanced diet.\r\n\r\n5.1.2   Sleep - Timing and Duration . Humans, other animals, and even plants (to some extent) sleep. This is a vital state, as it allows us to process what has happened during the day. The concept of sleep isn\'t unheard of in HCI, computers for examples can sleep or hibernate, however the closest approximation to a machine sleeping is the digital downtime process (such as that of the smart assistant) which effectively locks the user out of the devices between certain times of the day. In these situations, the devices aren\'t engaging in a different activity, such as dreaming or recovering. Sleep could be one of many other needs designed into members of the DHH. While sleeping, the member enters an alternate state where functionality is limited, and new activities can emerge (such as dreaming) and disturbing this state (i.e. waking it up) can have consequences. The time of day and duration of required sleep will vary from member to member.\r\n\r\n5.2 (Personality) Traits\r\n\r\nWith the diversification of artificial intelligence, internet of technology (IoT) devices and interaction concepts and theories, the existence of objects with personalities is ever increasing. However, what personalities can, or should, devices have? Personality, and similar social concepts such as anthropomorphism or behaviour, are a large focus in robotics (e.g. [25,49,56,60,62,73,74,96]). However, the idea of other devices, notably IoT devices, having personalities, and how that is undertaken, has also begun to gain interest. Pieroni et al. [70] propose “Affective IoT” as a framework that endows IoT products with feelings or personalities which impact how they behave in response to external and/or networked data-stimuli. Their preliminary work explores four personality types: explorer, researcher, celebrity and politician, each having their own formula and weighting for dealing with what they experience. Each personality generates different valence (positivity/negativity of an emotion) and arousal (intensity of the emotion) values based on the stimuli. The end result is a numerical fluctuating emotional state of the devices, although, in the context of their study, it doesn\'t impact what the devices do. Spadafora [86] and Spadafora et al. [87] suggest personality as a design method by employing metaphors of stereotypical personality traits (such as social, sombre, suspicious and calm) in the design of interactive product behaviours. This approach has been used to imbue drones with different personalities such as “the big boss” (a brave drone) or “the detached philosophers” (a grumpy drone) [19]. The various personalities, in this case, affect aspects of the drone\'s behaviour such as how it flies, what altitude it flies at and which specific actions it can execute. Annett et al. explore imbuing devices with more “paranormal” traits in their work [8]. They present several concepts of haunted devices that subtly (and spookily) interact with the humans in the room as well as offering a “haunted design framework” [8:1335]. In this context, we discuss various personality traits the members of DHH could embody as well as the concept of personality seeds. The type, variety and complexity of these, and other, traits will further render members of the DHH more individual and personal to each household.\r\n\r\n5.2.1   Degrees of Neediness - Baby, House Plant, Pet Rock . A simple way of understanding how members of the DHH can have degrees of neediness is to imagine a hypothetical “spectrum of neediness of things in the home” (see Figure 4) having at one end a human baby (which is very needy) and at the other a pet rock (that requires no attention at all). There are, of course, several different examples between these two extremes, such as house plants (ranging from the delicate orchid to the hardy cactus) and animal pets (including dogs, cats, fish, snails, etc.). Neediness or being needy as a concept and term aren\'t alien to the world of robotics [17,20] and design [3,9]. However, in the context of traits, neediness can be seen as a governing trait that affects the presence and strength of other traits. For example, if a DHH device has a high degree of neediness, it could require a very specific diet, require more than one feeding a day or gain traits such as neophobia.\r\n\r\nFigure 4\r\nFigure 4 The spectrum of neediness of things in the home.\r\n5.2.2   Consumption - Omnivorousness, Pickiness, Neophobia, Abstemiousness and Greediness . Our plants, pets, babies and selves all require specific types of food. The more complex and/or personality-imbued the entity we are feeding, the more specific the diet might be. We can simply water a plant, but humans require a diverse diet. Humans are omnivores, surviving by consuming a variety of foodstuffs. If this trait was integrated into a member of the DHH it would be able to be sustained on multiple data sources. Himilco, for example, is an omnivorous device, consuming various foodata sources in bundles. However, devices could also exist that survive on a single type of data. Building upon this, we all have personal tastes and occasional “pickiness” towards certain foods. Some don\'t like vegetables and others, fish. How might we reimagine concepts such as a picky eater or getting bored with the same meal every day? In this context, members of the DHH might be provided with the ability to reject certain types of foodata either because they don\'t like it (type/taste) or because the data provided to them have become boring or dull (e.g. if you take the same route to work every day). At the other end of the spectrum, DHH members could start with or gain foodata neophobia, a reluctance to or fear of new foodata. This would mean that the members in question would need a very specific set of data fed to them. These first three traits are related to how a member might respond to the quality or type of foodata. In terms of quantity, traits such as abstemiousness (abstaining from foodata or consuming in moderation) and greediness could be used.\r\n\r\n5.2.3   Sleep - Early Bird, Night Owl, Dysania and Insomnia . The terms “early bird” and “night owl” refer to whether a person prefers to get up early in the morning or stay up late at night. These are typically neutral, factual traits used to describe an individual and could be integrated into members of the DHH, potentially leading to devices waking up or going to bed before, after or with individuals, depending on sleep patterns. On the other hand, many people struggle with some or many of the stages of sleep. Dysania is a term used to describe a difficulty when waking up and getting out of bed whereas insomnia conveys a sleeplessness or an inability to get to sleep. Whereas an early bird is able to get up in the morning or a night owl can stay up late, members with dysania or insomnia will be more tired and have greater reduced functionality at certain points of the day.\r\n\r\n5.2.4   Personality Seeds . In computer science, a “seed” is a number given to a computer that it uses to generate random numbers. There are two basic types, a fixed seed (which generates pseudorandom or predictable random numbers) and a fluctuating seed (that can generate “truly” random numbers). This seed approach is used in videogames such as Minecraft to procedurally generate maps by passing the seed number through an algorithm [4:22]. In Minecraft, if one player finds a seed number that generates a world they enjoy, they can share it with others to generate the same world. What if this concept was transplanted and reimagined in the context of the DHH? Imagine if the personality traits described above had a certain amount of randomness or ambiguity governed by a unique seed for each individual device. This would give each device a quasi-unique personality and a further semblance of agency that begins to approach that of a pet (e.g. dog, cat, etc.), whilst also allowing people to share seeds between devices (as if you could reprogram your cat to match a friend\'s). Advancing this further, the seeds could be “truly” randomised by using fluctuating factors such exact times of day, phases of the moon, weather and so on. This could give the home/devices traits, such as mood swings or unpredictability. However, the opportunity to explore personalities that are neither typical machine nor human-like should also be considered. If a plant evolved a personality what would that be like? Are there traits that can be embodied by a device that cannot be anthropomorphised?\r\n\r\n5.3 Outcomes\r\n\r\nIn this context, the term outcome refers to the result of the evaluation of the (dis)satisfaction of needs against the influence of personality traits. Fulfilling needs will lead to positive or desirable outcomes and neglecting them results in negative outcomes. Furthermore, certain outcomes must occur in order for the output or interaction between the DHH member and the user, or other members, to occur. This subsection will discuss some of the possible outcomes relating to needs from the previous subsection.\r\n\r\n5.3.1   Foodata - Satisfaction, Lipogenesis and Starvation . The optimum outcome of feeding a member of the DHH is satisfaction. This occurs when all of the needs relating to foodata are met, however other outcomes can occur depending on the amount of foodata and other factors. The metabolic processes lipogenesis can be understood as the process of storing energy/nutrients in fat. Fat is a useful medium to store energy when there is an abundance of food, releasing that energy when there is not. From the perspective of the DHH, this process can be reimagined in two parts, virtually and physically. The virtual aspect would take the form of internal memory used as “fat stores”. These stores would hold unconsumed foodata collected over time for ingesting during a period when no foodata is being provided. The physical effect of this data lipogenesis could take multiple forms. For example, by employing the techniques and possibilities seen in shape changing interfaces/devices [1,24,53,67,72] a device in the DHH could literally become “fat” with data and then lose it when it is consumed. Furthermore, if a device were to become “obese” with data, it could exhibit a lack of fitness or health through a sluggishness in executing outputs. In the most extreme circumstances, the device could be fed so much it could die. On the other end of the spectrum, but with an equal outcome, members could also be starved of food meaning that they can represent becoming emaciated, lose their strength to perform interactions and, ultimately, die.\r\n\r\n5.3.2   Sleep - Well-rested-ness, Dreams, Tiredness and Nightmares . When someone has a good night\'s sleep, they “slept like a log” whereas a person of poor temperament “got out of the wrong side of the bed”. In other words, the quality of sleep is deeply integrated into our language, and outcomes of sleep can have positive and negative results. For members of the DHH, sleep can equally play an important role. When a member sleeps it will enter an alternate state than when it is awake and will have access to otherwise unreachable functionalities. This state, however, can be interrupted or not last long enough, leading to consequences. If a member has a good night/day\'s sleep it will be able to dream, manifest specific movements (similar to twitching and eye movements in human sleep) and undergo dedicated actions (such as sorting data), emerging well-rested and able to function normally. However, if the member does not get a good night\'s sleep, it will be tired and sluggish. Under certain circumstances, the device may experience nightmares. These can be brought about by external and internal factors, such as what is going on in the home or perhaps diet, e.g. “cheese” foodata before bed.\r\n\r\n6 Conclusion\r\n\r\nWe, as a species, gather and care for various companions in our homes, providing them with a safe and well-maintained existence, sometimes for little or no recompense. In return for our efforts, plants may filter our air, flower or produce fruit, a cat may sit on our laps or keep us company, however, they may not, and yet we continue providing for them. Equally, the acquisition, preparation and provision of food is a key part of relationship building across all facets of human life and culture. Devices have come to play an integral part in our daily lives and, as a result of current (and future) technology, have the potential to occupy an interesting middle ground between the truly animate and the truly inanimate. This paper explores the theoretical concept of the Data Hungry Home, a place in which the role and position of devices in our lives is elevated to something akin to pets, houseplants or even acquaintances. It does so by positing an initial definition of the DHH, exploring ways in which a DHH could be constructed and populated with technology. From this theoretical foundation we critically explore and question the forms that interactive technology might take (e.g. Carver and Himilco) and challenge the relationship between, and roles adopted by, devices and their owners suggesting a much more symbiotic relationship where the varying needs of the device and the wider DHH, in terms of foodata, are anticipated, met and, indeed, rewarded potentially through the act of acquisition as well as in response to the feeding. To achieve this outcome, we anticipate that members of the DHH would be imbued with traits akin to personalities, needs including a varied (or specific) diet and periods of sleep as well as behaviours. This concept identifies an interesting niche within which there is the potential for interactive devices to evolve into a role based on mutual fulfilment and satisfaction, not simply information. Through the exploration of these ideas, we will be able to explore and expand upon our expectation and presumptions of what interactions and relationships can be built with a home and its contents. Furthermore, pursuing the DHH and similar avenues can contribute to the realm of HCI as well as research that looks at the lifelikeness [18,77], individuation [5] and agency of artefacts [23], human-computer relationships or companionships [15], and the quantified self [57]. Finally, the next steps this work should look to create and trial members, explore more needs, traits and outcomes and flip the lens to look at a data hungry street, neighbourhood and city.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis research is being conducted with the funding and support of the EPSRC Centre for Doctoral Training in Embedded Intelligence (under grant reference EP/L014998/1), Loughborough University and Ordnance Survey. The authors would like to extend their thanks to the reviewers for their helpful feedback and advice.\r\n\r\nREFERENCES\r\n\r\nJason Alexander, Anne Roudaut, Jürgen Steimle, Kasper Hornbæk, Miguel Bruns Alonso, Sean Follmer, and Timothy Merritt. 2018. Grand Challenges in Shape-Changing Interface Research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18, 1–14. DOI: https://doi.org/10.1145/3173574.3173873  \r\nD E Allen. 1959. The History of the Vasculum. In Proceedings of the Botanical Society of the British Isles, 135–150.  \r\nPhilip van Allen, Joshua McVeigh-Schultz, Brooklyn Brown, Hye Mi Kim, and Daniel Lara. 2013. AniThings: Animism and Heterogeneous Multiplicity. In CHI ’13 Extended Abstracts on Human Factors in Computing Systems on - CHI EA ’13, 2247. DOI: https://doi.org/10.1145/2468356.2468746  \r\nAlba Amato. 2017. Procedural Content Generation in the Game Industry. In Game Dynamics, Oliver Korn and Newton Lee (eds.). Springer International Publishing, Cham, 15–25. DOI: https://doi.org/10.1007/978-3-319-53088-8_2  \r\nAloha Hufana Ambe, Margot Brereton, Alessandro Soro, and Paul Roe. 2017. Technology Individuation: The Foibles of Augmented Everyday Objects. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17, 6632–6644. DOI: https://doi.org/10.1145/3025453.3025770  \r\nZann Benjamin Anderson. 2017. “I Can Physically Feel the Difference”: Exploring Physicalizations of Running Data. Brigham Young University.  \r\nLeonardo Angelini, Nadine Couture, Omar Abou Khaled, and Elena Mugellini. 2017. Internet of Tangible Things (IoTT): Challenges and Opportunities for Tangible Interaction with IoT. (2017), 1–34. DOI: https://doi.org/10.3390/informatics5010007  \r\nMichelle Annett, Matthew Lakier, Franklin Li, Daniel Wigdor, Tovi Grossman, and George Fitzmaurice. 2016. The Living Room: Exploring the Haunted and Paranormal to Transform Design and Interaction. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems - DIS ’16, 1328–1340. DOI: https://doi.org/10.1145/2901790.2901819  \r\nJames Henry Auger. 2014. Living With Robots: A Speculative Design Approach. J. Human-Robot Interact.3, 1 (2014), 20. DOI: https://doi.org/10.5898/JHRI.3.1.Auger  \r\nSaskia Bakker, Elise van den Hoven, and Berry Eggen. 2015. Peripheral interaction: characteristics and considerations. Pers. Ubiquitous Comput.19, 1 (2015), 239–254. DOI: https://doi.org/10.1007/s00779-014-0775-2  \r\nSaskia Bakker, Elise van den Hoven, and Berry Eggen. 2015. Evaluating Peripheral Interaction Design. Human–Computer Interact.30, 6 (November 2015), 473–506. DOI: https://doi.org/10.1080/07370024.2014.921531  \r\nH G Barker. 1958. Origin of the Vasculum. In Proceedings of the Botanical Society of the British Isles, 41–43.  \r\nJacob Beaver, Andy Boucher, and Sarah Pennington. 2007. The Curious Home. Goldsmiths University of London, London.  \r\nSteve Benford, Chris Greenhalgh, Gabriella Giannachi, Brendan Walker, Joe Marshall, and Tom Rodden. 2012. Uncomfortable Interactions. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI’12, 2005. DOI: https://doi.org/10.1145/2207676.2208347  \r\nDavid Benyon and Oli Mival. 2010. From human-computer interactions to human-companion relationships. In Proceedings of the First International Conference on Intelligent Interactive Technologies and Multimedia - IITM ’10, 1–9. DOI: https://doi.org/10.1145/1963564.1963565  \r\nArne Berger, William Odom, Michael Storz, Andreas Bischof, Albrecht Kurze, and Eva Hornecker. 2019. The Inflatable Cat: Idiosyncratic Ideation Of Smart Objects For The Home. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19, 1–12. DOI: https://doi.org/10.1145/3290605.3300631  \r\nVanessa Budde, Nils Backhaus, Patricia H. Rosen, and Sascha Wischniewski. 2018. Needy Robots - Designing Requests for Help Using Insights from Social Psychology. In2018 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO), 48–53. DOI: https://doi.org/10.1109/ARSO.2018.8625724  \r\nIrem Cakiroglu and Cigdem Kaya Pazarbasi. 2019. Critical Design in Daily Life: Lifelike Products. Des. J.22, sup1 (April 2019), 1227–1234. DOI: https://doi.org/10.1080/14606925.2019.1594987  \r\nJessica R. Cauchard, Kevin Y. Zhai, Marco Spadafora, and James A. Landay. 2016. Emotion encoding in human-drone interaction. ACM/IEEE Int. Conf. Human-Robot Interact.2016-April, (2016), 263–270. DOI: https://doi.org/10.1109/HRI.2016.7451761  \r\nCatherine Caudwell and Cherie Lacey. 2019. What do home robots want? The ambivalent power of cuteness in robotic relationships. Convergence (2019), 1–13. DOI: https://doi.org/10.1177/1354856519837792  \r\nJustin Cheng, Akshay Bapat, Gregory Thomas, Kevin Tse, Nikhil Nawathe, Jeremy Crockett, and Gilly Leshed. 2011. GoSlow: Designing for Slowness, Reflection and Solitude. In Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems - CHI EA ’11, 429. DOI: https://doi.org/10.1145/1979742.1979622  \r\nPadma Chirumamilla and Joyojeet Pal. 2013. Play and Power: a Ludic Design Proposal for ICTD. In Proceedings of the Sixth International Conference on Information and Communication Technologies and Development Full Papers - ICTD ’13 - volume 1, 25–33. DOI: https://doi.org/10.1145/2516604.2516628  \r\nNazli Cila, Iskander Smit, Elisa Giaccardi, and Ben Kröse. 2017. Products as Agents: Metaphors for Designing the Products of the IoT Age. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17, 448–459. DOI: https://doi.org/10.1145/3025453.3025797  \r\nMarcelo Coelho and Jamie Zigelbaum. 2011. Shape-changing interfaces. Pers. Ubiquitous Comput.15, 2 (February 2011), 161–173. DOI: https://doi.org/10.1007/s00779-010-0311-y  \r\nBrian R. Duffy. 2003. Anthropomorphism and the social robot. Rob. Auton. Syst.42, 3–4 (March 2003), 177–190. DOI: https://doi.org/10.1016/S0921-8890(02)00374-3  \r\nJoep Frens. 2017. Designing for Embodied and Rich Interaction in Home IoT. In Proceedings of the Conference on Design and Semantics of Form and Movement - Sense and Sensitivity, DeSForM 2017. InTech, 64. DOI: https://doi.org/10.5772/intechopen.71130  \r\nBill Gaver. 2002. Designing for Homo Ludens, Still. I3 Mag.12 (2002), 2–6.  \r\nBill Gaver. 2007. Conclusion: The Anatomy of a Wave. In The Curious Home, Jacob Beaver, Andy Boucher and Sarah Pennington (eds.). Goldsmiths University of London, London, 5–10.  \r\nWilliam Gaver, Andy Boucher, Michail Vanis, Andy Sheen, Dean Brown, Liliana Ovalle, Naho Matsuda, Amina Abbas-Nazari, and Robert Phillips. 2019. My Naturewatch Camera: Disseminating Practice Research with a Cheap and Easy DIY Design. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19, 1–13. DOI: https://doi.org/10.1145/3290605.3300532  \r\nWilliam Gaver, John Bowers, Andrew Boucher, Andy Law, Sarah Pennington, and Brendan Walker. 2007. Electronic Furniture for the Curious Home: Assessing Ludic Designs in the Field. Int. J. Hum. Comput. Interact.22, 1–2 (April 2007), 119–152. DOI: https://doi.org/10.1080/10447310709336958  \r\nWilliam Gaver, Liliana Ovalle, Andy Boucher, Nadine Jarvis, David Cameron, Mark Hauenstein, Sarah Pennington, John Bowers, James Pike, and Robin Beitra. 2016. The Datacatcher: Batch Deployment and Documentation of 130 Location-Aware, Mobile Devices That Put Sociopolitically-Relevant Big Data in People\'s Hands: Polyphonic Interpretation at Scale. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16, 1597–1607. DOI: https://doi.org/10.1145/2858036.2858472  \r\nWilliam Gaver, Alex Wilkie, Andy Boucher, Andy Law, Sarah Pennington, John Bowers, Jacob Beaver, Jan Humble, Tobie Kerridge, and Nicholas Villar. 2008. Threshold Devices: Looking Out From The Home. In Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems - CHI ’08, 1429–1438. DOI: https://doi.org/10.1145/1357054.1357278  \r\nMaliheh Ghajargar and Mikael Wiberg. 2018. Thinking with Interactive Artifacts: Reflection as a Concept in Design Outcomes. Des. Issues 34, 2 (April 2018), 48–63. DOI: https://doi.org/10.1162/DESI_a_00485  \r\nMaliheh Ghajargar, Mikael Wiberg, and Erik Stolterman. 2018. Designing IoT Systems that Support Reflective Thinking: A Relational Approach. Int. J. Des.12, (2018), 21–35.  \r\nMathieu Le Goc, Charles Perin, Sean Follmer, Jean-daniel Fekete, and Pierre Dragicevic. 2019. Dynamic Composite Data Physicalization Using Wheeled Micro-Robots. IEEE Trans. Vis. Comput. Graph.25, 1 (January 2019), 737–747. DOI: https://doi.org/10.1109/TVCG.2018.2865159  \r\nLars Hallnäs and Johan Redström. 2001. Slow Technology – Designing for Reflection. Pers. Ubiquitous Comput.5, 3 (August 2001), 201–212. DOI: https://doi.org/10.1007/PL00000019  \r\nSabrina Hauser, Ron Wakkary, William Odom, Peter-Paul Verbeek, Audrey Desjardins, Henry Lin, Matthew Dalton, Markus Schilling, and Gijs de Boer. 2018. Deployments of the table-non-table: A Reflection on the Relation Between Theory and Things in the Practice of Design Research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18, 1–13. DOI: https://doi.org/10.1145/3173574.3173775  \r\nTrevor Hogan, Eva Hornecker, Simon Stusak, Yvonne Jansen, Jason Alexander, Andrew Vande Moere, Uta Hinrichs, and Kieran Nolan. 2016. Tangible Data, explorations in data physicalization. In Proceedings of the TEI ’16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction - TEI ’16, 753–756. DOI: https://doi.org/10.1145/2839462.2854112  \r\nSteven Houben, Connie Golsteijn, Sarah Gallacher, Rose Johnson, Saskia Bakker, Nicolai Marquardt, Licia Capra, and Yvonne Rogers. 2016. Physikit: Data Engagement Through Physical Ambient Visualizations in the Home. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16, 1608–1619. DOI: https://doi.org/10.1145/2858036.2858059  \r\nNoura Howell, Greg Niemeyer, and Kimiko Ryokai. 2019. Life-Afirming Biosensing in Public: Sounding Heartbeats on a Red Bench. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19, 1–16. DOI: https://doi.org/10.1145/3290605.3300910  \r\nHiroshi Ishii. 2008. Tangible Bits: Beyond Pixels. In Proceedings of the 2nd international conference on Tangible and embedded interaction - TEI ’08, xv. DOI: https://doi.org/10.1145/1347390.1347392  \r\nHiroshi Ishii and Brygg Ullmer. 1997. Tangible bits. In Proceedings of the SIGCHI conference on Human factors in computing systems - CHI ’97, 234–241. DOI: https://doi.org/10.1145/258549.258715  \r\nHiroshi Ishii, Craig Wisneski, Scott Brave, Andrew Dahley, Matt Gorbet, Brygg Ullmer, and Paul Yarin. 1998. ambientROOM: Integrating Ambient media with Architectural Space. In CHI 98 conference summary on Human factors in computing systems - CHI ’98, 173–174. DOI: https://doi.org/10.1145/286498.286652 \r\nNils Jäger. 2017. Interacting with adaptive architecture. interactions 24, 6 (October 2017), 62–65. DOI: https://doi.org/10.1145/3137113  \r\nNils Jäger, Holger Schnädelbach, Jonathan Hale, David Kirk, and Kevin Glover. 2017. Reciprocal Control in Adaptive Environments. Interact. Comput.29, 4 (January 2017), 512–529. DOI: https://doi.org/10.1093/iwc/iww037  \r\nYvonne Jansen, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, and Kasper Hornbæk. 2015. Opportunities and Challenges for Data Physicalization. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI ’15, 3227–3236. DOI: https://doi.org/10.1145/2702123.2702180  \r\nRikke Hagensby Jensen, Yolande Strengers, Jesper Kjeldskov, Larissa Nicholls, and Mikael B. Skov. 2018. Designing the Desirable Smart Home: A Study of Household Experiences and Energy Consumption Impacts. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18, 1–14. DOI: https://doi.org/10.1145/3173574.3173578  \r\nRikke Hagensby Jensen, Yolande Strengers, Dimitrios Raptis, Larissa Nicholls, Jesper Kjeldskov, and Mikael B. Skov. 2018. Exploring Hygge as a Desirable Design Vision for the Sustainable Smart Home. In Proceedings of the 2018 Designing Interactive Systems Conference - DIS ’18, 355–360. DOI: https://doi.org/10.1145/3196709.3196804  \r\nMichiel Joosse, Manja Lohse, Jorge Gallego Perez, and Vanessa Evers. 2013. What you do is who you are: The role of task context in perceived social robot personality. In2013 IEEE International Conference on Robotics and Automation, 2134–2139. DOI: https://doi.org/10.1109/ICRA.2013.6630863  \r\nSomi Ju, Kyung-Ryong Lee, Subin Kim, and Young-Woo Park. 2019. Bookly: An Interactive Everyday Artifact Showing the Time of Physically Accumulated Reading Activity. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19, 1–8. DOI: https://doi.org/10.1145/3290605.3300614  \r\nAyumi Kawakami, Koji Tsukada, Keisuke Kambara, and Itiro Siio. 2011. PotPet: Pet-like Flowerpot Robot. In Proceedings of the fifth international conference on Tangible, embedded, and embodied interaction - TEI ’11, 263. DOI: https://doi.org/10.1145/1935701.1935755  \r\nAnnakaisa Kultima, Timo Nummenmaa, Heikki Tyni, Kati Alha, Jaakko Stenros, Ville Kankainen, Jussi Holopainen, and Frans Mäyrä. 2018. Playful Furniture: Breaching a Serious Setting With Interactive Seats. Games Cult.13, 3 (2018), 301–321. DOI: https://doi.org/10.1177/1555412017718749  \r\nMatthijs Kwak, Kasper Hornbæk, Panos Markopoulos, and Miguel Bruns Alonso. 2014. The Design Space of Shape-changing Interfaces: A Repertory Grid Study. In Proceedings of the 2014 conference on Designing interactive systems - DIS ’14, 181–190. DOI: https://doi.org/10.1145/2598510.2598573  \r\nDavid Lakatos and Hiroshi Ishii. 2012. Towards Radical Atoms – Form-giving to Transformable Materials. In2012 IEEE 3rd International Conference on Cognitive Infocommunications (CogInfoCom), 37–40. DOI: https://doi.org/10.1109/CogInfoCom.2012.6422023  \r\nMatthew Lee-Smith, Tracy Ross, Martin Maguire, Fung Po Tso, Jeremy Morley, and Stefano Cavazzi. 2019. What Can We Expect from Navigating? Exploring Navigation, Wearables and Data Through Critical Design Concepts. In Companion Publication of the 2019 on Designing Interactive Systems Conference 2019 Companion - DIS ’19 Companion, 237–244. DOI: https://doi.org/10.1145/3301019.3323889  \r\nKwan Min Lee, Wei Peng, Seung-A Jin, and Chang Yan. 2006. Can Robots Manifest Personality?: An Empirical Test of Personality Recognition, Social Responses, and Social Presence in Human–Robot Interaction. J. Commun.56, 4 (December 2006), 754–772. DOI: https://doi.org/10.1111/j.1460-2466.2006.00318.x  \r\nDeborah Lupton. 2016. The Quantified Self (1st ed.). Polity Press.  \r\nBetti Marenko. 2014. Neo-Animism and Design. Des. Cult.6, 2 (2014), 219–241. DOI: https://doi.org/10.2752/175470814X14031924627185  \r\nBetti Marenko and Philip van Allen. 2016. Animistic design: how to reimagine digital interaction between the human and the nonhuman. Digit. Creat.27, 1 (2016), 52–70. DOI: https://doi.org/10.1080/14626268.2016.1145127  \r\nBernt Meerbeek, Martin Saerbeck, and Christoph Bartneck. 2009. Iterative Design Process for Robots With Personality. In Proceedings of the AISB2009 Symposium on New Frontiers in Human-Robot Interaction, 94–101.  \r\nSarah Mennicken, James Scott, A. J. Bernheim Brush, and Asta Roseway. 2014. Finding roles for interactive furniture in homes with EmotoCouch. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct Publication - UbiComp ’14 Adjunct, 923–930. DOI: https://doi.org/10.1145/2638728.2641547  \r\nAlexandros Mileounis, Raymond H. Cuijpers, and Emilia I. Barakova. 2015. Creating Robots with Personality: The Effect of Personality on Social Intelligence. In Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). 119–132. DOI: https://doi.org/10.1007/978-3-319-18914-7_13  \r\nIne Mols, Elise van den Hoven, and Berry Eggen. 2016. Technologies for Everyday Life Reflection: Illustrating a Design Space. In Proceedings of the TEI ’16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction - TEI ’16, 53–61. DOI: https://doi.org/10.1145/2839462.2839466  \r\nBeatrice Monastero, David McGookin, and Giuseppe Torre. 2016. Wandertroper: Supporting Aesthetic Engagement with Everyday Surroundings through Soundscape Augmentation. In Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia - MUM ’16, 129–140. DOI: https://doi.org/10.1145/3012709.3012725  \r\nJulien Nembrini and Denis Lalanne. 2017. Human-Building Interaction: When the Machine Becomes a Building. In Human-Computer Interaction INTERACT ’97, Regina Bernhaupt, Girish Dalvi, Anirudha Joshi, Devanuj K. Balkrishan, Jacki O\'Neill and Marco Winckler (eds.). Springer International Publishing, Cham, 348–369. DOI: https://doi.org/10.1007/978-3-319-67684-5_21  \r\nRachel S. Ng, Raghavendra Kandala, Sarah Marie-Foley, Dixon Lo, Molly Wright Steenson, and Austin S. Lee. 2016. Expressing Intent: An Exploration of Rich Interactions. In Proceedings of the TEI ’16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction - TEI ’16, 524–531. DOI: https://doi.org/10.1145/2839462.2856526  \r\nMie Nørgaard, Tim Merritt, Majken Kirkegaard Rasmussen, and Marianne Graves Petersen. 2013. Exploring the Design Space of Shape-Changing Objects: Imagined Physics. In Proceedings of the 6th International Conference on Designing Pleasurable Products and Interfaces - DPPI ’13, 251–260. DOI: https://doi.org/10.1145/2513506.2513533  \r\nWilliam Odom, Abigail Sellen, Richard Banks, David Kirk, Tim Regan, Mark Selby, Jodi L. Forlizzi, and John Zimmerman. 2014. Designing for Slowness, Anticipation and Re-visitation: A Long Term Field Study of the Photobox. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI ’14, 1961–1970. DOI: https://doi.org/10.1145/2556288.2557178  \r\nWilliam Odom, Ron Wakkary, Jeroen Hol, Bram Naus, Pepijn Verburg, Tal Amram, and Amy Yo Sue Chen. 2019. Investigating Slowness as a Frame to Design Longer-Term Experiences with Personal Data: A Field Study of Olly. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19, 1–16. DOI: https://doi.org/10.1145/3290605.3300264  \r\nMichael Pieroni, Lorenzo Rizzello, Niccolo Rosini, Gualtiero Fantoni, Danilo De Rossi, and Daniele Mazzei. 2015. Affective Internet of Things: Mimicking human-like personality in designing smart-objects. In2015 IEEE 2nd World Forum on Internet of Things (WF-IoT), 400–405. DOI: https://doi.org/10.1109/WF-IoT.2015.7389088  \r\nZachary Pousman and John Stasko. 2006. A Taxonomy of Ambient Information Systems: Four Patterns of Design. In Proceedings of the working conference on Advanced visual interfaces - AVI ’06, 67. DOI: https://doi.org/10.1145/1133265.1133277  \r\nMajken K. Rasmussen, Esben W. Pedersen, Marianne G. Petersen, and Kasper Hornbæk. 2012. Shape-Changing Interfaces: A Review of the Design Space and Open Research Questions. In Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems - CHI ’12, 735. DOI: https://doi.org/10.1145/2207676.2207781  \r\nHannes Ritschel and Elisabeth André. 2017. Real-Time Robot Personality Adaptation based on Reinforcement Learning and Social Signals. In Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction - HRI ’17, 265–266. DOI: https://doi.org/10.1145/3029798.3038381  \r\nHannes Ritschel, Ilhan Aslan, David Sedlbauer, and Elisabeth André. 2019. Irony Man : Augmenting a Social Robot with the Ability to Use Irony in Multimodal Communication with Humans Socially Interactive Agents Track. In Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS ’19), 86–94.  \r\nYvonne Rogers. 2006. Moving on from Weiser\'s Vision of Calm Computing: Engaging UbiComp Experiences. In Proceedings of the 8th international conference on Ubiquitous Computing - UbiComp’06, 404–421. DOI: https://doi.org/10.1007/11853565_24  \r\nYvonne Rogers, William R. Hazlewood, Paul Marshall, Nick Dalton, and Susanna Hertrich. 2010. Ambient Influence: Can Twinkly Lights Lure and Abstract Representations Trigger Behavioral Change? In Proceedings of the 12th ACM international conference on Ubiquitous computing - Ubicomp ’10, 261. DOI: https://doi.org/10.1145/1864349.1864372  \r\nYea-Kyung Row and Tek-Jin Nam. 2016. Understanding Lifelike Characteristics in Interactive Product Design. Arch. Des. Res.29, 3 (August 2016), 25. DOI: https://doi.org/10.15187/adr.2016.08.29.3.25  \r\nKim Sauvé, Steven Houben, Nicolai Marquardt, Saskia Bakker, Bart Hengeveld, Sarah Gallacher, and Yvonne Rogers. 2017. LOOP: A Physical Artifact to Facilitate Seamless Interaction with Personal Data in Everyday Life. In Proceedings of the 2017 ACM Conference Companion Publication on Designing Interactive Systems - DIS ’17 Companion, 285–288. DOI: https://doi.org/10.1145/3064857.3079175  \r\nHolger Schnädelbach, Ainojie Irune, David Kirk, Kevin Glover, and Patrick Brundell. 2012. ExoBuilding: Physiologically driven adaptive architecture. ACM Trans. Comput. Interact.19, 4 (2012), 1–22. DOI: https://doi.org/10.1145/2395131.2395132  \r\nLinda See, Jacinto Estima, Andrea Pődör, Jamal Jokar Arsanjani, Juan-Carlos Laso Bayas, and Rumiana Vatseva. 2017. Sources of VGI for Mapping. In Mapping and the Citizen Sensor, Giles Foody, Linda See, Steffen Fritz, Peter Mooney, Ana-Maria Olteanu-Raimond, Cidália Costa Fonte and Vyron Antoniou (eds.). Ubiquity Press, 13–35. DOI: https://doi.org/10.5334/bbf.b  \r\nPhoebe Sengers, Kirsten Boehner, Shay David, and Joseph “Jofish” Kaye. 2005. Reflective design. In Proceedings of the 4th decennial conference on Critical computing between sense and sensibility - CC ’05, 49. DOI: https://doi.org/10.1145/1094562.1094569  \r\nGeraint Rhys Sethu-Jones, Yvonne Rogers, and Nicolai Marquardt. 2017. Data in the Garden: A Framework For Exploring Provocative Prototypes as Part of Research In The Wild. In Proceedings of the 29th Australian Conference on Computer-Human Interaction - OZCHI ’17, 318–327. DOI: https://doi.org/10.1145/3152771.3152805  \r\nJaime Snyder, Mark Matthews, Jacqueline Chien, Pamara F. Chang, Emily Sun, Saeed Abdullah, and Geri Gay. 2015. MoodLight: Exploring Personal and Social Implications of Ambient Display of Biosensor Data. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing - CSCW ’15, 143–153. DOI: https://doi.org/10.1145/2675133.2675191  \r\nAlessandro Soro, Margot Brereton, Tshering Dema, Jessica L Oliver, Min Zhen Chai, and Aloha May Hufana Ambe. 2018. The Ambient Birdhouse: An IoT device to Discover Birds and Engage with Nature. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18, 1–13. DOI: https://doi.org/10.1145/3173574.3173971  \r\nRicardo Sosa, Victoria Gerrard, Antonio Esparza, Rebeca Torres, and Robbie Napper. 2018. DATA OBJECTS: DESIGN PRINCIPLES FOR DATA PHYSICALISATION. In Proceedings of International Design Conference, DESIGN, 1685–1696. DOI: https://doi.org/10.21278/idc.2018.0125  \r\nMarco Spadafora. 2015. Object\'s Personality, a Tool to Chase an Aesthetic Approach in the Design of Smart Objects. In Design and semantics of form and movement (DeSForM 2015): Aesthetics of interaction: Dynamic, Multisensory, Wise.  \r\nMarco Spadafora, Victor Chahuneau, Nikolas Martelaro, David Sirkin, and Wendy Ju. 2016. Designing the Behavior of Interactive Objects. In Proceedings of the TEI ’16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction - TEI ’16, 70–77. DOI: https://doi.org/10.1145/2839462.2839502  \r\nSimon Stusak. 2016. Exploring the potential of physical visualizations. Ludwig Maximilian University of Munich.  \r\nSimon Stusak, Aurelien Tabard, Franziska Sauka, Rohit Ashok Khot, and Andreas Butz. 2014. Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity. IEEE Trans. Vis. Comput. Graph.20, 12 (December 2014), 2201–2210. DOI: https://doi.org/10.1109/TVCG.2014.2352953  \r\nNam Tek-Jin and Kim Changwon. 2011. Design by Tangible Stories: Enriching Interactive Everyday Products with Ludic Value. Int. J. Des.5:1, 1 (2011), 1–16.  \r\nAlice Thudt, Uta Hinrichs, Samuel Huron, and Sheelagh Carpendale. 2018. Self-Reflection and Personal Physicalization Construction. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18, 1–13. DOI: https://doi.org/10.1145/3173574.3173728  \r\nSherry Turkle. 2010. In good company? On the threshold of robotic companions. In Close Engagements with Artificial Companions: Key social, psychological, ethical and design issues, Yorick Wilks (ed.). John Benjamins Publishing Company, 3–10. DOI: https://doi.org/10.1075/nlp.8  \r\nKate Vaisutis, Margot Brereton, Toni Robertson, Frank Vetere, Jeannette Durick, Bjorn Nansen, and Laurie Buys. 2014. Invisible Connections: Investigating Older People\'s Emotions and Social Relations Around Objects. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI ’14, 1937–1940. DOI: https://doi.org/10.1145/2556288.2557314  \r\nMark Weiser and John Seely Brown. 1997. The Coming Age of Calm Technology. In Beyond Calculation, Peter J. Denning and Robert M. Metcalfe (eds.). Springer New York, New York, NY, 75–85. DOI: https://doi.org/10.1007/978-1-4612-0685-9_6  \r\nCraig Wisneski, Hiroshi Ishii, Andrew Dahley, Matt Gorbet, Scott Brave, Brygg Ullmer, and Paul Yarin. 1998. Ambient Displays: Turning Architectural Space into an Interface between People and Digital Information. In Cooperative Buildings: Integrating Information, Organization, and Architecture. 22–32. DOI: https://doi.org/10.1007/3-540-69706-3_4  \r\nSarah Woods, Kerstin Dautenhahn, Christina Kaouri, R. Boekhorst, and Kheng Lee Koay. 2005. Is This Robot Like Me? Links Between Human and Robot Personality Traits. In5th IEEE-RAS International Conference on Humanoid Robots, 2005., 375–380. DOI: https://doi.org/10.1109/ICHR.2005.1573596  ',1,'Lee-Smith','Matthew Lee-Smith, Tracy Ross, Martin Maguire, Fung Po Tso, Jeremy Morley, and Stefano Cavazzi','Matthew Lee-Smith *(Loughborough Design School, Loughborough University, UK)*<br>\r\nTracy Ross *(Loughborough Design School, Loughborough University UK)*<br>\r\nMartin Maguire *(Loughborough Design School, Loughborough University, UK)*<br>\r\nFung Po Tso *(Department of Computer Science, Loughborough University, UK)*<br>\r\nJeremy Morley *(Ordnance Survey, UK)*<br>\r\nStefano Cavazzi *(Ordnance Survey, UK)*<br>',NULL,0,'10.1145/3363384.3363390','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,55,10,NULL,NULL,0,6),(29,'kim-growable-invisible-connected-toys-twitching-towards-ubiquitous-bacterial-computing','2019-09-02 15:24:57','2019-11-14 14:12:34','2019-09-02 15:24:57',NULL,1,'published','[]','Growable, Invisible, Connected Toys: Twitching Towards Ubiquitous Bacterial Computing','With the help of advances in synthetic biology, scientists are beginning to create early forms of bacteria computers, driven by artificial DNA circuits. We identify two immediate opportunities that would benefit the HCI and ubiquitous computing communities in better engagement with such developments. These are 1) The broadened curriculum for basic biological training and education, and 2) Increasingly shifting perception of living matter as hardware in interaction design. We introduce MouldCraft, a smartphone-controlled edutainment console, designed to facilitate playful interactions between humans and living micro-organisms. Main objectives of the console are to teach basic concepts in microbiology, and to re-frame the notion of bacterium as a growable, invisible, and connected ‘toy’, that can sense, actuate and communicate with computer systems and humans. With its accessible modular and interchangeable components, MouldCraft can be a timely toolkit for those outside of professional labs to start engaging with bacteria and their possible futures.','Raphael Kim and Stefan Poslad. 2019. Growable, Invisible, Connected Toys: Twitching Towards Ubiquitous Bacterial Computing. In *Proceedings of Halfway to the Future (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 9 pages. [https://doi.org/10.1145/3363384.3363387](https://doi.org/10.1145/3363384.3363387 \"DOI for the article \'Growable, Invisible, Connected Toys: Twitching Towards Ubiquitous Bacterial Computing\'\")','1 Introduction\r\n\r\nThe analogue natural and physical world is still largely very distinct from the digital technological world. Yet this distinction is becoming increasingly blurred, at least on two accounts. First, it is becoming increasingly easier to embed smart devices into the natural world, and to create smart environments [1]. Second, we are beginning to use organic materials (e.g. carbon-based small molecules or polymers) to synthesize new, cheaper and more sustainable organic types of smart devices [2]. For example, we can create digital displays from OLED (organic light-emitting diodes) consisting of a thin film of organic material that emits light under stimulation by an electric current [3]. However, such organic materials are non-living. A further evolution is to turn living material into digital smart devices using synthetic biology (artificial biological) systems.\r\n\r\n1.1 Bacteria Computers\r\n\r\nFollowing Adleman\'s introduction of the concept of using DNA as a manipulatable substrate for computation [4], the strive to construct nano and microscopic, living computers de novo has been gathering momentum in the last couple of decades. This has been helped by the emergence of synthetic biology, which in part implement electrical engineering principles to biology [5].\r\n\r\nIn synthetic biology, pieces of DNA are artificially programmed, synthesized, standardized, and assembled into ‘genetic circuits’ [6], which, once inserted into a cell, can transform organisms such as bacteria to function as custom-built computers. Currently, bacteria can be customized to biologically mimic, at least on a relatively modest level, some of the typical electronic and computing activities. These include operations of toggle switches [7], oscillators [8], and logic gates [9, 10], that are constructed from DNA and RNA. Engineered bacteria have also demonstrated the ability to solve mathematical problems [11], to store binary data [12], and to memorize past cellular events [13, 14]. Moreover, with a relatively recent arrival of CRISPR-Cas9 technology, more complex biological circuits seem to be on the horizon too [15].\r\n\r\nAs micro-organisms, bacteria computers would offer several economic advantages over silicone-based counterparts. Bacteria can self-reproduce quickly (‘Bacteria as computer making computers’ [16]), and in vast quantities too, by doubling in a relatively short period of time of twenty to thirty minutes. Furthermore, bacteria can function in high densities, as well as in extreme, toxic, and changing environments [17, 18].\r\n\r\nAs such, bacteria promise a range of promising applications in our everyday lives, including their implementation as ubiquitous computers. Serving us as a form of ‘microbial wetware’ – which may also be referred to as “smart dusts” (P. 196) [1] – the bacteria would thrive and function just about anywhere and everywhere: Tracking and remedying our health inside our bodies [19], collecting and sending environmental data from potentially hazardous or polluted areas [20], and helping us to cultivate food in Mars [21].\r\n\r\n1.2 Synthetic Biology and Calm Computing\r\n\r\nIn some ways, such bacteria-driven future seems to align well with Weiser\'s vision of calm computing. In the 1990s, in the hope of making computer technology ‘invisible’, and thus less distracting to end users, Weiser outlined his seminal concept of calm computing [22, 23]. It depicted a future with seamlessly integrated, ubiquitous computers in our daily lives, where the technology could efficiently dip in and out of our peripheral attention according to our whims and/or our needs.\r\n\r\nWith bacteria, computers would disappear quite literally, at least according to our naked eyes. Embedded into our clothing [24], ‘dissolved’ in water [25], and propelled outside of the Earth\'s stratosphere [21], the microbes would be conveniently hidden. They would remind us of their presence, and function, only when needed, through gene expressions such as GFP (green fluorescent protein) which enable bacteria to glow like gemstones and stars in the sky.\r\n\r\nFurthermore, if we consider the prominent themes underlying Weiser\'s calm computing concept, which are Context-Aware Computing, Ambient and Ubiquitous Intelligence, and Recording, Tracking and Monitoring [26], they are also present in the biotech industry as frameworks for research and development. In the field of medicine and human microbiome [27] for instance, researchers are aiming to engineer personalized bacteria that can sense and function in accordance to the human host\'s physiological and pathological contexts. Living inside the lining of the gut, they would spring into action when triggered by presence of certain molecules, all the while recording, monitoring, and reporting back the host\'s physiological condition.\r\n\r\n2 Opportunities\r\n\r\n2.1 Excitement of Biology-Based Interaction\r\n\r\nIn 2006, around ten years after Weiser\'s calm computing proposal, Rogers [26] provided a constructive critique of Weiser\'s vision of calm computing. Partly in response to ubicomp industry\'s frustrating lack of progress at that time towards realizing Weiser\'s vision, Rogers called for broadening of its scope, by encouraging alternative perspectives and practices in which ubiquitous computing could be perceived and implemented.\r\n\r\nRogers argued that calm computing was not only difficult to achieve, but its narrow focus was counterproductive in progressing ubiquitous computing field forward. Further still, Rogers recognized that the technology had potential to offer a lot more: Rather than being used as a passive tool, technology could be harnessed as an engagement medium to enrich human lives as well as augmenting scientific practices. One of the ways to achieve this, as suggested by Rogers, was to design interactive systems that could be used to inspire, provoke, teach, and entertain users into thinking about a wide variety of implications of ubiquitous computing.\r\n\r\nIn a similar vein, we also recognize the value of broadening the implementation of technology, to engage people in ways that may fall foul of de rigueur ideals expected by the industry. While synthetic biology community seeks seamless functioning of its microbial computers in offering cost-effective comfort and convenience to our lives, our motivation is to divert away from such notion.\r\n\r\nBiological systems, such as those embodied by bacteria, are compelling to engage with [28–30]. They are inherently noisy, clunky, mysterious, unpredictable, sometimes hazardous, and often ethically polarizing. So why not embrace, celebrate, and harness these traits to generate an alternative set of bio-flavoured excitement of interaction?\r\n\r\n2.2 Biology for HCI and Ubiquitous Computing\r\n\r\nA caveat that we acknowledge in this paper, is that functioning bacteria computer models, that are capable of performing computation, are not currently readily available, even to those in professional laboratories. One of the reasons behind this, is that standardization of biological circuits has been proving to be a tough nut to crack, ironically due to “circuit unpredictability, incompatible parts, or random fluctuations” (P. 342) [31]. In other words, we do not yet have the luxury of established, affordable and/or accessible computer hardware and software for us to tinker, build, and play with, in the same way that computer scientists, artists, and hobbyists do nowadays with computers like the Raspberry Pi. We do not see this as a major problem, however, as we can identify tools and systems that resemble a functioning bacteria computer to a reasonable degree, which would be a good starting point for engagement.\r\n\r\nMoreover, we also recognize that the HCI and ubiquitous computing community today face a more pressing and immediate challenge/opportunity, which our paper and our proposal will address. We see that there are essentially two types of opportunities, which may stem from the lack of basic knowledge, and limiting mindset of biology for meaningful integration. As Pablo Picasso once said, “learn the rules like a pro, so you can break them like an artist”.\r\n\r\n2.2.1  Basic Biology Training. In recent years, helped by the widening accessibility of the knowledge, tools, and materials of biotechnology outside of professional biology labs [32, 33], a growing number of HCI and ubiquitous computing researchers and practitioners are exploring the notion of integrating micro-organisms with interactive computer systems [33–37]. As the principles, materials, and techniques of biology become better acquainted within these communities, their curriculum has naturally broadened too. This has created a fresh scope for basic biological education and training, to cater for those who may be unfamiliar with the discipline.\r\n\r\n2.2.2  Shifting Perception of Living Matter as Hardware. The gaining of momentum in HCI and ubiquitous computing for the exploration of biologically integrated interaction designs indicate a gradual shift in perception of living matter as hardware, that can be designed to sense the world and interpret the input into a meaningful output as feedback. Yet much work is needed to grow the philosophy that can be implemented in a larger scale.\r\n\r\n3 MouldCraft\r\n\r\n3.1 Definition and Overview\r\n\r\nIn order to address the challenges and take advantage of opportunities outlined in this paper, we introduce MouldCraft [38], a game console for education and entertainment (hereafter called ‘edutainment’ [39]). MouldCraft is a smartphone-controlled console, which enables users to interact remotely with micro-organisms (Fig. 1 and Fig. 2).\r\n\r\nInteraction schema\r\nFigure 1: Interaction overview of MouldCraft game console. A: Player input using smartphone-based interface. B: Digital feedback from console in the form of notifications and changes in game screen graphics. C: Physical input by console to bacteria (e.g. heat and chemicals). D: Physical changes in bacteria (e.g. colour production) that are detectable by electronic sensors.\r\nsmartphone application\r\nFigure 2: Examples of MouldCraft smartphone user interface, built using Blynk application. Left: Culturing mode. Right: Game mode.\r\nThe idea is to enable users to learn about the basic aspects of microbiology (e.g. culturing, morphology, colony behaviour etc), and to explore the idea of bacterium as a connected device that can interact with humans and computer systems. Below we outline and discuss the main concept in further detail.\r\n\r\n3.2 Main Concept\r\n\r\n3.2.1  Bacterium as a Connected Device. In order to address the potential impact of the two emerging technologies – synthetic biology and nanotechnology – on Internet of Things (IoT) applications, Akyildiz et al. [19] coined the term Internet of Bio-Nano Things (IoBNT). It encompasses communication and network architecture that consist of biological materials (e.g. cells and DNA), as well as nanoscale devices.\r\n\r\nElaborating on the concept of IoBNT further, Kim and Poslad [40] drew comparisons between E.coli bacterium and a commonly-used modern IoT device, the Raspberry Pi. By comparing the key aspects of sensing, actuating, communicating, and processing, Kim and Poslad argued that E.coli can be considered as an IoBNT device, that offered distinctly-microbiological characteristics absent in conventional digital and electronic IoT devices.\r\n\r\nThis notion of bacterium as a ‘connected device’ – which in our case, a ‘connected toy’, defines the bacteria used in our MouldCraft console, an edutainment toolkit that can be used to demonstrate and teach players on the various mechanics of bacteria functioning as part of an IoBNT framework.\r\n\r\nWe consciously made the decision not to call our bacteria a ‘computer’, but rather a ‘device/toy’. We define the former as something that is capable of being artificially programmed to perform computation using DNA-based circuits, whilst the latter we define as an organism with a broader and more attainable specifications. This has alleviated the technical and practical challenges associated with creating synthetic biological circuits capable of computation, whilst retaining enough computer-related features to start engaging the users. We describe the biological components of MouldCraft that further illustrate this point, below.\r\n\r\n3.3 Biological Components\r\n\r\n3.3.1  Microbe. This is a key component of the MouldCraft console, as the microbe effectively drives the games that are played from it. There is no limitation in terms of the type of microbe that can be used with MouldCraft. Just as an example, however, here we specify and break down a cell of genetically transformed E.coli DH10B. It is a common bacterial strain used by the console, and the one that contains features analogues to computer components that are relevant in our discussion.\r\n\r\n3.3.2  Synthetic Biological Circuit. This is commonly referred to as a plasmid in biology. It is a circular loop made out of several DNA components, each designed with specific function. The plasmids can be artificially synthesized and inserted into most bacterial cells, and this would transform the microbial hosts with added capabilities. Fig. 3 shows the map of a particular circuit, pNCBE-Kan-GFP, which is found in our transformed E.coli strain. It contains several components, including a ‘control region’ (CR) which functions as the sensory and the actuating switch unit of the bacteria.\r\n\r\nMap of a DNA circuit\r\nFigure 3: Simplified map of DNA circuit (plasmid), pNCBE-Kan-GFP, for use in bacteria. Image courtesy of National Centre for Biotechnology Education, University of Reading, UK.\r\nTo address our point made in the main concept, it is worth noting that the circuit we present here is a relatively simple design. It is insufficient to illicit computation in bacteria, thereby rendering the organism not a computer per se, but a device of sorts that sense and react to stimuli. The circuit is, however, significantly easier and cheaper to obtain, and are also much more stable for functioning, than those with complex designs.\r\n\r\n3.3.3  Sensor. This component of our pNCBE-Kan-GFP circuit is designed to sense the presence of IPTG (Isopropyl-β-D-thiogalactoside), a sugar-like molecule. Once detected, molecular chain of events in the cell allows the activation of a switch that actuates production of GFP, effectively making the bacteria glow with green fluorescence under ultraviolet light (Fig. 4, bottom). Such effect is somewhat analogous to a green LED on an electrical circuit (Fig. 4, top).\r\n\r\nFigure 4:\r\nFigure 4: Circuits and their outputs. Top: (open) electrical circuit for LED light emission. Bottom: Simplified DNA circuit pNCBE-Kan-GFP for GFP gene expression in bacteria. CR: Control Region.\r\n3.3.4  Actuators. Here we define actuators as components that produce physical behaviour from bacteria, that are visible to the naked human eye, and more crucially, detectable with electronic sensors, such as colour and light sensors. The physical behaviours include growth, production of colour emitting proteins (e.g. GFP), and movement. All of these behaviours can be generated from an appropriately transformed E.coli strain. Multiple types of molecular actuators are responsible for each behaviour, including proteins, enzymes, DNA, and RNA. It is these electronically-detectable physical outputs of bacteria (and other micro-organisms) that enable them to interact with its computer host, which would then relay the information back to the human players via their smartphones.\r\n\r\n3.4 Non-Biological Components\r\n\r\n3.4.1  The Console. Overall, the MouldCraft console is divided into two parts. First is the control unit, which houses most of the electronic components. The job of the control unit is to translate online commands made by players into physical stimuli for the microbes. A player\'s smartphone MouldCraft Application (facilitated by Blynk [41] server) would process his/her commands and produce a specific set of RGB values in one of the three RGB LEDs via Arduino micro-controller (Fig. 5, parts A and B). These values in turn are read by RGB colour sensors of the Lego Mindstorms EV3 [42], which executes specific actions powered by a series of Lego motors (Fig. 6). The control unit is essentially a facilitator between human users and the microbes. Given the wide range of value combinations that can be generated with RGB LEDs, the actions that can be executed by the Lego robot can be extremely diverse and detailed.\r\n\r\nMouldCraft console\r\nFigure 5: MouldCraft console. A: Arduino micro-controller. B: RGB LEDs. C: Lego RGB colour sensors. D: Lego EV3 Mindstorms Intelligent Brick. E: The Playground. F: Thermostat (with a fan and heating element, not shown).\r\nLego-based motors\r\nFigure 6: MouldCraft robotic arm. A: Standard arm with syringe and pipette tip attachment [43]. B: Standard arm with secondary cotton bud attachment. C: Addition of colour sensor to the robotic arm.\r\n3.4.2  Robotic Arm. The players’ commands are executed physically via the robotic arm, which are built using Lego components. These can be customized to the game\'s needs, by taking advantage of Lego’s flexibility in allowing diverse structures to be built quickly. For example, the arm could consist of a liquid handling unit [43], with attached syringe to provide chemical injection to the microbial cultures. The arm can be modified further too, by attaching cotton buds (e.g. for microbial swabbing and cell transfers) (Fig. 6, part B), an extra colour sensor (e.g. to detect specific colours or glows produced by bacteria) (Fig. 6, part C), an electroporator (e.g. for introducing new genes into bacteria through application of electrical pulse), or a webcam.\r\n\r\n3.4.3  The Playground. This part of the console is where the micro-organisms are grown and stored (Fig. 5, part E). Its ambient temperature is controlled and monitored by a thermostat (Fig. 5, part F). The playground is fenced off by the walls of an appropriate container (e.g. culturing dish/disc), which can be any shape or size, even as tiny cubes (Fig. 7, part B), as long as it fits inside the console. The playground in many ways is similar to a video game disc for PlayStation or Xbox consoles, as they are both encoded with information, albeit in cellular and genetic formats.\r\n\r\nMouldCraft console\r\nFigure 7: MouldCraft console in action. A: Overview of physical components. B: Small cubic playground. C: Application of nutrients and stimulants via robotic arm and the syringe-pipette.\r\nThe physical grounding for the playground is provided by agar, a nutrient-infused seaweed-based material that is commonly used in microbiology for culturing most micro-organisms. Agar can also be customized too, by changing its viscosity, nutrient contents, and pigmentation. Fig. 8 shows examples of a visually compelling game scene that could be produced through ‘re-grounding’, i.e., changing the formulation of the agar, and also through the physical and chemical stimulations delivered by the robotic arm.\r\n\r\nMicrobial growth images\r\nFigure 8: Examples of possible microbial visual outputs from MouldCraft. Top: Collection of cubic playgrounds with different species of micro-organisms grown in customized culturing conditions. Since each cube can produce unique palette of colours, they can be used as triggers for Lego colour sensors, and to mediate gameplay. Bottom: Colourful, procedurally-generating game scene.\r\n3.4.4  Webcam. The console allows a space for a webcam or a smartphone to be mounted onto the console (image not shown) that can capture the progress of a game, and live stream the footage directly; not only to the user\'s smartphone application (Fig. 2), but also onto social media, such as Twitch, Facebook, YouTube, and Instagram. This is potentially useful for collective learning and for generating discourse over a global audience.\r\n\r\n3.5 Interchangeability\r\n\r\nAs described above, most components of MouldCraft console is modular and interchangeable, which provide versatility for tailored explorations and learning. As such, MouldCraft can be regarded as a form of hybrid gaming console, in the sense that it combines the modular qualities of both the tools of synthetic biology as well as those from the traditional, physical, and electronic disciplines together. A summary of the interchangeable components is provided in Table 1.\r\n\r\nTable 1: Interchangeable components in MouldCraft\r\nBiological    Non-Biological\r\nDNA Circuits    Lego Bricks\r\nMicrobial Species    Arm Attachments\r\nNutrients    The Playground\r\nStimulants    Sensors\r\nMicro-controllers\r\n3.6 Bio-Ethics and Safety\r\n\r\nGiven the biological integration in MouldCraft console, potential ethical and safety issues must be addressed. For the users of MouldCraft, it is recommended that the physical console should be operated under controlled laboratory environment, in order to minimize risk to the moderator. Games will be played online, through a smartphone application, which will ensure that no physical contact can be made between the players and the microbial cultures. For hosting of the console, the organisms and biological processes used by MouldCraft console should match the containment level of the hosting laboratory (e.g. high-level certified labs for potentially pathogenic micro-organisms). And lastly, ethical guidelines provided by Harvey et al. [44] is recommended for the gameplay: No pain; Engage with Public; Respect the Player; and Respect the Organism.\r\n\r\n4 Playful Vignettes\r\n\r\nBelow we outline some of the primitive ideas which could be developed into biotic games [45] that would be played on the MouldCraft console. We felt that these were appropriate starting points for exploring the basic concepts of microbiology, as well as their role in future IoT and ubiquitous computing. Moreover, the organisms and materials used in these ideas were chosen deliberately for their ease of access. All of the concepts listed here could utilize the infrastructure of the MouldCraft console to facilitate interaction between the user and the micro-organisms involved. For example, any significant colour outputs produced by microbes during gameplay could be detected by the colour sensor, which would in turn subsequently relay this information as a form of a smartphone notification or digital changes in the game head-up display (HUD) (Fig. 2).\r\n\r\n4.1 Command and Contaminate\r\n\r\n4.1.1  Game Concept on Microbial Ubiquity and Self-Replication. This is designed to teach players about the basic growth principles of micro-organisms, such as bacteria, yeast, and moulds. Furthermore, it demonstrates ubiquity of microbes by visualizing the formation of colonies and their ability to spread onto new regions (Fig. 8). Each player is given a colony (in single cubes) to spread onto other cubes, over a given period of time. This could be achieved by swabbing a microbial colony using the robotic arm and transferring it onto a designated cube. The player with most occupied number of cubes would be declared as the winner.\r\n\r\n4.2 Micro-Olympics\r\n\r\n4.2.1  Game Concept on Sensing and Actuating Through Cell Motility. This concept teaches players on how bacteria sense the environment (e.g. an exposure to directional light) and act accordingly. The cyanobacteria imaged in Fig. 9 is showing movement pattern which resembles a race towards a light source. Players could choose a particular strain of cyanobacteria and race against others, and also control the intensity of the light using their smartphones to vary the outcomes.\r\n\r\nMigrating colonies of bacteria\r\nFigure 9: Cyanobacteria phototaxis (example of an upward migration). The migration of individual colonies produce finger-like patterns. Image adapted from Ursell et al. [46].\r\n4.3 Treasure Hunt/Micro-Sweeper\r\n\r\n4.3.1  Game Concept on Genetic Circuits. This demonstrates how genetic circuits can be used by bacteria to sense and actuate. A plasmid (a short circular DNA) can be designed online, using open source software, to include specific functional component of the player\'s choice. For example, GFP gene could be included in the plasmid circuit design, which can be expressed when certain environmental trigger is activated. Once the circuit is designed, it can be ordered to be manufactured by a third party. Once the plasmid is delivered, it can be applied to microbes in the MouldCraft console to let the bacteria take up the plasmid into their cells. A game could be designed around this, for the players to anticipate which colonies of bacteria have taken up the circuit. GFP can be then made visible through exposure to ultraviolet light to reveal those that have taken up the plasmid successfully (Fig. 10).\r\n\r\nFigure 10:\r\nFigure 10: Detecting green fluorescence produced by GFP-transformed bacteria. Without UV light (top), and with UV light exposure (bottom).\r\n4.4 Hidden Messages\r\n\r\n4.4.1  Game Concept on Molecular Communication and Digital/DNA Data Storage. This is an adaptation from a scientific experiment carried out by Tavella et al. [47]. This concept is relatively more complex than the previous examples, but it nevertheless teaches the player several aspects of bacterial computing.\r\n\r\nAt the start of the game, motile bacteria are released at one end of the playground, which arrive at the center (Fig. 11). They meet with another, non-motile colony of bacteria at the center, which have digital information encoded inside their cells in the form of DNA. The transfer of this DNA to the motile bacteria occurs, through a natural conjugation process (a form of mating), which effectively passes on the encoded digital information to the motile bacteria. The motile bacteria with new information arrive at the end of the playground, and they subsequently express the GFP gene to indicate successful data pick up and transportation. This could be gamified further by making the encoded DNA messages cryptic in some way.\r\n\r\nData storage, exchange and transfer in bacteria\r\nFigure 11: A playground to demonstrate bacterial motility, data storage, data transfer, data transport, and an indicating marker gene expression. A: Area for releasing motile bacteria. B: Center of playground where motile bacteria receive data from non-motile bacteria through DNA transfer. C: Motile bacteria glows green by switching on the GFP-circuit to indicate successful data pick-up.\r\n5 Further Work\r\n\r\nAs part of our continuing strive to create better engagement with synthetic biology and its impact on future ubiquitous computing, we identify three areas for further development and evaluation. For the immediate future, we aim to develop some of the game vignettes that were proposed, into functioning prototypes. These will be user-tested and evaluated for their impact on user engagement, especially from the perspective of the game\'s ability to generate discourse and shifts in perception of bacterium (and other microbes) as a playful, connected device.\r\n\r\nSecond, we aim to create a form of an online repository called The Registry of Biotic Gaming Parts. It would consist of interchangeable genetic circuits and DNA components that can be inserted into bacteria and other micro-organisms. We do not wish to limit ourselves with circuits that only produce GFP, but also utilize a wide range of circuits that can produce a palette of colours too. We could also use other components that would be potentially ‘gamifiable’ too, meaning that they could be used to improve or change the host organism\'s behaviour, and thereby change the dynamics and/or speed of the game. Thirdly, we will continue to generate discussions between synthetic biologists, computer scientists, artists, and designers, through talks, workshops, and game jams. In doing so, we strive to develop a set of hybrid philosophies that would help the HCI and ubiquitous computing communities to engage with the concept of bacterial (and microbial) computing in a creative, thought-provoking, and entertaining manner.\r\n\r\n6 Summary\r\n\r\nIf we begin to wonder about the future of ubiquitous computing through a biotechnological lens, we would encounter computers of a rather different kind. With the emergence of synthetic biology, the notion of creating bacteria computers anew, using circuits made from standardized DNA components, is becoming closer to reality. Once established and fine-tuned, bacteria computers would save lives, improve our health, and solve environmental issues with great efficiency and cost-effectiveness that could outperform their conventional silicone-based counterparts. Should such future arrive, it would draw parallels with that envisioned by Weiser and his calm computing concept. Not only would bacteria computers operate invisibly in the literal sense, they would perform their duties seamlessly with molecular precision and sophistication.\r\n\r\nAnd contrastingly, as the biotech industry endeavours to iron out the inherent imperfections of biological systems – instability, unpredictability, noise, and so forth – we argue that incorporating such qualities in interactive systems can enrich user experiences, as they can become catalysts for provocation, inspiration, and entertainment. Yet before we can implement our philosophy, there is an immediate imperative for laying the foundation consisting of basic biological knowledge and the appropriate mindset, within the HCI and ubiquitous computing community.\r\n\r\nWe have introduced MouldCraft, a smartphone-controlled edutainment console that allows playful interaction between human players and micro-organisms. The aim of the console is two-fold. First, to educate players on the basics of microbiology, and second, to demonstrate bacteria as a connected device that can sense, actuate and communicate with its computer host and remote players through gaming and play. The accessibility and modularity of the interchangeable parts in MouldCraft can offer a cost-effective, safe, and practical pathway to engage those outside of synthetic biology and novices to the concept of bacteria computing.\r\n\r\nAnd finally, we hope that MouldCraft can also offer a positive case study for practitioners in HCI and ubiquitous computing, in helping to create alternative products and toolkits of their own, that would allow alternative, re-framing of technology for engagement, provocation, and entertainment.\r\n\r\nACKNOWLEDGMENT\r\n\r\nThis research was supported by EPSRC and AHRC Centre for Doctoral Training in Media and Arts Technology (EP/L01632X/1). The development of MouldCraft gaming console was partly supported by Queen Mary University\'s Enterprise Fund. We also thank Open Cell (https://opencell.webflow.io/) for promoting MouldCraft through exhibitions, and for hosting public engagement workshops.\r\n\r\nREFERENCES\r\n\r\nStefan Poslad. 2009. Ubiquitous Computing: Smart Devices, Environments and Interactions.John Wiley & Sons Ltd, West Sussex, United Kingdom.  \r\nDavid Voss. 2000. Organic electronics: Cheap and cheerful circuits. Nature 407, 442–444.  \r\nSunkook Kim, Hyuk-Jun Kwon, Sunghun Lee, Hongshik Shim, Youngtea Chun, Woong Choi, Jinho Kwack, Dongwon Han, MyoungSeop Song, Sungchul Kim, Saeed Mohammadi, InSeo Kee, and Sang Yoon Lee. 2011. Low-power flexible organic light-emitting diode display device. Advanced Materials 23, 3511-3516.  \r\nLeonard M. Adleman. 1994. Molecular computation of solutions to combinatorial problems. Science 266, 5187, 1021-1024.  \r\nErnesto Andrianantoandro, Subhayu Basu, David K. Karig, and Ron Weiss. 2006. Synthetic biology: New engineering rules for an emerging discipline. Mol Syst Biol 2, 2006.0028. doi: 10.1038/msb4100073  \r\nDaniel J. Sayut, Pavan Kumar Reddy Kambam, and Lianhong Sun. 2007. Engineering and applications of genetic circuits. Mol BioSyst 3, 835–840.  \r\nTimothy S. Gardner, Charles R. Cantor, and James J. Collins. 2000. Construction of a genetic toggle switch in Escherichia coli. Nature 403, 339-342.  \r\nMichael B. Elowitz and Stanislas Leibler. 2000. A synthetic oscillatory network of transcriptional regulators. Nature 403, 335-338.  \r\nBaojun Wang, Richard I. Kitney, Nicolas Joly, and Martin Buck. 2011. Engineering modular and orthogonal genetic logic gates for robust digital-like synthetic biology. Nature Communications 2, 508. DoI: 10.1038/ncomms1516  \r\nAlexander A. Green, Jongmin Kim, Duo Ma, Pamela A. Silver, James J. Collins, and Peng Yin. 2017. Complex cellular logic computation using ribocomputing devices. Nature 548, 7665, 117-121. doi:10.1038/nature23271  \r\nJordan Baumgardner, Karen Acker, Oyinade Adefuye, Samuel T. Crowley, Will DeLoache, James O. Dickson, Lane Heard, Andrew T. Martens, Nickolaus Morton, Michelle Ritter, Amber Shoecraft, Jessica Treece, Matthew Unzicker, Amanda Valencia, Mike Waters, AMalcolm Campbell, Laurie J. Heyer, Jeffrey L. Poet, and Todd T. Eckdahl. 2009. Solving a Hamiltonian Path Problem with a bacterial computer. Journal of Biological Engineering 3, Article 11 (2009), 11 pages. doi: 10.1186/1754-1611-3-11  \r\nSeth L. Shipman, Jeff Nivala, Jeffrey D. Macklis, and George M. Church. 2016. Molecular recordings by directed CRISPR spacer acquisition. Science 353, 6298, aaf1175. DOI: 10.1126/science.aaf1175  \r\nPiro Siuti, John Yazbek, and Timothy K. Lu. 2013. Synthetic circuits integrating logic and memory in living cells. Nature Biotechnology 31, 5, 448-453. Doi:10.1038/nbt.2510.  \r\nNathaniel Roquet, Ava P. Soleimany, Alyssa C. Ferris, Scott Aaronson, and Timothy K. Lu. 2016. Synthetic recombinase-based state machines in living cells. Science 353, 6297, aad8559. DOI: 10.1126/science.aad8559  \r\nBarbara Jusiak, Sara Cleto, Pablo Perez-Piñera, and Timothy K. Lu. 2016. Engineering synthetic gene circuits in living cells with CRISPR technology. Trends Biotechnol 34, 7, 535-547. doi: 10.1016/j.tibtech.2015.12.014  \r\nAntoine Danchin. 2009. Bacteria as computers making computers. FEMS Microbiol Rev 33, 3-26.  \r\nGerd H.G. Moe-Behrens. 2013. The biological microprocessor, or how to build a computer with biological parts. Computational and Structural Biotechnology Journal 7,8. e201304003  \r\nRafael Lahoz-Beltra, Jorge Navarro, and Pedro C. Marijuán. 2014. Bacterial computing: A form of natural computing and its applications. Frontiers in Microbiology 5, 101. doi: 10.3389/fmicb.2014.00101  \r\nIan F. Akyildiz, Max Pierobon, Sasi Balasubramaniam, and Evgeni Koucheryavy. 2015. The Internet of Bio-Nano Things. IEEE Communications Magazine (March 2015), 32-40.  \r\nGraham Templeton. 2016. How MIT\'s New Biological ‘Computer’ Works, and What it Could Do in the Future. Retrieved from https://www.extremetech.com/extreme/232190-how-mits-new-biological-computer-works-and-what-it-could-do-in-the-future.  \r\nLynn J. Rothschild. 2016. Synthetic biology meets bioprinting: Enabling technologies for humans on Mars (and Earth). Biochemical Society Transactions 44, 4, 1158-1164.  \r\nMark Weiser. 1991. The Computer for the 21st Century. Scientific American, 94–104.  \r\nMark Weiser and John S. Brown. 1997. The Coming Age of Calm Technology. In: Beyond Calculation. Springer, New York, NY. https://doi.org/10.1007/978-1-4612-0685-9_6  \r\nLining Yao, Jifei Ou, Chin-Yi Cheng, Helene Steiner, Wen Wang, Guanyun Wang, and Hiroshi Ishii. 2015. bioLogic: Natto cells as nanoactuators for shape changing interfaces. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI \'15).ACM, New York, NY, USA, 1-10. DOI: https://doi.org/10.1145/2702123.2702611  \r\nAbhilasha S. Mathuriya. 2015. Magnetotactic bacteria: Nanodrivers of the future. Crit Rev Biotechnol, Early Online, 1-15. DOI: 10.3109/07388551.2015.1046810  \r\nYvonne Rogers. 2006. Moving on from Weiser\'s vision of calm computing: Engaging Ubicomp experiences. In UbiComp 2006: Ubiquitous Computing (Lecture Notes in Computer Science), Paul Dourish and Adrian Friday (Eds.). Springer Berlin Heidelberg, 404–421.  \r\nDanielle B. Pedrolli, Nathan V. Ribeiro, Patrick N. Squizato, Victor N. de Jesus, Daniel A. Cozetto, and Team AQA Unesp at iGEM 2017. 2017. Engineering microbial living therapeutics: The synthetic biology toolbox. Trends in Biotechnology 37, 1, 100-115. DOI: https://doi.org/10.1016/j.tibtech.2018.09.005  \r\nAmanda Parkes and Connor Dickie. 2013. A biological imperative for interaction design. Proc. of the 2013 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, New York, 2013, 2209-2218. https://doi.org/10.1145/2468356.2468742  \r\nRaphael Kim, Siobhan Thomas, Roland van Dierendonck, Antonios Kaniadakis, and Stefan Poslad. 2018. Microbial integration on player experience of hybrid bio-digital games. In: Cortez P., Magalhães L., Branco P., Portela C., Adão T. (eds). Intelligent Technologies for Interactive Entertainment. INTETAIN, 2018. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, 273. Springer, Cham.\r\nRaphael Kim, Roland van Dierendonck, and Stefan Poslad. 2019. Moldy Ghosts and Yeasty Invasions: Glitches in Hybrid Bio-Digital Games. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA \'19). ACM, New York, NY, USA, Paper LBW1619, 6 pages. DOI: https://doi.org/10.1145/3290607.3312895  \r\nJavier Macia, Francesc Posas, and Ricard V. Sole. 2012. Distributed computation: The new wave of synthetic biology devices. Trends in Biotechnology 30, 6, 342-349.  \r\nThomas Landrain, Morgan Meyer, Ariel Martin Perez, and Remi Sussan. 2013. Do-It-Yourself-Biology: Challenges and promises for an open science and technology movement. Syst Synth Biol 7, 115-126. DOI: 10.1007/s11693-013-911-4.  \r\nStacey Kuznetsov, Alex S. Taylor, Eric Paulos, Carl DiSalvo, and Tad Hirsch. 2012. (DIY)biology and opportunities for HCI. Proc. of the Designing Interactive Systems Conference, ACM, New York, 2012, 809-810. https://doi.org/10.1145/2317956.2318085  \r\nRaphael Kim, Siobhan Thomas, Roland van Dierendonck, and Stefan Poslad. 2018. A new mould rush: designing for a slow bio-digital game driven by living micro-organisms. In Proceedings of the 13th International Conference on the Foundations of Digital Games (FDG \'18), Steve Dahlskog, Sebastian Deterding, José Font, Mitu Khandaker, Carl Magnus Olsson, Sebastian Risi, and Christoph Salge (Eds.). ACM, New York, NY, USA, Article 10, 9 pages. DOI: https://doi.org/10.1145/3235765.3235798\r\nRaphael Kim and Stefan Poslad. 2019. Augmentable experiences in hybrid biological digital games. Acoustic Space Journal 17, Rasa Smite, Raitis Smits (Eds.), RIXC. Riga, Latvia. ISBN-13: 978-9934843471.\r\nLukas C. Gerber, Honesty Kim, and Ingmar H. Riedel-Kruse. 2016. Interactive biotechnology: Design rules for integrating biological matter into digital games. DiGRA/FDG 13, 1 (August 2016), 16 pages.\r\nPat Pataranutaporn, Todd Ingalls, and Ed Finn. 2018. Biological HCI: Towards Integrative Interfaces Between People, Computer, and Biological Materials. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems (CHI EA \'18). ACM, New York, NY, USA, Paper LBW579, 6 pages. DOI: https://doi.org/10.1145/3170427.3188662  \r\nMouldCraft. Retrieved from https://biohackanddesign.com/mouldcraft/  \r\nStefan Poslad, Heimo Laamanen, Rainer Malaka, Achim Nick, Phil Buckle, and Alexander Zipf. 2001. Crumpet: Creation of user-friendly mobile services personalised for tourism. Proc. IEE 3G2001 Conf. Mobile Communication Technologies, 28-33.  \r\nRaphael Kim and Stefan Poslad. 2019. The thing with E.coli: Highlighting opportunities and challenges of integrating bacteria in IoT and HCI. arXiv:1910.01974. Retrieved from https://arixiv.org/abs/1910.01974  \r\nBlynk. Retrieved from https://blynk.io/  \r\nLego Mindstorms EV3. Retrieved from https://www.lego.com/en-gb/themes/mindstorms  \r\nLukas C. Gerber, Agnes Calasanz-Kaiser, Luke Hyman, Kateryna Voitiuk, Uday Patil, and Ingmar H. Riedel-Kruse. 2017. Liquid-handling Lego robots and experiments for STEM education and research. PLoS Biology 15, 3, e2001413. https://doi.org/10.1371/journal.pbio.2001413  \r\nHayden Harvey, Molly Havard, David Magnus, Mildred K. Cho, and Ingmar Riedel-Kruse. 2014. Innocent fun or microslavery? An ethical analysis of biotic games. Hastings Center Report, 44, 6, 38-46.  \r\nIngmar H. Riedel-Kruse, Alice M. Chung, Burak Dura, Andrea L. Hamilton, and Byung C. Lee. 2011. Design, engineering and utility of biotic games. Lab Chip 11, 14-22. DOI: 10.1039/c01c00399a.  \r\nTristan Ursell, Rosanna Man Wah Chau, Susanne Wisen, Devaki Bhaya, and Kerwyn Casey Huang. 2013. Motility enhancement through surface modification Is sufficient for cyanobacterial community organization during phototaxis. PloS Comput Biol, 9, 9, e1003205. doi:10.1371/journal.pcbi.1003205  \r\nFederico Tavella, Alberto Giaretta, Triona Marie Dooley-Cullinane, Mauro Conti, Lee Coffey, and Sasitharan Balasubramaniam. 2018. DNA molecular storage system: Transferring digitally encoded information through bacterial nanonetworks. arXiv:1801.04774. Retrieved from https://arxiv.org/abs/1801.04774  \r\n',1,'Kim','Raphael Kim and Stefan Poslad','Raphael Kim *(Queen Mary, University of London, UK)*<br>\r\nStefan Poslad *(Queen Mary, University of London, UK)*','https://www.researchgate.net/profile/Raphael_Kim2/publication/336592289_Growable_Invisible_Connected_Toys_Twitching_Towards_Ubiquitous_Bacterial_Computing/links/5da7adc192851caa1baa5e66/Growable-Invisible-Connected-Toys-Twitching-Towards-Ubiquitous-Bacter',1,'10.1145/3363384.3363387','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,65,10,NULL,NULL,0,3),(30,'antonini-social-ai-for-engaging-ubicomp','2019-09-02 15:24:57','2019-11-14 14:12:37','2019-09-02 15:24:57',NULL,1,'published','[]','Social AI for Engaging UbiComp','This short paper introduces the concept of Social AI as pivot technology between the two visions of Weiser\'s “calm” and Rogers\'s “engaging” UbiComp technologies. We discuss three types of AI solutions, Personal AI, System AI and Social AI, in relation to their interaction with ubiquitous technologies and humans. We highlight as Personal and System AI are the perfect users of calm technologies, while Social AI instantiates the vision of engaging Ubicomp. We elaborate the concept of Social AI as a technology for navigating the dual complexity of social systems and operating in synergy with humans without eroding their agency and by seeking their support through communication. We conclude by envisioning an entangled future between the research agenda on Social AI and engaging Ubicomp.','Alessio Antonini and Lucia Lupi. 2019. Social AI for Engaging UbiComp. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 5 pages. [https://doi.org/10.1145/3363384.3363483](https://doi.org/10.1145/3363384.3363483 \"DOI for the article \'Social AI for Engaging UbiComp\'\")','1 Introduction\r\n\r\nAbe checks if Mary is sleeping well in her bedroom every morning at 7 o\'clock. Then, Abe has to wake up Mary before 9 and reminds her to take her medications because Berta does not help with that. Today Mary has an appointment with Doctor Paul for a periodical check-up. Once assessed the traffic conditions in the district, Abe decided to book a taxi for Mary because the usual bus at the peak time will make her to miss her appointment.\r\n\r\nBerta serves the new traffic control room of the city, which supports local police, hospital emergency units and traffic management. Berta is engaged all day in analysing the automatic-generated feed of the CCTV system, but she can also remotely control cameras distributed all around the city when she needs to have a better view of traffic congestions or a car crash. Today there is an important match at the stadium, and Berta is mostly focused on the parking area to facilitate fluid access to the stadium, and also because the last time a fight broke out between team supporters. In the case of fights, Berta will alert the police and provide real-time feeds to support law-enforcement operations. \r\n\r\nCamille supports the coordination of the new community care project. Since her the first day, Camille began to receive a wide range of reports about the health conditions of elderlies in the district, from their neighbours and directly from wearables devices provided to people with chronic diseases. For instance, Bob was not seen for several days at the community centre, which was found strange as Bob likes to be deeply involved in community initiatives. Camille, aware that Bob must stay socially and physically active to slow the progression of his condition, asked John (a close friend of Bob) to check on him before deciding to call Bob\'s doctor.\r\n\r\nAbe, Berta and Camille are artificial agents and direct users of Ubiquitous Technologies (Ubicomp), relying on data and capabilities of Ubicomp to intermediate the interactions between people and technologies. The ambiguity of the three stories wants to stress that the users of Ubicomp are not limited to humans, also pointing out how web services and cloud computing, machine learning and big data, parallel computing and deep neural networks are deeply affecting our life through their integration in Ubicomp Technologies.\r\n\r\nAbe, a personal AI assistant [1], analyses the feeds from Martha\'s wearable devices and logs her quality of sleep to monitor and predict her conditions. Berta, an example of System AI managing urban infrastructures and services, processes real-time information from the cameras installed on the road networks to support the decisions and actions of local service providers. Camille envisions a kind of AI agent designed to act for communicating, engaging, negotiating, coordinating its actions with other humans and artificial agents. Camille is an example of what we define a Social AI, a model of future AI technologies aimed to address issues beyond the personal and organisational scale, by operating in a complex social context with multiple stakeholders1 .\r\n\r\nThis short paper introduces the perspective of Social AI as pivot technology between the two visions of Weiser\'s “calm” and Rogers\'s “engaging” UbiComp technologies [2]. Firstly, we briefly reflect on the three types of artificial agents as users and interface of UbiComp technologies. Then, we frame a Social AI as an “engaging” UbiComp. Lastly, we outline a few considerations about the entanglement between the future of AI and UbiComp.\r\n\r\n2 AI & UbiComp\r\n\r\nArtificial agents are the ideal users in Weiser\'s vision of calm UbiComp [3]. AI agents are predictable and rational, and they have routine behaviours and no privacy concerns. Moreover, despite recent advances in AI solutions, artificial agents continue not to be able to adapt to new situations and singular cases [4]. Thus, artificial agents as a personal AI assistant or System AI are the types of users that benefit the most from predictable environments, and that can perform at best specifically in stable settings, see Figure 1.\r\n\r\nFigure 1:\r\nFigure 1: AI agents are users of ubiquitous technologies, mediating their direct access to human users. AI agents exploit on one side their ability to learn users’ behaviours, and on the other side to be predictable and rational and thus legible by UbiComp.\r\nA Personal AI is the realisation of the \"invisible computer\" [2], seamless technology embedded in the user\'s material and digital sphere (e.g. through a wearable, home assistant, smartphone) and instantiating the concept of calm technology. The goal of a personal AI is to facilitate the user in his/her activities, by exploiting learning algorithms and data integration (e.g. emails, calendar, bookings) to plan how to overcome potential difficulties related to the implementation of these activities. A personal AI is usually hidden in the shadow of the user, listening and learning user\'s habits and operating by predicting user\'s intentions. However, this understanding of the user\'s context by the personal AI is elaborated in a hybrid world of digital services, sensors, digital actuators (e.g. home IoT) in which the AI is embodied, and that determine its vision of the current situation (see Figure 2). The resulting vision of the user\'s context is only partially shared with the user and not necessarily aligned to the user\'s understanding of his/her context of action.\r\n\r\nFigure 2:\r\nFigure 2: A Personal AI acts on behalf of the User, aligned with his/her intentionality. A System AI acts on behalf of a System Administrator as a proxy interacting with end-users. A Social AI synthesises the perspectives and intentions of different users/stakeholders, which are translated into engagement inputs in the context of their actions.\r\nA System AI, such as an AI changing speed limits on road displays and closing a road lane forcing drivers in a funnel, is not a calm technology for its end-users. It is a technology operating as the implementer of rules and decisions of a system administrator (e.g. motorway authority). A System AI works differently from a personal assistant: its primary users are not human agents, the objects of \"recording/tracking and monitoring\" [2], but the manager of the infrastructure or service controlled by the AI. As a Personal AI, a System AI is aligned with someone intentionality (the system administrator), even though the objects of its attention and learning are the end-users of the system.\r\n\r\nA System AI can have a \"calming effect\" on the system administrator because it removes the need of understanding the complexity of the context to make decisions and, at the same time, ensuring the implementation of his/her intentions (such as enforcing service regulations). On the other hand, the legibility of the System AI actions to the end-users is critical because it is difficult to clearly identify the AI as a proxy (and agent) of the system administrator intentionality in the context of end-users\' actions, see Figure 2. Furthermore, the efficacy of a System AI is not left to the compliance of end-users with system administrator\'s goals, but achieved through \"nudging\" (i.e. subtle exploitation of cognitive mechanisms aimed to suggest a specific behaviour) or normative actions (e.g. speed limits).\r\n\r\nDifferently from a System AI, the focus of a Social AI is not a service and its users, but the different stakeholders in the context and their relationships. In this setting, AI agents are delegated to:\r\n\r\nCreating a synthesis of the plurality of their instances\r\nMaking legible to each stakeholder the different perspectives of others\r\nEngaging individual users and stakeholders in cooperating to implement shared initiatives.\r\nA Social AI is not a social player, and it does not represent any specific social player. A Social AI is not “aware” of society. On the contrary, a Social AI is called to develop and report its own understanding of the situation (i.e. social context and contingencies) to individual users and stakeholders. A Social AI develops its understanding by integrating the data acquired from Ubicomp with the inputs from users and stakeholders on contingencies. This understanding acts as a synthesis built by mediating the expressions of the multiple roles (e.g. competencies) and intentionalities (e.g. goals) that users/stakeholders can assume in the social context under analysis, see Figure 2.\r\n\r\nThese three types of AI are direct users of ubiquitous technologies and ubiquitous technologies in themselves, at least because they “participate in the world they represent” [5] as agents embodied in the environment of human users. Indeed, the interactions between AI and users are dynamically configured in the context of the use of technology. These interactions result from an evolving language “coupling” [6] functionalities and feedbacks related to the features of technology from the characteristics of the environment in which the joint actions of AI agents and humans are performed.\r\n\r\nAs highlighted by Rogers, calm technologies assume the ability to understand the user and the situation in which the user operates [2]. To this regard, a Personal AI uses its capabilities to mimic the user and anticipate its needs exploiting the ecosystem of ubiquitous technologies and cloud computing. Similarly, a System AI exploits the same ecosystem to track/record and monitor infrastructures and services to implement the agenda of a system administrator. Both Personal and System AI are \"calming\" for someone, while a Social AI is challenging or \"engaging\" by design for everyone.\r\n\r\nOn this ground, our standpoint is that Social AI is the natural evolution of System AI, able to operates through communication and trust-based interactions with humans, instead than relying on nudging and normative actions. The focus of the Social AI on the social system (rather than on infrastructures and service provision) embraces a vision in which the actions related to the use of infrastructures and services reflect the interactions between service providers and end-users in the context, see Figure 3.\r\n\r\nFigure 3:\r\nFigure 3: The different scope of personal, system and social AI. The scope of Social AI is supporting stakeholders’ relationships, actively engaging users and service providers acting in the same social context.\r\nThe next section outlines the connection between in situ engagement and Social AI by integrating the Rogers\' vision of an engaging UbiComp [2].\r\n\r\n3 Social AI & Engaging UbiComp\r\n\r\nThe concept of Social AI implies the ability of the AI to manage two different types of complexities. The first type of complexity is related to the plurality of social actors and the various roles they assume in the different activities in which they are involved acting as human agents. The second type of complexity is given by the \"interscalarity\" of dynamic systems interweaving physical and digital environments, services and organisations, providers and consumers of information, and the periodical configurations (e.g. hour-by-hour, day-by-day) and evolution over time of the system in itself. Cities are the most typical example of this type of setting, in which the uncertainty and unpredictability of people decisions and actions in urban environments is increased by the multitude of interrelated urban systems and components constituting the materiality of the city in itself [7].\r\n\r\nThe dual complexity of social ecosystems precludes to both human and artificial agents the total comprehension of the general status of the system and the contingencies associated with the actions of each user in the system. On the other hand, the complexity of a social ecosystem is not \"messy\", but it has its structure: it is a system of systems. In this frame, the roles of artificial and human agents can be reconfigured coherently with a dual-layer structure. On the one hand, artificial agents excel in managing multiple inputs, historical series, and multiscale systems, and performing systematic analysis aimed to identify recurrent patterns, even though they are not able to correctly interpret particularities. On the other hand, humans are able to understand others, their reasons and rationales for acting, and managing unique cases and deviations, while the systematic analysis of heterogeneous information requires considerable effort and time. \r\n\r\nThe complementarity between Social AI and humans is given by the fact that a Social AI can operate through a holistic comprehension of the complexity of the upper system (the system of systems), while humans act aware of the local complexity, that is the lower systems of the environment closer to users, see Figure 4. In other words, humans are the interpreters of themselves and the context contingencies, while the AI elaborate the differences of roles and activities of humans and elaborate them in a general view of the social (and physical) ecosystem in which they act. Wrapping up, human and artificial agents do have access to different complementary perspectives mutually precluded.\r\n\r\nFigure 4:\r\nFigure 4: Dual-complexity of the social ecosystem, as a system of systems.\r\nIn this frame, by being face-to-face and working shoulder-to-shoulder, human and artificial agents can provide the opportunity to access the respective facets of their shared reality through their actions. Following the Dourish arguments about embodied technologies, their respective \"embodied interactions turn action into meaning\" [5] and “meaning arise on multiple levels\" [5]. Thus, the proposed concept of Social AI reflects a technology that can \"provoke us to learn, understand and reflect more upon our interactions with technologies and each other\" [2], \"assist the development of the powers of the mind\" [8] and foster the creation of new practices around technologies [5] opening-up aspects of our reality otherwise hidden. This definition of Social AI incorporates the concept of engaging Ubicomp as a technology that makes the \"pluralities\" of situations evident, legible and accessible to users.\r\n\r\nSo far, we argued that Social AI is an engaging UbiComp. Now we briefly try to support that an engaging UbiComp must be a type of Social AI. Indeed, in our view of engagement in a social ecosystem, the purpose of the engagement is providing different perspectives of the current situation to users. Consistently with this standpoint, an engaging ubicomp technology must be able to understand the current situation without focusing on understanding the user only, but expanding its understanding to the contingent state of the system or the perspectives of other users acting in the same context. Therefore, an engaging Ubicomp is required to have learning skills and ability to navigate the dual complexity of social ecosystem at the upper level, and thus it has capabilities similar to the ones characterising a Social AI.\r\n\r\nWe envisage a social AI operating as a bridge between people, without eroding their agency and by seeking their support through communication, see Figure 5. More specifically, a Social AI acts as an interface abstracting the capabilities and services of the technological ecosystem into appropriate engagement inputs for the different stakeholders into the human ecosystem. This vision implies a shift in the object and target of AI solutions from analysing and learning humans’ behaviours to coordinating and facilitating the access and use of technological resources by users in their context of action.\r\n\r\nFigure 5:\r\nFigure 5: A Social AI acts as interface abstracting the capabilities and services of a technological ecosystem into appropriate engagement for the different actors of a human ecosystem.\r\nIn this sense, it is possible to foreshadow a natural evolution of UbiComp following the evolution process of web technologies, which are nowadays mostly oriented toward machine-to-machine interactions [9, 10]. This horizon configures artificial agents as users of \"calm computing\", and engaging UbiComp and Social AI covering the role that web portals and applications have in the domain of web-based technologies: the \"mountain top\" of an ecosystem designed to be complementary to human users and human users capabilities, see Figure 6.\r\n\r\nFigure 6:\r\nFigure 6: Most of the AI and UbiComp technology are machine-oriented, while a minority (the mountain top) is adapted for humans. Pushing machine-oriented technologies to be used as human-oriented technologies prompts the emerging issues related to ethics, data ownership, user\'s agency and privacy.\r\n4 Conclusions\r\n\r\nIn the introduction, we suggested AI agents as the ideal users of Weiser\'s \"calm computing\" [3]. Then, we introduced the concept of Social AI, a vision of an AI acting in a social ecosystem. The goal of a Social AI is engaging users and stakeholders by relying on the overview of the different perspectives and contingencies in their context of action.\r\n\r\nWe argued that 1) a Social AI is a type of \"engaging UbiComp\" accordingly to the definition of Rogers [2], and that 2) UbiComp technologies aimed to \"engage\" users in their social context must behave as a Social AI. These arguments lead to our proposal of considering engaging UbiComp and Social AI as two complementary paradigms of ubiquitous intelligent technologies. Their combination is not aimed to replace humans and human abilities (e.g. in understanding other people\'s intentions, managing unique situations), but to cooperate with humans (e.g. compensating memory, time, commitment limitations).  \r\n\r\nIn our vision, Social AI is not a persuasive technology, designed to \"nudge\" users\' behaviour [11], or instrumentally used to control society at scale as a \"Big Brother\". On the contrary, the combination of engaging UbiComp and Social AI instantiates a vision of the human and artificial agent intersubjectivity. This vision outlines how artificial and human agents can understand each other regardless of their differences in order to operate in the same environment and on the same digital, social and physical artefacts. \r\n\r\nWe foresee (or hope to see) a unified research agenda addressing what human and machines should learn from each other by close acting in the same context, what should be the focus of their interactions, and how we can facilitate this synergic relation based on an explicit sustainable framing of their reciprocal roles.\r\n\r\nReferences\r\n\r\nMyers, Karen, Berry, Pauline, Blythe, Jim, Conley, Ken, Gervasio, Melinda, McGuinness, Deborah L., Morley, David, Pfeffer, Avi, Pollack, Martha, and Tambe, Milind 2007. An intelligent personal assistant for task and time management. AI Magazine, 28(2), 47-47. DOI: https://doi.org/10.1609/aimag.v28i2.2039  \r\nRogers, Yvonne. 2006. Moving on from weiser\'s vision of calm computing: Engaging ubicomp experiences. In International conference on Ubiquitous computing. Springer, Berlin, Heidelberg, 404-421. DOI: https://doi.org/10.1007/11853565_24  \r\nWeiser, Mark, and Brown, John S. 1997. The coming age of calm technology. In Beyond calculation (pp. 75-85). Springer, New York, NY. DOI: https://doi.org/10.1007/978-1-4612-0685-9_6  \r\nAlkhatib, Ali, & Bernstein, Michael. 2019. Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (p. 530). ACM. DOI: https://doi.org/10.1145/3290605.3300760  \r\nDourish, Paul. 2001. Where the action is. Cambridge: MIT press. DOI: https://doi.org/10.1162/leon.2003.36.5.412  \r\nSuchman, Lucy. 2007. Human-machine reconfigurations: Plans and situated actions. Cambridge University Press. DOI: https://doi.org/10.1017/CBO9780511808418  \r\nPortugali, Juval. 2011. Complexity, cognition and the city. Springer Science & Business Media. DOI https://doi.org/10.1007/978-3-642-19451-1  \r\nBruner, Jerome. 1973. The relevance of education. WW Norton & Company. ISBN: 0393006905  \r\nSculley, Arthur B. and Woods, William W. 1999. B2B Exchanges: The Killer Application in the Business-To-Business Internet Revolution. ISI Publications. ISBN: 9627762598  \r\nKelion, Leo. 2013. Bots now ‘account for the 61% of web traffic’. BBC news. Retrieved June 1, 2019 from https://www.bbc.co.uk/news/technology-25346235.  \r\nSchneider, Christoph, Weinmann, Markus, and vom Brocke, Jan. 2018. Digital Nudging–Guiding Choices by Using Interface Design. Communications of the ACM, 61(7), 67-73. DOI: https://doi.org/10.1145/3213765  \r\nFOOTNOTE\r\n\r\n1In this paper, the term “stakeholder” is always referred to groups of individuals and organisations characterised by specific interests, roles, missions in the social context, that determine their reciprocal social relationships and actions. The term stakeholders is not used to indicate the different interest groups respect to AI technologies, but in a broader sense related to the idea of social contexts as arena hosting a multiplicity of social instances.',1,'Antonini','Alessio Antonini and Lucia Lupi','Alessio Antonini *(Knowledge Media Institute, The Open University, UK)*<br>\r\nLucia Lupi *(DIST, Polytechnic of Turin, Italy and University of Turin, Italy)*',NULL,0,'10.1145/3363384.3363483','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,75,5,NULL,NULL,0,39),(31,'linehan-imagining-the-cool-ag-or-freedom-considered-harmful','2019-09-02 15:24:57','2019-11-14 14:12:41','2019-09-02 15:24:57',NULL,1,'published','[]','Imagining the Cool-ag: Or, Freedom Considered Harmful','This short paper makes an argument about our lack of comfort, as researchers, in developing a science, and a technology, for enacting control over behavior. We present a design fiction about a smart prison, in which behavior change is facilitated via always-on IoT-facilitated monitoring. This fiction may be read simultaneously as a constructive application of behavioural science to an appropriate context, and as a dystopian attack on personal freedom. We argue that the implementation of ubicomp systems that are intended to facilitate behavior change (i.e., almost all ubicomp systems), will inevitably lead to questions over personal freedom. We draw parallels to the reaction of society to the field of behavioural psychology, which has an expressed goal of gaining prediction and control over behavior. Ultimately, if we are to realise the potential of ubicomp to change society positively, we need to become comfortable with enacting control, or in other words, taking responsibility.','Conor Linehan and Ben Kirman. 2019. Imagining the Cool-ag: Or, Freedom Considered Harmful. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363485](https://doi.org/10.1145/3363384.3363485 \"DOI for the article \'Imagining the Cool-ag: Or, Freedom Considered Harmful\'\")','1 CRUELTOWN - THE “COOL-AG” OF THE FUTURE\r\n\r\n“There\'s this place called CruelTown. It is a vision of scientists, engineers and “other researchers” at HB (Human Behaviour) labs. It\'s a vision of a world where everybody and everything is connected wirelessly through the world wide web. People, places and even objects have websites. Beacons beam out their web addresses. People are connected to a wide variety of smart, wireless information appliances that know who you are, where you are, and what\'s going on around you. And it all comes together to provide a service that people need:” Punishment and Rehabilitation.\r\n\r\nHere at HB Labs1, we have very recently developed the technology capable of enacting perfect behavioural control. We have developed wearable, pervasive, cloud-based, internet of things technologies capable of measuring peoples’ precise location inside and outside of buildings, their heart rate, temperature, sleep quality, and relationship quality. We have the ability to remotely turn on and off peoples heating and lights, to lock and unlock their doors, to disable their cars, to change the language on their devices, and control access to social media and information more generally. More importantly, we have found exactly the context in which full behavioural control can and should be achieved: state incarceration.\r\n\r\nCruelTown is a gated society, organized and controlled along the principles of behavior modification [2, 4, 6], facilitated by IoT measurement devices, and designed to teach offenders appropriate social behaviours. It takes the guesswork out of the rehabilitation function of incarceration. Inmates can be released when appropriate behavior has become stable and predictable - and never before.\r\n\r\n\r\nFigure 1: Examples of disorienting CruelTown Architecture [HP Labs].\r\n1.1 How does it work?\r\n\r\nUpon incarceration, the prisoner is processed, chipped and shipped to the Cruel Town complex, the architecture of which closely resembles a disorientating early-1990s office park complex (see fig 1.). The prisoner is given a smart watch and communication device, and introduced to “Marcy”. Marcy is an overseeing artificial agent that sets personalised short- and long-term goals for behavior change, and monitors behavior with respect to those goals, and delivers reinforcement and punishment using nearby IoT devices.\r\n\r\n1.2 CruelTown values you!\r\n\r\nReinforcement is a critical component of behavioural modification techniques. Inmates gain access to items that they value, such as heat and food, in exchange for demonstrating appropriate behavior. Reinforcement techniques include both negative reinforcement, such as a temporary peace from the demands of Marcy, and positive reinforcement in the case of “illustrious service awards”. These awards are issued to inmates based on achieving behavioural goals while inside cruel town (see Fig. 2). Service awards function like tokens in other behavior modification contexts, with the exception that they are delivered from every piece of technology encountered.\r\n\r\n\r\nFigure 2: Powerful “service awards” help keep occupants motivated. [HP Labs].\r\n\r\nFigure 3: Extreme punishments, such as destruction of personal property can be effective mechanisms for change. [HP Labs].\r\n1.3 Punishment\r\n\r\nOf course, like any other prison solution, CruelTown must also punish undesirable behavior (see Fig 3.). Cruel Town can take action to ensure that less desirable behavior, when observed, does not occur again. Marcy has a wide range of abilities in delivering punishment. Through controlling locks on bedrooms and bathrooms, manipulating heat and light while sleeping, denying access to the ubiquitous vending machines - the only source of nourishment in Cruel Town - Marcy can deliver personalized punishment plans to convince even the most ardent of criminal to change their ways. For example, one prisoner may be required to sit through a long meandering powerpoint presentation on a glaring transparent screen (Fig. 1; bottom). For other prisoners, social punishments can work better. For example, Carruthers and Brown (Fig 1; top), must endure humiliating personal development evaluation meetings together.\r\n\r\n1.4 Daily life in CruelTown\r\n\r\nLike other gated communities, CruelTown has a full schedule of organized events taking place every day. Attendance is mandatory, and through these events, prisoners are placed in increasingly complex social situations, through which their behaviour can be monitored and improved. These events can range from basic level cleaning duty, through to potentially conflict-inducing activities such as preparing group presentations.\r\n\r\n\r\nFigure 4: Special unit for young offenders. [HP Labs].\r\n1.5 “I\'m very proud of you, you are doing such a great job”\r\n\r\nOne of the great challenges of corrective systems is handling young offenders. Juveniles are not yet habituated to the horrors of modern open plan office architectures, and as a result, methods for management of behaviour of adult inmates in Cruel Town proper is often not appropriate. Instead, a special wing of Cruel Town is dedicated to more domestic settings where children can be isolated totally from the rest of the prison population, instead only interacting with Marcy through computer terminals and refrigerators.\r\n\r\n2 DISCUSSION\r\n\r\nRecent years have seen widespread recognition of the ability of ubiquitous, pervasive technologies such as smart phones, IoT devices, and ”big data” analytic practices to; 1) monitor ongoing human behaviour, and 2) take action based on the data collected in a way that materially affects a person\'s life. We have seen many prototype examples of these practices in HCI research in supporting healthier exercise habits [1] encouraging environmental decision-making [11] and influencing mood [5].\r\n\r\nRecent years have also seen much speculation over potential future implications of these data capture and analysis practices; with many TV shows, films and academic papers dedicated to forecasting dystopian futures in which humans are removed from decision making power by the tools that were initially designed to help them (e.g. [7]). Concerned ubicomp researchers invariably discuss the problems inherent in pervasive monitoring technology by citing Foucault [3], who used the Panopticon - a design innovation intended to help prison guards to monitor behaviour and enforce prison rules - as a metaphor for how control is enforced in modern societies. Essentially, the argument is that ubicomp technology facilitates the prison-like control of the state over peoples behaviour.\r\n\r\nPeople are undoubtedly wise to be critical of technology capable of monitoring and exerting control over their behaviour in a way that is difficult to speak with, react against, or even understand. However, we argue that often the argument against such technology revolves primarily around notions of personal freedom; technology that reduces our freedom to make choices as an individual is inherently bad, instead we need technology that improves our ability to make choices. Hence, we get ”recommender systems,” and ”decision support systems” that give illusions of choice and self-determination, rather than systems that explicitly take decisions and exert overt behavioural control. We argue, following Skinner in his seminal work on the politics of behavioural science Beyond Freedom and Dignity [9], that personal freedom is not necessarily an inherent good, nor is the loss of control over your behaviour to institutional intervention necessarily bad.\r\n\r\nWe argue that systems that help us to monitor, analyse and control human behaviour in an accurate and precise manner have a lot of very practical applications, under appropriate supervision and in appropriate contexts. The CruelTown smart prison can be read as invasive and dehumanising, and many people will read it that way. At the same time, it can be read as ”more humane than existing prisons”, by ensuring the prison functions not only as a site of randomised punishment, but also as a feasible and effective site of rehabilitation-related functions. In other words, by removing personal freedoms and increasing technocratic behavioural control, we improve the chances of prisoners in leading fulfilling lives after release from prison. There are many other examples where such improved control over behaviour would be advantageous to both society and the individual, and for which we could have written a sales pitch like the CruelTown one above, including probation procedures, formal education, and social care.\r\n\r\n2.1 Control is Good!\r\n\r\nImportantly, the argument over whether we should even have a technology capable of monitoring and controlling behaviour is one very familiar to behavioural scientists [10]. The ultimate goal of behavioral science is to understand the processes through which our behavior is shaped by our experiences and our environment. Through advancing our knowledge of behavioral science we get closer to causal explanations for behavior. Specifically, we develop a set of tools and principles that we can apply in order to make our behaviours, and the behaviours of others, more or less likely to occur. In other words, we advance our ability to both predict, but also control human behavior.\r\n\r\nSince the publication of B.F. Skinner\'s utopian novel Walden Two in 1948 [8], behavioral scientists have often suggested that societies would be better organized, fairer, more ecologically friendly, and happier if they were organized according to the principles of behavioral science. Walden Two describes a utopian community whose members live together bound by a strict set of rules defining how tasks are completed and rewards granted in such a way to encourage positive behavior change and maximize motivation. For example, working less desirable jobs earns more Labourcredits, which means those workers get more free time for leisure. Walden Two acts as an argument for how the principles of behavioral psychology can be used to help people become better motivated, productive, and healthy.\r\n\r\nAttempts have been made previously to run utopian communities according to the principles of behaviour analysis. However, very few of these have sustained for a longer term. People are typically, and understandably, uncomfortable with the notion that their own behaviour is being controlled directly by others. Moreover, we have never had technology capable of the pervasive and precise monitoring, measurement, and analysis of behavior necessary to enact perfect behavioural control. Given the latter problem is now solved, thanks to decades of technology-focused work by Ubicomp researchers, we argue that ubicomp researchers, possessing technology capable of prediction and control over behaviour, must now deal with the former. We must deal with the types of questions and criticisms that have dogged behavioural psychologists for the past 50 years. Specifically, if we are to possess a technology and a science of behaviour change, one that works, does anyone want to (consciously, knowingly) use it?\r\n\r\n2.2 Beyond Freedom and Dignity\r\n\r\nOne of the main challenges in implementing any effective system for shaping and changing behaviour (focused on anything from recycling behaviours, to water usage, to public transport utlisation, exercise and healthy eating) is the tendency of Western society to over-value personal freedom. While personal freedom is an undoubted Good, one that has been denied to the majority of humans throughout our his- tory, and thus deserves celebration where it can be achieved, it is undoubtedly often in competition with other, more public goods. In some respects, we must overcome our fetishisation of personal freedom if we want to ensure that technology serves public goods, rather than solely private ones.\r\n\r\nIn his book Beyond Freedom and Dignity [9]), Skinner argues that the concept of Freedom as discussed colloquially is problematic, as it is defined primarily based on subjective feelings, rather than systematic analyses. People want to feel as if they are free; they don\'t want to feel that their behaviour, their choices and opportunities, are under the control of others. And yet, our behaviours are hugely constrained by the environment we grow up in, and the situations that we encounter on a day to day basis. To claim that we freely choose daily to catch one bus over another, is to ignore the impact of other controlling factors, such as our children\'s school timetable, our partners dinner plans, the specificities of bus routes and timetables, traffic incidents etc. If we are to think critically about personal freedom, we must acknowledge the impact of the systems with which we interact on our behaviour. These systems are already designed to make certain types of behaviour more likely. People own, design and control these systems.\r\n\r\nSkinner builds his argument by suggesting that the concept of Dignity is in direct conflict with the above analysis. By Dignity, Skinner refers to the prevailing idea that we are entirely in control of our own actions, so we should be praised and rewarded for achievements, and likewise, punished and shunned for anti-social or unsuccessful decisions. Of course, any successful achievements are made possible by a complex supporting infrastructure of technologies and people. Similarly, any anti-social behaviour is undertaken within a socio-technical context that supports or encourages that behaviour. If we are to accept that our opportunities are largely determined by the socio-technical systems with which we interact, we must reject the colloquial concepts of personal freedom and dignity as unhelpful. Thus, any criticism of ubicomp as infringing on freedom and dignity becomes bearable.\r\n\r\nBehaviour changing ubicomp technology is directly in conflict with the colloquial ideas of freedom and dignity - ideas to which many people are emotionally attached. But those ideas are disingenuous - they are a poor analysis of the socio-technical reality of our day to day lives. If we are to accept that our opportunities are determined by the systems that we interact with, then we can start to build systems that implement the values that we want to see. More importantly, we see the immediate imperative in doing so. We must give up freedom and dignity, in order to achieve fairness and sustainability.\r\n\r\nThe problem is not that we have developed a technology that is capable of monitoring human behaviour, measuring, processing and analysing those data, and taking action in ways that materially affect individuals and society. As Skinner [9] argued, we should not be afraid that we have developed a science and technology capable of pervasive and effective behavioural control - this is a huge positive in many ways. The problem is that we have not yet developed appropriate methods for ensuring that technology is applied in the public interests, open to democratic public scrutiny and objection. In other words, the problem is that the prison guard in the Panopticon is no longer a state employee that we can sack. Ultimately, if we are to realise the potential of ubicomp to change society positively, we need to become comfortable with enacting control, or in other words, we must become comfortable with taking responsibility for the outputs of that system.\r\n\r\nREFERENCES\r\n\r\nSunny Consolvo, David W McDonald, Tammy Toscos, Mike Y Chen, Jon Froehlich, Beverly Harrison, Predrag Klasnja, Anthony LaMarca, Louis LeGrand, Ryan Libby, et al. 2008. Activity sensing in the wild: a field trial of ubifit garden. In Proceedings of the SIGCHI conference on human factors in computing systems. ACM, 1797–1806.  \r\nJohn O Cooper, Timothy E Heron, William L Heward, et al. 2007. Applied behavior analysis. (2007).  \r\nMichel Foucault. 1977. Discipline and punish: The birth of the prison. Pantheon.  \r\nAlan E Kazdin. 2012. Behavior modification in applied settings. Waveland Press.  \r\nAdam DI Kramer, Jamie E Guillory, and Jeffrey T Hancock. 2014. Experimental evidence of massive-scale emotional contagion through social networks. Proceedings of the National Academy of Sciences 111, 24(2014), 8788–8790.  \r\nRaymond G Miltenberger. 2011. Behavior modification: Principles and procedures. Cengage Learning.  \r\nBlack Mirror. 2016. Nosedive. Netflix.  \r\nBurrhus Frederic Skinner. 1966. Walden two. Hackett Publishing.  \r\nBurrhus Frederic Skinner. 1972. Beyond freedom and dignity. Number 04; BF319. 5. O6, S5. Springer.  \r\nBurrhus Frederic Skinner. 1974. About behaviorism. Knopf.  \r\nAnja Thieme, Rob Comber, Julia Miebach, Jack Weeden, Nicole Kraemer, Shaun Lawson, and Patrick Olivier. 2012. We\'ve bin watching you: designing for reflection and social persuasion to promote sustainable lifestyles. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2337–2346. ',1,'Linehan','Conor Linehan and Ben Kirman','Conor Linehan *(University College Cork, Ireland)*<br>\r\nBen Kirman *(University of York, UK)*',NULL,0,'10.1145/3363384.3363485','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,80,5,NULL,NULL,0,41),(32,'hook-soma-design-and-politics-of-the-body-addressing-conceptual-dichotomies-through-somatic-engagement','2019-09-02 15:24:57','2019-11-14 14:07:00','2019-09-02 15:24:57',NULL,1,'published','[]','Soma Design and Politics of the Body: Addressing Conceptual Dichotomies Through Somatic Engagement','Human reasoning often revolves around dichotomies: male-female, rational-irrational, emotion-thinking, body-mind, white-black, and so on. Through our design processes, we often repeat and reinforce these patterns. We argue that a stronger somatic engagement with the digital materials might open the design space in different manners, thereby bypassing some of these ready-made conceptualizations. Through a *soma design* stance we have attempted to address: dualism; feminist qualities such as pluralism and participation; addressing and counteracting privilege; and how to get closer to our bodies and our selves instead of letting data and interaction distance ourselves from our bodies, emotion, and experience.','Kristina Höök, Sara Eriksson, Marie Louise Juul Sondergaard, Marianela Ciolfi Felice, Nadia Campo Woytuk, Ozgun Kilic, Vasiliki Tsaknaki, and Anna Ståhl. 2019. Soma Design and Politics of the Body: Addressing Conceptual Dichotomies Through Somatic Engagement. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 8 pages. [https://doi.org/10.1145/3363384.3363385](https://doi.org/10.1145/3363384.3363385 \"DOI for the article \'Soma Design and Politics of the Body: Addressing Conceptual Dichotomies Through Somatic Engagement\'\")','1 INTRODUCTION\r\n\r\nHuman reasoning often revolves around dichotomies: male-female, rational-irrational, emotion-thinking, body-mind, white-black, and so on [20]. In a sense, it is a very helpful way of reasoning, as it makes it possible to divide the world into reasonable chunks that we can make sense of. It allows us to orient ourselves in a world full of uncertainties and dynamic unfoldings. At the same time, it leads our thinking astray in many ways. For example, in Western society, the male-female dichotomy is associated with the thinking-emotion and mind-body dichotomies. This association casts females as emotional beings, anchored in their bodies, without the ability to reason and think rationally. That particular division goes back to the Greek philosophers and is still alive and kicking in our Western culture today [18]. In other cultures, other dichotomies have come to dominate thinking. For example, some cultures associate women with fire, because women would typically carry the coal that makes fire [25]. If fire is dangerous, then women are dangerous. In this way, categories and metaphors come to influence our thinking and reasoning. These associations, in turn, affect not just our thinking, but our behaviors, all the way to how we move, sit, run, and engage with others. More importantly, in this context, they are all highly intertwined with our design practice. Our stance towards political issues, such as dualism, feminism, privilege, class or oppression in various forms, will directly impact which artifacts we can and want to imagine and build. Our choices, in turn, will have effects on our society, because the design and technologies we shape will, in turn, shape us.\r\n\r\nRecently, there has been a call for action from ACM [17]. ACM recognizes that “the negative impacts of our research are increasingly high-profile, pervasive, and damaging” and asks all authors to consider not only what new technologies afford in terms of positive developments, but also all the possible negative consequences. For design research, the question is better asked slightly differently: what are the ways by which we can design in harmony with our values? Which leads to the unavoidable question: what are our values and what does it mean to do good design where our values are embedded in the interactions that the design affords/promotes? In short, what are the ideals we adhere to and promote in HCI? Some argue that one of the reasons HCI is not a coherent field is because we cannot agree on any such ideals [8, 12, 26].\r\n\r\nWe have been exploring a path to design grounded in somaesthetic theories [20]. Somaesthetics is an ethical and aesthetic project [40], where the pragmatic aim is that we can ”live a better life” through engaging with and learning through all our senses. When applied to interaction design, we have found that it requires us to engage more deeply, honestly, and with our whole selves, beyond ready-made concepts and cultural ideas. This, in turn, has helped us question some of the dichotomies that we otherwise often reinforce in our design processes.\r\n\r\nBelow, we will provide a brief introduction to somaesthetics and soma design before we describe how it has, in some ways, allowed us to break free from conceptual dichotomies, and instead ground our design work in our own bodily, somatic experiences, opening design spaces in novel ways.\r\n\r\n2 BACKGROUND: SOMA DESIGN\r\n\r\nA soma design process is a holistic approach to aesthetics in design [20] building on philosopher Richard Shusterman\'s somaesthetics theory [40]. Somaesthetics is a way to examine and improve on all connections between sensation, feeling, emotion, and subjective understanding and values [24] – in short: improving on our somas.\r\n\r\nAs we discussed in a recent paper on how to teach soma design [45], this design stance requires training your ability to aesthetically appreciate all your senses, but also to imagine through your senses, movements and material encounters – what could be. As with any design process, when you shape the interactive artifact you are, in a sense, also shaping future users’ bodies and movements. This is why we emphasize that what is taking form in a soma design process is not only the digital and physical materials you use to build your interactive artifact with, but also the end-users’ somas. A soma design process, therefore, thrives off the “aesthetic potential of the sociodigital materials and the creative process of shaping these into dynamic gestalts and orchestrated experiences” ([20], p. 127). These two sides of the material, the digital on the one hand, and the future users’ engagements on the other, come together to form the interactive aesthetic experience.\r\n\r\nNot only are movements and the living body the lens through which we can understand the world, but this “tool of tools” [41] itself is also moldable. By learning, improving, and playfully engaging with movements involving our muscles, nervous system and senses, we may extend our experiences and create richer and potentially better ways of being in the world. In a soma design process, our bodies and our subjective experiences, feelings, values, meaning-making, and movement-based engagements are altered by the design process. It is the whole dynamic gestalt arising through use that we aim to engage with somaesthetically.\r\n\r\nAlthough embodiment [28] and embodied interaction [9] have been central tenets in HCI for quite some time, the actual corporeal, pulsating, live, felt body has been notably absent from both theory and practical design work. Furthermore, as Sheets-Johnstone [38] argued, embodiment can be seen as a mere “lexical band-aid” to remedy a problem that is rooted in a fundamental misunderstanding – because there is never any possibility for us to be disembodied. This means that we cannot understand and design for the body by simply including an embodied view as some sort of add-on in our process. Instead, we need to incorporate the actual living, corporal body with its muscles and moving limbs.\r\n\r\nIn recent years, scholars have reached out to different fields in an attempt to overcome the absence of the living body. But interaction designers are not skilled when it comes to designing with movement, emotion, and holistic engagements. To counter this problem, several different methods and techniques have been suggested. To engage with one half of the sociodigital material, the soma expertise, Schiphorst [34] suggests involvement with Somaesthetic Connoisseurs (e.g. choreographers, yoga instructors, culinary chefs) to support the design team. To engage with the other half of the materials, computational materials, Akner-Koler and Parivash suggest approaching the materials in a structured manner – feeling, touching, tasting, in order to extract their aesthetic affordances [1]. There are also methods of making strange [27], where the underlying idea is that movements and experiences become more clear in our minds if we shift from habitual movements, so deeply ingrained in our habits that we cannot ‘see’ them anymore, into non-habitual, strange movements. Imagine (or try it now as you read), for example, folding your arms the ‘wrong’ way in order to discern what is involved in the habitual movement of folding your arms. What is involved in that movement? When this is more ’clear’ in your mind you can investigate it and later you can use it as part of your design process (in case it happens to involve moving your arms).\r\n\r\n3 WHAT SOMA DESIGN CONTRIBUTES\r\n\r\nWhat appeals to us as interaction design researchers, is how the somaesthetic project is not only an analytical stance but also a pragmatic and practical endeavor. Our corporeal realities, our somas, can be seen as an intertwinement of aesthetics, politics, culture, sociality and subjectivity [11]. Cultural practices and digitally-enabled objects, such as mobile phones and computers, enforce a form of sediment, agreed-upon movements, enabling endless variation but with prescribed ways to act. The way we make sense of emotions combines the experiential and emotional processes in our bodies with interaction with others, colored by our learned cultural practices. By engaging in a soma design process [20], we can put the felt experience and enactment of our somatic presence in the foreground. We can probe which movements lead to deepened somatic awareness; heightened awareness of others, our environment, and how we are affected by technologies; uncovering and questioning norms; bodily freedoms rather than constraints and oppression; and in general engaging with aesthetic experiences and expressions. Soma design offers or even demands a non-dualistic stance, where the plurality of bodies becomes inescapable.\r\n\r\nBelow we discuss some of the issues we see as core to address with future interaction design work and where we believe soma design has something to contribute. The topics come out of our work with designing for body awareness [21], mental health [33], everyday household products [45], menarche, menopause, and sensory misalignment in playful settings.\r\n\r\n3.1 Changing bodies\r\n\r\nI tried a mechanical body extension in the form of a tail [44] at a workshop. To make the tail wiggle, I had to move my hips in different patterns, like a circular motion in the sagittal plane, or a smooth sashay from side to side, or a tilt as if I was putting the tail between my legs. The circular movements of my hips encouraged movements that I associate with a feminine, sexy, flirtatious way of walking. As the flirtation was directed backwards, behind my back, I repeatedly turned my head, cocking it, nodding, smiling, to check out the effect on others behind me. Putting the tail between my legs put bodily reality into the expression of shame. I could feel my face crumble into a sad embarrassed expression — again looking behind me to see the effect on others, but now looking under my brows, with a facial expression saying ”excuse me”. - Kristina, in [20]\r\nThe ways we move, feel, think, and interact with our surroundings are inseparable processes that together determine how we create meaning in our everyday lives. It is through movement that we understand and act in the world. Our bodies move, our thinking is movement. As Sheets-Johnstone [38] put it: ”What is distinctive about thinking in movement is not that the flow of thought is kinetic, but that the thought itself is. It is motional through and through; at once spatial, temporal, dynamic”. Our somas are continuously adjusting to the material constraints of our environment that are dynamically changing, and composites other human (and non-human) bodies, objects and technologies [2]. For designers, this means that the technologies we design and the interactions our users engage in have a concrete impact on our movements, behaviors, and thinking – our bodies are shaped by the affordances of the digital materials we engage with.\r\n\r\nThrough deep somatic involvement with the digital materials during the design process, we have found that we gain a better understanding of how our bodily ways of being are spurred through the envisioned interactions. In our design processes, we repeatedly touch, feel, taste and move with unfinished compositions until we find those interactions that make sense [1]. We use methods such as estrangement [47] – that is making a movement in a non-habitual way in order to make the habitual clearer in our minds. We probe the aesthetic potential of materials by slowly changing and shaping their form and dynamic gestalt. A soma design requires moving to be moved. We do not verbalize our design ideas as much as we enact them, as some experiences are inevitably be lost in the translation from the experience of moving to words and drawings on paper.\r\n\r\nIt is important to note that our bodies are not only changing in interaction with technology. The way one\'s body grasps the world is not static but transforms with the pull of gravity as we age; transition through puberty and pregnancy; with illness or disability; and changes in shape and size. At times, one\'s subjectivity has to adapt to adjustments that can be monumental in terms of the way the body is constituted. Soma design, with the commitment to deepening researchers’, designers’ and users’ somatic sensibilities – that is, training our senses [5] – have the potential to bring awareness of and attunement to both the self and the other. But we need to find ways, methods, and approaches that can ensure we do not fall into ableist or shallow understandings, and that enable us to attend to experiences that change, transform and transition over time.\r\n\r\n3.2 Dualism and the minded body\r\n\r\nThrough engaging in body practices such as Feldenkrais or Contact Improvisation dancing (performed in pairs), I have built up an experienced somatic movement design repertoire to return to and extend on. It has made me reflect not only on my own dynamic soma but my soma in relation to other beings, physical objects, situations. I realize that it is not only my somatic experience or/and the other, but a unique in-betweenness, which alters depending on who is participating. It is like painting, if you change your attention from the persons or objects you are painting, and focus on the spaces in-between, other things stand out. You become aware of a greater whole. - Anna\r\nWith the shift in concerns from usability and efficiency to personal engagement with systems following the ’third wave’ HCI, scholars have embraced approaches from the arts, design and philosophy in an attempt to transcend the divide between work, leisure, arts as well as the dichotomies between rationality and emotion [15], to instead consider “people\'s whole lives” ([6], p. 6). Since then, emotion has gained prevalence in academic study partly because of the realization that emotion is, in fact, fundamental to rational thinking. In this view, emotions are still a matter of mind. In reality, emotions take on other prominent roles in our lives, beyond decision making and rationality, in ”connecting our thinking, bodies, sociality, and meaning-making processes together” ([20] p. 179). All is linked in the body [37, 38]. Irrational-rational and emotion-thinking, as binary opposites, stems from one of the Western thoughts’ most defining dichotomy, and greatest misconception of the human condition: the mind-body divide. That is, the separation of mind and body in favor of the mind as the site, where knowledge and reason are situated. The body is neglected as some functional apparatus that simply responds to commands formed in thought and sometimes has these strange, emotional reactions. This mechanistic attitude towards the body is clearly mirrored in the design of interactive technologies, where the body (that barely even existed in HCI research before its third wave) is often regarded as some sort of machinery that can be ’improved’ or ’enhanced’ by means of technology (’typical’ examples include those of the quantified self-movement [29] and various health tracking apps [48]).\r\n\r\nDualism, like any conceptualization or theoretical perspective, colors our reasoning and shapes the way in which we approach and explore a design space, and thus imposes certain creative limitations in the design process. As a result, a dualistic stance might render interactions and technologies that are oppressive or neglecting in constraining our movements, experiences, and thinking. While we are not claiming that this is always the default case, we are questioning whether designs such as the Soma mat, the Breathing light [43] or the Mediated body [19] could have been the result of a design process that reinforces a third-person perspective on the body? Perhaps. What is certain, however, is that these exemplars all came out of a first-person, bodily, somatic engagement with digital materials and thrive off the connection between movement and affect. A non-dualistic somaesthetic perspective in design promotes a deepened awareness of and engagement with the ’bodymind’ – an integration of emotion, aesthetics, body, values, cognition and movement [20] – for designers in the design process and users in interaction.\r\n\r\n3.3 Feminist qualities and plurality of bodies\r\n\r\nOur soma design process includes using body maps to attend to our bodily experience, and how it changes throughout our bodily exercises (see figuure 1). But in our projects on the menstruating body, we have found it difficult to express our bodily sensations and changes within the predefined lines of an apparently ’universal’ body; a body that with its thick abrupt outline and missing organs does not stimulate reflection on how our bodies are always in a state of becoming. Instead, during some exercises we have been drawing ’monsters’; bodies that go beyond normative silhouettes to evoke curious, silly, provocative expressions of how our bodies are always in transition. - Nadia, Marie Louise, and Mai\r\n\r\nFigure 1: Above: body maps documenting the experienced body before and after an exercise, represented through colors, shapes and words. Below: ”monster” body maps.\r\nAt the core of soma design lies a first-person perspective on the body, in which designers engage with their somas thoroughly and slowly. Throughout the design process, soma designers learn to appreciate their own bodily experiences, training themselves to recognize and cherish not only meaningful moments but also subtle changes in mundane, and possibly repetitive, daily life events. By means of this engagement, designers can become aware of existing norms and forms of oppression anchored in and expressed through bodily movements [20, 41]. Noticing and challenging how human behavior and movement patterns are to some extent prescribed by an intersection of systems of oppression, allows for questioning the status quo and designing for those interactions that might be neglected or suppressed.\r\n\r\nHowever, a first-person perspective is not enough for a designer to understand the lived experiences of other designers or users. As argued by Höök [20], “[o]ne can imagine having a different body [...] but one cannot experience being another body” (p. 185). In a soma design process, it is therefore fundamental to acknowledge that bodily experiences are all different, that there is not just one way to experience the body. Neither is there one objective experience. Rather, in a soma design process, we acknowledge a plurality of experiences. The feminist quality of pluralism [3] rejects the idea that there is a single, objective and universal point of view and a universal user to design for. A pluralist stance recognizes that the category of human is “too rich, too diverse, and too complex a category to bear a universal solution” ([3], p. 1306). Through soma design, we abandon the notion of universalism and instead build on the plurality of bodies; emphasizing that their corporeal differences are not sought to be generalized or ignored, but rather brought forward and generative in their uniqueness. Providing recognition and space for diverse somatic experiences from the start of the process is fundamental for ensuring pluralism in design.\r\n\r\nHowever, evoking pluralist somatic experiences between soma designers does not guarantee that they will be able to empathize with users by simply engaging with their own somas. In order to truly put the users’ lived experience at the center of design, designers must try to develop a sense of intersubjectivity [28] with them. We argue that to accomplish this form of empathetic engagement from a feminist stance, soma designers must combine a plurality of perspectives on the body in a participatory approach where users become active agents, hereby supporting the participation quality of the Feminist HCI framework [3]. In line with Bennett and Rosner [5], we see opportunities for participation to be developed in the frame of long-lasting partnerships with the communities involved in a research project, ’being with’ instead of ’being like’. Moreover, as soma designers, we argue that these alliances need to be fostered slowly, given that cultivating an appreciation towards the body and how it changes is an extensive and attentive process [20]. Such a participatory, slow, long-term approach would bring the first-person perspective of users to the table, evoking feminist qualities of pluralism and participation.\r\n\r\nWhile involving users in the design process may bring a pluralist perspective, it is also important that designers focus on values and situations that users care about and wish to fight for. From a feminist point of view, soma designers must constantly question their own political position, identifying what preconceptions and ideals they are imposing on the users. This is a requirement for truly supporting advocacy [3] and not merely participation. Engaging with a plurality of bodies for effecting positive change is in itself an act of political emancipation, and establishing partnerships within soma design processes would be a first step to redistributing the power balances between designers and users. Soma design addresses the positionality and the power differentials by decentering the interaction from symbolic interfaces towards bodies, which allows for more agency for users to express their unique body and lived experience.\r\n\r\nIn addition to supporting the feminist qualities of pluralism, participation, and advocacy within soma design, we also see opportunities for using soma design methods in the topic of bodily transitions. Initiating in the 1980s, women\'s health scholars noted a need to put the lived experiences of women at the center of health initiatives [4], appreciating bodily transitions such as menarche and menopause as the norm, not as disease. In order to design with and for these experiences, the body must be central to the design process. In this context, soma design approaches are a potent ally for carrying feminist research on bodily transitions in HCI.\r\n\r\n3.4 Class, privilege, and bodily freedoms\r\n\r\nWe were studying the artistic process of a choreographer creating a choir of drones for the opera stage, dancing with them in real-time [10]. I realized that the only way I could know what it feels like to move with the drones was to engage with them myself (see figure 2). At first, it was scary to move with them. As I began to learn to adapt my movements to the drones’ responses to mine – in the moment, pre-reflectively – I began to feel confident and eager to explore new ways of moving that the drones encouraged, and the expressions we enabled together. - Sara\r\nNot only do we have to attend to how our bodies and somas are constituted and gendered, but also in terms of privilege and class. Context, culture, and practices impose certain aims and ways of engaging. Technologies, on their part, encourage certain movements, certain aesthetic experiences, certain practices, and responses, while discouraging others [20], therefore shaping our ways of being. And it is in that interplay of movements and adaptations of behaviors that the political is enacted and enforced. Our privileges or oppression, culture, and subjectivity are joined in the body, shaped through our concrete everyday practices – practices that are grounded in movement [20, 31]. Sheets-Johnstone [36] describes how the political ”defines us both as creatures of a natural history and as culturally – and individually – groomed bearers of meaning” (p. 2).\r\n\r\n\r\nFigure 2: Sara (author) dancing together with the drones of The Aerial Robotic Choir (see [10]) to capture her first-person experience.\r\nWesternized technologies are often introduced to developing parts of the world and societies in ways that force bodies to conform to the cultural understandings manifested in those designs [13, 14]. Driven by instrumental values, experiences grounded in play and dance – that is, bodily exploration beyond everyday movement – are considered to be frivolous add-ons. But we do not have to look that far to find those whose corporeality is constrained by technological realities formed in solutionism and ideals of productivity and efficiency. Ideals that tend to subject bodies to objecthood, and may render a life of repetitive motions in the factory; with the back bent over a vacuum cleaner cleaning other people\'s floors; or pushing buttons on a keyboard while sitting down all day in front of a computer screen. These interactions and movements have concrete effects on the body, on people\'s sensory perceptual capabilities, possible aesthetic experiences, and ultimately their condition in the world. Soma design is, like the philosophy of somaesthetics, a practical endeavor. By not only criticizing practices and conceptualization that might lead to somatic mistreatment or even harm but also engaging with methods that give way for better somatic experiences [39], soma designers improve on their ability to also design for better somatic experiences.\r\n\r\nBut because soma design has often been based on bodily practices such as mindfulness or the Feldenkrais technique, some tend to disregard soma design as some ’spiritual’ path to ’self-indulgence’, practiced by affluent, cultured design researchers [20]. When it comes to our (authors of this paper) position in the world as designers and researchers, the latter might not be far from the truth. But is soma design exclusively for a privileged class of designers who have the resources to explore esoteric or luxurious designs, far from the reality of most people\'s everyday lives? Here, we believe there is a call for action for soma designers to explore how their methods and aims can be used to designing with scarce resources [13], in utilitarian settings. Beyond utilitarian design aims, we must also ensure that freedom of movement, playfulness, and engagement are not seen as affordable only for the rich, but as basic human rights for all – much along the same line as Amartya Sen\'s freedom and capability theories [35]. We have a responsibility to design for enactments of bodily freedom, defending the right to explore and enjoy our bodies; to engage in movements that are both challenging and enjoyable; and have technology reflect us in ways that promotes our whole somas.\r\n\r\n3.5 Data and bodily (dis)engagement\r\n\r\nWe engage with the sociodigital materials during all stages of a soma design process. We conduct workshops in order to experience materials not only with our hands but also experience how they smell, taste or feel when placed e.g. on our heels. This way of keeping in touch with materials is also about keeping in touch with our corporeal bodies. When we experience smart materials close to our bodies, we always come back to what experiences these evoke. We aim to discuss and articulate those. An insight from this is that we may need new ways of reflecting on how materials affect our senses and new ways of articulating how our in-body materials, organs or microorganisms are affected by the encounters with smart systems, contributing to a broader engagement between us and technologies, and an intimate correspondence with smart material systems that can account for our whole somas. - Vasiliki and Ozgun\r\nWe find ourselves surrounded by a palette of smart and adaptive technologies that aim to connect digital information seamlessly to the physical world. Wearable biosensors, augmented garments, and shape-changing user interfaces are unleashing new opportunities in our day-to-day interactions. Design around the body increasingly relies on data collected from sensors, interpreted through specialized tools such as movement or facial recognition and biosensor data analysis. But these tools tend to isolate measurable units from their surrounding context. If we use them in an attempt to capture somatic experiences, we risk making single interpretations, objectifying our bodies [7, 20], and further a disengagement with our own corporeality – rather than cater for personal interpretation and co-production of experience [15, 42].\r\n\r\nBesides engaging with data and analytical tools, soma designers explore physical materials as an entry point to probe the dynamic gestalt of the interaction [20], by combining the explicit knowledge from material science, engineering and computation with felt material experience. Our rationale as to why we prefer one material over another on our skin is no more limited to utilitarian concerns as materials are found to elicit experiences beyond function. An in-depth understanding of how certain materials make us move, feel, think and act while knowing their constraints can provide new ways of designing material-driven tools [46] and eventually novel experiences with these materials [22].\r\n\r\nWith the material-turn in the third wave HCI, materiality gained strength to the extent of re-asserting itself in the form of programmable matter, capturing the attention of engineers, scientists as well as interaction designers [16]. Smart materials promise to add new affordances to artifacts and in turn affect our experience with them. Even the “smartness” of smart materials can be quantified in theory by assessing their responsiveness, agility, and complexity [32]. A smart second skin, for example, may offer many advantages beyond its conventional function by mimicking the color-changing abilities of the cephalopods [30] in response to contextual change, while also monitoring the wearer\'s bio-signals to make claims about her health and well-being. Some studies go further and extend the bio-integration as exemplified by such wearable technology, all the way into the body in the form of biologically consumable technology; e.g. consumable soft robots. Since the material is suitable to interact with the biological tissue, it became almost natural to think of a device that can be implanted inside our bodies and can interact intimately with our internal mechanisms and structures. In all such situations, we hold the two components of computation: input and output. By combining these components with the responsive properties inherent to smart materials, material programmers aim to realize adaptive systems around our corporeal bodies that can compute autonomously, assuming that the technology we wear knows our somas better than we do. This is a powerful yet controversial paradigm which bears a potential estrangement of our own body in the long run, and therefore must be delicately approached not only by soma designers but also by everyone.\r\n\r\nThis intimate correspondence with data, analytical tools and smart material systems may challenge somaesthetic values in a number of ways, impacting the shaping of both form and function in the design process. They may constrain us to think, feel, and move in certain ways – or expand our repertoire of possible movements [10, 23] to enrich our senses. It is a question about how we approach data in the design process, and shape these tools and materials in ways that allow interactions that harmonize with our somas, attending to the aesthetics of our somatic experiences rather than attempting to objectify them in order to disambiguate meaning. Understanding materials as expressive entities demands new approaches and being sensitized to working with them in our research and practice.\r\n\r\n\r\nFigure 3: Participant tasting, touching and smelling different materials in an Aesthetic laboration (A-lab) [1] session during a soma design workshop.\r\n4 DISCUSSION\r\n\r\nBy deepening our ability to aesthetically appreciate our everyday lives, engaging deeply and purposefully with the world around us, Shusterman argues that we can improve our condition. Similar to how we can educate our minds by attending to the world of concepts and language, we can educate our whole selves through attending to our somas. We learn how to appreciate through all our senses, our movements, as well as through our thought processes and ways of reasoning. In fact, all of these processes are, as we now know through the work in neurology, evolutionary biology, and psychology, tightly interlinked processes: movement, emotion and thinking are not separable. In the case of the soma, values and perspective on the world are embodied. Somaesthetics, is, therefore, by necessity, a critical and political project, as politics happen in people\'s concrete everyday practices, and those practices are grounded in movement, in people\'s corporealities [20, 31].\r\n\r\nThis, in turn, means that a soma design practice is grounded in what we (designers as well as end-users) experience, not in preconceptions about how to divide the world into conceptual categories. On the other hand, those concepts are deeply engrained in our whole ways of being and will be enacted and re-enacted in our design work, unless we are able to ”see” them, deconstruct them, attend to them, and thereby design in novels ways. We have found that soma design offers one such possible path to appreciation of the body\'s ambiguity, as subject and object, as bodymind, as self and world. An ambiguity that is not ambivalent nor a set of contradictions, but an interlinking of movement, perception, emotion and subjectivity [15]. By engaging deeply with our felt sense throughout the whole design process, we start to discern those practices that are otherwise ’out of sight’ for us. We see this is a fruitful path to designing for a better engagement, beyond ready-made ideas and ideals. This said, much work remains to show that this will indeed deliver better designs for all.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nWe would like to thank the Soma Design research group for the continuous work on these topics, especially Pedro Sanches, Charles Windlin, Pavel Karpashevich and Madeline Balaam. This work has been supported by Swedish Research Council project 2016-04709 and 2017-05133, Swedish Foundation for Strategic Research project RIT15-0046 and Knut and Alice Wallenberg Foundation project KAW 2015.0080, Engineering the Interconnected Society: Information, Control, Interaction.\r\n\r\nREFERENCES\r\n\r\nCheryl Akner-Koler and Ranjbar Parivash. 2016. Integrating Sensitizing Labs in an educational design process for haptic interaction. FORMakademisk 9, 2 (August 2016), 1–25. https://doi.org/10.7577/formakademisk.1269  \r\nKaren Barad. 2007. Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning. Duke University Press, Durham, NC, USA.  \r\nShaowen Bardzell. 2010. Feminist HCI: Taking stock and outlining an agenda for design. In Proceedings of the 2010 CHI Conference on Human Factors in Computing Systems(CHI ’10). ACM, New York, NY, USA, 1301–1310. https://doi.org/10.1145/1753326.1753521  \r\nAngela Barron McBride and William L. McBride. 1982. Theoretical underpinnings for women\'s health. Women & Health 6, 1-2 (1982), 37–56. https://doi.org/10.1300/J013v06n01_04  \r\nCynthia L. Bennett and Daniela K. Rosner. 2019. The promise of empathy: Design, disability, and knowing the ”Other”. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 298, 13 pages. https://doi.org/10.1145/3290605.3300528  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the Fourth Nordic Conference on Human-computer Interaction(NordiCHI ’06). ACM, New York, NY, USA, 1–8. https://doi.org/10.1145/1182475.1182476  \r\nKirsten Boehner, Rogério DePaula, Paul Dourish, and Phoebe Sengers. 2007. How emotion is made and measured. International Journal of Human-Computer Studies 65, 4 (January 2007), 275 – 291. https://doi.org/10.1016/j.ijhcs.2006.11.016  \r\nGilbert Cockton. 2004. Value-centred HCI. In Proceedings of the Third Nordic Conference on Human-computer Interaction(NordiCHI ’04). ACM, New York, NY, USA, 149–160. https://doi.org/10.1145/1028014.1028038  \r\nPaul Dourish. 2004. Where the Action Is: the Foundations of Embodied Interaction. MIT Press, Cambridge, MA, USA.  \r\nSara Eriksson, Åsa Unander-Scharin, Vincent Trichon, Carl Unander-Scharin, Hedvig Kjellström, and Kristina Höök. 2019. Dancing with drones: Crafting novel artistic expressions through intercorporeality. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 617, 12 pages. https://doi.org/10.1145/3290605.3300847  \r\nGurur. Ertem and Sandra. Noeth. 2018. Bodies of Evidence: Ethics, Aesthetics, and Politics of Movement. Passagen Verlag Ges.m.b.H., Vienna, Austria.  \r\nDaniel Fallman. 2011. The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction. In Proceedings of the 2011 CHI Conference on Human Factors in Computing Systems(CHI ’11). ACM, New York, NY, USA, 1051–1060. https://doi.org/10.1145/1978942.1979099  \r\nPedro Ferreira. 2015. Play as freedom: Implications for ICT4D. Ph.D. Dissertation. KTH Royal Institute of Technology, Stockholm, Sweden.  \r\nPedro Ferreira and Kristina Höök. 2011. Bodily orientations around mobiles: lessons learnt in Vanuatu. In Proceedings of the 2011 CHI Conference on Human Factors in Computing Systems(CHI ’11). ACM, New York, NY, USA, 277–286. https://doi.org/10.1145/1978942.1978981  \r\nWilliam W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a resource for design. In Proceedings of the 2003 CHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 233–240. https://doi.org/10.1145/642611.642653  \r\nSeth C. Goldstein, Jason D. Campbell, and Todd C. Mowry. 2005. Programmable matter. IEEE Computer 38, 6 (June 2005), 99–101. https://doi.org/10.1109/MC.2005.198  \r\nBrent Hect, Lauren Wilcox, Jeffrey P. Bigham, Johannes Schöning, Ehsan Hogue, Jason Ernst, Yonatan Bisk, Luigi De Russis, Lana Yarosh, Bushra Anjum, and Cathy Wu. 2018. It\'s time to do something: Mitigating the negative impacts of computing through a change to the peer review process. Retrieved June 12, 2019 from https://acm-fca.org/2018/03/29/negativeimpacts/  \r\nYvonne Hirdman. 1990. The gender system: theoretical reflections on the social subordination of women. Maktutredningen, Uppsala.  \r\nMads Hobye and Jonas Löwgren. 2011. Touching a stranger: Designing for engaging experience in embodied interaction. International Journal of Design 5, 3 (December 2011), 31–48.  \r\nKristina Höök. 2018. Designing with the Body: Somaesthetic Interaction Design. MIT Press, Cambridge, MA, USA.  \r\nKristina Höök, Martin P. Jonsson, Anna Ståhl, and Johanna Mercurio. 2016. Somaesthetic appreciation design. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems(CHI ’16). ACM, New York, NY, USA, 3131–3142. https://doi.org/10.1145/2858036.2858583  \r\nElvin Karana, Bahar Barati, Valentina Rognoli, and Anouk van der Laan. 2015. Material driven design (MDD): A method to design for material experiences. International Journal of Design 9, 2 (August 2015), 25–54.  \r\nPavel Karpashevich, Eva Hornecker, Michaela Honauer, and Pedro Sanches. 2018. Reinterpreting Schlemmer\'s Triadic Ballet: Interactive costume for unthinkable movements. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 61, 13 pages. https://doi.org/10.1145/3173574.3173635  \r\nGeorge Khut. 2006. Development and evaluation of participant-centred biofeedback artworks. Unpublished doctoral exegesis, University of Western Sydney. (2006).  \r\nGeorge Lakoff. 2008. Women, Fire, and Dangerous Things. University of Chicago Press, Chicago, IL, USA.  \r\nAnn Light, Irina Shklovski, and Alison Powell. 2017. Design for existential crisis. In Extended Abstracts of the 2017 CHI Conference on Human Factors in Computing Systems(CHI EA ’17). ACM, New York, NY, USA, 722–734. https://doi.org/10.1145/3027063.3052760  \r\nLian Loke and Toni Robertson. 2013. Moving and making strange: An embodied approach to movement-based interaction design. ACM Transactions on Computer-Human Interaction (TOCHI) 20, 1 (March 2013), 7. https://doi.org/10.1145/1978942.1978981  \r\nMaurice Merleau-Ponty. 2013. Phenomenology of Perception. Routledge, London, UK.  \r\nClaudia Núñez-Pacheco. 2015. Expanding our perceptual world through technology: a subjective bodily perspective. In Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers. ACM, New York, NY, USA, 951–956. https://doi.org/10.1145/2800835.2806206  \r\nLong Phan, Rylan Kautz, Erica M Leung, Kyle L Naughton, Yegor Van Dyke, and Alon A Gorodetsky. 2016. Dynamic materials inspired by cephalopods. Chemistry of Materials 28, 19 (September 2016), 6804–6816. https://doi.org/10.1021/acs.chemmater.6b01532  \r\nNikolas Rose. 2001. The politics of life itself. Theory, culture & society 18, 6 (December 2001), 1–30. https://doi.org/10.1177/02632760122052020  \r\nJonathan M Rossiter. 2017. Robotics, smart materials, and their future impact for humans. Vol. 9. BBVA, Bilbao, Spain, 27–44.  \r\nPedro Sanches, Axel Janson, Pavel Karpashevich, Camille Nadal, Chengcheng Qu, Claudia Daudén Roquet, Muhammad Umair, Charles Windlin, Gavin Doherty, Kristina Höök, et al. 2019. HCI and affective health: Taking stock of a decade of studies and charting future research directions. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems(CHI ’19). ACM, New York, NY, USA, Article 245, 17 pages. https://doi.org/10.1145/3290605.3300475  \r\nThecla Schiphorst. 2011. Self-evidence: applying somatic connoisseurship to experience design. In CHI’11 extended abstracts on human factors in computing systems. ACM, New York, NY, USA, 145–160. https://doi.org/10.1145/1979742.1979640  \r\nAmartya Sen. 1999. Development as Freedom. Oxford University Press, New York, NY.  \r\nMaxine Sheets-Johnstone. 1994. The Roots of Power: Animate Form and Gendered Bodies. Open Court Publishing, Chicago, IL, USA.  \r\nMaxine Sheets-Johnstone. 1999. Emotion and movement: A beginning empirical-phenomenological analysis of their relationship. Journal of Consciousness Studies 6, 11-12 (1999), 259–277.  \r\nMaxine Sheets-Johnstone. 2011. The Primacy of Movement. John Benjamins Publishing, Amsterdam, Netherlands.  \r\nRichard Shusterman. 2003. Somaesthetics and The Second Sex: A pragmatist reading of a feminist classic. Hypatia 18, 4 (January 2003), 106–136. https://doi.org/10.1111/j.1527-2001.2003.tb01415.x \r\nRichard Shusterman. 2008. Body Consciousness: A Philosophy of Mindfulness and Somaesthetics. Cambridge University Press, Cambridge, UK.  \r\nRichard Shusterman. 2012. Thinking Through the Body: Essays in Somaesthetics. Cambridge University Press, Cambridge, UK.  \r\nAnna Ståhl, Kristina Höök, Martin Svensson, Alex S. Taylor, and Marco Combetto. 2009. Experiencing the Affective Diary. Personal Ubiquitous Computing 13, 5 (June 2009), 365–378. https://doi.org/10.1007/s00779-008-0202-7  \r\nAnna Ståhl, Martin Jonsson, Johanna Mercurio, Anna Karlsson, Kristina Höök, and Eva-Carin Banka Johnson. 2016. The soma mat and breathing light. In Extended Abstracts of the 2016 CHI Conference on Human Factors in Computing Systems(CHI EA ’16). Association for Computing Machinery, ACM, New York, NY, USA, 305–308. https://doi.org/10.1145/2851581.2889464  \r\nDag Svanæs and Martin Solheim. 2016. Wag your tail and flap your ears: The kinesthetic user experience of extending your body. In Extended Abstracts of the 2016 CHI Conference on Human Factors in Computing Systems(CHI EA ’16). ACM, New York, NY, USA, 3778–3779. https://doi.org/10.1145/2851581.2890268  \r\nVasiliki Tsaknaki, Madeline Balaam, Anna Ståhl, Pedro Sanches, Charles Windlin, Pavel Karpashevich, and Kristina Höök. 2019. Teaching Soma Design. In Proceedings of the 2019 on Designing Interactive Systems Conference. ACM, New York, NY, USA, 1237–1249. https://doi.org/10.1145/3322276.3322327  \r\nAnna Vallgårda, Laurens Boer, Vasiliki Tsaknaki, and Dag Svanæs. 2016. Material Programming: A Design Practice for Computational Composites. In Proceedings of the 9th Nordic Conference on Human-Computer Interaction(NordiCHI ’16). ACM, New York, NY, USA, Article 46, 10 pages. https://doi.org/10.1145/2971485.2971554  \r\nDanielle Wilde, Anna Vallgårda, and Oscar Tomico. 2017. Embodied design ideation methods: analysing the power of estrangement. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems(CHI ’17). ACM, New York, NY, USA, 5158–5170. https://doi.org/10.1145/3025453.3025873 \r\nKaiton Williams. 2015. An anxious alliance. In Proceedings of The Fifth Decennial Aarhus Conference on Critical Alternatives(CA ’15). Aarhus University Press, Aarhus, Denmark, 121–131. https://doi.org/10.7146/aahcc.v1i1.21146  \r\n',1,'Hook','Kristina Höök, Sara Eriksson, Marie Louise Juul Søndergaard, Marianela Ciolfi Felice, Nadia Campo Woytuk, Özgün Kilic, Vasiliki Tsaknaki, and Anna Ståhl','Kristina Höök *(KTH Royal Institute of Technology, Sweden)*<br>\r\nSara Eriksson *(KTH Royal Institute of Technology, Sweden)*<br>\r\nMarie Louise Juul Søndergaard *(KTH Royal Institute of Technology, Sweden)*<br>\r\nMarianela Ciolfi Felice *(KTH Royal Institute of Technology, Sweden)*<br>\r\nNadia Campo Woytuk *(KTH Royal Institute of Technology, Sweden)*<br>\r\nÖzgün Kilic *(KTH Royal Institute of Technology, Sweden)*<br>\r\nVasiliki Tsaknaki *(KTH Royal Institute of Technology, Sweden)*<br>\r\nAnna Ståhl *(RISE Research Institutes of Sweden, Sweden)*',NULL,0,'10.1145/3363384.3363385','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,45,10,NULL,NULL,0,1),(33,'menheere-graceful-interactions-and-social-support-as-motivational-design-strategies-to-encourage-women-in-exercising','2019-09-02 15:24:57','2019-11-14 14:07:06','2019-09-02 15:24:57',NULL,1,'published','[]','Graceful Interactions and Social Support as Motivational Design Strategies to Encourage Women in Exercising','Increasingly aware of the importance of active lifestyles, many people intend to exercise more. Yet the main challenge remains to translate these intentions into action. Wearable devices supporting exercise regrettably tend to adopt a one-size-fits-all approach by monitoring activity through quantified data as a motivation strategy. Since certain individuals are driven by social motives to exercise, less addressed through quantification, the impact of these devices on user experience and motivation is questionable.\r\n\r\nWe contribute to the field by defining interaction attributes of graceful interactions in product design. We then embedded these in designing Grace, a piece of jewelry enabling women to share exercise intentions with friends to encourage social support. Instead of focusing on quantification, we rely on a qualitative approach using graceful interaction. Through this we extend the design space of sport-related wearables for women and inform how to design for exercise motivation through social support and graceful interactions.','Daphne Menheere, Carine Lallemand, Ilse Faber, Jesse Paping, Bram Monkel, Stella Xu, and Steven Vos. 2019. Graceful Interactions and Social Support as Motivational Design Strategies to Encourage Women in Exercising. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 9 pages. [https://doi.org/10.1145/3363384.3363404](https://doi.org/10.1145/3363384.3363404 \"DOI for the article \'Graceful Interactions and Social Support as Motivational Design Strategies to Encourage Women in Exercising\'\")','1 Introduction\r\n\r\nPhysical inactivity is a growing public health concern, leading to increased awareness of the importance of an active and healthy lifestyle [37]. More and more people are thus having positive intentions of being physically active [28]. Even though sport was once an activity practiced mainly by men, one witness positive developments in gender equality in this area with considerable growth of women participating in sport [32].\r\n\r\nThe main challenge for many people is to translate their positive intentions into actual, preferably long-term, exercise behavior [28]. Most studies indicate the drop-out rate for exercise interventions is around 50% [3, 17], where women are more likely to discontinue exercising as compared to men. This is due to more unforeseen perceived barriers but also because of the greater importance women attach to social support [17].\r\n\r\nIn line with the growing awareness of the importance of physical activity, there has been an exponential increase in the use of sport-related wearables. Indeed, the global market size of smart wearables fitness and sports devices, supporting exercising and motivating people and allow them to monitor their progress [19], is expected to keep growing [34]. However, the question arises whether these devices only reach a small target group that already has a strong affinity and identify with sports and exercise and thus is more interested in capturing health and sports-related data [11, 40]. Other parts of the population, who perceive sports as a short-term cost (e.g., costs energy, time, sweating, pain) [7] and value social support, might be less addressed. Studies show that this type of social thinking seems to appeal to women in particular [17]. Furthermore, research also indicates women mention feeling uncomfortable wearing activity trackers [33] due to the sporty and bulky appearance of the devices, preferring ones that are more graceful [22, 24].\r\n\r\nIn this paper, we introduce the design of Grace, a piece of jewelry that allows women to share their exercise intentions with friends to enable social support. While the current design space of wearable sports devices mainly focuses on quantification, we extend it here by relying on a qualitative aesthetics of interaction [9, 21]. Away from the use of numbers as a feedback mechanism, our approach combines meaningful gestures with a specific aesthetics of the artifact. Through an expert study involving industrial designers, we contribute to the field by defining the interaction attributes of graceful interaction in product design. We then designed Grace to embed the notion of graceful interaction. Grace acts as a propositional object enabling us to investigate how to design for exercise motivation through social support and graceful interactions.\r\n\r\n2 Related Work\r\n\r\nAlong with the increased popularity of sports, there has been an exponential increase in the development of sport-related wearable technology [34]. These devices enable body-monitoring and data tracking, offering the possibility of improving personal health outcomes. Even though there is a general acceptance that people are different, most of these devices still tend to take a “one-size-fits-all” approach of stimulating exercise performance or competition [26]. These quantitatively driven approaches might not suit “all” since many people prefer thinking in stories (i.e., qualitatively) [26] rather than in numbers (i.e., quantitatively). Additionally, the one-size-fits-all approach also influences the perceived aesthetics of the devices, where women have indicated to feel uncomfortable wearing these in previous studies [11].\r\n\r\nQuantification in Body-Monitoring. The current paradigm of sports tracking is that everything can and is being quantified (e.g., by the use of numbers and graphs). The idea here is to create better cognitive awareness among users about their state of health or performance to eventually change their lives for the better [10, 19, 33]. Even though this paradigm speaks to a particular type of encouragement, a lot of people are not encouraged by knowing that they are faster or stronger than others (or than they used to be), but they are encouraged by being part of a community [17, 39]. The use of such a paradigm of exercise encouragement through a more qualitative social interaction seems to be a relatively unexplored area [21]. Yet it seems promising to give social meaning to sport-related feedback [23] through a more abstract and poetic way [38] by incorporating ambiguity and visualizing uncertainty in the feedback [10]. In the present paper, we therefore argue for the use of a more qualitative aesthetics among sport-related wearables.\r\n\r\nPublic Performance vs. Social Support. The nature of the exercise environment and sport-related technology are of masculine origin [4], with performance and competition often being the main stimuli for motivation [18, 19]. Even though these motivational triggers drive a segment of female exercisers, research shows that for certain groups of women, health and social support are more effective motivators to exercise [39]. Social support as a motivational strategy can increase adherence in exercise [31]. Numerous studies thus advocate for including social features in sport-related technology [30, 35]. This can be done, for instance, by integrating social elements in training sessions of athletes to make sports more fun. One example is “Jogging over a Distance” by Mueller et al. [25], where individual runners can run together in different physical locations via audio. A different approach was taken in RUFUS [43], a system developed to allow people to cheer from a distance for participants in running competitions. Even though these designs facilitate social experiences for individuals throughout the exercise, lack of social support is primarily experienced before the exercise itself and is proven to affect motivation negatively [27], indicating the importance of integrating social support before the actual training. External online fitness platforms (e.g., Runkeeper ©, Strava ©) try to bridge that gap by enabling people to share their sports performance with others [36]. Even though these platforms allow for social support throughout the day, it is performance and competition-driven and whether this is desirable for everyone is questionable [41].\r\n\r\nAppearance of Sport-Related Wearables. Previous research revealed that some customer segments, especially women, can feel uncomfortable wearing sport-related wearables [15]. This is partly due to the sportive and masculine appearance of the devices. In a study where different activity trackers were rated by user impressions among women, the ones that hinted towards pieces of jewelry and a graceful aesthetics were preferred over the sportive and masculine looking ones [22, 24], indicating the importance of also striving for a less sportive look and feel within these types of everyday objects. The current market only presents scarce examples of sport-related wearables (e.g., BellaBeat ©, Selah Cuff ©, Tory Burch Fitbit ©) considered pieces of jewelry.\r\n\r\nAnother reason why women felt uncomfortable wearing these devices was due to the perceived identity (and the social acceptability) associated with them, having a negative impact on the person wearing it [11]. One might prefer a more personal approach of interaction opposed to the currently open and publicly visible feedback [23] since not everyone is interested in or feel comfortable with showing that they are wearing a sport-related device [33]. This is why we argue, when designing this type of device, to shift its look and feel from a sport-related wearable to interactive jewelry.\r\n\r\nInteractive Jewelry. Jewelry has a long history of being an explicit private and social communication tool [42] while still closely intertwining in our everyday lives like no other wearable does [2]. The emergence of wearable technologies has expanded the opportunities for jewelry to be a ‘communication tool’ by integrating a digital layer to the tangible object [38]. Interactive jewelry thus can dynamically react on wearers inputs following different interaction modalities (e.g., usually touching modalities such as fidgeting, hovering, sliding or, rotation elements) [2, 38]. Since these types of interactions can still integrate the poetic qualities of jewelry, like sensorial engagement and intimacy (toward other people, places and self) [2], we highlight the potential of interactive jewelry to integrate social support for exercise engagement among women, when aiming for qualitative interactions.\r\n\r\nIn this paper, we focus on graceful interaction and social support as motivational design strategies. In the following section, we describe the iterative design process of Grace as a reflection on the aforementioned discussed perspectives.\r\n\r\n3 Designing Graceful Interactions\r\n\r\nWhile easily linked to a certain form of beauty, attained through posture and motion, it is hard to fully grasp what constitutes gracefulness [6]. Common examples associated with gracefulness are swans or ballerinas (hence the figure of speech ‘graceful as a swan’). Transposing this concept to the act of design, thus represents a challenging endeavor, with very few attempts in the HCI literature so far [15]. How would the aesthetic quality of gracefulness materialize in interaction design?\r\n\r\n3.1 Materializing Gracefulness in Interaction Design: An Exploratory Study\r\n\r\nTo explore how the concept of graceful interactions could materialize in a design artifact, we invited industrial designers (n = 22) to participate in a short study. Using the Interaction Vocabulary Cards by Diefenbach, Lenz & Hassenzahl [9], we asked them to describe how a graceful interaction with a physical product would feel/look like. Participants were provided with the following definition of gracefulness (combining definitions by [6] and [8]: “Gracefulness is characterized by elegance or beauty of form, manner, movement, or speech. It is elegant. Grace is the appearance of an easy presence (graceful movements appear as easy and effortless). And such presence involves a harmonious relatedness to one\'s context.” [6].\r\n\r\nThe Interaction Vocabulary consists of 11 seven-point semantic differential items to describe the interaction. The participants were asked to evaluate only the pairs of words that they consider relevant to design for graceful interactions and to leave the others blank. They were also instructed to leave aside aspects that they consider relevant yet dependent on the type of product or use context. After the assessment of the 11 items, we asked the participants to select 3 attributes, out of the aforementioned items, which they consider the most important interaction attributes to design for gracefulness. Out of the 22 designers, 18 answered that open-ended question (one participant only provided two attributes, and another gave an attribute that was not part of the initial list, namely ‘harmonious’).\r\n\r\nOur results show that seven attributes are associated with gracefulness in the context of interaction design: slow, fluent, uniform, constant, precise, gentle, and targeted (Figure 1). Amongst those, fluency (14), gentleness (12) and slowness (7) were selected as the most important attributes for a graceful aesthetic of interaction.\r\n\r\nFigure 1\r\nFigure 1: Attributes used by design professionals (n = 22) to describe a graceful interaction, using the Interaction Vocabulary [9].\r\nTo incorporate the most important elements for graceful interaction elicited through the survey (slow, fluent, and gentle), we conducted an iterative and explorative design process with close user involvement. In this design process, the goal was to enable social support among women who want to exercise by use of a qualitative approach.\r\n\r\n4 Design of Grace\r\n\r\nGrace is a piece of jewelry (Figure 2) that encourages women to share and support exercise intentions with friends through graceful interactions. Through Grace, users are able to see whether friends have the intention to go exercise that day, and eventually if they actually went. The same information is also shared about themselves. This commitment-based way of motivating is closely intertwined with an increased feeling of group coherence and social support. To amplify the awareness of sharing goals and accomplishing them together, Grace also enables to cheer for your friends, stimulating them to get active, or celebrating with them for turning their intentions into action. Relying on a qualitative aesthetics of interaction, Grace embeds the notion of gracefulness as a novel perspective, as opposed to the current quantification trend.\r\n\r\nFigure 1\r\nFigure 2: Grace, a piece of interactive jewelry, enabling women to share their exercise intentions\r\nGrace entails several touch, motion, and mid-air gesture interactions: (1) To plan an exercise, the hand is placed on the heart as to mimic the salutation of promise. The display, divided into slots for different friends, will now display skewed stripes. (2) When the user is done exercising, she taps herself three times on the chest, showing off a feeling of pride, and changing the stripes into mellow post-workout waves. (3) Lastly, to cheer (regardless of their effort) for friends with a lively zig-zag pattern, you hold your hand on your heart for a feeling of connectedness (Figure 3). By supporting the user values within Grace, we focus on implementing the symbolic meaning of committing to exercising [1].\r\n\r\nFigure 2\r\nFigure 3: Grace interactions for committing to exercising (1), sharing one\'s achievement (2) and cheering for friends (3)\r\n4.1 Underlying Design Principles\r\n\r\nAesthetics of Interaction. We used the Interaction Vocabulary [9] to describe the interaction qualities of Grace. It consists of eleven descriptive, non-judgmental, non-technology bound attributes of interactions. The interactions with the bracelet are intended to be subtle and graceful, to propose a different motivational strategy opposed to the performance and competition-driven approaches. Translating these notions into the vocabulary of interaction led us to design Grace\'s interaction style as slow, gentle, fluent, and covered. The first three elements were considered the most important for graceful interaction in our exploratory study. While described by expert designers as a context-dependent dimension (i.e., depending on the context, an interaction can be graceful while being either ‘apparent’ or ‘covered’), we choose to add the attribute “covered” to represent a feeling of intimacy, which was deemed important in our context.\r\n\r\nSlow and gentle interaction qualities allow us to distinguish Grace from activity-related devices focused on performance, which are usually designed as being fast, powerful, and precise and use numbers to provide users with feedback. Slowness is expressed in the design of Grace in the way the feedback is received throughout the day and cannot be seen on demand. We translated Gentleness in all the styles of interaction within Grace, placing your hand on the heart to make a commitment and the gentle turning of the bracelet to see the moiré effect.\r\n\r\nThe choice of a fluent interaction style is linked to gracefulness, corresponding to the definition of graceful movements as “apparently easy or effortless” [6]. Fluency is translated within the design of Grace in the gestural interaction, as well as the smooth act of fidgeting, making the feedback more visible.\r\n\r\nUsers are able to personalize their visuals (i.e., the moiré effect) and therefore construct individual meaning to the patterns that are linked to different types of feedback. In this way, this personal information remains covered, meaningless to other people, in the immediate vicinity of the user, who is not familiar with the constructed patterns. The aim was to integrate a subtle and personal interface while still being valuable to the wearer. Furthermore, when the moiré effect appears (Figure 4), this enhances the overall appearance of Grace.\r\n\r\nFigure 3\r\nFigure 4: Testing different moiré patterns and final implementation of a moiré pattern in Grace\r\nMoiré Patterns as Ambiguous Information Representation. To provide feedback in a poetic and abstract form (as opposed to the quantified data provided by most activity trackers), we made use of the moiré effect (Figure 4). This is a visual phenomenon that occurs when two similar types of patterns are moved over each other, thus creating a new pattern. When fidgeting with Grace, the top layer of the bracelet is moved over the bottom layer (supporting a covered aesthetics of interaction again), creating this Moiré effect. The top layer is part of the bracelet and keeps its shape, while the bottom layer is an integrated e-paper display, enabling the possibility to change the pattern.\r\n\r\nCommitment to Exercise. Users need to interact with the device to indicate their exercise planning and activity. Cognitive interactions tend to disrupt the user\'s day-to-day routine, so the goal was to choose a relevant, motion-based gesture that can be performed without an active focus on the interaction itself. Multiple poses were experienced through role-playing among the designers (Figure 5). Power poses were considered for their empowering, encouraging effect, but were dropped because they could not be performed subtly (1). Fun or wacky poses were discarded for the same reason (2). Ultimately, a pose associated with a promise to the heart was chosen, representing the promise to exercise made to oneself (3).\r\n\r\nFigure 4\r\nFigure 5: Experiencing multiple poses through role playing: power poses (1), fun or wacky poses (2), symbolic poses (3)\r\nSocial Support and Feeling of Togetherness. The aim of Grace is to exercise individually while experiencing a feeling of togetherness with friends, proven to have a motivating effect [20]. According to Hassenzahl et al. [16], this feeling of relatedness, mediated through technology, can be achieved through awareness, physicalness, and joint-action, amongst other strategies.\r\n\r\nThe awareness strategy consists of “sharing different types of ambient information about current activities or moods among partners, without a conversation or doing anything together” [16]. Reciprocal self-disclosure and ambiguity [12] are both described as essential principles to design for awareness. With Grace, awareness is achieved through the received updates throughout the day presented in an ambiguous way through the moiré effect, where the user understands the information and raises awareness while its meaning remains unknown to others.\r\n\r\nThe physicalness strategy includes artifacts that “mediate a feeling of physical intimacy, simulating secondary effects of the physical proximity of meaningful gestures” [16]. Grace embeds physicalness in the way the user intuitively interacts with Grace through fidgeting. Through this intimate interaction, the moiré effect will appear contributing to the look and feel of the bracelet. Lastly, artifacts allowing for carrying out an action together fall into the joint action strategy [16]. Joint-action comes forward within the Grace concept in the sharing and celebrating of goals, as well as in the behavioral interdependence between women.\r\n\r\n4.2 Technology and Realization\r\n\r\nTo measure the different expressions the user makes: (i) committing to exercise, (ii) finishing the exercise and (iii) supporting for a friend, the microcontroller calculates the movement and measures the angle of the wrist through the accelerometer and gyroscope (Figure 6). Based on these values, the microcontroller identifies which gesture is performed and thus adjust the e-paper display (Wemos 2.13 inch E-Ink) accordingly, visualizing various moiré patterns linked to the different expressions.\r\n\r\nFigure 5\r\nFigure 6: Electronics of Grace: left, integrated e-paper display. Right, Light Blue Bean with accelerometer\r\nFitting the electronics, while remaining its accessibility as well as combining the plastic base with a rotating aluminum body was a major challenge in the design. Following the validation of the motivating power of the concept, a more robust and eminent prototype was desirable to be able to validate the interactions and visualizations. The choice was made to use metals with a silver hue such as stainless steel or aluminum, due to women\'s preferences of the aesthetics of activity trackers being luxurious, graceful, and feminine [24].\r\n\r\nTo create the moiré effect, it was decided to make use of an outer rotatable ring. From here, multiple different prototypes and material explorations were created (Figure 7), validating the effectiveness of the moiré effect, and identifying the location of electronics and wire outputs.\r\n\r\nFigure 6\r\nFigure 7: Material exploration of Grace cuff\r\nDuring the validation, it was seen that the full circle design was not associated with gracefulness, mainly due to its corresponding size. To preserve these values, a cuff with the ability to slip over the wrist with ease, ensuring a smaller size and a more feminine look was chosen as the salvation. The size for this cuff was tested (Figure 7), concluding a size of 65 mm inner diameter, corresponding with a “large” for different cuffs at local jewelry stores.\r\n\r\n5 User Study\r\n\r\nTo gain first insights into how our target women experience Grace, we set up an exploratory user study. We investigated whether the different interactions with Grace and the feedback given by this interactive piece of jewelry were considered as graceful. We also assess the perceived meaningfulness of qualitative social support mechanisms as a motivational strategy.\r\n\r\nThree participants wore and interacted with Grace for one day on which they had the intention to exercise. The women participating in the study all sometimes indicated to experience difficulties in turning their exercise intentions into actual exercising that day. Since we only had one working prototype, we used a Wizard of Oz approach to simulate the intentions and support of two other friends. After wearing Grace for a day, the women were interviewed about their experience, how they interacted with the bracelet, and how they felt wearing Grace throughout the day. The interviews were transcribed, analyzed via thematic analysis, and translated from Dutch to English by the researchers.\r\n\r\nCheering component of Grace. All three participants indicated to value the cheering component of Grace, enabling social cohesion and support. “The function I appreciated most was being able to cheer for others.” - P3\r\n\r\nInterestingly, they did not only value this for their own motivation (by receiving a cheer from their friends but also themselves) but also being enabled to cheer for others. “I really liked the cheer function; it really had a positive effect when other people were cheering for me. But I\'ve been cheering for myself all day as well.” - P2\r\n\r\nSubtle yet graceful feedback. The participants indicated to consider the feedback being subtle yet graceful. The notifications were provided in real-time and could not be seen on demand. Therefore, users might miss supporting cheers of friends or friends expressing intentions. Integrating an interaction that makes it possible to recall previous notifications might solve this. “I had to look at it quite often to see whether it changed, approximately four times per hour I think” - P1\r\n\r\n“Maybe it was too subtle to notice whether there were changes” - P3\r\n\r\nAdding such a feature, will not influence the form of the feedback of Grace, which is important since the unobtrusiveness and feedback subtlety was also considered as an added value by the participants. P3 explicitly mentioned that when they did experience the feedback on demand, it was appreciated that it was not screaming for attention since this was adding to the quality of the aesthetics of the bracelet. “The visualizations were graceful and subtle; it\'s not a light which is screaming for attention. I really liked that it was abstract and appreciated that the visualization is presented in a more artistic way” - P3\r\n\r\nAmbiguity of Visualizations. Some participants indicated they experienced some difficulties recalling the different meanings of the feedback because of its abstract form. However, this was only encountered at the beginning of the day (when they started to use Grace), which improved quickly when interacting with the device throughout the day. “Fidgeting with Grace is nice because you see everything move, but it also adds uncertainty to its meaning.” - P1 “The visualizations were abstract, so the different meanings had to be learned; however, they were very easy to learn.” - P3\r\n\r\nAnother suggestion by P2 was to be able to visualize in real-time when one of your friends is sporting, and to express some disappointment perhaps - “and if they are not doing it, to show a sad face.” – P2\r\n\r\n6 Discussion and Future Work\r\n\r\nThroughout this paper, we explored the relevance of adopting a qualitative aesthetics of interaction to extend the design space of sports wearables for women. Deliberately positioning this work in opposition to the widespread use of quantification as a motivational strategy [21], we question the current tailoring of motivational design to address the needs of a specific target group and notably amongst women [29]. Our interactive bracelet Grace acts here as a propositional object embedding notions of gracefulness and social support.\r\n\r\nDesigning for gracefulness is a challenging endeavor, which we addressed in two ways. First, by involving industrial designers (n = 22) in the definition of a graceful aesthetic of interaction. Second, by embedding and materializing these attributes in the design of an interactive wearable in order to gain insights into the effect of a graceful interaction style on exercising motivation.\r\n\r\nIn addition, through the medium we selected, we uncovered the vast potential space of input interaction enabled by interactive jewelry [2]. The poetic qualities of jewelry, such as sensorial engagement, intimacy and symbolic meaning [42], might appeal to specific target groups and constitute an alternative to the rather sportive and masculine look and feel of current sports wearables [22, 24]. By not being perceived as activity trackers, jewelry artifacts offer a high potential to personalize the visualization (in our case, through the self-defined Moiré patterns) while also providing an opportunity to cover the interaction (if one does not identify as a sports person).\r\n\r\nWe combined the qualitative aesthetics perspective with a social support strategy, described in the literature as effective [31], especially for users with less difficult goals who could benefit from social feedback more [14]. Interestingly, we noticed during the design process, how difficult it is to refrain from designing social features promoting competition rather than cooperation. As an example, visualizing in real-time when a friend is sporting to express disappointment could unintentionally promote a certain form of competition or demotivating friction. We decided to focus on the intention and the outcomes (cheering) to stay as close as possible to the supportive social positivity we intended to embrace with Grace.\r\n\r\nWhile conducted on a limited sample and for a short duration, the findings of our user study tend to confirm the relevance of our approach as a complement to existing technology design supporting physical activity.\r\n\r\nOf course, while we seem to adopt a rather dichotomous gender perspective on the topic of exercising motivation in the present paper, we acknowledge and do not underestimate the role of other variables in the users’ preferences for a specific motivational strategy. Goal-focus, goal-orientation, and other inter-individual differences [13, 14, 36] definitely play a role in the perception of – and reaction to – different types of motivation. Women can also be motivated by numbers, gamification, or social competition [5], and our approach is not proposed as a one-size-fits-all solution addressing females’ needs. Alternatively, the present example aims at opening up new perspectives for designers to provide meaningful, motivational technologies.\r\n\r\nIn future work, we aim to refine the design of Grace and to conduct a longitudinal field study over several weeks, featuring real interactions between the participants and their friends. From a design perspective, we intend to improve the aesthetics of the bracelet to increase the looks and feel towards a graceful piece of jewelry. At the moment, and mostly due to technical constraints, the bracelet can still be considered as a somewhat ‘bulky’ prototype, even though its appearance does not reveal its main purpose to encourage exercising. For women to feel comfortable wearing it, it is important to refine the aesthetics of Grace by making use of the full potential of interactive jewelry as a medium for graceful interactions.\r\n\r\nWith designing Grace, we extend the design space of sport-related wearables for women and inform how to design for exercise motivation through social support and graceful interactions. We believe our work shows a promising and different approach towards a more qualitative way to support women with exercising. The present study thus provides encouraging and inspiring practical implications to designers of wearable technologies. In addition, designers can also use the gracefulness interaction attributes as a starting point for the design of interactive technologies in other application areas.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThe authors would like to thank the reviewers for their valuable comments and feedback improving the quality of the paper. We would also like to thank all the participants who contributed to this study. This work is part of the project Nano4Sports, which is financed by Interreg Vlaanderen-Nederland.\r\n\r\nREFERENCES\r\n\r\nMichael Allen. 2006. A dual-process model of the influence of human values on consumer choice. Revista Psicologia: Organizações e Trabalho 6, 1: 15–49. https://doi.org/10.1177/136346159303000305  \r\nJatin Arora, Kartik Mathur, Aryan Saini, and Aman Parnami. 2019. Gehna: Exploring the Design Space of Jewelry as an Input Modality. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 521. https://doi.org/10.1145/3290605.3300751  \r\nJanet Buckworth, Rod K Dishman, Patrick J. O\'Connor and Phillip D. Tomporowski. (2013).  Exercise psychology. Human kinetics, Inc.  \r\nAïna Chalabaev, Philippe Sarrazin, Paul Fontayne, Julie Boiché, and Corentin Clément-guillotin. 2013. The influence of sex stereotypes and gender roles on participation and performance in sport and exercise : Review and future directions. Psychology of Sport & Exercise 14, 2: 136–144. https://doi.org/10.1016/j.psychsport.2012.10.005  \r\nEun Kyoung Choe, Nicole B. Lee, Bongshin Lee, Wanda Pratt, and Julie A. Kientz. 2014. Understanding quantified-selfers’ practices in collecting and exploring personal data. Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI ’14: 1143–1152. https://doi.org/10.1145/2556288.2557372  \r\nChristopher Cordner. 2003. The meaning of graceful movement. Journal of the Philosophy of Sport 30, 2: 132–143. https://doi.org/10.1080/00948705.2003.9714639  \r\nBenedicte I. Deforche, Ilse M. De Bourdeaudhuij, and Ann P. Tanghe. 2006. Attitude toward physical activity in normal-weight, overweight and obese adolescents. Journal of Adolescent Health 38, 5: 560–568. https://doi.org/10.1016/j.jadohealth.2005.01.015  \r\nDictionary.com Retrieved June 26, 2019 from https://www.dictionary.com/browse/gracefully  \r\nSarah Diefenbach, Eva Lenz, and Marc Hassenzahl. 2013. An Interaction Vocabulary. Describing the How Of Interaction. In Conference on Human Factors in Computing Systems - Proceedings, 607–612. https://doi.org/10.1145/2468356.2468463  \r\nElisabeth Kersten van Dijk, Joyce Westerink, and Wijnand IJsselsteijn. 2016. Deceptive Visualizations and User Bias: a Case for Personalization and Ambiguity in PI Visualizations. In The 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct, 588–593. https://doi.org/10.1145/2968219.2968326  \r\nDavid A Ellis and Lukasz Piwek. 2018. Failing to encourage physical activity with wearable technology: what next? Journal of the Royal Society of Medicine 111, 9: 310–313. https://doi.org/10.1177/0141076818788856  \r\nWilliam W Gaver. 2003. Ambiguity as a Resource for Design. In CHI ’03 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 233–240.  \r\nPeter M Gollwitzer, Kentaro Fujita, and Gabriele Oettingen. 2004. Planning and the implementation of goals. Handbook of self-regulation: Research, theory, and applications: 211–228.  \r\nJuho Hamari, Lobna Hassan, and Antonio Dias. 2018. Gamification, quantified-self or social networking? Matching users’ goals with motivational technology. User Modeling and User-Adapted Interaction 28, 1: 35–74. https://doi.org/10.1007/s11257-018-9200-2  \r\nWan Norizan Wan Hashim, Nor Laila Md Noor, and Wan Adilah Wan Adnan. 2009. The Design of Aesthetic Interaction: Towards a Graceful Interaction Framework. In Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human, 69–75. https://doi.org/10.1145/1655925.1655938  \r\nMarc Hassenzahl, Stephanie Heidecker, Kai Eckoldt, Sarah Diefenbach, and Uwe Hillmann. 2012. All You Need is Love: Current Strategies of Mediating Intimate Relationships through Technology. ACM Transactions on Computer-Human Interaction (TOCHI)19, 4. https://doi.org/10.1016/S0262-4079(17)32358-8  \r\nDavid V.B. James, Lynne H. Johnston, Diane Crone, Adrienne H. Sidford, Chris Gidlow, Clare Morris, and Charlie Foster. 2009. Factors associated with physical activity referral uptake and participation. Journal of Sports Sciences 27, 10: 1007–1017. https://doi.org/10.1080/02640410701468863  \r\nMark Janssen, Jeroen Scheerder, Erik Thibaut, Aarnout Brombacher, and Steven Vos. 2017. Who uses running apps and sports watches? Determinants and consumer profiles of event runners’ usage of running-related smartphone applications and sports watches. PLoS ONE 12, 7: 1–17. https://doi.org/10.1371/journal.pone.0181167  \r\nMads Møller Jensen and Florian Floyd Mueller. 2014. Running with technology : Where are we heading ? In Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: the Future of Design, 527–530.  \r\nKristina Knaving, Paweł Wołniak, Morten Fjeld, and Staffan Björk. 2015. Flow is Not Enough: Understanding the Needs of Advanced Amateur Runners to Design Motivation Technology. In CHI ’15 Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, 2013–2022. https://doi.org/10.1145/2702123.2702542  \r\nDan Lockton, Delanie Ricketts, Shruti Aditya Chowdhury, and Chang Hee Lee. 2017. Exploring Qualitative Displays and Interfaces. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems, 1844–1852. https://doi.org/10.1145/3027063.3053165  \r\nJean-Bernard Martens. 2019. Interpreting the Diversity in Subjective Judgments. In Proceedings of the 2019 CHI Conference Extended Abstracts on Human Factors in Computing Systems. https://doi.org/10.1145/3290605.3300449  \r\nDaphne Menheere, Carl Megens, Erik van der Spek, and Steven Vos. 2018. Encouraging physical activity and self-enhancement in women with breast cancer through a smart bra. In In Proceedings of DRS: Design Research Society 2018: Design Research Society. https://doi.org/10.21606/dma.2018.437  \r\nDaphne Menheere. 2015. Activogue: A fashion forward activity tracker. Master\'s report. Eindhoven University of Technology department of Industrial Design, Eindhoven, the Netherlands.  \r\nFlorian Mueller, Frank Vetere, Martin R. Gibbs, Darren Edge, Stefan Agamanolis, and Jennifer G. Sheridan. 2010. Jogging over a distance between Europe and Australia. In Proceedings of the 23nd annual ACM symposium on User interface software and technology - UIST ’10, 189. https://doi.org/10.1145/1866029.1866062  \r\nPeeters, M. M. R., & Megens, C. J. P. G. (2014). Experiential design landscapes: how to design for behaviour change, towards an active lifestyle.  \r\nLisa Pridgeon and Sarah Grogan. 2012. Understanding exercise adherence and dropout: An interpretative phenomenological analysis of men and women\'s accounts of gym attendance and non-attendance. Qualitative Research in Sport, Exercise and Health 4, 3: 382–399. https://doi.org/10.1080/2159676X.2012.712984  \r\nRyan E. Rhodes and Gert Jan De Bruijn. 2013. How big is the physical activity intention-behaviour gap? A meta-analysis using the action control framework. British Journal of Health Psychology 18, 2: 296–309. https://doi.org/10.1111/bjhp.12032  \r\nAmy A. Ross. 2018. Tracking Health and Fitness: A Cultural Examination of Self-quantification, Biomedicalization, and Gender. eHealth: Current Evidence, Promises, Perils and Future Directions Studies in Media and Communications 15: 123–151. https://doi.org/10.1108/s2050-206020180000015003  \r\nRichard M. Ryan, Christina M. Frederick, Deborah Lepes, Noel Rubio, and Kennon M. Sheldon. 1997. Intrinsic Motivation and Exercise Adherence. International Journal of Sport Psychology 28: 335–354.  \r\nTanya Maria Filomena Scarapicchia, Steve Amireault, Guy Faulkner, and Catherine Michelle Sabiston. 2017. Social support and physical activity participation among healthy adults: A systematic review of prospective studies. International Review of Sport and Exercise Psychology 10, 1: 50–83. https://doi.org/10.1080/1750984X.2016.1183222  \r\nJeroen Scheerder, Koen Breedveld, & Julie Borgers. 2015. Running across Europe: the rise and size of one of the largest sport markets. Springer.  \r\nPatrick C Shih and The Pennsylvania. 2015. Use and Adoption Challenges of Wearable Activity Trackers. In IConference 2015 Proceedings.  \r\nSmart Wearable Fitness and Sports Devices Market 2019: Global Key Players, Trends, Share, Industry Size, Segmentation, Opportunities, Forecast To 2025. Retrieved June 25, 2019 from https://www.reuters.com/brandfeatures/venture-capital/article?id=120311  \r\nJeroen Stragier, Peter Mechant, Lieven De Marez, and Greet Cardon. 2018. Computer-Mediated Social Support for Physical Activity: A Content Analysis. Health Education and Behavior 45, 1: 124–131. https://doi.org/10.1177/1090198117703055  \r\nJeroen Stragier, Mariek Vanden Abeele, and Lieven De Marez. 2018. Recreational athletes ’ running motivations as predictors of their use of online fitness community features. Behaviour & Information Technology 37, 8: 815–827. https://doi.org/10.1080/0144929X.2018.1484516  \r\nStewart G Trost, Steven N Blair, and Karin M Khan. 2014. Physical inactivity remains the greatest public health problem of the 21st century: evidence, improved methods and solutions using the “7 investments that work” as a framework. British Journal of Sports Medicine 48, 5: 394–401. https://doi.org/10.1136/bjsports-2013-092492  \r\nMaarten Versteeg, Elise van den Hoven, and Caroline Hummels. 2016. Interactive Jewellery: A Design Exploration. In Proceedings of the TEI ’16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction, 44–52. https://doi.org/10.1145/2839462.2839504  \r\nSteven Vos, Ruben Walravens, Paul Hover, Julie Borgers, and Jeroen Scheerder. 2014. For Fun or Prestige? Typology of event runners [Voor de pret of de prestatie? Typologieen van evenementenloopsters.] Vrijetijdsstudies 32, 2: 19–34.  \r\nSteven Vos, Mark Janssen, Jos Goudsmit, Coen Lauwerijssen, and Aarnout Brombacher. 2016. From Problem to Solution: Developing a Personalized Smartphone Application for Recreational Runners following a Three-step Design Approach. Procedia Engineering 147, December: 799–805. https://doi.org/10.1016/j.proeng.2016.06.311  \r\nSteven Vos. 2016. Designerly solutions for vital people. Eindhoven: Eindhoven University of Technology  \r\nJayne Wallace, James Thomas, Derek Anderson, and Patrick Olivier. 2013. Mortality as Framed by Ongoingness in Digital Design. Design Issues 29, 4: 1–5. https://doi.org/10.1162/DESI  \r\nPaweł Woźniak, Kristina Knaving, Staffan Björk, and Morten Fjeld. 2015. RUFUS: Remote Supporter Feedback for Long-Distance Runners. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services, 115–124. https://doi.org/10.1145/2785830.2785893 ',1,'Menheere','Daphne Menheere, Carine Lallemand, Ilse Faber, Jesse Pepping, Bram Monkel, Stella Xu, and Steven Vos','Daphne Menheere *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nCarine Lallemand *(Industrial Design, Eindhoven University of Technology, Netherlands and HCI Research Group, University of Luxembourg, Luxembourg)*<br>\r\nIlse Faber *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nJesse Pepping *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nBram Monkel *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nStella Xu *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nSteven Vos *(Industrial Design, Eindhoven University of Technology, Netherlands and School of Sport Studies, Fontys University of Applied Sciences, Netherlands)*<br>',NULL,0,'10.1145/3363384.3363404','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,55,10,NULL,NULL,0,20),(34,'sturdee-sketching-and-drawing-as-future-inquiry-in-hci','2019-09-02 15:24:57','2019-11-14 14:07:14','2019-09-02 15:24:57',NULL,1,'published','[]','Sketching & Drawing as Future Inquiry in HCI','Creating visual imagery helps us to situate ourselves within unknown worlds, processes, make connections, and find solutions. By exploring drawn ideas for novel technologies, we can examine the implications of their place in the world. Drawing, or sketching, for future inquiry in Human Computer Interaction (HCI) can be a stand-alone investigative approach, part of a wider ‘world-building’ in design fiction, or simply ideation around a concept. By examining instances of existing practice in HCI, in this paper we establish recommendations and rationales for those wishing to utilise sketching and drawing within their research. We examine approaches ranging from ideation, diagramming, scenario building, comics creation and artistic representation to create a model for sketching and drawing as future inquiry for HCI. This work also reflects on the ways in which these arts can inform and elucidate research and practice in HCI, and makes recommendations for the field, within its teaching, processes and outcomes.','Miriam Sturdee and Joseph Lindley. 2018. Sketching & Drawing as Future Inquiry in HCI. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 10 pages. [https://doi.org/10.1145/1122445.1122456](https://doi.org/10.1145/1122445.1122456 \"DOI for the article \'Sketching & Drawing as Future Inquiry in HCI\'\")','1 INTRODUCTION\r\n\r\n\r\nFigure 1: An example of subjective sketching and ideation of prototypes for a console game controller. The initial sketch (bottom middle) serves as a springboard for further iterations and tangents. The final image is coloured to highlight different areas and interactions. By keeping all images on the same sheet quick comparisons can be made and the story of design followed.\r\n\r\nFigure 2: Participant ideation sketches and notes developed further during the research process [59]. Two participants independently sketched and made notes about the concept of a shape-changing key which could retract its shape until used (bottom). The researcher sketched a central concept, then made further sketched notes to think about the issues and practicalities associated with the design, build and use of such an object. For example, mechanical-digital keys of this nature would require many working parts, could become bulky, and would need charging.\r\nDrawing is vision [50]. Hence, when simple tools like the pen and paper become a method of inquiry – through sketching our thoughts and ideas – we can develop far-reaching insights that would a prohibitively long time to design and build into systems. Human Computer Interaction (HCI) already employs a wide range of methods, whose novelty are sometimes unfamiliar to computer science. Because of this, to maximise their potential, a consolidation of how we use the “offline” creative arts, in particular the drawn image, imports palpable benefits for the field. Drawing for the sciences is not a new concept, for example, Leonardo Da Vinci was an artist and scientist using sketching and drawing to imagine machines that were hundreds of years ahead of their time [53]. The divide between art and science is a relatively new invention and is an artificial divider. Before the professional specialisation that the Industrial Revolution demanded prised them apart, it seemed quite normal that the ‘science’ of nature was referred to as ’Natural Philosophy’: while there is clearly “private territory” there is a lot of shared ground across art, science, research and other practices [24]. On a psychological level, the differences in creativity between great artists and scientists are slim to none [2]. Hence, given there should be no stigma attached to approaches utilising the creative idiom, and the imagination and future-focus of the HCI field, the field owes itself to better embrace sketching and drawing in the course of its investigations.\r\n\r\nCurrent research and practice around drawing and sketching in HCI is astounding: we have developed near-realistic paper-style interfaces [38], we can interact with sketches on digital whiteboards [9], we can see the story of a product\'s life-cycle within the sketched ‘residue’ left behind [73], we embrace sketching user experiences [10, 30], and we can even teach a novice to draw with gamified sketch-engines [74]. So why have we not embraced a return to the origin of the sketch? When used to illustrate and explore a concept the humble line – that which connects thought and the unknown – has vast potential in research. Similarly, a ‘humble divide’ between the arts and sciences should be erased and surpassed. With this in mind, where exactly does the overlap between traditional ‘hands-on’ sketching and drawing fall within HCI? Here, we provide an overview of ways in which we can – and have – used sketching and drawing as future inquiry in HCI. Using these examples of creative HCI scholarship we make recommendations for the utilisation of sketching practice for making, building and understanding the nature of our emerging interactions future with technology.\r\n\r\nThis text is intended as provocation, a call to take up arms in the form of pens, pencils, and paper, and return to the roots of creative process and inquiry. To sketch and draw out one\'s thoughts and ideas is to communicate, to communicate creates collaboration, and to collaborate and further, to research and build, is key to our field. Here, we examine the current state of the art within the field of HCI, and make recommendations for the field as a whole to embrace drawing and sketching as a form of future inquiry, a base on which to build ideas, products and impactful activity. Alongside the text, we include images which illustrate the related work and recommendations for practice, these rich, expressive research artefacts are of equal value to the written word [4, 59], and form part of the story in this paper – the enhanced captions allow snapshots into these case studies.\r\n\r\n2 Existing Processes & Practice\r\n\r\nSketching and drawing can be seen as subjective arts practice – but it is also more than that. When a designer or HCI practitioner sketches, they are telling the future, a version of something that has the potential to be built and adopted into everyday life. Socially and culturally, we are exposed to a visual world of science fiction, in comics, books, and art, populated by robots, superheroes and fantastical technologies – and this is mirrored by HCI research. At its core, sketching can be seen as speculative, a piece of human imagination, or subjective view of the world with the potential for re-interpretation. When furthered, these sketches consolidate into drawing – the neater, more final version of the initial idea.\r\n\r\nSo far, within HCI, both sketches and these neater, more polished drawn images have been used for story-telling [57], world-building [61], ideation and elaboration [67], connection with participants and stakeholders [41, 66], objects of analysis [62] ... to name but a few examples. Sketching is a crystal ball from which new products spawn, such as Alessi\'s Juicy Salif lemon squeezer, which started life as a gathering of lines on a napkin [1]. In contrast, for products, programs and their adoption in HCI, we strive to recreate the simple pleasure and interaction of the pencil and paper in tablets and tabletop surfaces [37, 38], or look at ways in which sketch interaction can be used for search [11], passwords [55] or learning [68]. The following text contains descriptions of hand-drawn images and their application to HCI research, in the areas of Ideation & Communication, Teaching & Community, Design Fiction, Comics, Storyboards & Scenarios and Diagrams, Analysis & Requirements. These studies set the scene for recommendations on sketching and drawing for future inquiry in Human Computer Interaction.\r\n\r\n2.1 Ideation & Communication Activities\r\n\r\nSketching for ideation is a common tool in the designers’ repertoire [20, 30, 39], with significant overlap into HCI as a whole. Sketching in this respect makes reference to ambiguity [26] for the ideation sketch is intended as a queryable structure – because of its non-final state it can be edited and discussed. Sketched ideation can also be participatory [17], involve working with novices and the public [7, 63], or be captured to inform the design of new software [58]. Ideation from the participant approach can then further be elaborated upon to create meaningful research inquiry [63]. Rarely do projects not contain an ideation stage, although sketching for ideation is in competition or collaboration with conversational and written elements, and can be eschewed in favour of these techniques due to the fear of I can\'t draw [14], or lack of perceived value. Sketching for ideation communicates concepts for development (Figures 1, 2), but also can be used a a method of summary and documentary, as is the case of sketchnotes [52, 66]. Further, sketching purely for communicative purposes can offer additional insights into both desired outcomes and the thoughts and feelings of a participant or co-worker [25], hence sketching for ideation and subsequent communication communicates intent for future work.\r\n\r\n2.2 Teaching & Community\r\n\r\nTo get by the “fear” of sketching and drawing for HCI, for the past 7 years there have been courses addressing penmanship at high profile conferences, as well as smaller, private group classes in industry. These courses often cover the absolute basics – “Learn to sketch - even if you can\'t draw” – [22], or particular domains such as sketchnoting [52, 66]. More recently, combined approaches covering both practical and novel aspects have been rising in popularity, for example, hands-on Applied sketching in HCI [43, 44]. Such courses are highly subscribed, indicating demand from novices in the field, and participants often go on to use their new-found skills in their everyday practice, such as developing scenarios (Figure 3). This community is further supported by existing researchers who already utilise sketching and drawing in their forward-thinking HCI practice and host workshops [32, 42], special interest groups [45, 46] and offer formats for collaboration [65]. The ongoing up-skilling, meetings between practitioners, and published work also trickles down into teaching at the higher education level, with researchers using sketching and ideation as a way of getting students interested in HCI [76].\r\n\r\n\r\nFigure 3: Example of a scenario from the HCI improv game created during the Applied Sketching in HCI course [43] [64]. Here, participants respond to verbal prompts from the audience and are challenged to create a diagram and scenario outlining their new technology, before presenting their concept and visuals to the room.\r\n\r\nFigure 4: Sketches and elaborative drawing used to show how a future console game might work within the context of a game manual for First Hand [60]. This game is based in the research space of tangible, Augmented Reality, and shape-changing prototypes, where the user has the option to terraform or evolve species in a ‘hands-on’ manner. The diagrammatic sketches from the interior of the manual are in contrast to the cover image which is rich and colourful, designed as a ‘plausible’ design fiction which is both retro and futuristic at the same time. This work provides a rich resource for future game designers.\r\n2.3 Design Fiction\r\n\r\nDesign fiction is often built around narratives [5], and can tell us about products, scenarios and worlds which do not yet exist [49]. The drawn image can be a pivotal part of a Design Fiction\'s world-building. Working hand-in-hand with other ‘entry points’ into a Design Fiction, the universal visual language can lend vision to the written word, and can act as a rapidly developed prototypes for more complex entry points such as video and physical builds [15]. Blythe et al. state that “making things imageable is at the heart of what designers do, from sketching to prototyping” [6] but as we have already postulated, sketching is not just for designers, and can be learned [14, 30]. Grand et al. go further than this, and suggest that sketching is “part of the design fiction toolbox” [29]. Figure 4 shows a design fiction game manual where both polished drawing and rough sketches are used to communicate the potential for a future game engine and console based on tangible and mixed reality interactions [60]. Further to this concept, Johnson et al. [36] see science fiction protoyping as also containing the use of drawn comics as a form of development. There is significant overlap between the comic as storytelling for the future, and other forms of storyboards and scenarios in HCI – but the drawn image in any of these forms remains a valuable part of the HCI process [67].\r\n\r\n2.4 Comics, Storyboards & Scenarios\r\n\r\nHow to Build a Voight-Kampff Machine is a comics based approach to design fiction that builds on the ‘world building hypothesis’ [15], telling the story of the concept of a digital empathy detector in a near future dating scenario (Figure 5) [61]. HCI has also embraced comics in other research contexts aside from design fiction however, such as describing ongoing work with technology and research through design [21], provocations [59] and data-driven storytelling [3], amongst others. HCI comics sit as both future inquiries and as delivery vehicles for ground-breaking research, and concepts we often find in research papers and symposiums are even finding their way into the mainstream, creating a new audience for the forward thinking focus of our field [51]. Our work in this context reflects and enforces the importance of traditional entertainment comics from the past 50 years, such as Jack Kirby\'s The One Man Army Corps (OMAC) which contained ideas from computers in communication with each other across the world, drones and high power submarines which are able to cruise at 12,000 feet below the ocean surface. Works in this vein show the importance of the artistic inquiry and ideation for HCI. In contrast, research storyboards and scenarios rarely find their way into the public domain, but are no less valuable in working through concepts and problems for future spaces – for example the storyboard as a method for generating and explaining interface behaviours [40], or to create scenarios based on future work ideas from existing research prototypes (Figure 6) which can then be used to gather responses from research teams and a wider public [67].\r\n\r\n\r\nFigure 5: How to Build a Voight-Kampff Machine: Comics as future storytelling in HCI [61]. This comic investigation was based upon a series of work into digital empathy and its intersections with science fiction. The story is set in a plausible future where we add the empathy detector from the film Bladerunner to the hand-held digital device and it is supported by a dating application. The object itself is delivered by drone. The work suggests a basic story around finding love in the future, but has deeper implications for deception and trust in an increasing technological world. By making this investigation into the form of a comic, it becomes accessible to an audience which may not access research papers, but can be taken as a contribution on both sides of the academic/public divide – breaking down barriers to understanding research.\r\n\r\nFigure 6: Scenarios based upon authors’ Future Work sections in published papers [67]: Left – A robotic pet as home assistant for the infirm [54]; Right – Smart jacket made with variable stiffness fabric [23]. These scenarios were given to researchers and public participants to illustrate new concepts, but also to get feedback on the implications of such technology on peoples’ lives – both good and bad. Colour is used to highlight the object of interest in each case, whereas the style of drawing is clear in order to support comprehension. From this work, both parties were able to make suggestions for future research to consider, e.g. what happens when your home support pet is ’hacked’? Would I want to have a jacket that was difficult to wash?\r\n2.5 Diagrams, Analysis & Requirements\r\n\r\nThe creation of images as a technique for inquiry also lends itself to post-hoc analysis. Qualitative image analysis can give us insights as to how research can be communicated, for example, via the analysis of graphical abstracts [33]), show how novices understand concepts relating to complex topics such as cybersecurity on the dark net [25], but also provide novel insights to existing processes such as software design [13]). Analysis can also provide novelty: sketching and storyboarding have been used to generate design requirements [31, 75]. On the other side, researchers also use diagrams and UML to sketch technical processes and outcomes [12]. When used in combination, ideation, diagram sketching and storyboards or scenarios can be a powerful tool to create dialogue between participants and researchers, and have effects on future directions for sub-fields within HCI (Figure 7) [62]. In the labelled example given, the way in which the technology is represented can offer insights into how it might work in the real world setting (for example, representation of digitally rendered, physical fur), yet the image was created by a novice, with basic pen and paper for material inquiry.\r\n\r\n3 WAYS OF ADOPTION\r\n\r\nThe prior examples show ways in which researchers and practitioners are already utilising sketching and drawing within the context of HCI inquiry, but the practice is far from universal in the field, despite the proven benefits of this form of inquiry. Sketches are a quick and low cost method of producing meaningful results, and their ambiguity allows conversation and misinterpretation before more final drawn outputs are created [26], which have their own value in storytelling and analysis. Sketching and drawing can tell worlds about a subject area of prototype, and unite disparate views in their application. We propose the act of sketching and drawing in HCI as having three main foci: A sketch is the act of creation, a worked drawing becomes an object of communication, and both outputs are sources of information via analysis and interpretation. The following paragraphs suggest opportunities and methods for adoption, outlining ideation and subjective inquiry, utilising outputs for communication, and how we analyse our imagery.\r\n\r\n\r\nFigure 7: Identifying design requirements and implications from participant imagery [62]. These images were produced by a participant with no prior experience within computer science. They ideated around a concept about loneliness in the digital age, and the transience of modern life not allowing for the acquisition of pets. In the diagram they consider what size a digital, tangible pet would need to be to support travel, and what it might look like. The scenario elaborates upon the features in the diagram, and allows us to look deeper into the more technical requirements of such an application. This work used sketching alongside an open coding approach.\r\n3.1 Creation\r\n\r\nIdeation is the start-point for future thinking, and can be subjective, team based, or used as a method of combined inquiry or co-creation with participants. The sketch, rather than the polished, drawn image lends itself best to this form. Design provides a valuable resource of techniques for inspiring idea generation, such as the De Bono method [19] or design thinking [18] – and many more. However, successful ideation via sketching can take place without the application of design-led techniques [63]. By providing questions or prompts for participants, and a clear direction, ideas can be generated for complex, technical outcomes [62, 70]. The important aspects of participant sketching for ideation in HCI remain informational (what background knowledge do your participants need?), material (provide the tools with which to create without boundaries), and encouraging (prompts and reassurance as to the desired quality of the image).\r\n\r\nThese suggestions can also be used within teams in the workshop or co-creation setting. Following ideation, individuals can be led to elaborate upon their initial, or favourite response, and create drawings that delve deeper into the desired object or story. Where confidence in skill is lacking, the creation of these more detailed images can be a team effort where viable. Figure 2 shows a combined approach of both participant-based ideation and subjective inquiry by the researcher, working through ideas and concepts to address potential problems and outcomes in development of a prototype [67]. Sketching problems can be as valuable as sketching successful outcomes, and can “future-proof” the design and build process. Researcher led sketching can be supported by ongoing learning and development to refine motor-skills and personal style.\r\n\r\n3.2 Communication\r\n\r\nImages created via the ideation process can branch into two outcomes: the elaborative diagram or explanation, to use to communicate concepts and practical aspects of an idea, often internally within teams; and the outward facing image, showing process, containing a story, or existing as an artefact, with an audience beyond the institutional setting. Internally, elaborative drawing can produce blueprints for builds and processes, and remain as a tool that can be referred back to which is easy to understand and interrogate. The elaborative work can also be translated into UML or CAD drawings (for example) where precision lines and relationships are needed for practically engineering a solution. This suggests the need for sketching and drawing for team members at all levels. In the outward facing context, the drawn image becomes an impactful resource, to be utilised in published work to show process and outcome, or as a method of outreach to non-technical audiences. The nature of drawn images for communication suggests moving away from ambiguity, to clear, interpretable outcomes with practical applications, such as scenarios and comics, visual abstracts, or evidence of process and development.\r\n\r\n3.3 Information\r\n\r\nThe informational aspects of sketching and drawing can be gleamed from both the outward facing imagery, but also from sketches and elaborative drawings, thus the drawn image becomes an object of analysis. Analysis can be large scale, as in the identification of design patterns, icons, co-occurring motifs (such as for graphical abstracts [33]), or on a case by case basis, as outlined in the elicitation of requirements or meaning through graphical diagramming and storytelling [62]. Images lend themselves to qualitative analysis techniques such as thematic analysis [8], but also to novel, hybridised techniques such as identifying implications of the adoption of our technologies [47, 62]. Analysis of the drawn image can also be in the form of reactive responses, via presentation to participants or stakeholders, for example, the scenarios in Figure 6 were used to explore potential public reactions to the prospect of living with such devices [67]). In essence, once produced, images themselves can become boundary objects for further inquiry.\r\n\r\n4 DISCUSSION\r\n\r\nThe works contained within this paper show how we can embrace sketching and drawing for future inquiry in HCI. The provenance and potential of this area is not in doubt, what remains is the question of how we can encourage adoption of these techniques into the wider community in a targeted way to deliver maximum impact and in support of more traditional research approaches? In this respect, the concept of building teaching and research communities around this arts-based approach becomes key: the continued offering of opportunities to engage with students and professionals alike, forums for advice and questions, databases of relevant research, and so forth [64]. The current lack of perceived value, support and training for creative practice within HCI remains the biggest limitation of the approach. Sketching and drawing is often seen as a “soft” skill, of lower value than technical practices and outputs such as coding and writing, or a “hobby” – but we show here the added value they can bring to the research table.\r\n\r\nBeyond the inherent merit of the examples such approaches also offer timely responses to the increasingly complex demands of our field. HCI\'s persistent concern with ”proximate futures” puts pressure on researchers not only to demonstrate feasibility, but to unpack the implications of innovation [47]. Moreover the moving-target of disruptive progress, particularly around the Internet of Things (IOT) and so-called Artificial Intelligence (AI), disrupts our well-established, ways of viewing the world and how our research sits within it [56]. These ’shifting sands’ of our socio-technical reality demand new ways of looking at it and researching it. Recently, responding to an increasing interest in ’post-anthropocentric’ perspectives such as Object-Oriented Ontology [48], Thing Ethnography [27], and Postphenomenology [72], proposals to augment the traditions of Human-Centred Design to become a More-Than Human Centred Design approach, have taken shape [16]. The sketch-based approaches outlined and reviewed in this paper are apt and timely approaches ways to respond to these needs. We are in the midst of a paradigm shift, and while we become accustomed to the new reality, methods which are nimble, efficient and insightful are needed to help us be agile and adapt at a rate traditional approaches are not able to. Sketch-based inquiries can play a part in addressing this clear-and-present need.\r\n\r\nHand-drawn outputs remain a self-contained method of future inquiry, but have the potential to be further expanded by the very technologies that we strive to produce as a community. In the introduction, we suggest ways in which the field embraces and expands upon traditional perspectives of what drawing is, by refining it digitally and breathing new life and direction into a reflex that we, as humans, have had since we first developed motor-skills. We do not focus on the digital/paper divide in the related work, as to draw with stylus rather than pencil is still the same process, although the very existence of the tablet rather than paper can “interrupt” or change the ideation and thinking process in comparative studies [34]. There is no doubt that the hand-drawn sketch can be more than the sum of its parts, but it also exists in a safe space – remaining relevant despite the advances of technology [28].\r\n\r\nThe “humble line” can therefore co-exist with its future self, where it fuels discovery and outputs, from becoming a skill also belonging to machines [71], to automated mutating from 2D image to 3D structure [35]. The rise in advances for brain machine interfaces may also signpost a world where the hand no longer conveys the thoughts and ideas of the mind [69]. These types of advances embrace more than human design, our AI capabilities are growing, can we use the humble line to build bridges between the human and machine world, through shared sketching and drawing practice? These practices are simple, as well as material and labour un-intensive, yet have the capacity to represent complexity – for example, could we use sketching to represent bias in AI systems? Could we use emotionally based drawing to inform a machine as to how to make decisions or to represent itself? We wish to start these conversations.\r\n\r\nWhat remains however, is that it all starts with a sketch. The drawn image has no boundaries to expression, and contains worlds of emotion, background, culture, and unknowns. These creative practices underpin a wide swathe of HCI research, but exist as a methodology in their own right, and can support and advance our field as we move through the next century and beyond. We hope that this provocation can start a dialogue and instil the value of traditional, hand-drawn imagery into a highly technological future. Will you be drawn into the discussion?\r\n\r\n5 CONCLUSION\r\n\r\nSketching and drawing are already methods of future inquiry, but can benefit from greater transparency in research process, communication to diverse groups within HCI, and wider adoption within the community. No other method lends itself to novice and expert alike, is quick and cheap to produce, and can have such a varied influence on a final idea, process or product. Case studies and related work offer evidence of success, and can provide guidelines for those who require assistance in working this artistic practice into their projects. Further, by blending sketching and drawing as technique with prototypical and maker practice, there is the potential for our drawings of the future to quite literally jump off the page as concrete technologies. Drawing is vision.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThanks to the Sketching in HCI community, namely Makayla Lewis and Nicolai Marquardt, and all the practitioners that lend their research and practice for the discovery of others in this domain.\r\n\r\nREFERENCES\r\n\r\nAlberto Alessi. 2001. The dream factory: Alessi since 1921. Electa/Alessi.  \r\nNancy C Andreasen. 2012. Creativity in art and science: are there two cultures?Dialogues in clinical neuroscience 14, 1 (2012), 49.  \r\nBenjamin Bach, Nathalie Henry Riche, Sheelagh Carpendale, and Hanspeter Pfister. 2017. The emerging genre of data comics. IEEE computer graphics and applications 37, 3 (2017), 6–13.  \r\nEli Blevis, Sabrina Hauser, and William Odom. 2015. Sharing the hidden treasure in pictorials. interactions (2015).  \r\nMark Blythe. 2017. Research fiction: storytelling, plot and design. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 5400–5411.  \r\nMark Blythe, Kristina Andersen, Rachel Clarke, and Peter Wright. 2016. Anti-solutionist strategies: Seriously silly design fiction. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 4968–4978.  \r\nAdrien Bousseau, Theophanis Tsandilas, Lora Oehlberg, and Wendy E Mackay. 2016. How novices sketch and prototype hand-fabricated objects. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 397–408.  \r\nVirginia Braun, Victoria Clarke, Nikki Hayfield, and Gareth Terry. 2019. Thematic analysis. Handbook of Research Methods in Health Social Sciences (2019), 843–860.  \r\nJeffrey Browne, Bongshin Lee, Sheelagh Carpendale, Timothy Sherwood, and Nathalie Riche. 2011. iSketchVis: Integrating Sketch-based Interaction with Computer Supported Data Analysis. GSWC 2011 (2011), 25.  \r\nBill Buxton. 2010. Sketching user experiences: getting the design right and the right design. Morgan kaufmann.  \r\nYang Cao, Hai Wang, Changhu Wang, Zhiwei Li, Liqing Zhang, and Lei Zhang. 2010. Mindfinder: interactive sketch-based image search on millions of images. In Proceedings of the 18th ACM international conference on Multimedia. ACM, 1605–1608.  \r\nQi Chen, John Grundy, and John Hosking. 2003. An e-whiteboard application to support early design-stage sketching of UML diagrams. In IEEE Symposium on Human Centric Computing Languages and Environments, 2003. Proceedings. 2003. IEEE, 219–226.  \r\nEunyoung Chung, Carlos Jensen, Koji Yatani, Victor Kuechler, and Khai N Truong. 2010. Sketching and drawing in the design of open source software. In 2010 IEEE Symposium on Visual Languages and Human-Centric Computing. IEEE, 195–202.  \r\nNeil Cohn. 2012. Explaining ‘I can‘t draw’: Parallels between the structure and development of language and drawing. Human Development 55, 4 (2012), 167–192. https://doi.org/10.1159/000341842  \r\nPaul Coulton, Joseph Lindley, Miriam Sturdee, Mike Stead, et al. 2017. Design fiction as world building. (2017).  \r\nPaul Coulton and Joseph Galen Lindley. 2019. More-Than Human Centred Design: Considering Other Things. The Design Journal (2019), 1–19.  \r\nBrock Craft and Paul Cairns. 2009. Sketching sketching: outlines of a collaborative design method. In Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology. British Computer Society, 65–72.  \r\nAlma L Culén and Asbjørn Følstad. 2014. Innovation in HCI: what can we learn from design thinking?. In Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational. ACM, 849–852.  \r\nEdward De Bono. 1986. De Bono\'s thinking course. (1986).  \r\nTomás Dorta. 2008. Design flow and ideation. International Journal of Architectural Computing 6, 3 (2008), 299–316.  \r\nThomas Dykes, Mark Blythe, Jayne Wallace, James Thomas, and Tim Regan. 2016. RtD comics: A medium for representing research through design. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems. ACM, 971–982.  \r\nStephanie Foehrenbach. 2015. Learn to Sketch (Even if You Can\'t Draw): Hands-on Sketching Course. In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 2467–2468.  \r\nSean Follmer, Daniel Leithinger, Alex Olwal, Nadia Cheng, and Hiroshi Ishii. 2012. Jamming user interfaces: programmable particle stiffness and sensing for malleable and shape-changing devices. In Proceedings of the 25th annual ACM symposium on User interface software and technology. ACM, 519–528.  \r\nChristopher Frayling. 1993. Research in art and design. (1993).  \r\nKevin Gallagher, Sameer Patil, and Nasir Memon. 2017. New me: Understanding expert and non-expert perceptions and usage of the Tor anonymity network. In Thirteenth Symposium on Usable Privacy and Security ({SOUPS} 2017). 385–398.  \r\nWilliam W Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a resource for design. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 233–240.  \r\nElisa Giaccardi, Nazli Cila, Chris Speed, and Melissa Caldwell. 2016. Thing ethnography: doing design research with non-humans. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems. ACM, 377–387.  \r\nGabriela Goldschmidt. 2017. Manual sketching: Why is it still relevant?In The Active Image. Springer, 77–97.  \r\nSimon Grand and Martin Wiedmer. 2010. Design fiction: a method toolbox for design research in a complex world. In proceedings of the DRS 2010 conference: Design and Complexity.  \r\nSaul Greenberg, Sheelagh Carpendale, Nicolai Marquardt, and Bill Buxton. 2011. Sketching user experiences: The workbook. Elsevier.  \r\nMieke Haesen, Kris Luyten, and Karin Coninx. 2009. Get your requirements straight: Storyboarding revisited. Human-Computer Interaction–INTERACT 2009(2009), 546–549.  \r\nTracy Hammond and Paul Taele. 2019. Sketching Cognition and Creativity: Leveraging Sketch Interfaces for Enhancing Creativity and Cognition. In Proceedings of the 2019 on Creativity and Cognition. ACM, 708–713.  \r\nJessica Hullman and Benjamin Bach. 2018. Picturing Science: Design Patterns in Graphical Abstracts. In International Conference on Theory and Application of Diagrams. Springer, 183–200.  \r\nRahinah Ibrahim and Farzad Pour Rahimian. 2010. Comparison of CAD and manual sketching tools for teaching architectural design. Automation in Construction 19, 8 (2010), 978–987.  \r\nTakeo Igarashi, Takeo Igarashi, Satoshi Matsuoka, and Hidehiko Tanaka. 2007. Teddy: a sketching interface for 3D freeform design. In Acm siggraph 2007 courses. ACM, 21.  \r\nBrian David Johnson. 2011. Science fiction prototyping: Designing the future with science fiction. Synthesis Lectures on Computer Science 3, 1 (2011), 1–190.  \r\nGabe Johnson, Mark Gross, Ellen Yi-Luen Do, and Jason Hong. 2012. Sketch it, make it: sketching precise drawings for laser cutting. In CHI’12 Extended Abstracts on Human Factors in Computing Systems. ACM, 1079–1082.  \r\nGabe Johnson, Mark D Gross, Jason Hong, Ellen Yi-Luen Do, et al. 2009. Computational support for sketching in design: a review. Foundations and Trends® in Human–Computer Interaction 2, 1(2009), 1–93.  \r\nBen Jonson. 2005. Design ideation: the conceptual sketch in the digital age. Design studies 26, 6 (2005), 613–624.  \r\nJames A Landay and Brad A Myers. 1996. Sketching storyboards to illustrate interface behaviors. In Conference on Human Factors in Computing Systems: Conference companion on Human factors in computing systems: common ground, Vol. 13. 193–194.  \r\nMakayla Lewis and Lizzie Coles-Kemp. 2014. A Tactile Visual Library To Support User Experience Storytelling. In Proceedings of NordDesign. 386.  \r\nMakayla Lewis, Miriam Sturdee, Jason Alexander, Jelle Van Dijk, Majken Kirkegård Rasmussen, and Thuong Hoang. 2017. SketchingDIS: Hand-drawn Sketching in HCI. In Proceedings of the 2016 ACM Conference Companion Publication on Designing Interactive Systems. ACM, 356–359.  \r\nMakayla Lewis, Miriam Sturdee, and Nicolai Marquardt. 2018. Applied Sketching in HCI: Hands-on Course of Sketching Techniques. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, C08.  \r\nMakayla Lewis, Miriam Sturdee, and Nicolai Marquardt. 2019. Sketching in HCI: Hands-on Course of Sketching Techniques. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, C04.  \r\nMakayla Lewis, Miriam Sturdee, Nicolai Marquardt, and Thuong Hoang. 2018. SketCHI: Hands-On Special Interest Group on Sketching in HCI. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems(CHI EA ’18). ACM. https://doi.org/10.1145/3170427.3185366  \r\nMakayla Lewis, Miriam Sturdee, Jagoda Walny, Nicolai Marquardt, Thuong Hoang, Joanna Foster, and Sheelagh Carpendale. 2019. SketCHI 2.0: Hands-On Special Interest Group on Sketching in HCI. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, SIG12.  \r\nJoseph Lindley, Paul Coulton, and Miriam Sturdee. 2017. Implications for adoption. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 265–277.  \r\nJoseph Galen Lindley, Paul Coulton, and Haider Akmal. 2018. Turning Philosophy with a Speculative Lathe: Object Oriented Ontology, Carpentry, and Design Fiction. (2018).  \r\nConor Linehan, Ben J Kirman, Stuart Reeves, Mark A Blythe, Joshua G Tanenbaum, Audrey Desjardins, and Ron Wakkary. 2014. Alternate endings: using fiction to explore design futures. In CHI’14 Extended Abstracts on Human Factors in Computing Systems. ACM, 45–48.  \r\nAndrew Loomis. 1963. Successful Drawing. Three-Dimensional Drawing.(Revised Edition of Successful Drawing.) With Illustrations.Chapman & Hall.  \r\nAaron Marcus. 2015. HCI goes mainstream in the comics. In HCI and User-Experience Design. Springer, 265–269.  \r\nNicolai Marquardt and Saul Greenberg. 2012. Sketchnotes for Visual Thinking in HCI. In Proc. ACM Conference on Human Factors in Computing Systems: CHI Workshop on Visual Thinking and Digital Imagery.(Workshop held at the ACM CHI Conference), Vol. 5.  \r\nFrancis C Moon. 2007. The Machines of Leonardo Da Vinci and Franz Reuleaux: kinematics of machines from the Renaissance to the 20th Century. Vol. 2. Springer Science & Business Media.  \r\nTakuya Nojima, Yoshiharu Ooide, and Hiroki Kawaguchi. 2013. Hairlytop interface: An interactive surface display comprised of hair-like soft actuators. In 2013 World Haptics Conference (WHC). IEEE, 431–435.  \r\nMizuki Oka, Kazuhiko Kato, Yingqing Xu, Lin Liang, and Fang Wen. 2008. Scribble-a-secret: Similarity-based password authentication using sketches. In 2008 19th International Conference on Pattern Recognition. IEEE, 1–4.  \r\nJames Pierce and Carl DiSalvo. 2017. Dark Clouds, Io&#!+, and [Crystal Ball Emoji]: Projecting Network Anxieties with Alternative Design Metaphors. In Proceedings of the 2017 Conference on Designing Interactive Systems. ACM, 1383–1393.  \r\nMajken Kirkegård Rasmussen, Giovanni Maria Troiano, Marianne Graves Petersen, Jakob Grue Simonsen, and Kasper Hornbæk. 2016. Sketching Shape-changing Interfaces: Exploring Vocabulary, Metaphors Use, and Affordances.. In CHI. 2740–2751.  \r\nPieter Jan Stappers and James M Hennessey. 1999. Toward electronic napkins and beermats: Computer support for visual ideation skills. In Visual representations and interpretations. Springer, 220–225.  \r\nMiriam Sturdee, Jason Alexander, Paul Coulton, and Sheelagh Carpendale. 2018. Sketch & The Lizard King: Supporting image inclusion in HCI publishing. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, alt15.  \r\nMiriam Sturdee, Paul Coulton, and Jason Alexander. 2017. Using Design Fiction to Inform Shape-Changing Interface Design and Use. The Design Journal 20, sup1 (2017), S4146–S4157.  \r\nMiriam Sturdee, Paul Coulton, Joseph G Lindley, Mike Stead, Haider Ali, and Andy Hudson-Smith. 2016. Design fiction: How to build a Voight-Kampff machine. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 375–386.  \r\nMiriam Sturdee, Aluna Everitt, Joseph Lindley, Paul Coulton, and Jason Alexander. 2019. Visual Methods for the Design of Shape-Changing Interfaces. In IFIP Conference on Human-Computer Interaction. Springer, xx–xx.  \r\nMiriam Sturdee, John Hardy, Nick Dunn, and Jason Alexander. 2015. A Public Ideation of Shape-Changing Applications. In Proceedings of the 2015 International Conference on Interactive Tabletops & Surfaces. ACM, 219–228.  \r\nMiriam Sturdee, Makayla Lewis, and Nicolai Marquardt. 2018. Feeling SketCHI?: the lasting appeal of the drawn image in HCI. interactions 25, 6 (2018), 64–69.  \r\nMiriam Sturdee, Makayla Lewis, and Nicolai Marquardt. 2018. SketchBlog# 1: the rise and rise of the sketchnote. interactions 25, 6 (2018), 6–8.  \r\nMiriam Sturdee, Samuel Mann, and Sheelagh Carpendale. 2019. Sketching Sustainability in Computing. In Proceedings of the 2019 on Creativity and Cognition. ACM, 29–40.  \r\nMiriam Amber Sturdee. 2018. Sketching as a support mechanism for the design and development of shape-changing interfaces. Ph.D. Dissertation. Lancaster University.  \r\nPaul Taele, Laura Barreto, and Tracy Hammond. 2015. Maestoso: an intelligent educational sketching tool for learning music theory. In Twenty-Seventh IAAI Conference.  \r\nDesney Tan and Anton Nijholt. 2010. Brain-computer interfaces and human-computer interaction. In Brain-Computer Interfaces. Springer, 3–19.  \r\nMaryam Tohidi, William Buxton, Ronald Baecker, and Abigail Sellen. 2006. User sketches: a quick, inexpensive, and effective way to elicit more reflective user feedback. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 105–114.  \r\nPatrick Tresset and Frederic Fol Leymarie. 2013. Portrait drawing by Paul the robot. Computers & Graphics 37, 5 (2013), 348–363.  \r\nRon Wakkary, Doenja Oogjes, Sabrina Hauser, Henry WJ Lin, Cheng Cao, Leo Ma, and Tijs Duel. 2017. Morse Things: A Design Inquiry into the Gap Between Things and Us.. In Conference on Designing Interactive Systems. 503–514.  \r\nJagoda Walny, Jonathan Haber, Marian Dörk, Jonathan Sillito, and Sheelagh Carpendale. 2011. Follow that sketch: Lifecycles of diagrams and sketches in software development. In Visualizing Software for Understanding and Analysis (VISSOFT), 2011 6th IEEE International Workshop on. IEEE, 1–8.  \r\nBlake Williford. 2017. SketchTivity: Improving Creativity by Learning Sketching with an Intelligent Tutoring System. In Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition. ACM, 477–483.  \r\nDustin Wüest, Norbert Seyff, and Martin Glinz. 2015. Sketching and notation creation with FlexiSketch Team: Evaluating a new means for collaborative requirements elicitation. In 2015 IEEE 23rd International Requirements Engineering Conference (RE). IEEE, 186–195.  \r\nSarita Yardi, Pamela Krolikowski, Taneshia Marshall, and Amy Bruckman. 2008. An HCI approach to computing in the real world. Journal on Educational Resources in Computing (JERIC) 8, 3 (2008), 9.  ',1,'Sturdee','Miriam Sturdee and Joseph Lindley','Miriam Sturdee *(Lancaster University, UK)*<br>\r\nJoseph Lindley *(Lancaster University, UK)*',NULL,0,'10.1145/3363384.3363402','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,65,10,NULL,NULL,0,18),(35,'borutecene-otherworld-ouija-board-as-a-resource-for-design','2019-09-02 15:24:57','2019-11-14 14:07:26','2019-09-02 15:24:57',NULL,1,'published','[]','Otherworld: Ouija Board as a Resource for Design','The Ouija board is a device to contact spirits from the so-called otherworld. Although it is considered paranormal activity, the way it works rests on ideomotor actions and we argue that the Ouija is a resource for design for the following aspects: It is a 1) collective tangible exploration tool operated by two or more people through a physical pointer that moves, seemingly on its own, around the letters to probe meanings by composing messages. It has been used by artists as a medium offering 2) creative stimulation to generate material and develop ideas for their work. The Ouija also enables people to express nonconscious knowledge, as research suggests, and thus can provide 3) access to tacit dimension. In this paper, we present the Otherworld Framework that describes its principal elements and provide speculations on how to exploit them in design for collaborative, engaging and unconventional group interactions.','Ahmet Börütecene and Oguz Turan Buruk. 2019. Otherworld: Ouija Board as a Resource for Design. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363388](https://doi.org/10.1145/3363384.3363388 \"DOI for the article \'Otherworld: Ouija Board as a Resource for Design\'\")','1 INTRODUCTION\r\n\r\nThroughout history humans have invented numerous mechanisms to contact the supernatural or the so-called otherworld and inquire into the unknown [1, 3, 10, 15]. One of these mechanisms is the Ouija board 1 [3, 5, 19, 25]. The Ouija offers a playful activity in which a group of people engage in a spiritual session and experience the feeling of a supernatural contact - both collectively and individually. In a Ouija session, two or more participants gather around a board that bears letters and numbers as well as some words such as “Yes, No, and Goodbye” (Figure 1). They keep their index fingers placed on a physical pointer (planchette) that is on the board and ask a series of questions, supposedly directed to a spirit. After each question, the planchette starts moving around, seemingly on its own, and goes from one letter to another. This eventually forms words or sentences as an answer. The answers trigger conversation among participants and thus more questions, which makes the Ouija a social and exploratory experience.\r\n\r\n\r\nFigure 1: An example of a Ouija board and a planchette (Photo by Paul Tamayo [6]).\r\nThis experience involves a number of interrelated factors. First of all, it is true that the planchette moves. Although people are free to believe that spirits are responsible for the movement, there is in fact a scientific explanation: ideomotor actions. These are subtle bodily movements that individuals tend to perform when they observe, or think of, a motion without feeling a sense of agency [20, 26]. An explanation for this reduced perception of conscious control, which is also defined as automatism, is what [32, p112] calls movement confusion. Underestimating self-generated force adds to this and reinforces the illusion of an external intervention [7].\r\n\r\nLikewise, ambiguity plays a fundamental role in the Ouija. The question “Who moves the planchette?” creates an ambiguous situation (movement confusion) and triggers ideomotor response in participants. Gaver et al. argue that ambiguity is a powerful tool for design and propose three types of ambiguity [18]. Ambiguity of information refers to deliberate use of incomplete information. Ambiguity of context refers to presenting things in different contexts than originally intended. Ambiguity of relationship is about crafting things and spaces to trigger imagination and self-reflection. In the following sections, we describe further how the Ouija benefits from these.\r\n\r\nAnother factor is nonconscious knowledge. According to Gauchou et al., a Ouija-type apparatus can become a means for people to express what they think they do not know, that is nonconscious contents of thought [17, 23]. Tacit knowledge, defined as the opposite of formalized and explicit knowledge, refers to a similar situation: we know more than we can tell, as Polanyi stated [27]. Transmitting this kind of knowledge is a challenge and the Ouija may offer alternative ways to engage implicit cognition.\r\n\r\nAdditionally, our research direction is motivated by previous studies that considered paranormal phenomena and magic as a source of inspiration for design research in HCI [12, 13, 24, 30, 31].\r\n\r\nIn this regard, the Ouija might be a mechanism to explore novel paradigms in collaborative creation and exploration, user experience assessment, and interaction techniques. In this paper, we propose the Otherworld Framework based on the Ouija and present three use cases.\r\n\r\n2 OUIJA BOARD FOR DESIGN\r\n\r\nHere we explain why the Ouija is relevant for design by discussing its salient points.\r\n\r\n2.1 Collective Tangible Exploration\r\n\r\nThe board and the planchette offer a collocated group activity in which people bodily engage with a shared physical pointer to probe meanings and reveal the unknown together. Here it is important to maintain the ambiguity of context regarding the origin of action (Who moves the planchette?) so that the sense of agency is reduced and each participant feels that a joint activity is in progress. This setting might help prevent dominant members of a group from taking over the discussion and create a more equal relationship. Furthermore, this ambiguity might also enable timid members to influence the planchette movements and participate more actively in group discussions.\r\n\r\n2.2 Creative Stimulation\r\n\r\nThe Ouija can become a medium to generate material and develop ideas for artistic expression. William B. Yeats, Sylvia Plath and James Merrill, among others, used the Ouija as a source of inspiration to write literary works [8, 16, 22]. Ambiguity also plays a role here. Since we do not know exactly which participant moves the planchette, an uncertainty appears: who answers the questions? The reduced sense of agency might intensify the effect of this ambiguity of context. There is also another question: what do the answers mean? This may be considered ambiguity of information. Answers given by the board might not always be complete or self-evident which encourages multiple readings of a situation. The meaning is constructed and contextualized in a collective way by the participants’ own interpretation.\r\n\r\n2.3 Access to Tacit Dimension\r\n\r\nThe Ouija works as a medium that enables people to express what they know but cannot, for different reasons, always verbalise [17]. It suggests an alternative way of exploiting tacit knowledge. Using the planchette as a probe, participants access their nonconscious and explore a situation as they are jointly shaping it [9]. This recalls using a stick to explore a dark cavern and understanding the surrounding through the probe\'s impact on our hand [27, p.12-13]. The Ouija offers a reflective conversation in which the situation ”talks back” to participants [29, p76-79], engaging their individual or collective unconscious. This mechanism might facilitate decision making situations in hierarchical organizations and prevent power relations and biases from taking the lead. Instead, experience-based knowledge might become more salient and have a say in group decisions.\r\n\r\n\r\nFigure 2: Principal elements (A, B, C) of the Otherworld Framework.\r\n3 THE OTHERWORLD FRAMEWORK\r\n\r\nWe first present our dissection of the Ouija mechanism and describe its principal elements (Figure 2). We discuss below how the Ouija can be repurposed as a means for design exploration by describing how each element can be reconfigured.\r\n\r\n3.1 The Board and the Planchette\r\n\r\nOuija boards exist in different forms, including electronic versions [2, 3, 28] (Figure 3). In the Otherworld Framework, the modification of the board and the planchette is an important aspect. Boards can be designed in such a way that they include letters, ideas, shapes, sketches, tactile geometry etc. Planchettes can also have various forms depending on the intended actions such as sketching, meaning making or form giving [4]. Possibilities can be expanded by augmenting both objects with interactive technologies such as tangibles in reacTable [21].\r\n\r\n\r\nFigure 3: Different types of Ouija boards [3]. © Museum of Talking Boards, used with permission.\r\n3.2 Participants\r\n\r\nAnother important aspect of the Otherworld Framework is the people who connect to “the other side”. The participants’ backgrounds as well as their number can change the structure of the activity. For instance, a creation activity may be facilitated by a designer while users or developers (and “maybe spirits”) may take part as participants from diverse stakeholder groups in this “divine” brainstorming session. The Ouija can also be used by different participants in the same contexts, which would conceivably yield different outcomes.\r\n\r\n3.3 Context\r\n\r\nThe context refers to two elements: the narrative and the purpose of a Ouija session. The narrative can be adapted to the topic explored. For example, a narrative in which the spirit of Leonardo da Vinci is summoned can be adapted to an exploration study about flying machines (e.g., drones). The narrative also depends on the participants, as their belief in spirituality would influence the way they approach the session (i.e., the planchette is moved by spirits versus by humans) [9]. For participants who are reluctant to take part in activities that might be associated to occult or spirituality, the narrative can also be created around themes such as playfulness and games; similar to the transformation of the Ouija from a divination device into a parlour game [25]. The second element of the context, the purpose, instead, refers to the intention of the study, whether it is the exploration of a topic, the creation of an artefact or the evaluation of an idea. This would also affect the design of the Ouija board and the planchette. While a board designed for an evaluation might bear simple words such as yes/no/maybe, an exploration or creation study may require concepts, shapes or letters to engage with.\r\n\r\n4 USE CASES\r\n\r\nWe present below some speculations on how the Ouija and the Otherworld Framework can be exploited in HCI.\r\n\r\n4.1 Difficult Conversations\r\n\r\n(Board with letters and symbols; Participants: Humans - Family caregivers and a facilitator; Context: Exploratory and Evaluative)\r\n\r\nTaking care of a loved one with dementia can be challenging and demanding. This makes family caregivers vulnerable to psychological distress [11]. Moreover, they may feel uncomfortable talking about this sensitive topic with others and thus lack social support. A Ouija board can be designed by an expert (e.g., doctor, therapist, designer) to facilitate such difficult conversations. It can bring together the family members of a person with dementia and enable them to share their experiences without feeling exposed or guilty. They can answer the facilitator\'s questions regarding sensitive topics of dementia-care by navigating through letters or symbols while remaining incognito (Who moves the planchette?). Each member might influence the answers moving the planchette unconsciously and express a concern or raise awareness in others. This might enable caregivers to identify and discuss the sources of distress as well as the experts to learn from them. Designers can use this method to have more insightful feedback from stakeholders in designing for taboo topics as well as in evaluating concepts through different stages.\r\n\r\n4.2 Product Ideation\r\n\r\n(Augmented board design that creates traces; Participants: Human - Designers; Context: Exploratory and Creative)\r\n\r\nThree designers brainstorm on the design of a wearable device that will be used in Virtual Reality (VR) by working with a Ouija board that allows them to move around the depicted body parts and zoom on them to collaboratively sketch the form of the device. One of them asks the board “Which ’body part’ would be the most ’functional’?” Questions may vary according to purpose. The cursor moves around the screen and stops on the shoulder. The Ouija zooms to shoulder. The other designers ask “What would this shoulder wearable look like?” The cursor starts moving again by leaving traces on the screen, eventually suggesting an ambiguous shape. The Ouija enables a collaboratively created base for facilitating further discussion, either during the same session or in a follow-up after producing new knowledge with the information obtained. Here, the context is known to a certain extent as the designers are creating a wearable for VR. Yet, they do not know what the collaborative sketch means or promises. This ambiguity of information might trigger their imagination to generate new ideas [14, p173-174].\r\n\r\n4.3 Scenario Planning\r\n\r\n(Board reflecting visualisations of AI predictions; Participants: Human - Operators, Non-human - AI; Context: Exploratory and Evaluative)\r\n\r\nThree operators work in the control room of a partially autonomous warehouse. They are standing around a Ouija board where an assistive AI visualises its predictions of delivery performance. They place their fingers on the physical pointer (planchette) to start navigating the visualisation and explore possible scenarios. In this case, the planchette becomes a tangible contact between the AI and its colleagues; while diverse tactile feedback may convey the uncertainty levels of AI predictions, ideomotor responses from the operators might provide directions of their thought as input for the AI [32, p123]. As the Ouija enables access to nonconscious knowledge, operators may also use the planchette to reinforce their educated guess, if needed. When power relations between operators mislead discussions, the Ouija may play an equalizing role as it enables them to involve bodily senses as an alternative way to assess situations. This might enable a more participatory and informed discussion as it encourages collective decision making and each participant is a potential influencer in the process.\r\n\r\n5 CONCLUSION\r\n\r\nIn this paper, we presented the Otherworld Framework to explain how the Ouija board can be used as a resource in designing for exploration, ideation, and evaluation. We defined what the Ouija offers for design (collective tangible exploration, creative stimulation and access to tacit knowledge) and how these can be facilitated by modifying three elements (board and planchette, participants, context). Our study embodies limitations inherent to speculative studies, meaning that the components and actions defined here may differ in the realization process. However, we believe our paper provides a ground to initiate a discussion about such a method, which introduces people with less domain knowledge (e.g., users, managers) to the role of ambiguity in design in a playful and engaging way. It also offers to more experienced stakeholders (e.g., design researchers, practitioners) new embodied and tangible ways to explore, ideate and create.\r\n\r\n6 ACKNOWLEDGEMENTS\r\n\r\nThis publication is partially funded by the European Union\'s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No:833731-WEARTUAL. Thanks to Jonas Löwgren for stimulating discussions and feedback and Nevin Dogan for her attentive proofreading.\r\n\r\nREFERENCES\r\n\r\n[n. d.]. Chevreul pendulum - Oxford Reference. https://doi.org/10.1093/oi/authority.20110803095606403  \r\n[n. d.]. The Electric Mystifying Oracle. https://www.museumoftalkingboards.com/myst.html  \r\n[n. d.]. Museum of Talking Boards Collection. https://photos.google.com/share/AF1QipODnzQ1kiQtMzolJ5n5n__3QkcmOuLGPxZ301kS7RWzplrr34o5IIUkszblm4dU6g?key=ZXpoNkVVOVg0UmR6U1A2YWN0VlBBNVpQSXNUYUFn  \r\n[n. d.]. Museum of Talking Boards, Planchettes. https://www.museumoftalkingboards.com/planchet.html  \r\n[n. d.]. Ouija Game | Ouija. https://shop.hasbro.com/en-us/product/ouija-game:86117134-5056-9047-F5E1-46EB2553A56A  \r\n[n. d.]. The Real Fakery of the Ouija Board. https://kotaku.com/the-real-fakery-of-the-ouija-board-1819805308  \r\n[n. d.]. Two Eyes for an Eye: The Neuroscience of Force Escalation. 301 ([n. d.]). https://doi.org/10.1126/science.1085327  \r\n2016. How Sylvia Plath Used a Ouija Board to Write Poetry. https://ultraculture.org/blog/2016/01/31/sylvia-plath-ouija-board/  \r\nMarc Andersen, Kristoffer L. Nielbo, Uffe Schjoedt, Thies Pfeiffer, Andreas Roepstorff, and Jesper Sørensen. 2018. Predictive minds in Ouija board sessions. Phenomenology and the Cognitive Sciences (July 2018). https://doi.org/10.1007/s11097-018-9585-8  \r\nEdna Aphek and Yishai Tobin. 1990. The Semiotics of Fortune-telling. John Benjamins Publishing Company, Amsterdam; Philadelphia.  \r\nHenry Brodaty and Marika Donkin. 2009. Family caregivers of people with dementia. Dialogues in clinical neuroscience 11, 2 (2009), 217.  \r\nKieran Browne and Ben Swift. 2018. The Other Side: Algorithm as Ritual in Artificial Intelligence. ACM, alt11. https://doi.org/10.1145/3170427.3188404  \r\nAhmet Börütecene, İdil Bostan, Tilbe Göksun, and Oğuzhan Özcan. 2016. Informing Design Decisions for Advice Mediating Handheld Devices by Studying Coffee Cup Reading. In Proceedings of the 9th Nordic Conference on Human-Computer Interaction(NordiCHI ’16). ACM, New York, NY, USA, 7:1–7:10. https://doi.org/10.1145/2971485.2971523 event-place: Gothenburg, Sweden.  \r\nLeonardo Da Vinci. 2008. Notebooks, ed. Irma A. Richter, Thereza Wells and Martin Kemp.  \r\nAnn Fiery. 1999. The Book of Divination(first edition edition ed.). Chronicle Books, San Francisco.  \r\nPoetry Foundation. 2019. ’Even the spirits get a say’: A Look Into James Merrill\'s Ouija Poems by Harriet Staff. https://www.poetryfoundation.org/harriet/2016/08/even-the-spirits-get-a-say-a-look-into-james-merrills-ouija-poems  \r\nHélène L. Gauchou, Ronald A. Rensink, and Sidney Fels. 2012. Expression of nonconscious knowledge via ideomotor actions. Consciousness and Cognition 21, 2 (June 2012), 976–982. https://doi.org/10.1016/j.concog.2012.01.016  \r\nWilliam W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity As a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 233–240. https://doi.org/10.1145/642611.642653 event-place: Ft. Lauderdale, Florida, USA.  \r\nNational Endowment for the Humanities. 1891. Pittsburg dispatch. (Pittsburg [Pa.]) 1880-1923, February 01, 1891, SECOND PART, Image 12. (Feb. 1891), 12. https://chroniclingamerica.loc.gov/lccn/sn84024546/1891-02-01/ed-1/seq-12/  \r\nAnne Häberle, Simone Schütz-Bosbach, Rafael Laboissière, and Wolfgang Prinz. 2008. Ideomotor action in cooperative and competitive settings. Social Neuroscience 3, 1 (March 2008), 26–36. https://doi.org/10.1080/17470910701482205  \r\nSergi Jordà, Günter Geiger, Marcos Alonso, and Martin Kaltenbrunner. 2007. The reacTable: Exploring the Synergy Between Live Music Performance and Tabletop Tangible Interfaces. In Proceedings of the 1st International Conference on Tangible and Embedded Interaction(TEI ’07). ACM, New York, NY, USA, 139–146. https://doi.org/10.1145/1226969.1226998 event-place: Baton Rouge, Louisiana.  \r\nBenjamin Kunkel. 1999. Slouching to the Ouija Board. (Oct. 1999). https://www.thenation.com/article/slouching-ouija-board/  \r\nUBC Visual Cognition Lab. 2014. Academic Research Using Ouija to Explore the Subconscious. https://www.youtube.com/watch?v=8v8XldKLxQs  \r\nJoe Marshall, Steve Benford, and Tony Pridmore. 2010. Deception and Magic in Collaborative Interaction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’10). ACM, New York, NY, USA, 567–576. https://doi.org/10.1145/1753326.1753410 event-place: Atlanta, Georgia, USA.  \r\nLinda Rodriguez McRobbie. [n. d.]. The Strange and Mysterious History of the Ouija Board. https://www.smithsonianmag.com/history/the-strange-and-mysterious-history-of-the-ouija-board-5860627/  \r\nJay A. Olson, Ewalina Jeyanesan, and Amir Raz. 2017. Ask the pendulum: personality predictors of ideomotor performance. Neuroscience of Consciousness 2017, 1 (Jan. 2017). https://doi.org/10.1093/nc/nix014  \r\nMichael Polanyi. 1966. The tacit dimension.Doubleday, Garden City, N.Y.OCLC: 374908.  \r\nPop Punk Picker\'s Ebay Demos. [n. d.]. Ouija Board The Mystifying Oracle Hasbro 2013 Light Up Planchette Complete. https://www.youtube.com/watch?v=Jpv_20QbPSg  \r\nDonald A Schön. 2017. The reflective practitioner: How professionals think in action. Routledge.  \r\nDag Svanaes and William Verplank. 2000. In Search of Metaphors for Tangible User Intefaces. In Proceedings of DARE 2000 on Designing Augmented Reality Environments(DARE ’00). ACM, New York, NY, USA, 121–129. https://doi.org/10.1145/354666.354679 event-place: Elsinore, Denmark.  \r\nBruce Tognazzini. 1993. Principles, Techniques, and Ethics of Stage Magic and Their Application to Human Interface Design. In Proceedings of the INTERACT ’93 and CHI ’93 Conference on Human Factors in Computing Systems(CHI ’93). ACM, New York, NY, USA, 355–362. https://doi.org/10.1145/169059.169284 event-place: Amsterdam, The Netherlands.  \r\nDaniel M. Wegner. 2002. The Illusion of Conscious Will. MIT Press. Google-Books-ID: eQnlRg56piQC.  \r\nFOOTNOTE\r\n\r\n1Hereafter referred to as the Ouija.',1,'Borutecene','Ahmet Börütecene and Oğuz Turan Buruk','Ahmet Börütecene *(Media and Information Technology, Linköping University, Sweden)*<br>\r\nOğuz Turan Buruk *(Gamification Group, Tampere University, Finland)*',NULL,0,'10.1145/3363384.3363388','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,75,5,NULL,NULL,0,4),(36,'neubauer-reconfiguring-human-centred-design-of-technology-as-a-technohuman-intervention','2019-09-02 15:24:57','2019-11-14 14:07:29','2019-09-02 15:24:57',NULL,1,'published','[]','Reconfiguring Human-centred Design of Technology as a Technohuman Intervention','Human-centred design has been conceptualised as the simultaneous splitting and synthesising of the human and the technology, for the purpose of reconfiguring orders and positions of people and things within organisational innovation practices. Describing this function of design as an intervention, the paper makes visible the designer subject position being enacted as the mediating of different knowledges within the technohuman designer body. Using these insights into design practices, a reconceptionalisation is proposed, away from the current individual designerly agency of the technohuman designer, towards an intervention through collaborative technohuman reconfiguration by design.','Ruth Neubauer. 2019. Reconfiguring Human-centred Design of Technology as a Technohuman Intervention. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363473](https://doi.org/10.1145/3363384.3363473 \"DOI for the article \'\'Reconfiguring Human-centred Design of Technology as a Technohuman Intervention\")','1 Introduction\r\n\r\nBased on my PhD, which investigated design practices in digital innovation, this paper is a further exploration of the tentatively introduced concept of the ‘technohuman’ agent of design. This concept was inspired by Haraway\'s image of the cyborg [8], and is derived from the study\'s new conceptualisation of human-centred design as the simultaneous splitting and synthesising of the human and the technology, for the purpose of reconfiguring orders and positions of people and things within organisational innovation practices. Using posthuman theory, the professional practices of human-centred design are visualised as an ongoing intervening in the reconfiguration work taking place as the ‘innovation games’. In the organisational innovation games, design emerges as a useful object of intervention, as well as the object of design. The design object\'s function is the bounding and reshuffling of people, things and their knowledges, as knowledge entities, into new orders and positions. The research further argues that design works to blackbox and obscure these conditions of boundary-making and ordering, by way of representing itself as a methodology ‘naturally’ capable of synthesising these knowledge entities, and in turn implicitly splitting these entities by emphasising them as ‘naturally separate’. The designers’ subject positions are enacted within these human-centred design practices as the bodily mediating of knowledge entities. This representation is anchoring designerly agency in the individual body of the technohuman designer. The technohuman design agent uses the design object to make interventions. I will show the work of intervention in the example of the design of a design process diagram.\r\n\r\nThis conceptual paper calls for the opening up of these designerly interventions, which are currently ascribed to the individual designer. Taking as a starting point a view on design practices as the active reconfiguring of orders and positions, these practices will be explored as an activity of intervention which may be opened up and made accessible for collaboration. Designerly intervention should be turned from an individual technohuman agency into a collaborative activity of innovation.\r\n\r\nThree concepts need to be clarified in order to prepare the stage for the opening up of the ‘design object’ as a tool of reconfiguration:\r\n\r\n(1) Design is often represented as making partial things whole [12]. ‘Knowledge entities’ are the partial elements which are claimed to be reunited in a ‘whole’ in design as a knowledge production. Entities can be ‘intuitive knowing’ and ‘logical knowing’, ‘subjective knowledge’ and ‘objective knowledge’, or ‘individual interests’ and ‘team goals’, and they encompass ascriptions of persons and things, such as ‘artists’ and ‘engineers’, or ‘humans’ and ‘technology’, with these ways of knowing. The ‘human’ and the ‘technology’ are core entities in the constitution of human-centred design.\r\n\r\n(2) The concept of the ‘technohuman’ design agency is ascribed to the individual designer in human-centred innovation. ‘Technological domination’ is understood as a threat against which superheroic designers can help to rebalance ‘humanity’ [4]. By understanding the body and knowledge as separate, it is the designer body who enacts designerly knowing as a form of mediating other knowledges. The practice of empathy, for example, supports the understanding of the designer\'s ability to represent someone else\'s experience. Representations of designers’ abilities inspire the old notion of designer genius by speaking of ‘superior’ capabilities of processing ideas within designer bodies, hidden from view [9, 10]. Designers enact special abilities, which only they are capable of, mediating different knowledge entities. Design ability is understood as special.\r\n\r\n(3) The concept of the ‘innovation games’ is derived from Gherardi\'s ‘production games’ [6], and conceptualises how teams negotiate the rules and conditions of their work. The negotiation feeds from the tension existent in the space of ambiguity, created through the differing views on things. Ambiguity can be used as a resource for design, so that the emerging tension can be translated into an agency to resolve the differences [5]. It is through the opening up of a space of ambiguity that the negotiating of realities – such as the actual taking up of particular subject positions – within innovation work can be initiated. The ‘innovation games’ are the space in which, to use Mol\'s language, multiple realities compete and a dominant reality wins [11].\r\n\r\n2 Human-centred design as individual agency\r\n\r\nDesign is used by the individual designer as a device in the intervention of ordering and positioning knowledge entities within the organisational innovation games. A key activity in this practice of design is the representing of design as a human-centred process for synthesising different knowledge entities, such as logical knowing and intuitive knowing, and subjective and objective knowledges. Particularly through centring the human and through bridging of individual interests and collective goals, design has been successfully positioned as the better alternative to traditional top-down and engineering-led organisational practices [3, 10, 14]. In these representations, knowledge entities are isolated, located, and ordered. A map of accountability is created, assigning responsibilities to particular locations in the map, and its associated people and things. See Figure 1 for the isolation and location of, for example, the ‘Technical Lead’ and the ‘Development’ and the respective ‘matter’ of dealing with ‘Technical Feasibility’.\r\n\r\nDesign process diagram\r\nFigure 1: The UX designer as an individual agent\r\nThe UX (user experience) designer tells me that she seeks to change her organisation from a ‘tech-driven’ into a ‘user-centred’ one. This initiates her drawing of the design process diagram, through which I will analyse the function of design:\r\n\r\n(1) In the diagram, roles and activities are defined, and a location is assigned to each. A location may be described as existent, and as existing ‘before’ or ‘after’ or ‘next to’ another location, describing an order and a hierarchy. ‘After’ is constrained by ‘before’ and is thus hierarchically ‘lower’.\r\n\r\n(2) Designers appear generously in many places. They are represented to reside in almost all locations, and thus are the glue that connects everything in the process. Activities related to ‘the user’, e.g. ‘User Journeys’ or ‘Mental Models’, are in the responsibility of the UX designer. The UX designer allocates activities to the user-related ‘User Experience’ role (herself) throughout the design process aiming for an even and constant distribution of user-centeredness. While all entities are located in particular places, designers are located everywhere. By drawing the diagram, the designer is able to take up a flexible location. She is able “to represent while escaping representation” [7]. Furthermore, through the representing and standing in for the user, the separation between ‘production’ and ‘use’ is reinforced. The user is in fact not able to take up a place in the design process which is taken up already by the designer. The activities around representing the user (‘User Research’, ‘Research Analysis’, ‘User testing’) take up the place of the user, occupying it, and obscuring the actual users’ absence.\r\n\r\n(3) ‘Technology’ is isolated as a ‘thing’ in danger of driving the process. To contain the threat, technology is assigned to the ‘Technical Lead’ and is positioned ‘next to’ ‘User Experience’ at an equal position at the beginning of the design process, in tasks such as ‘Scope Definition’ or ‘User Stories Definition’. It so puts both, designers and engineers, together in the driving seat. In the rear, and more constrained, parts of the design process, the work with the technical user interfaces is associated with ‘Visual design’ and ‘Development’ in equally ‘low’ positions next to each other, with activities such as ‘Style Guide’ and ‘Technical Validation’ respectively. Even within ‘design’, those designers who deal with the tangible part of the design, such as the user interface, are associated with ‘technology’. The UX designer says that activities such as describing the appearance of a user interface should come ‘after’ the other decisions have been made. Technology is so isolated and contained within the design process. It is associated with certain activities which tend to concern the activities in the ‘lower’ and more constrained positions of the ordering process.\r\n\r\nDesign\'s function is here demonstrated as the making of entities (such as the ‘user’ and the ‘technical’), the ordering of entities, the hierarchical positioning of entities (through ‘before’, ‘after’ and ‘next to’), and the attributing of responsibilities to various locations, including to locations which are filled only in representation of the user through the designer. ‘The user’ serves as a useful construct for the attribution of responsibility in design decisions [15, 16]. In this map of accountability, not everyone who appears to be present is present, such as the user. The designer is present everywhere – often in the representation of the user – and therefore actually present nowhere. The use of design as a tool engenders a certain measure of flexible accountability, where the invisibly present (the designers) can shift accountability onto the invisibly absent (the users). The so-called ‘human-centred’ process is therefore relatively flexible in the centring of needs and its accounting for it.\r\n\r\nFurthermore, the UX designer drawing the design process diagram shows how design intervention is anchored in the technohuman design agent, and thus hidden and mystified as existent within the designer body, inaccessibly to a non-designer body. It might be possible to release this agency from its hiding in the technohuman designer and open it up for a collaborative, human-centred form of design action.\r\n\r\n3 Representations of design as interventions\r\n\r\nConceptualising design as the simultaneous splitting and synthesising of the human and the technology, and so intervening in the ordering processes, can open up this designerly agency for a ‘technohuman reconfiguration’ as a way to innovate. I propose to reconceptualise the activity of designerly intervening in innovation work, by turning it from an individualised agency into a collaborative form of engagement with design.\r\n\r\nA key action in the intervention takes place through the representations of design action as bringing together different activities and knowledge entities. This action can be opened up by inviting collaboration in the making, ordering, and hierarchical positioning of entities, and an in the attributing of responsibilities to various locations in concert by everyone present. Presence in the action of representing seems crucial. It entails that everyone who is represented is required to be present in the representing work. Thus, absent users become apparent, and the possibility arises for them to be invited. Designers’ work will be located within the representation, and with this, the flexibility in accounting for design action is eliminated. The map of accountability becomes explicit.\r\n\r\nFigure 2 visualises the proposed collaboration in making design representations. Inviting teams to make collaborative representations as an activity of intervention, makes explicit the practice of configuring boundaries. In the collaborative reconfiguring of boundaries people can have a hand in the representation of their subject positions (‘This is who I am’) and of the activities, they are located with (‘This is what I do’). Opening up the representation as an intervention makes visible the configuring of boundaries. No longer is someone ‘naturally’ who she is, and no longer is someone ‘naturally’ competent in knowing something, or in being hierarchically lower as someone else. The activity of representing makes visible the labour of boundary-making and positioning [2]. Such a reconceptualisation also acknowledges the physical presence of things, such as bodies and technologies, as an effect of boundary-making [1, 13]. Humans, technologies, and technohuman hybrids become visible as made up and negotiated in action. With this visibility comes the possibility of intervening in the making up of things. Innovation would become an undertaking that is accessible, and that can be collaboratively accomplished.\r\n\r\nTeam work\r\nFigure 2: Opening up the representation of design to the team\r\nIn the imaginary of this collaborative design intervention, process diagrams will begin to look different. They might begin to situate design-actions next to use-actions, overcoming the forever-problem of the gap between production and consumption. Design situations will begin to look different. Designers will be alongside others in the distribution of responsibilities, and in the inscription of action. This imaginary is the representation of a possible future, which could tackle participation in design. It assumes that everyone has the capacity to engage in design action and in shaping our existence.\r\n\r\nOpening up design as a collaborative activity of representing who will be doing what, does not only account for presence and absence, it also prevents design from being used for shifting accountability flexibly off invisible agents of innovation. Locations and presences/absences become visible and reconfigurable. Design as an intervention will be open to participation, and change can be collaboratively effected. Design can be made visible as a technohuman reconfiguration – as the synthesising, splitting and reordering of people and things.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nI thank Erik Bohemia and Kerry Harman for supervising me in the conceptualisation of design practices, and for their invaluable feedback on the concept of the ‘technohuman’ design agent, allowing me to clarify it as an idea.\r\n\r\nREFERENCES\r\n\r\nKaren Barad. 1998. Getting Real: Technoscientific Practice and the Materialization of Reality. differences: A Journal of Feminist Cultural Studies 10, 2, 87–126.  \r\nGeoffrey C. Bowker and Susan Leigh Star. 1999. Sorting Things Out: Classification and Its Consequences. The MIT Press, London.  \r\nTim Brown. 2009. Change by design: how design thinking transforms organizations and inspires innovation. HarperCollins Publishers, New York.  \r\nLeah Buley. (2013). The User Experience Team of One: A Research and Design Survival Guide. New York: Rosenfeld Media, New York.  \r\nWilliam Gaver, Jacob Beaver, and Steve Benford. (2003). Ambiguity as a Resource for Design. In Proceedings of the SIGCHI conference on Human factors in computing systems, ACM.  \r\nSilvia Gherardi. 2012. How to conduct a practice-based study: Problems and Methods. Edward Elgar Publishing Limited, Northampton, Massachusetts.  \r\nDonna Haraway. 1988. Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective. Feminist Studies. 14, 3, 575–599.  \r\nDonna Haraway. 1991. A Cyborg Manifesto: Science, Technology, and Socialist-Feminism in the Late twentieth Century In Simians, Cyborgs, and Women: The Reinvention of Nature, Free Association Books, London, 149–181.  \r\nJon Kolko. 2010. Abductive Thinking and Sensemaking: The Drivers of Design Synthesis. Design Issues 26, 1, 15–28.  \r\nRoger L. Martin. 2009. The design of business: Why design thinking is the next competitive advantage. Harvard Business Press, Boston, Massachusetts.  \r\nAnnemarie Mol. 2002. The body multiple: Ontology in medical practice. Duke University Press, Durham, NC.  \r\nRuth Neubauer, Erik Bohemia, and Kerry Harman. (forthcoming). Rethinking Design: From the Methodology of Innovation to the Object of Design. Design Issues.  \r\nLucy Suchman. 2007. Human-Machine Reconfigurations: Plans and Situated Actions. Cambridge University Press, New York.  \r\nRoberto Verganti. 2009. Design-driven innovation: Changing the rules of competition by radically innovating what things mean. Harvard Business Press, Boston, Massachusetts.  \r\nAlex Wilkie. (2010). User Assemblages in Design: An Ethnographic Study. (Ph.D.), Goldsmiths, University of London, London.  \r\nSteve Woolgar. (1991). Configuring the user: the case of usability trials. In J. Law (Ed.), A sociology of monsters: essays on power, technology and domination (pp. 58–100). Routledge, London.  \r\n',1,'Neubauer','Ruth Neubauer','Ruth Neubauer *(Institute for Design Innovation, Loughborough University, London, UK)*',NULL,0,'10.1145/3363384.3363473','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,80,5,NULL,NULL,0,29),(37,'lechelt-how-can-we-balance-research-participation-and-innovation-as-hci-researchers','2019-09-02 15:24:57','2019-11-14 14:14:29','2019-09-02 15:24:57',NULL,1,'published','[]','How Can We Balance Research, Participation and Innovation as HCI Researchers?','This paper reflects upon the growing expectation for HCI research projects to collaborate closely with partners in industry and civil society. Specifically, we suggest that this type of engagement is often prefigured around the agendas, needs and capacity of diverse research partners, which researchers must then carefully negotiate. We explore this by describing a case of a recent large UK research project called Creative Informatics, where our research and co-design activities are heavily influenced by the UK\'s Industrial Strategy. As researchers just beginning to work on this project, we call attention to its initial challenges. By doing so, we invite future-oriented discussion about how existing and new research approaches - ranging from participatory design approaches to reflective frameworks - might evolve to meet the challenges of projects where industrial and social impact is equally important to research impact.','Susan Lechelt, Chris Elsden, Ingi Helgason, Inge Panneels, Michael Smyth, Chris Speed, and Melissa Terras. 2019. How Can We Balance Research, Participation and Innovation as HCI Researchers?. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363394](https://doi.org/10.1145/3363384.3363394 \"DOI for the article \'How Can We Balance Research, Participation and Innovation as HCI Researchers?\'\")','1 INTRODUCTION\r\n\r\nBeyond undertaking research that is carefully ’situated’ [18] or ’in the wild’ [5], contemporary HCI research builds on participatory approaches that reflect diverse voices, needs and critiques of technology development [20], or even explicitly adopt activist stances [10]. In many cases, this desire to work with real people on real world problems, leads HCI researchers to collaborate closely with a great range of research partners in industry and civil society. Partners often provide a link or representation to a specific community, or access to specific technologies and related expertise. In a UK context at least, such collaborations are often explicitly required to secure significant funding from research councils, and it is expected that the knowledge generated by these partnerships will have impact beyond academia1. Perhaps most explicitly, in a UK context, research is increasingly funded as part of a broader economic Industrial Strategy2.\r\n\r\nA more industrial focus may ensure applied research that tackles society\'s ’grand challenges’, but inevitably this also means that research is configured in new ways, to engage a wider range of stakeholders. This shift also presents an opportunity for the voices and political stances of HCI researchers to be more readily heard beyond academia. In this provocation, we briefly explore the future of research and design in HCI that must increasingly negotiate a three-point dilemma between producing high-quality research, ensuring meaningful participation with project partners, and delivering societal innovation and impact through industry engagement. To explore these challenges further, we will reflect on our emerging experience of a new research project where these varied demands come to the fore, and consider briefly how the suite of methods and approaches in HCI research are placed to meet the challenge.\r\n\r\n2 The Creative Informatics Project\r\n\r\nThe Creative Informatics project is a large-scale, 4-year project in Edinburgh, UK, which has been funded by the Arts and Humanities Research Council and other regional deals with the aim of stimulating ’data-driven innovation’ (DDI) [15], throughout the creative industries3 across the region. In effect, the project poses the question: what is a creative industry in a data-driven society? However, what is notable about this project is the extent to which it is driven by both research and industrial goals.\r\n\r\n2.1 From R&D Priorities to Minimum Viable Products\r\n\r\nA priori, the project identified four initial ’R&D priorities’ that DDI is envisaged to support in the context of the creative industries:\r\n\r\nDeveloping access to and engagement with new audiences and markets\r\nDeveloping new modalities of experience\r\nUnlocking the value of archives and data sets\r\nExploring new business models for the creative industries\r\nThese priorities offer an initial scaffolding for the project, and hint at research agendas, as much as business strategies. In purely academic terms, our research aims are potentially much broader and open-ended than this, cutting across a number of disciplines, from design and HCI to digital humanities and innovation studies. Furthermore, the researchers on the project each bring their own research interests; these range from investigating the implications of new financial technologies in the creative economies, to building tools to enable creative practitioners to engage with datasets in new ways, for example to assess the sustainability of their work.\r\n\r\nHowever, these priorities are only seen as a starting point. In a variety of ways our project seeks deep participatory engagement from the creative sector locally to pose their own questions and challenges. Getting this participation right is especially important, because in practice the project will primarily act as a quasi-funding council by administering, supporting and researching the award of hundreds of small grants to individuals and organisations working in the local creative and tech industries. Most strikingly, despite the outlining of R&D priorities, in many cases we expect creatives themselves to outline the ’challenges’ that they hope might be addressed with data. In another scheme, we will offer numerous residency projects for creatives to work on their own ’data-driven projects’. Ultimately, the project\'s key deliverables are not simply academic research outputs, but also encouraging a whole sector of creative practitioners to leverage data and DDI in new ways in their work, and in collaboration with technology partners, to develop ’minimum viable products’ that will lead to new data-driven businesses and sustainable growth in the creative industries.\r\n\r\nAs such, this is an exciting and potentially impactful project, and will allow us, as HCI researchers, to impart our voices and political stances to the broader agenda of DDI; yet at the same time, it presents profound challenges for how we organise and approach our research. We argue that as HCI research increasingly engages with - and in some cases is even led by - the Industrial Strategy, configuring this practice will be of increasing importance, and lies beyond even waves of epistemological and methodological debate [3].\r\n\r\n2.2 Balancing Research, Participation and Innovation in Practice\r\n\r\nIn the remainder of the paper, we first introduce challenges we have encountered so far within our project, and reflect upon how approaches and frameworks in HCI may be required to change, in order to overcome the tensions arising from balancing research, multi-stakeholder participation, and impactful innovation.\r\n\r\n2.2.1 What counts as Data-Driven Innovation? Within our project, a challenge emerges from the way in which DDI is defined and conceptualised. As an industrial strategy, DDI is explicitly concerned with stimulating economic growth through the gathering and application of data across all industries [6, 15]. Within HCI and academia more broadly, there are increasingly critical views about the implications of a data-driven society (e.g. [9, 11, 13, 16, 21]); these range, for example, from the need to ensure privacy and control over personal data [14], to the need to consider that data requires context and becomes situated ’in place’ [19]. Yet again, creative practitioners with whom we will be working themselves have mostly never heard the phrase ’data-driven innovation’ before, and when they do, it is more likely perceived on the very pragmatic terms of how recording, generating or processing data might contribute to their work or practice. Therefore, in our research, we are faced with the challenge of balancing this triad of perspectives, that is: supporting academic, applied research that contributes to new understandings of how people interact in a data-driven society; engaging with and supporting projects that leverage data to forge growth in the creative sector; and supporting creative practitioners in building and diversifying their skillsets in order to innovate on their terms, within their fields.\r\n\r\n2.2.2 Whose research agendas are prioritised? As part of the project, our role as researchers includes steering the creative industries toward innovative R&D questions, rather than those aimed at just boosting their immediate efficiency and output. Questions that meet these goals may include, for example, addressing new modalities of experience within a specific sector (for example using AI in textile making, or creating Internet of Things technologies for festival audiences) or unlocking new value in existing datasets (for example, by using new digitisation methods to make analogue historical artefacts accessible to wider audiences).\r\n\r\nSimultaneously, however, our research should be continually reflective of the real needs of creative industries. Although we need to stimulate new ideas and agendas for the creative industries, we must be careful of predetermining the projects of the creative partners. While we may have clear ideas of academically rich research directions, a participatory approach, and the aim to meet real-world commercial needs means we require considerable work to liaise between envisioned technological opportunities, and the extent to which new technologies can solve real-world problems. In such a large and broad project, this raises questions of how our multiple research agendas can be satisfied, while fulfilling obligations to a diverse community with whom we hope to collaborate?\r\n\r\n2.2.3 Supporting both inclusion and innovation. Genuine and diverse participation is central to our project. This is because we seek to understand the implications of DDI across a whole range of creative industries [8] rather than just those well placed to immediately benefit from it. Further, across the creative industries, there is considerable variance in the knowledge base as regards data and digital technologies. Evidently, organisations who have already made a data-driven turn (for example within the games industry, or advertising) are much more likely to be in a position to immediately engage with and propose innovative research agendas. In many respects, these organisations would make the most natural and exciting research partners who could deliver world-leading innovation; however, we would then potentially exclude other significant partners or industries who have had few opportunities or needs to engage with DDI so far. In short, how can we ensure both inclusivity, and at the same time stimulate genuine innovation in an ultimately technologically-driven project?\r\n\r\n2.2.4 Critical and ethical boundaries to commercial aims? HCI research has frequently positioned itself critically and ethically in relation to the introduction of new technologies. Numerous scholars have recently revealed complex challenges of data-driven anything: most notably, ’surveillance capitalism’ [21] and ’algorithmic inequality’ [9]. In many cases, one might well argue that the economic premises of ’data-driven innovation’ as outlined by the Organisation for Economic Co-operation and Development (OECD) and in subsequent industrial strategy reports [6, 15] promote business models that are in direct contest with these challenges, as well as perhaps our own University\'s ethical guidelines. We see part of our role in this project to help unpack these challenges in the context of the creative industries, and perhaps even to develop alternative modes of data-driven innovation than currently envisaged. Nonetheless, given the industrial imperatives of our project, how do we, as researchers and a delivery team establish not only ethical but critical boundaries and spaces for the project?\r\n\r\n3 CONCLUDING REMARKS\r\n\r\nThis paper has sought to briefly showcase the challenges that can arise when balancing applied HCI research, ensuring meaningful participation with multiple project partners across a sector, and working to deliver commercial innovation together with societal impact. In our case, these challenges include fostering the creative sector\'s digital literacy skills, enabling project partners to define and co-produce novel, data-driven R&D, all the while keeping an eye on inclusivity and the ethical boundaries of DDI.\r\n\r\nEspecially in context of emerging funding body initiatives like the UK Knowledge Excellence Framework, this intermingling of research and broader impact objectives is becoming increasingly common, and is thus not unique to our project. Therefore, we expect that the underlying threads of the challenges we have described may already be familiar to many researchers within HCI. However, although they are central to determining how research agendas and approaches are shaped in these types of projects, the way in which these challenges are addressed and negotiated may not always be explicitly reflected on in research outputs.\r\n\r\nThe many frameworks for configuring participation and person-centred engagement that have emerged from the 2nd and 3rd wave [3] have positioned HCI well as a discipline that continuously adapts to and reflects on the values of people. This is frequently showcased through participatory design [4, 20] and action research (e.g., [1]) approaches. Moreover, a growing community of HCI researchers is now investigating how to explicitly reflect on the social, environmental and economic impact of applied research - for example by appropriating Responsible Innovation frameworks into their research [2, 12], and by adding new value-centred dimensions to existing evaluation frameworks [17].\r\n\r\nHowever, what is still nascent, is work on widening these emerging frameworks to reflect on: 1) how research can best be shaped in light of a sector\'s needs more broadly, that is, beyond a specific organization or community while at the same time; 2) how research (and researchers) can hold their own amidst competing real-world priorities. In our case, for example, this involves understanding how to set and evaluate goals for the envisioned social and cultural value of the project, in addition to a purely economic value. It also means understanding the opportunities and challenges in different types of relations we might form with participants, stakeholders, and ultimately collaborators in our research. As researchers only beginning to explore these issues, we aim this paper to serve as an opening provocation and invitation for discussion from others charting these new terrains.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis work has been funded by the AHRC as part of the Creative Industries Clusters Programme, with support from the Scottish Funding Council and the Edinburgh and South East Scotland City Region Deal. We would also like to thank the Creative Informatics project directors and delivery team for their contributions to this work.\r\n\r\nREFERENCES\r\n\r\nMara Balestrini, Yvonne Rogers, Carolyn Hassan, Javi Creus, Martha King, and Paul Marshall. 2017. A city in common: a framework to orchestrate large-scale citizen engagement around urban issues. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2282–2294.  \r\nOliver Bates, Kathy New, Samantha Mitchell-Finnigan, Matthew Louis Mauriello, Christian Remy, Roy Bendor, Samuel Mann, Simran Chopra, Adrian K. Clear, and Chris Preist. 2019. Towards a Responsible Innovation Agenda for HCI. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, W24.  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 1–8.  \r\nSusanne Bødker and Morten Kyng. 2018. Participatory design that matters—Facing the big issues. ACM Transactions on Computer-Human Interaction (TOCHI) 25, 1(2018), 4.  \r\nAndy Crabtree, Alan Chamberlain, Rebecca E. Grinter, Matt Jones, Tom Rodden, and Yvonne Rogers. 2013. Introduction to the Special Issue of” The Turn to The Wild”.ACM Trans. Comput.-Hum. Interact. 20, 3 (2013), 13–1.  \r\nDepartment for Business, Energy and Industrial Strategy. 2016. Science and innovation audits: wave 1 summary reports.Technical Report. GOV.UK. https://www.gov.uk/government/publications/science-and-innovation-audits-first-wave-reports  \r\nDepartment for Digital Media, Culture and Sport. 2001. Creative Industries Mapping Documents.Technical Report. GOV.UK. https://www.gov.uk/government/publications/creative-industries-mapping-documents-2001  \r\nDepartment for Digital Media, Culture and Sport. 2015. Creative Industries Economic Estimates. Technical Report. GOV.UK. https://www.gov.uk/government/statistics/creative-industries-economic-estimates-january-2015  \r\nVirginia Eubanks. 2018. Automating inequality: How high-tech tools profile, police, and punish the poor. St. Martin\'s Press.  \r\nSarah Fox, Mariam Asad, Katherine Lo, Jill P. Dimond, Lynn S. Dombrowski, and Shaowen Bardzell. 2016. Exploring social justice, design, and HCI. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 3293–3300.  \r\nSarah E. Fox, Kiley Sobel, and Daniela K. Rosner. 2019. Managerial Visions: Stories of Upgrading and Maintaining the Public Restroom with IoT. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 493.  \r\nBarbara Grimpe, Mark Hartswood, and Marina Jirotka. 2014. Towards a closer dialogue between policy and practice: responsible design in HCI. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2965–2974.  \r\nAndrew Iliadis and Federica Russo. 2016. Critical data studies: An introduction. Big Data & Society 3, 2 (2016), 2053951716674238.  \r\nRichard Mortier, Jianxin Zhao, Jon Crowcroft, Liang Wang, Qi Li, Hamed Haddadi, Yousef Amar, Andy Crabtree, James Colley, and Tom Lodge. 2016. Personal data management with the databox: What\'s inside the box?. In Proceedings of the 2016 ACM Workshop on Cloud-Assisted Networking. ACM, 49–54.  \r\nOECD. 2013. Exploring Data-Driven Innovation as a New Source of Growth: Mapping the Policy Issues Raised by ”Big Data”. https://www.oecd-ilibrary.org/science-and-technology/exploring-data-driven-innovation-as-a-new-source-of-growth_5k47zw3fcp43-en  \r\nKathleen H. Pine and Max Liboiron. 2015. The politics of measurement and action. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. ACM, 3147–3156.  \r\nChristian Remy, Oliver Bates, Alan Dix, Vanessa Thomas, Mike Hazas, Adrian Friday, and Elaine M. Huang. 2018. Evaluation beyond usability: Validating sustainable HCI research. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 216.  \r\nLucy A. Suchman. 1987. Plans and situated actions: The problem of human-machine communication. Cambridge university press.  \r\nAlex S. Taylor, Siân Lindley, Tim Regan, David Sweeney, Vasillis Vlachokyriakos, Lillie Grainger, and Jessica Lingel. 2015. Data-in-place: Thinking through the relations between data and community. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems. ACM, 2863–2872.  \r\nJohn Vines, Rachel Clarke, Peter Wright, John McCarthy, and Patrick Olivier. 2013. Configuring participation: on how we involve people in design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 429–438.  \r\nShoshana Zuboff. 2015. Big other: surveillance capitalism and the prospects of an information civilization. Journal of Information Technology 30, 1 (2015), 75–89.  \r\nFOOTNOTE\r\n\r\n⁎Both authors contributed equally to this research.\r\n\r\n1 https://re.ukri.org/knowledge-exchange/knowledge-exchange-framework\r\n\r\n2 https://www.gov.uk/government/publications/industrial-strategy-the-grand-challenges\r\n\r\n3The creative industries have been defined by the UK government\'s Department for Digital, Culture, Media & Sport as ”those industries which have their origin in individual creativity, skill and talent and which have a potential for wealth and job creation through the generation and exploitation of intellectual property.” Specifically, these include: advertising, architecture, the art and antiques market, crafts, design, designer fashion, film and video, interactive leisure and software, music, the performing arts, publishing, software and computer services, television and radio [7]',1,'Lechelt','Susan Lechelt, Chris Elsden, Ingi Helgason, Inge Panneels, Michael Smyth, Chris Speed, and Melissa Terras','Susan Lechelt *(Design Informatics, University of Edinburgh, UK)*<br>\r\nChris Elsden *(Design Informatics, University of Edinburgh, UK)*<br>\r\nIngi Helgason *(Centre for Interaction Design, Edinburgh Napier University, UK)*<br>\r\nInge Panneels *(Centre for Interaction Design, Edinburgh Napier University, UK)*<br>\r\nMichael Smyth *(Centre for Interaction Design, Edinburgh Napier University, UK)*<br>\r\nChris Speed *(Design Informatics, University of Edinburgh, UK)*<br>\r\nMelissa Terras *(Digital Cultural Heritage, University of Edinburgh, UK)*',NULL,0,'10.1145/3363384.3363394','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,75,5,NULL,NULL,0,10),(38,'stahl-a-successful-failure-or-a-failed-success','2019-09-02 15:24:57','2019-11-14 16:09:39','2019-09-02 15:24:57',NULL,1,'published','[]','A Successful Failure or a Failed Success?','We reflect back on a previous paper writing process, where we initially set out to share experiences of forest walks and discuss how these were part of a design process for an application around sustainable grocery shopping. We describe our inability in finding a working way of articulating the experiences and the design process led us into route of unintended rationalization and systematization. Instead of strengthening our arguments and articulation of the value in our forest walks, we step by step rationalized our design decisions by tying them to discrete occurrences in the forest, shaping a paper that fitted the traditional form of HCI research. In this paper we reflect on this process and how our original intentions could be reached. Finally, we reason around the value of these forms of purposeless experiences in relation to design, and how there could be space for these types of contributions in HCI.','Anna Ståhl and Jakob Tholander. 2019. A Successful Failure or a Failed Success?. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 9 pages. [https://doi.org/10.1145/3363384.3363391](https://doi.org/10.1145/3363384.3363391 \"DOI for the article \'A Successful Failure or a Failed Success?\'\")','1 INTRODUCTION\r\n\r\nA couple of years ago we conducted a sustainability-oriented design project where a key activity in our design process was to conduct regular walks in a local forest over the various seasons of a year. The design was to a large extent, but in a fairly loose and open-ended fashion, based on our experiences of the forest from those walks. In those experiences we often emphasised things like the atmosphere of merely being in the forest, the occasional stopping to examine a piece of rotten wood or the moss on a rock, taking pictures of random things, such as trees, trails, snow, ice, mosses, leaves, mushrooms, or whatever we happened to encounter that caught our attention. The project resulted in the design of a mobile app for sustainable grocery shopping, and eventually also a number of papers [13, 14, 15, 16, 17]. One of the papers [14] was initially written to share the way our experiences of merely being in the forest influenced us and somehow also the design that we finally ended up in. We have to admit that the initial version of this was not a particularly good paper, as it had turned out to be very challenging to try to capture and share our experiences together with our design process in a form that our reviewers would find to be a valuable contribution to the CHI-community. While we largely agreed on much of the criticism we got, the process of rewriting this paper threw us into process of rewriting it that after yet another couple of more rejects ended up in paper that was accepted and positively received by reviewers as well by the conference attendees. So the story could have ended here and we should be content with the outcome: Paper accepted and reviewers satisfied through a process that the CHI-community (and the scientific community overall) sees as one of the cornerstones of how we produce reliable knowledge - peer review at its best. However, a friction remained inside us, the paper we ended up with was far from the one we had set out to write. It was a classic example of a paper that represent much of an HCI-tradition that the field lately has tried to move away from [4], that of turning interaction design into a instrumentalized process capturing creativity and design into neatly packaged step by step courses of action. A process where every design decision can be back-tracked in a well identified and articulated line of decisions feeding into each other, and in which the idea of open-mindly exploring a design space [18] is not embraced. Even more so, we are quite convinced that most of our reviewers would also agree on the value of moving away from such a simplistic view of interaction design. What we have been asking ourselves is why we allowed ourselves to get caught in the CHI-community peer review mangle, which serves the quite productive purpose of shaping papers, such as ours, into a seemingly useful and instrumentalized form, rather than trying to sharpen our arguments and discussion points in order to share what we had actually found valuable in our design process, and potentially for other designers as well? We would like to see this largely as difficulties on our side in dealing with the form of critique that the review process represents. In retrospect, the feedback we received was highly meaningful and helped us reconsider the way we had shaped our findings, leading us to formulate them in a more structured and possibly useful way. However, in the end, this process of reconsideration made us lose ourselves and the values that we wanted to portray, in favour of a systematisation of the experiences that lie at the core of our work, or even to devise a neatly describe framework for someone else to bring into their own design project. We are convinced that the path that our paper was led into is not the only way to communicate our experiences and share our design process with fellow researchers. In the following reflection piece, we will make an attempt at bringing up and discuss some other ways of doing this in the future.\r\n\r\n2 RELATED STUFF\r\n\r\nThe third wave HCI has taught us to open up for new and diverse ways of approaching HCI and interaction design [4], allowing us to expand the boundaries for what is considered as research in our field, and to widen the scope for capturing rigour in research. This expanded view of what we should count as research has for several years now been discussed from a range of different perspectives [8, 10, 19]. For instance, Dourish [7], early on questioned the obsession in the field that all kinds of empirical people-oriented research has to end with well-formed implications for design [7]. Further, DiSalvo et al. [6] raised similar arguments around research on sustainability and persuasiveness. Successful examples of how to allow for more diverse ways of empirically grounding interaction design has been provided by, for example, [9, 10, 12]. Several conferences has also introduced pictorials as a publications format that allow for a more diverse set of values to come forth in how we report our research. This has proven particularly valuable for illustrations of design processes. In line with this work, we would like to share our own story of how we have experienced the challenges (and in the end failure) in moving away from instrumentalized forms of portraying interaction design research. There are several examples of HCI research that have successfully reported on processes of design and creativity without squeezing the results into one-directional implications for design, guidelines, or principles - instead capturing and telling stories of how values of partially goal-less and ill-defined experiences could also be considered meaningful in our research endeavours. Our aim here is not set to conduct thorough literature overview of how this could or should work. Instead we have picked three examples [1, 3, 5], that we find provide a background that is in line with what we would have liked to achieve with our original paper. First and foremost, these articles appealed to us in the way they were written. They all capture different aspects of addressing the challenges we have also faced, either in the way they question the outcome, their style of writing or in the actual format used. The recent work by Devendorf et al. [5] deliberately set out to create what they call a non-contribution for and within HCI, in order to challenge the boundaries of what counts as research by engaging in a practice that would not meet the traditional metrics most commonly used to judge what is considered to be a research contribution in HCI. They suggest their research activities to be labelled as para-research and the intention is that it should work alongside dominant research practices and eventually contribute to reform HCI to become more divers to include a variety of ways of doing and portraying research. In their work on para-research they attempt to circumvent, what they call the “problematics of progressivist narratives“ [5], and aim to open for a co-existence of various forms of knowledge in HCI, to also include the mundane and inconsequential, and not only the logical and rational. Devendorff et al. base their work on parallels to art history. By making so called HCI-amusements, they suggest practices which are often characterised by being personal and subjective to also be impactful in research, if we manage to sidestep questions of evaluation, analysis, and contribution, forwarding values other than the measurable. A related example of research along these lines is Akama et al.’s essay on traces of a middleway [3] that intends to capture the involved researchers’ sharing of “merely being” or mindful moments. The essay deals with the notion of mindfulness, and how it can be represented to trigger resonances and evoke mindfulness with readers. They have chosen a documentary format using photos, videos and written vignettes representing their mindful, creative practices (video, photography and gardening). In their writing they manage to evoke a frame of mind that in a poetic way transfers the reader to the authors’ own mindful places. At the same time they question the form that conference papers are commonly forced to take on, and instead suggest other ways to allow for sharing these formless states of being, while still allowing for discussing their relevance for design. In other words, the publication formats may have to develop in order to capture the sharing of knowledge from design practices that go outside of positivist traditions. Although the authors speak about mindfulness, there are aspects that cover how to articulate and transfer these open-ended creative experiences into design that carry values outside of this specific area. They struggle with tensions in representing intangible facets of being and the inherent simplification in using words and images as representations of the meaning of an experience. They conclude that planning and rationalisation might not have been a better route, rather, rigour exists in honesty and conviction.\r\n\r\nThe final inspirational paper is by about attuning to ”Ma”, a japanese philosophical expression meaning betweenness [1]. Ma refers to the things that happens in-between and are therefore difficult to consciously be aware of or grasp. In her paper, Akama discusses the importance of attuning to Ma, this in-betweeness is rarely considered in design, since we are mostly occupied with categorizations of the things, people and context we design for, the sort of elements that are consciously in focus, while Ma is about attending to things that are left out [1]. To make a comparison to sketching or painting, it is about a shift in focus - to the areas in between objects or bodies that contain a lot of value and often take away our preconceptions of how things should appear. Ma brings more than a shift of perspective, it is a way of sensing the relational, processual and atmospheric. Ma is about not separating, but try to direct our attention to the whole and what that can possibly be, taking us beyond pre-defined boundaries: ”Why do we separate when there is richness that occurs across, in-between and beyond it? And what will it mean if betweenness, and not individual subjects, is the ground for being and ‘becoming with’?” (p.24 [1]) To design or write attuning to Ma would mean trying to evoke a betweenness with the user or reader, deliberately shaping and working with tonality, pauses, rhythms.\r\n\r\nSo what is it in these papers that is compelling to us in the story we would have liked to tell about our forest experiences? We see some common traits of values within these papers, such as: openness, richness, holistics, creativity, imagination, non-linearity, and potential. The challenge is however not simply in finding the values, but how to convey them, and in some way relate them to the system we ended up designing. The real challenge for us as authors is to develop a way of presenting our research that works for these different perspectives. As HCI-researchers we are trained in writing research publications in a style developed to capture values of a more objective, formalized and analytic manner than that of Ma for instance. As authors, we know how to write a paper describing the design of an interactive system or analysing outcomes of a user study, but we are much less trained in accounting for experiences of this kind. Further, in these papers reports on end solutions are rare.\r\n\r\n3 THE WRITING AND REVIEW PROCESS\r\n\r\nFrom reflecting on the above, we decided to backtrack on earlier versions of our paper and the reviews we had received in order to try to understand why we ended up where we did, trying to make sense of where, when and how we could have acted differently. At the core of this was the question of how we could have written our paper in a way that would allow us to combine the two types of outcomes that comprises our work: both evoking the richness of our shared forest experience and the role it played in our research, and in the same text portray this in a process of design aiming towards a technology solution.\r\n\r\nIn looking at our initial attempts in writing this story, we found that we were struggling with moving outside the form of writing a research paper that we are used to. We became aware of how our attempts at evoking the central aspects of our forest experiences to our readers, searching for a relevant body of work to relate to - while at the same time formulating it as a design approach and an end solution - often became contradictory. From reading our notes and reflecting over our discussions there was a lot of frustration on “ what is this thing that we are trying to describe”: Is it about the forest itself and things we saw and felt, or was it more about abstract aspects such as the specific materialities and temporalities of the forest? What was the relation between certain experiences in the forest and our design attempts? Was it about bringing certain dynamics of what we experienced into our design sketches? Was it how we concretely used aspects of our experiences to design for a sense of the interface coming alive to the users? Or was it on a more general level about how we practically used these experiences to sketch a specific kind of technology-based solution? What we repeatedly attempted to do was to create ties between these things, ties that we now have realised became artificial and overly rational. We tried to describe clear and concrete influences from our experiences in the technology by turning them into well-packaged descriptions, rather than keeping outcomes from the two domains as separate and distanced. This became a process of rationalisation even though this was far from what we had initially intended.\r\n\r\nLet us try to exemplify this using some excerpts from early versions of our paper together with excerpts from the feedback and advice from our reviewers. In one of the first versions of our writing, a comment in the margin to the design process states:\r\n\r\n”Numerous studies suggest that design processes are not linear, but multi-grounded, iterative, and non-deductive. So we cannot expect predictive and generative results by applying a certain approach to design. But very few examples illustrate what it means to stay with this claim throughout a design process, illustrating to others how to keep the openness throughout the design process. We attempted this without ambitions of repeatedly thinking and going back to questions, solutions and end-goals, but by recurrently walking and being in the forest, bringing our design challenges along with us. The experiences of being forest is not about certain thing s or phenomena of the forest, but merely about being there, keeping our senses open, having our design by our side. Not forcing solutions or ideas upon ourselves.”\r\nHowever, the ambitions of how we wanted to portray our design process did not come through in our actual paper. In the same version of the paper, we seemed to almost desperately try to make sense of our experiences by claiming that there was a well-identifiable mapping between events in the forest and our design. By analysing photos from the forest together with notes from our experience we attempted to formulate a design quality that we coined “aliveness”. In our writing we provided an anecdote supposed to outline the character of aliveness:\r\n\r\n”Aliveness Anecdote, Forest walk November 19th 2014 We are back in the outskirts of Stockholm. The landscape we move through has changed from autumn to early winter. Grey compact clouds overhead make the forest space seem narrower. Damp clouds filter the light, softening and smoothing air to make the form of things less distinct. The ground is covered in a thin layer of snow. A fresh smell of moist snow and ice is carried by the heavy air. It is above freezing, but the humid air still carries the cold through your layers right into your bones. Everything in the forest seems to be moving downwards as saturated snow falls in lumps from the trees. The soundscape feels muted, like the acoustics only allow for noise really close by to reach our ears. The snow and ice are changing with the surroundings, telling us if there is water or rock underneath our feet, telling us about changes in temperature and precipitation. On a small trail, we hear a squelching sound when the soles of our boots meet the snow. Suddenly the sound changes to a crisp cracking. We have left the trail and the ground is covered by a layer of thin ice. Grass and pine needles can be glimpsed through peek holes. We bring our impressions back to the design studio through photographs.”\r\nIn what followed, we tried to show how we made use of these experiences in our design. While this might give one potential perspective on the way the design process unfolded, the deconstruction of the experience that we make below was far from the most valuable aspect for our design process. What was critical to our design was the actual experience as such, an experience that was largely made away with through our ongoing efforts of trying to squeeze it into the rigid structure of a research paper:\r\n\r\n”When reflecting back on the forest walk through annotating the printed photos, we saw how snow and ice had an effect similar to a filter. It changed the shape of the surface layer, from being fragmented and uneven covered by needles, small rocks and plants, to a smoothly covered surface with soft billowing shapes. The ice on a mound made the deposition from the soil appear as a brown pattern, this did not appear before it was frozen. This filter-like appearance allowed for objects to shift looks [...] In our design efforts we connected the thoughts from that day\'s forest walk to the problem we were facing and started reflecting on how snow and ice could change the appearance (colours, smells, textures, shapes, rhythms and sounds) of the very same object, as if a filter was applied. This idea we took further to consider how we could manipulate the appearance of fruits and vegetables that we were thinking of using in the system we were designing.”\r\nOur intention with the anecdotes in our paper was at least twofold. First, to give a sense of how experiences such as our forest walks played an important part in designing our system, both to illustrate alternative routes for doing design, potentially serving as an inspiration for other designers. Second, while trying to achieve the above we also tried to provide a structured and systematic description of how this impacted graphical and interactive elements of our design, primarily through two themes; temporality and openness for interpretation. In retrospect, there is a contradiction here that might seem obvious, but for our reviewers it must have seemed as confusing as it was to us. They repeatedly advised us to go in a direction of writing in a format we are most familiar with, creating systematic links between various design exercises (such as a forest walk) and the sketches and design ideas that followed from these. What we did not fully realise then, was that this was not what we actually wanted to achieve. The anecdotes were not about links between experiences and design elements. Thus, the way our attempts were described became unfamiliar to ourselves and difficult to grasp for our reviewers. They could not make sense of the value that our descriptions brought to the field of HCI, and we certainly did not manage to show it clearly enough. What we were constantly faced with from the reviewers was the question of what the actual takeaway of our paper was:\r\n\r\n”I am not sure if this is possible, but could the authors maybe present a list of clear recommendations for designers that want to follow a similar process?” (review)\r\nOur intentions of taking “inspiration” from experiences of nature in design and at the same time concretely describe how these could be tied to our design, became a hole that we dug ourselves deeper and deeper into:\r\n\r\n“Why do the top five products have a pink border? How does this relate to the forest?” (review)\r\nOur attempt to meet the expectations of our reviewers led to a systematisation of how we conducted our walks, how we looked at things, how we documented, and described things that were correct, but this was far from how we wanted them to be seen. Of course, there were examples of feedback in the reviews that we got that expressed appreciation of our attempts of trying to describe the value of our experiences in the forest. But instead of embracing and clarifying the contradictions that we constantly faced in trying to describe this, we began to tone down the parts in our writing that we did not manage to communicate the value of to our reviewers. This led us into a process where the irrational, purposeless and non-methodical elements of our anecdotes and reflections gradually disappeared, despite being the things that turned our experiences into what they actually were. We continued the rationalizations and abstractions in our writing, deconstructing the experiences and relevance for design into something tangible and potentially easier to grasp. For instance, we developed three detailed examples to describe processes of material transformation in the forest:\r\n\r\n“The analytical work of understanding transformational processes of elements in the forest from the point of view of materiality and material interaction and putting them in relation to design practice, ended up in three different aspects of experiencing transformations and change: - Experiencing temporalities of change in the forest (melting, decay, freezing, perennial processes) (see Figure 1) - Experiencing relations within a material (structuring and layering of leaves, decay of leaves, melting, freezing) - Experiencing rhythms of change (perennial cycles, intensities of freezing and melting)”\r\n\r\nFigure 1: Representation of the transformation process of snow and ice like a filter.\r\nCertainly, several aspects in the way we described our attempts at taking our experiences and mapping them to our designs were in many ways true. But still, the analytical process that we went through removed the core of what we were trying to portray. The more we rationalized, analysed and tried to justify the value of our forest experiences, the more the reviewers seemed to ask for traditional forms of proof for our argumentation:\r\n\r\n“A detailed discussion is provided of practical aspects of design elements, but there is no discussion of how these elements are experienced in use. Do they enhance user experience, or inhibit / slow down what may otherwise be an automatic process for some (using an app to more effectively choose fruit and vegetables)?” (review)\r\nThese are clearly relevant and useful comments from our reviewers. However, by considering them more broadly, it becomes clear to us that they pushed us in a direction that we ourselves had not intended, and that we were not able to deal with them in a proper way in our writing. So, at this point, this paper had turned into one of these long-running papers with three or four rounds of reject, papers that you as an author have invested a substantial amount of time and energy in, but it never seems to pay-off. We had lost track of our initial aim, worn out by borderline rejects and just wanted closure (i.e. accept).\r\n\r\nAt this stage it was almost impossible for us to take a step back and evaluate the process, we became blind to the flaws that really mattered. We started running for every ball that the reviewers threw at us. We decided to ask for help from our colleagues, but the paper was already way into the systematized design process track, so the feedback we got only confirmed what the reviewers had already told us. Instead of sharing the richness of how an experience of the forest could play a part in a design process, evoking some kind of betweenness (Ma) with the reader, we deconstructed our design process into scattered bits and pieces. In the end, we managed to glue it all back together in a conceptualisation with neatly articulated links between different aspects of designing with experiences from the forest. In the last and now published version of the paper, we presented three abstracted interrelated kinds of activities for other designers to use when attempting to link nature or similar spaces into their design processes. The three activities were about ways of being in nature, the importance of bringing materials and processes of nature back to the lab, and creative ways of bridging nature and interaction design practices.\r\n\r\nThe conceptualisation was described in the form of a nice little map linking the different activities and qualities of being in the forest (see Figure 2), perfectly applicable for others who wish to engage in similar forms of design. Good enough! Paper accepted, and potentially useful for other researchers and practitioners in our field. But far from telling the story that we had initially wanted. One of the reviews nicely captured this rationalization:\r\n\r\n“The descriptions of design activities are already in themselves illuminating and stimulating and the higher level reflections (i.e. the categorization) bring in additional rigour to the argumentation.” (review)\r\n\r\nFigure 2: A map of how activities from the forest are linked to design.\r\n4 TWO ANECDOTES FROM THE FOREST\r\n\r\nIn hindsight we cannot stop ourselves from asking what we should do if we had the chance to redo this? By coincidence, when we started to write this reflection piece, it turned out that much of our conversations evolved from reflections that happened when jogging, running or cross-country skiing in our local forests. Even though running the risk of making the same mistake again, we therefore attempted to yet again try to capture some of the richness and the betweenness (an in-betweenness, Ma) of these jogs and runs and evoke these to the readers of this paper. But this time, not putting them into the process that we did the last. Instead, we have decided to just leave them be.\r\n\r\nThe form grew out of a common interest in exercising either by skiing, trail running or orienteering. Common to these activities were the importance that they took place in a forest, both of us experienced a clear difference compared to movement in other environments. We shared a common in-betweenness in these activities, and this had grown out of being close colleagues and from endless discussions of writing the previous paper. The authors were also inspired by the research in the related work section of this paper [2, 3]. In the anecdotes shared here, we tried to embrace the experienced sensory atmosphere and maintain the purposelessness. Where, how long or in which order things happened is of less importance. Neither do we intend to make couplings to a design or in this case our writing efforts.\r\n\r\n\r\nFigure 3: Unblurred text for readability: There is a startup distance in my running, where I am very aware of the exercise and that is hard, I slowly transition into the forest experience, gradually the scents come to me, the scent of slightly wet pines on the ground, a particular scent. There has been a slight rain earlier this evening. I feel the wind blowing on my skin, I like the touch of the wind, coming and going, cooling me down. The air is humid and filled with oxygen making it easy to breathe. There is something with the uneven ground, to be fully surrounded by the vegetation walls of saturated early summer light green, the scents, the wind. I stop noticing details of the forest, it becomes blurred, my vision gets blurred and other senses take over, the smells are forwarded. My feet become sensitive, I am not only using my eyes to avoid tripping, my feet work like antennas over the uneven ground. The soundscape of the forest contribute to the orchestration, the birds singing, the wind in the trees, the squeaking sound of a dead tree in the wind. Scents come to me, nuances of the same scent as before or a completely new one, the scent of wild flowers on a meadow permeating the air. Every thought has stopped whirling around in my head or I don\'t care anymore, I feel like I have had a refill. The forest makes out a breathing space, where I can find my own freedom, my own world of thoughts, where I can let my mind wander, my own world. That I don\'t have to articulate, just let it be. No constraints, the connections of thoughts that happen, simply happens. It is the same, but totally different every time. I cannot achieve or imagine this elsewhere but in the forest.\r\n\r\n\r\nFigure 5: Expression of Jakob\'s experience.\r\n5 FINAL WORDS\r\n\r\nAt the bottom of all this lies the question concerning how (or if) experiences from walking or running in the forest, and technology design can be meaningfully combined in research like this. In this piece of reflection, we have not attempted to provide answers to this in any systematic fashion. We have merely tried to bring some reflections to the table that - at least - helped ourselves to understand this better. Throughout this process we have become convinced that we have to dare, in Haraway\'s words, “stay with the trouble” [11], and for us this has been exactly what the process of deconstruction and linking of experience to concrete solutions did not help us with. Instead, it engaged us in a process that did away with many of the things that were found to be most meaningful, simply because we constantly choose to focus on those things that were within easy reach for making them understandable. The question we see then, is if there is a way that we should go in order to let experiences such as these play a more central role in the portrayal of our research, but without having to squeeze them into a form that in the end removes much of what made them meaningful to start with. In considering anecdotes such as these, is there an actual value in them also for others doing design and research in our area? We believe there must be. Experiences like those above played a central role in the process of reflecting and writing this text and in the process of designing a system such as the one discussed in this paper. Sometimes we talked about something we saw, something we felt or an idea that came up. And most often they connected to what we were working on or writing. They helped us think about the purposeless, but highly meaningful character of the forest walks we conducted when doing our design. They lacked a well-formulated structure to the process, had no clear systematicity to be described in logical steps. Still though, we would be bold enough to claim that it is at occasions such as those describe above, that the really important work goes on. It might seem contradictory - maybe as an non-contribution - to on one hand try to evoke richness in a forest experience, while later in the same text describe an application for sustainable grocery shopping, as we had done in our paper, but without making any explicit connections. Our shared forest experiences definitely influenced how the design of the application evolved. But when writing about it we were not able to combine the two. Instead, we ended up reducing our experience in the forest into what could be taken as concrete mappings between elements and processes of nature and our design. These were not irrelevant or uninteresting, but they were far from the core of what we wanted to portray. Seemingly, this combination of rich, open-ended goalless-ness together with the well organised solution of our system was both confusing to us, and consequently, to our reviewers. To end, we would like emphasise that we do not claim that it is wrong to try to systematize design processes in the fashion that we did in our paper. To us, it became a first step in trying to show how the work that we did actually unfolded. We used the tools we had at hand, and ordering things is one of the strongest that we have. But we claim that we also need new ones, tools that help us analyse and portray design processes, such as these, from other points of view. For us, it became quite clear that the tools we had at hand did not help us go in the right direction (apart from finally getting a paper published and a reason to reflect on why it was the wrong paper to write). Perhaps, we should try the opposite next time? Just let accounts of our design experiences be as they are. Not forcing any mappings or logical coupling between them and the challenges that we work with. Simply see where we end up? Or perhaps we should not even consider attempting to write about them in the context of research. Just leave it be?\r\n\r\nREFERENCES\r\n\r\nYoko Akama. 2014. Attuning to Ma (between-ness) in designing. In Proceedings of the 13th Participatory Design Conference: Short Papers, Industry Cases, Workshop Descriptions, Doctoral Consortium papers, and Keynote abstracts-Volume 2. ACM, 21–24.  \r\nYoko Akama and Ann Light. 2015. Towards mindfulness: between a detour and a portal. In Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 625–637.  \r\nYoko Akama, Ann Light, and Simon Bowen. 2017. Mindfulness and technology: traces of a middle way. In Proceedings of the 2017 Conference on Designing Interactive Systems. ACM, 345–355.  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 1–8.  \r\nLaura Devendorf, Kristina Andersen, Daniela K Rosner, Ron Wakkary, and James Pierce. 2019. From HCI to HCI-Amusement: Strategies for Engaging what New Technology Makes Old. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 35.  \r\nCarl DiSalvo, Phoebe Sengers, and Hrönn Brynjarsdóttir. 2010. Mapping the landscape of sustainable HCI. In Proceedings of the SIGCHI conference on human factors in computing systems. ACM, 1975–1984.  \r\nPaul Dourish. 2006. Implications for design. In Proceedings of the SIGCHI conference on Human Factors in computing systems. ACM, 541–550.  \r\nAnthony Dunne and Fiona Raby. 2013. Speculative everything: design, fiction, and social dreaming. MIT press.  \r\nBill Gaver and John Bowers. 2012. Annotated portfolios.interactions 19, 4 (2012), 40–49.  \r\nWilliam Gaver. 2012. What should we expect from research through design?. In Proceedings of the SIGCHI conference on human factors in computing systems. ACM, 937–946.  \r\nDonna J Haraway. 2016. Staying with the trouble: Making kin in the Chthulucene. Duke University Press. \r\nJonas Löwgren. 2013. Annotated portfolios and other forms of intermediate-level knowledge.Interactions 20, 1 (2013), 30–34.  \r\nMaria Normark and Jakob Tholander. 2014. Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 271–280.  \r\nAnna Ståhl, Jakob Tholander, Jarmo Laaksolahti, and Elsa Kosmack Vaara. 2017. Being, Bringing and Bridging: Three Aspects of Sketching with Nature.. In Conference on Designing Interactive Systems. 1309–1320.  \r\nJakob Tholander and Mattias Jacobsson. 2013. Ecofriends: designing for critical reflection using social voices.interactions 20, 1 (2013), 58–62.  \r\nJakob Tholander, Anna Ståhl, Mattias Jacobsson, Lisen Schultz, Sara Borgström, Maria Normark, and Elsa Kosmack-Vaara. 2012. But i don\'t trust my friends: ecofriends–an application for reflective grocery shopping. In Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services. ACM, 143–146.  \r\nElsa Kosmack Vaara, Anna Ståhl, Sara Borgström, and Jakob Tholander. 2012. Ecofriends, reflection with technology. In Proceedings of CHI, Vol. 12. 5–10.  \r\nBo Westerlund. 2009. Design Space Exploration: co-operative creation of proposals for desired interactions with future artefacts. Ph.D. Dissertation.  \r\nJohn Zimmerman, Jodi Forlizzi, and Shelley Evenson. 2007. Research through design as a method for interaction design research in HCI. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 493–502. ',1,'Stahl','Anna Ståhl and Jakob Tholander','Anna Ståhl *(RISE Research Institutes of Sweden, Sweden)*<br>\r\nJakob Tholander *(Stockholm University, Sweden)*',NULL,0,'10.1145/3363384.3363391','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,45,10,NULL,NULL,0,7),(39,'comber-towards-post-interaction-computing-addressing-immediacy-unintentionality-instability-and-interaction-effects','2019-09-02 15:24:57','2019-11-14 14:14:42','2019-09-02 15:24:57',NULL,1,'published','[]','Towards Post-Interaction Computing: Addressing Immediacy, (un)Intentionality, Instability and Interaction Effects','The changes that have come about through the increased speed, ubiquity, and scale of computational systems require a reconceptualisation of how we think about and study the relationship between humans and computers. Driven by the increased production of data in interaction and the transfer of value from interaction to data, we argue that computing that fundamentally impacts human-computer relations is no longer happening only in interaction but also without and outside interaction. While recent arguments have highlighted interaction as a problematic concept for HCI — challenging what constitute users, use, the human, and the computer in interaction — we propose post-interaction computing as one means to conceptualise a fourth wave of HCI. We propose four concepts — immediacy, (un)intentionality, interaction effects, and instability — that can help us in identifying and slicing our objects of analysis in new ways that better match the challenges that HCI is now faced with.','Rob Comber, Airi Lampinen, and Jesse Haapoja. 2019. Towards Post-Interaction Computing: Addressing Immediacy, (un)Intentionality, Instability and Interaction Effects. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 8 pages. [https://doi.org/10.1145/3363384.3363477](https://doi.org/10.1145/3363384.3363477 \"DOI for the article \'Towards Post-Interaction Computing: Addressing Immediacy, (un)Intentionality, Instability and Interaction Effects\'\")','1 INTRODUCTION\r\n\r\nWhile the ‘third wave’ of Human-Computer Interaction echoed changes in how and where people interacted with computers, it was also reflective of an underlying shift in what and how computers helped us to know, and conversely, through approaches such as affective and experiential design, how we should conceive of computing [11]. As much as the third wave was defined by the shift of computing into the spheres of the home, leisure, and arts, it was transformed through the epistemologies of phenomenology and the ontological realm of, inter alia, emotions, values, identity, and culture. To us, what defines the shift from one wave to the next, then, is a change in how we can think about what computing technologies are, rather than a shift in domains of study.\r\n\r\nOver the past years, a number of researchers have begun to articulate and address an apparent crisis of Human-Computer Interaction, through the guise of one of the founding concepts in the field — ‘interaction’ [55, 65, 68]. At stake has been the ability of HCI to generate knowledge, through a shared understanding of interaction and through a limited scoping of ‘interaction’ precluding consideration of its impacts. We continue this conversation and suggest that this crisis of interaction is indicative of the presence of a ‘fourth wave’ in HCI. We argue that this ‘wave’ can be characterised by any number of shifts in how we interact with computers — the scale, speed, and ubiquity of computing, alongside its seeming increasing visibility in public life and invisibility in our daily lives — but that the most significant shift is one we don\'t observe or interact with directly. Where the third wave moved computing into the forefront of our lives, this fourth wave has set those third wave interactions as only one part of the complex computational landscape of current human-computer interaction. That is, while the third wave sought to design computing systems for interaction, the fourth wave is more concerned with designing interaction for and with computing — data mining, analytics, advertising, and so on. The computational aggregation of human-computer interactions in the fourth wave has an increased focus on not only the implications of interaction for individuals, but the political and social justice implications of HCI on a broader level.\r\n\r\nIn this paper, we characterise the fourth wave as Post-Interaction Computing. In what follows, we define what we understand as the necessity of a post-interaction framing of HCI, what constitutes such a framing, and how we might take this approach. While many new topics, technologies and application areas define contemporary HCI, we believe that the fourth wave is defined by a change in the epistemological and ontological tools necessary to understand how we are interacting with computers, more or less directly, sometimes to the point where interaction risks failing to make sense as the organising concept. Akin to Susanne Bødker\'s [11] articulation of the third wave, the aim of this paper is to articulate the challenges and opportunities that we consider central for the community to tackle. We offer four concepts — immediacy, (un)intentionality, interaction effects, and instability — that we believe can help in identifying and slicing our objects of analysis in new ways that better match the research challenges we are faced with.\r\n\r\n2 TOWARDS POST-INTERACTION COMPUTING\r\n\r\nIn this section, we want to briefly outline our motivation for, on the one hand, thinking of our current state of HCI and computing as being in a fourth wave and, on the other hand, being in a wave that we want to call post-interaction computing. Before we do that, it is worth noting that the fourth wave of HCI as we see it is not altogether different from the third in that both touch upon many sites of interaction: we interact with computing systems in our homes, on the move, at our leisure, and while at work. We do not propose the death of ‘interaction’, much like the emergence of the third wave did not make second wave concerns obsolete, but a move which attempts to re-situate interaction. Articulating an understanding of what interaction now does in computing, we argue that the proposed fourth wave is different from the third in the characteristics of its computational footprint in three regards:\r\n\r\nFirst, fourth wave computing is driven by the increased production and value of data in interaction with computing systems. The data that we produce when interacting with systems is now a significant economic and political resource. The scale and ubiquity of data collection has led to transnational legislation to return rights to the producers of data, and the value of the data-driven economy is estimated anywhere from hundreds of billions (estimates for the current value of the data economy in the EU are at EUR300 billion, growing to EUR739 billion or 4% of overall GDP [48], while estimates have suggested a figure closer to 2% in the US [51]) to over USD20 trillion or close to 90% of the stock market value of the most valuable companies [16]. Aside from the economic value of data derived from interaction and the potential this opens for exploiting those producing content through interaction [23], an issue closer to traditional HCI concerns is that this data is itself being used to change interaction. As such, interaction serves only one purpose of a fourth wave of human-computer interaction — it produces the data necessary for computing [14]. That interaction always produced data (inputs and outputs) is uncontested, though with the fourth wave of computing, computing is happening ‘without’ interaction and ‘out with’ interaction. Through sensors and algorithms we no longer need to interact with computers directly, while at the same time, our interactions feed computing that takes place outside of our interaction. To understand why a post-interaction computing framing in HCI is needed, let us consider the example of high-frequency trading. In their 2013 paper, Neil Johnson and colleagues [38] examine the occurrence of what they call Ultrafast Extreme Events (UEEs) in the financial markets. High-frequency trading is motivated by the desire to make profits by responding to information faster than anyone or anything else [40]. UEEs, where a significant change in the market occurs and is reversed within a few microseconds, are driven by computational and algorithmic decision making that happens at speeds that outpace human perception, cognition, and action. This has led to an argument for a new theory of economics which de-centers human agency and capability [38]. Evidently, computational systems that outpace humans are a challenge not only for economics but also for the field of Human-Computer Interaction. Computation is happening faster than we can interact with it, and it is more complex than we can make sense of.\r\n\r\nSecond, in parallel with the rising diversity and complexity of the systems at play, HCI seems to — once again — expand its concerns, placing a stronger emphasis on the economic, political, and other societal implications of the systems it envisions, builds, and studies (cf. [3, 19, 36, 59, 62, 63, 67]). Calls for critical consideration of where HCI stands when it comes to social justice issues and its implications to the well-being of individuals, social relationships, and entire societies are not new, but they seem to have become louder and more urgent. The scale of computing\'s footprint in our individual and collective lives is huge and growing — computing saturates society. At these scales, ‘interaction’ loses focus [65].\r\n\r\nFinally, the changes in Human-Computer relations that have come about through the increased speed, ubiquity, and scale of computational systems in human life, require a reconceptualisation of the relationship between humans and computing. Not only are the ‘loops’ of human-computer interaction often too small to ‘fit’ a human (as in the case of UEEs), but they are also too long and complex, as in the case of environmental sustainability [42, 53], for their effects to be known or knowable to the human actant. These scales (temporal, geographical, aggregation across populations) also interfere with readings of where and how the human is in-the-loop, to the extent that we argue that human agency, and with it intentionality, are no longer the only perspective from which we should consider sense-making. Again, the extent to which these computational timespans, long and short, are interwoven with our own human, but also sub-perceptual and conversely geological, timescales, sets this apart from previous waves of HCI. While in these timespans it might be tempting to ascribe agency directly to computational and algorithmic systems, as we will discuss, we should be cautious of not recognising the intentionality in the design of systems and the question of scale in understanding human-computer interaction [60].\r\n\r\n3 RECONSIDERING CENTRAL APPROACHES\r\n\r\nGiven these changes in computing in society, we review how other authors have begun to unravel the crisis of ‘interaction’. Following concerns for the current state of interaction (see [65, 68]), a number of authors have attempted to either rein in interaction as a concept, or to dissect the constituent elements of interaction, including ‘interaction’ [34], the ‘user’ [6], the ‘human’ or human-exceptionalism [46], alongside recounting the human work of ‘computing’ [1, 56, 70]. We map out key developments in recent literature that have been influential to our formulation of Post-Interaction Computing: First, we will review research that reflects on interaction as a foundational yet ambiguous concept in HCI. Second, we will consider ongoing discussions regarding reconfiguring the user and post-userism — a conversation that calls into question how we approach the human in HCI. Third, getting closer to the computer in HCI, we discuss work that troubles the notion of the interface.\r\n\r\n3.1 Interaction\r\n\r\nInteraction as a foundational concept in HCI has come under renewed scrutiny, largely due to the arguably “incoherent” definitions of interaction in use in the field [34, 55], despite contrary articulations of the productivity of epistemological plurality [31]. These discussions range from making order of interaction [34], to rethinking interaction [65], to arguments that, in fact, interaction as the focus of HCI design and study, is misplaced [68]. In their CHI 2017 essay on interaction, Kasper Hornbæk and Antti Oulasvirta [34] argue that there have been scarce efforts to define what interaction is, despite the term\'s field-defining role in HCI. They describe how interaction is variously viewed in HCI literature as dialogue, transmission, optimal behavior, embodiment, and tool use. Unsurprisingly, given the supposed crisis of interaction, they point out that the concepts have different scopes and ways of construing causal relationships between the human and the computer. The authors answer the question of what interaction is in part in the negative: “Interaction is not the idea promoted and repeated in folk notions that a computer and a human are engaged in some interplay.” More interestingly for our purposes in this essay, the authors, following Mario Bunge [15], state that interaction concerns two entities that determine each other\'s behavior over time. They point out that the mutual determination of humans and computers can be of many types, including statistical, mechanical, and structural. Yet, despite the multi-determination supposed by this, Hornbæk and Oulasvirta [34] tie the characterisation of interaction back to human intention: “Users, with their goals and pursuits, are the ultimate metric of interaction.”\r\n\r\n3.2 User\r\n\r\nThe concept of the ‘user’ has been pervasive in HCI, partly as a boundary around which the discipline has been built [17] and, as the concept has evolved — from ‘user’ to ‘person’ and beyond (cf. [4]) — as a means to demarcate the ethical space of who the user is and, more importantly, is not, as in the traditions of cooperative and participatory design [12, 50] and with renewed interest in socially just design [19, 63]. While already the foundational work by Steve Woolgar [70] showed how developers try to use technology to configure users to fit into a certain mold, HCI research has opened up questions on how ‘users’ go beyond these categories, both practically, for instance when individuals use systems to help someone else [6, 58], and as a resistance to normative expectations on use [7] and users [29, 41, 45, 62]. Rena Bivens and Oliver Haimson [9] demonstrate how, even when the user-facing system can appear without such categories, interconnected systems such as those for advertising, reinforce normative categories of who or what a ‘user’ should be.\r\n\r\nEric Baumer [4] has used the term ‘usee’ to refer to cases where the ‘user’ is designated not by their use but by their being used by a computational system. Studies of computational labour where ‘cheap’ human labour ‘fills in’ for algorithmic systems [61] are explicit examples of this, pushing against the seamless vision of automation. The consequence of such a framing can be clearly seen in the broader arguments on social injustices [22] — people are embroiled in interactions with digital society often without knowing it, without control over it, with or without intention to engage, and even with the intention to disengage or actively resist use. In this sense also, interactions with different kinds of systems have consequences for those who have no direct contact with them. One drastic example of consequences that interactions may have to those whose intentionality is not part of them is the case of how data gathered with satellites to monitor atrocities occurring in Sudan during conflict were apparently being used to commit further atrocities [66]. In a relatively more prosaic situation, the consequences of transactions in, for instance, Airbnb may affect the neighbours of those who rent out apartments [43]. In the short-term, guests may be noisy, but the consequences may also act on a broader scale, for instance by driving up rental prices in certain areas and thus making them unattainable for some groups of people [44].\r\n\r\nWhile we do not wish to claim that the user is not important, it is obvious, as others have already shown [5, 7], that if we do not challenge this category and look beyond it, we risk creating an atomistic picture of information technology\'s role in the world.\r\n\r\n3.3 Interface\r\n\r\nPerhaps the most developed argumentation, and implementation, of what we might start to consider as post-interaction is the notion of computers without interfaces. Since Mark Weiser and John Seely Brown [69] articulated the dream of a less intrusive and arguably more natural or organic interface to computers, HCI research has pursued the capture of human action through sensors, the sense making of sensed data through algorithms, and the conceptual language and tools for dealing with such implicit interaction [39]. In these configurations, the ‘interface’ is understood as the site of interaction, but it is also one that can be foregrounded or, importantly, backgrounded. This backgrounding of the interface, and thereby the computer, is intended to allow for seamless action on behalf of the user without explicit interaction per se. The faceless interface [37] is one that does not present itself for use, but that through various sensed inputs corresponds to the user.\r\n\r\nConceptually, this maintains many of the notions of interaction, though the intentionality of interaction is less well articulated. While an automatic door opener should respond to a potential user\'s approach, such faceless interaction is prone to errors, such as reacting to non-users who are just passing by. Alex Taylor [65] has argued that this pulling back of interaction has consequences beyond the system itself, consequences that are ultimately political and societal. With his example drawn from London\'s bicycle hire scheme, he shows how the interface to the system is both distributed and often invisible to the cyclist. More worryingly, so too are the impacts of the inequality presented by the availability of the bikes as an interface to the city. As Lucy Suchman [64] has suggested, Weiser\'s ubicomp dream and the techno-utopian version of post-interaction where computers are not in the way, but just part of a nice continuity of human activity that they facilitate without humans needing to think about them, propagate a problematic vision of computing, not as interface but as infrastructure. The post-interaction computing concern here is that, while increased computational sophistication can help to background our interactions with computers to the extent that we no longer ‘see’ or ‘experience’ interaction with them, our reliance on invisible and inscrutable systems leads to questions of responsibility and accountability for the actions and decisions being made.\r\n\r\n4 RESLICING THE UNITS OF ANALYSIS\r\n\r\nIn the previous sections, we have attempted to outline some of the current challenges in dealing with interaction. From here, we propose that these challenges point to a need to rethink what interaction is doing. To be clear, this is not about taking interaction out or somehow removing it from our analyses. Instead, the challenge here is to go beyond it in our conceptualisations of who and what are the subjects and objects of computational processes, making interaction just one of those subject/objects. We are talking about computing because we are talking about interactions with technologies but also about how data is processed, how we use computers for computational tasks, and how our use of computers ends up contributing to computational processes that we may not have intended to take part in — and the broader implications of those processes.\r\n\r\nWhere Hornbæk and Oulasvirta [34] have shown that intentionality is central to the dominant conceptualisations of interaction in HCI, we call for a post-interaction orientation that grapples with shifts in immediacy, (un)intentionality, interaction effects, and instability in order to revisit the unit of analysis we work with and the methodologies necessary for conducting our research. We offer these concepts as an invitation for the community to consider together how we might slice our objects of analysis differently and focus on different slices and how they intra-act [2]. Our aim here is to articulate issues we are faced with in transitioning to meet the challenges of fourth wave HCI. How to best resolve those issues is an open and interesting question.\r\n\r\n4.1 Immediacy\r\n\r\nAs evidenced by the example of ultrafast extreme events, computational speeds far exceed human perception and cognition, and that speed is being used to create events, make decisions, and change the human-world, in ways which we can no longer fully account. This computational speed is allowing longer distance interactions, with instantaneous quantum communication achieved between Earth and an orbiting satellite. Simultaneously, as Don Ihde\'s [35] proposition in postphenomenology of background relations and embodiment relations suggest, technology is both ‘out of sight’, taking examples such as smart thermostats and email servers, and is literally ‘all seeing’ to take his examples of eyeglasses. In this way, technology is both immediate in its direct mediation of the world and immediate in its inescapable ubiquity. These alterations of the human perceptible space-time of computing begins the change we intend in suggesting post-interaction. We make three contentions: First, feedback loops have become too small to ‘fit’ a human. Second, feedback loops have become too long to be meaningfully human alterable. Third, feedback loops have become spatio-temporally distributed making them effectively non-cohesive and, consequently, non-interactive.\r\n\r\nOur contentions about the space-time of computing prompt us to trouble and expand the metaphor of human-in-the-loop: When does it make sense to talk of a human in the loop? Where in the loop is the human involved and in what ways? This is different from moves that try to displace humans from the loop altogether, in pursuit of full automation. Rather than pushing humans out of the picture entirely, we need ways to think of where and in what ways they are involved. As Nick Seaver [60] advises, we might do well to take narratives of computational systems working without a human in the loop with a grain of salt: “If you cannot see a human in the loop, you just need to look for a bigger loop.” Here, he points at the steady accumulation of feedback loops where there are people everywhere “making little stitches, tacking software to the social world”.\r\n\r\nIn addition to looking more broadly for where in the loop the humans are, we can take guidance from David Mindell\'s [49] orienting questions in his book on robotics and the myths of autonomy and consider when they are involved: “Where are the people? Which people are they? What are they doing? When are they doing it?” As an example, he discusses how when flying a traditional airplane, the human inputs come as the events are happening and have immediate results, where as in a spaceflight scenario, the vehicle might be on Mars and it might take twenty minutes for it to receive a command and another twenty minutes for the operator to get feedback. As a further complication, planes that land ‘automatically’ can be thought of as controlled by those who specified their functioning, sometimes months or years earlier.\r\n\r\nHowever, while some of this involvement can still meaningfully be placed under the umbrella of interaction, and while thinking with the notion of loops can be generative (for instance, through the parallels of craft and computing [56]), we propose that we would benefit from new metaphors for making sense of human-machine relationships where interaction may not be the most appropriate or productive concept. Foregrounding issues of time seems like a particularly productive direction to explore, and certainly an area where HCI scholars are already making headway [27, 47]. Following an epistemological stance, we might consider how time is made and made sense of in interaction. Madhu Reddy\'s [54] study on medical work suggests ideas of, for instance, human-computer rhythms. Drawing from ontological studies of time, we must ask what types of time do we even consider in our design and study of computing systems. We can already see that computational ontologies of time are problematic in terms of scale, density, and the tensions of linear and periodic timescales [21]. The challenge we see here is that in sync with the broadening concerns about the implication of HCI, it is becoming clear that it is not enough to be thinking about human time and computer time, but that we need to account for bigger scales, too, all the way up to geological time [42, 46]. We must consider how different immediacies, in and outside of interaction, are mutually constituted.\r\n\r\n4.2 (Un)Intentionality\r\n\r\nAt the heart of theories of HCI is the notion of ‘intentionality’ [20, 34]. According to Hornbæk and Oulasvirta, this pervasive consideration — that human-computer interaction is always, in some way, goal-directed — is also one of the limitations. There is little conceptual work done to talk about how intentions are formed, nor how they are influenced by interaction. Hornbæk and Oulasvirta suggest that all models of interaction are seen “as channeling and realization of human intentions through a computer, furthermore assuming that these intentions are outside the realm of interaction itself.” Here, rather than contest the argument that intentionality should be better conceptualised in interaction, we want to demonstrate how the pervasive nature of intentionality is itself a limitation of the thinking on interaction within the field of HCI.\r\n\r\nFirst, let us start with a mundane example. Every morning, when I (Rob) open my phone and check my email for the first time, my interactions communicate with a number of services. My intended interaction is with my institution\'s email server. However, in the process I interact with a number of other services, including those on my phone, my router, my ISP, and so on. We can think of these as perhaps not ‘unintentional’ (since they are in the ‘path’ of my intention), but ‘consequential’. When I check the morning news I engage with a similar series of servers and services, some of which, such as advertising, are explicitly outside of my goal directed actions — they make it slower for me to do my ‘task’. Here, ‘intentionality’ might still serve as a useful concept — how quickly can I achieve what I intended — and the result being that advertising is ‘bad’ design for my interaction. Yet, these interactions are further used to profile my behaviour, to target me for advertising, and ultimately to try to shape my interactions. These actions are ‘intended’ by advertisers and system developers, but are not my intention when interacting. I am not intending to get better ads by doing better interaction. A further unintended consequence comes in the fact that, when, in this case Airi\'s sister opens her phone in the morning when staying with the parents, the phone automatically turns on the printer downstairs in their family home. This alerts her father to the fact that she is awake. That these interactions might also be habitual and routine without meaningful intentionality, or in some cases designed to exploit lapses in our intentions [25], and that we might enact impacts without or against our intentions such as time and energy cost (cf. [53]), adds a further complication to intentionality\'s centrality in human-computer interaction.\r\n\r\nIn looking at intentionality we can see that social practice theory provides a starting point to reconcile individual actions/interactions, their cultural and normative reproduction, and the possibilities for unintended outcomes. Examining how food is wasted, Eva Ganglbauer and colleagues [24] highlight the seemingly unintended food waste that comes from well-intended practices of shopping, cooking, and so on. This is conceptualised as a split between integrated and dispersed practices. While we recognise the practice of ‘shopping’ or ‘buying food’, we do not ever notice that at the same time we are ‘wasting food’ by, for instance, overpurchasing. Shopping here is an intentional and recognisable, integrated practice, while wasting food is, in this case, a dispersed practice. Similarly, with the use of music listening and sharing services, we can observe some integrated practices, such as listening to music and recommending music to a friend. We do not so easily recognise the practices of automated profiling of our musical taste, the automated recommending of music to others, and so on. In these cases, the interaction might be intentional, but the data and outcomes are not always so, where we produce data that has some meaning for an algorithm or computer, but not for us. As Eli Blevis has demonstrated with regards to environmental and social sustainability in design [10], the choices we make in designing systems are distributed to individuals, people, and places far beyond our intentions. This is not to say we don\'t know that those other practices are happening, but that we are focused (or intended) on one integrated practice.\r\n\r\nWe suggest that a post-interaction computing perspective would be to begin to unravel the connected practices of interaction and computing. As with the relationships between use and non-use, we must not always assume intentionality in interaction as the norm, but investigate it. Unintentionality then gives us a frame from which we can understand what is left out of and left over from our interactions, particularly where those things that are left out are the intentions of others. Accounting for the residuals or even the unnoticed, might better support us in understanding when and where things are noticed, integrated, and intended.\r\n\r\n4.3 Interaction effects\r\n\r\nAs computing systems have proliferated, the consequences of interaction with one system now often influence or even propagate to another. Beyond the questions of (un)intentionality discussed already, these effects — we call them ‘interaction effects’ — have profound impacts on people, across populations and in aggregate.\r\n\r\nAt the individual level, the most mundane instances of interaction effects is the ever present ‘personalisation’, or the recursive case where interacting interacts with interaction [14]. This can be immensely beneficial for users, even when it goes beyond the assumption that my interaction is improving my interaction to include the interaction of others. Yet, it can also be highly problematic — singling out users or ‘leaking’ data to another system or user [32]. The house of cards of interaction effects is also not robust and it is embedded in itself. We can\'t ‘delete’ data without losing structure, meaning or ‘experience’, nor can we escape the bubbles of personalisation. Moreover, our experiences and interactions with one system cannot be removed from interaction with others [9].\r\n\r\nThis is not only an issue of use, but also non-use. As I (Rob) am not a Facebook user, when I had to use Facebook\'s Messenger application for work purposes, the company\'s algorithm was unable to connect me with meaningful social contacts in its recommended contacts. In other cases, what data exactly is collected and how it is used can affect how services are built and personalised for different users. While online news outlets may use clicks as a metric to decide what kind of content to produce or suggest to readers, it is also possible to measure other things, such as reading time [26], to make these decisions. From the user\'s perspective, the interaction would be more or less the same, but it could lead to different kinds of outcomes. As a consequence, and in their design, interaction effects are difficult to observe through user-centred approaches — they are, by design, aggregated and normalised.\r\n\r\nFor populations, these interaction effects have become part and parcel of a narrative, and increasing reality, of the automation of decision-making which reinforces existing biases in technological and social systems [22, 52, 57]. These effects are likely to increase in scale and scope as the use of algorithmic inference increases and in spite of legislative attempts to diminish practices such as data profiling.\r\n\r\nThe point we want to make here is that a shift from the third wave occurs where computing is designed around interaction effects. Systems rely on sending data across platforms, services, and applications — the ubiquity of APIs demonstrates some of this thinking and engineering. However, this has also led to a challenge for HCI researchers. To do such design work, to build systems around interaction effects, needs rich and wide data [14]. This scale of data — or of ‘interaction’ — is beyond what most prototypes or research systems can generate [13]. When we design relying on the idea of data and interaction effects, things fail when the data is not there.\r\n\r\n4.4 Instability\r\n\r\nPersonalisation, A/B testing and the online nature of modern services mean that the systems we interact with are not the same to everyone, nor do they stay the same over time [14]. We encounter a slightly different Facebook everyday, and our Facebook differs from those around us. Also, if we look back, many services that we have incorporated to our lives have changed drastically: for example, in addition to the plethora of other changes that have been made to the service, Youtube now hosts longer videos than when it first appeared online. As ‘interaction effects’ play out, for instance, our geographical location affects what advertisements we see, and as we grow older we move between target segments which changes the kind of material companies want to market to us. This instability means that making sense of services is always tied to specific moments and contexts— both for the users and for the researchers — as the systems we encounter will not stay the same [8].\r\n\r\nFollowing from such instability, and given the instabilities already described in relation to the ‘user’, ‘interface’, and so on, it seems clear that in a fourth wave, HCI will struggle to study and describe interaction without an extensively limiting depiction in the only here and now [36]. These challenges are already known from the third wave, epitomised in the concerns for the embodied and situated nature of interaction [20, 64] and the desire to challenge the biases of naive generalisation [36]. Yet, while the third wave sought to make sense of the particular from the general, a post-interaction perspective echoes the vast mechanisms of computational aggregation to ask what is general in the particular. Again, Alex Taylor\'s [65] example of the London bicycle hire scheme highlights how, although the ‘interaction’ with a bicycle might seem the same for any rider, the aggregated use of the bicycles, represented through visualisation, shows systematic exclusion of certain geographies. While any ‘one’ can use the system, there are many who generally cannot. Don Ihde\'s [35] notion of ‘multistability’ provides a means to make sense of patterns of interaction — although objects are never fully known [30], they are in some perceptual ways persistent. Understanding such stabilities, when we can articulate them from our own standpoint [31], allows us to extend to those normativities and normalisations [7], and to go as far as troubling them [28, 31]. This also serves to acknowledge the power and persistence of norms and expectations in use, both productively, where in design we might want to design for certain experiences, and progressively, where we can identify, acknowledge, and hopefully rectify, the exclusion of particular stabilities and perspectives.\r\n\r\n5 CONCLUSION\r\n\r\nIn this paper, we have made a move towards what we think post-interaction computing as a fourth wave of HCI might entail, emphasising in part how it is driven by the increased production and value of data in interaction with computing systems. We have discussed immediacy, (un)intentionality, interaction effects, and instability as four concepts that pinpoint challenges the field of HCI is faced with, while offering some initial thoughts on how we might work on each. We are neither the first to discuss these issues, nor do we have the answers at the ready. Yet as we move between ‘waves’, we believe that there is value in identifying and articulating the shift we are going through so that we can move the conversation forward.\r\n\r\nIn shifting attention away from more straightforward interaction that we can observe in user studies and individual experiences that participants can to some degree account for in interviews, we are faced with tremendous methodological challenges. These range from how to slice our units of analysis to locating and scoping our sites of study, to gathering and analysing the kinds of materials that could help us make sense of the complex consequences and implications at play. One central concern here are issues of scale [13] — how can HCI create big enough data sets or run big enough trials to create knowledge on par with the large technology companies that are currently dominating the landscape? If we cannot (and do not want to) replicate these settings, then how do we keep up and stay relevant?\r\n\r\nOur emphasis has been to look at the multiple interactions, users, and interfaces to see intra-actions and those multistable patterns, perceptions, interactions, and effects [33] that are produced in the relational spaces between immediacies, (un)intentions, interaction effects, and instabilities. Design, in among these knots of ‘interacting’, might be understood as a means to shake the web, to push back, trouble, and reveal the (in)stabilities [18, 28]. As we move forward, we will be asking ourselves: How do we connect immediacies and timespans? How are interactions stabilised currently (and in the future)? Who are our unintended users? What are the points of collapse of interaction effects, and what is produced in these points and moments of collapse? How are multiple intentionalities, including unintentionality, performed and accounted for? How are normativities of intention accounted for in system design and use(s)? We will also turn our questions on themselves and ask: What are our (un)intended immediacies, stabilisations, and interaction effects? How do we stabilise our immediacies? How are our immediacies stacked against each other, producing interaction effects?\r\n\r\nMore practically, we hope this paper will be an early turn in a broader conversation of what post-interaction studies could look like and how we might engage in interaction design with post-interaction sensitivities.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis work has been supported by the Swedish Foundation for Strategic Research project RIT15-0046 and by Swedish Research Council grant number 2017-05382_3 and the KONE foundation project Algorithmic Systems, Power, and Interaction.\r\n\r\nREFERENCES\r\n\r\nMadeline Balaam, Rob Comber, Rachel E. Clarke, Charles Windlin, Anna Ståhl, Kristina Höök, and Geraldine Fitzpatrick. 2019. Emotion Work in Experience-Centered Design. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (2019) (CHI ’19). ACM, 602:1–602:12. https://doi.org/10.1145/3290605.3300832  \r\nKaren Barad. 2007. Meeting the Universe Halfway : Quantum Physics and the Entanglement of Matter and Meaning. Duke University Press.  \r\nShaowen Bardzell. 2010. Feminist HCI: Taking Stock and Outlining an Agenda for Design. ACM Press, 1301. https://doi.org/10.1145/1753326.1753521  \r\nEric P.S. Baumer. 2015. Usees. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (2015) (CHI ’15). ACM, 3295–3298. https://doi.org/10.1145/2702123.2702147  \r\nEric P.S. Baumer, Morgan G. Ames, Jenna Burrell, Jed R. Brubaker, and Paul Dourish. 2015. Why Study Technology Non-Use?First Monday 20, 11 (2015). https://doi.org/10.5210/fm.v20i11.6310  \r\nEric P. S. Baumer and Jed R. Brubaker. 2017. Post-Userism. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (2017) (CHI ’17). ACM, 6291–6303. https://doi.org/10.1145/3025453.3025740  \r\nEric P. S. Baumer, Jenna Burrell, Morgan G. Ames, Jed R. Brubaker, and Paul Dourish. 2015. On the Importance and Implications of Studying Technology Non-Use. interactions 22, 2 (2015), 52–56. https://doi.org/10.1145/2723667  \r\nSophie Bishop. 2018. Anxiety, panic and self-optimization: Inequalities and the YouTube algorithm. Convergence 24, 1 (2018), 69–84. https://doi.org/10.1177/1354856517736978  \r\nRena Bivens and Oliver L. Haimson. 2016. Baking Gender Into Social Media Design: How Platforms Shape Categories for Users and Advertisers. Social Media + Society 2, 4 (2016), 2056305116672486. https://doi.org/10.1177/2056305116672486  \r\nEli Blevis. 2018. Seeing What Is and What Can Be: On Sustainability, Respect for Work, and Design for Respect. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (2018) (CHI ’18). ACM, 370:1–370:14. https://doi.org/10.1145/3173574.3173944  \r\nSusanne Bødker. 2006. When Second Wave HCI Meets Third Wave Challenges. In Proceedings of the 4th Nordic Conference on Human-Computer Interaction Changing Roles - NordiCHI ’06 (2006-10). ACM Press, 1–8. https://doi.org/10.1145/1182475.1182476  \r\nSusanne Bødker, Kaj Grønbæk, and Morten Kyng. 1995. Cooperative Design: Techniques and Experiences From the Scandinavian Scene. In Readings in Human-Computer Interaction, Ronald M. Baecker, Jonathan Grudin, William A. S. Buxton, and Saul Greenberg (Eds.). Morgan Kaufmann, 215–224. https://doi.org/10.1016/B978-0-08-051574-8.50025-X  \r\nBarry Brown, Susanne Bødker, and Kristina Höök. 2017. Does HCI Scale?: Scale Hacking and the Relevance of HCI. interactions 24, 5 (2017), 28–33. https://doi.org/10.1145/3125387  \r\nTaina Bucher. 2018. IF...THEN: Algorithmic Power and Politics. Oxford University Press, United Kingdom.  \r\nMario Bunge. 1979. Causality and Modern Science. Dover Publications.  \r\nDan Ciuriak. 2019. Unpacking the Valuation of Data in the Data-Driven Economy. ID 3379133 (2019). https://papers.ssrn.com/abstract=3379133  \r\nGeoff Cooper and John Bowers. 1995. Representing the User: Notes on the Disciplinary Rhetoric of Human-computer Interaction. In The Social and Interactional Dimensions of Human-computer Interfaces, Peter J. Thomas (Ed.). Cambridge University Press, New York, NY, USA, 48–66. http://dl.acm.org/citation.cfm?id=214811.214821  \r\nCarl DiSalvo. 2012. Adversarial Design. The MIT Press.  \r\nLynn Dombrowski, Ellie Harmon, and Sarah Fox. 2016. Social Justice-Oriented Interaction Design: Outlining Key Design Strategies and Commitments. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems (2016). ACM, 656–671.  \r\nPaul Dourish. 2004. Where the Action Is: The Foundations of Embodied Interaction (1st ed.). MIT Press. \r\nVadim Ermolayev, Sotiris Batsakis, Natalya Keberle, Olga Tataryntseva, and Grigoris Antoniou. 2014. Ontologies of Time: Review and Trends. International Journal of Computer Science and Applications 11 (12 2014), 57–115.  \r\nVirginia Eubanks. 2017. Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor (1st ed.). St. Martin\'s Press.  \r\nChristian Fuchs. 2010. Labor in Informational Capitalism and on the Internet. The Information Society 26, 3 (2010), 179–196. https://doi.org/10.1080/01972241003712215  \r\nEva Ganglbauer, Geraldine Fitzpatrick, and Rob Comber. 2013. Negotiating Food Waste: Using a Practice Lens to Inform Design. ACM Transactions on Computer-Human Interaction (TOCHI) 20, 2(2013), 11. https://doi.org/10.1145/2463579.2463582  \r\nColin M. Gray, Yubo Kou, Bryan Battles, Joseph Hoggatt, and Austin L. Toombs. 2018. The Dark (Patterns) Side of UX Design. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems - CHI ’18 (2018). ACM Press, 1–14. https://doi.org/10.1145/3173574.3174108  \r\nJesse Haapoja and Airi Lampinen. 2018. ’Datafied’ reading: Framing Behavioral Data and Algorithmic News Recommendations. In Proceedings of the 10th Nordic Conference on Human-Computer Interaction - NordiCHI ’18. Oslo, 125–136. https://doi.org/10.1145/3240167.3240194  \r\nLars Hallnäs and Johan Redström. 2001. Slow Technology - Designing for Reflection. Personal and Ubiquitous Computing 5, 3 (2001), 201–212. https://doi.org/10.1007/PL00000019  \r\nDonna Jeanne Haraway. 2016. Staying with the Trouble: Making Kin in the Chthulucene. Duke University Press.  \r\nJean Hardy and Silvia Lindtner. 2017. Constructing a Desiring User: Discourse, Rurality, and Design in Location-Based Social Networks. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing (2017) (CSCW ’17). ACM, 13–25. https://doi.org/10.1145/2998181.2998347  \r\nGraham Harman. 2017. Object-Oriented Ontology : A New Theory of Everything.PELICAN.  \r\nSteve Harrison, Phoebe Sengers, and Deborah Tatar. 2011. Making Epistemological Trouble: Third-Paradigm HCI as Successor Science. Interacting with Computers 23, 5 (2011), 385–392. https://doi.org/10.1016/j.intcom.2011.03.005  \r\nKarey Helms. 2017. Leaky Objects: Implicit Information, Unintentional Communication. In Proceedings of the 2017 ACM Conference Companion Publication on Designing Interactive Systems (2017) (DIS ’17 Companion). ACM, 182–186. https://doi.org/10.1145/3064857.3079142  \r\nKristina Höök and Jonas Löwgren. 2012. Strong Concepts: Intermediate-Level Knowledge in Interaction Design Research. ACM Transactions on Computer-Human Interaction 19, 3(2012), 1–18. https://doi.org/10.1145/2362364.2362371  \r\nKasper Hornbæk and Antti Oulasvirta. 2017. What Is Interaction?. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (2017) (CHI ’17). ACM, 5040–5052. https://doi.org/10.1145/3025453.3025765  \r\nDon Ihde. 1993. Postphenomenology: Essays in the Postmodern Context. Northwestern University Press. \r\nLilly Irani, Janet Vertesi, Paul Dourish, Kavita Philip, and Rebecca E. Grinter. 2010. Postcolonial Computing: A Lens on Design and Development. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (2010) (CHI ’10). ACM, 1311–1320. https://doi.org/10.1145/1753326.1753522  \r\nLars-Erik Janlert and Erik Stolterman. 2015. Faceless Interaction-A Conceptual Examination of the Notion of Interface: Past, Present, and Future. Human-Computer Interaction 30, 6 (2015), 507–539. https://doi.org/10.1080/07370024.2014.944313  \r\nNeil Johnson, Guannan Zhao, Eric Hunsader, Hong Qi, Nicholas Johnson, Jing Meng, and Brian Tivnan. 2013. Abrupt Rise of New Machine Ecology beyond Human Response Time. Scientific Reports 3(2013), 2627. https://doi.org/10.1038/srep02627  \r\nWendy Ju. 2015. The Design of Implicit Interactions(1st ed.). Morgan & Claypool Publishers.  \r\nTero Karppi and Kate Crawford. 2016. Social Media, Financial Algorithms and the Hack Crash. Theory, Culture & Society 33, 1 (2016), 73–92. https://doi.org/10.1177/0263276415583139  \r\nOs Keyes. 2018. The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition. Proceedings of the ACM on Human-Computer Interaction 2 (2018), 1–22. Issue CSCW. https://doi.org/10.1145/3274357  \r\nBran Knowles, Oliver Bates, and Maria Håkansson. 2018. This Changes Sustainable HCI. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (2018) (CHI ’18). ACM, 471:1–471:12. https://doi.org/10.1145/3173574.3174045  \r\nRosalie Koolhoven. 2018. Regulating Airbnb in the Netherlands. Journal of European Consumer and Market Law 7, 6 (2018), 253–256.  \r\nDayne Lee. 2016. How Airbnb short-term rentals exacerbate Los Angeles\'s affordable housing crisis: Analysis and policy recommendations. Harv. L. & Pol\'y Rev. 10 (2016), 229.  \r\nAnn Light. 2011. HCI as Heterodoxy: Technologies of Identity and the Queering of Interaction with Computers. Interacting with Computers 23, 5 (2011), 430–438. https://doi.org/10.1016/j.intcom.2011.02.002  \r\nAnn Light, Irina Shklovski, and Alison Powell. 2017. Design for Existential Crisis. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’17 (2017). ACM Press, 722–734. https://doi.org/10.1145/3027063.3052760  \r\nSiân E. Lindley. 2015. Making Time. In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing (2015) (CSCW ’15). ACM, 1442–1452. https://doi.org/10.1145/2675133.2675157  \r\nGiorgio Micheletti and Cristina Pepato. 2017. The European Data Market Monitoring Tool: Key Facts & Figures, First Policy Conclusions, Data Landscape and Quantified Stories. SMART 2016/0063 (2017). http://datalandscape.eu/sites/default/files/report/D2.6_EDM_Second_Interim_Report_28.06.2019.pdf  \r\nDavid A. Mindell. 2015. Our Robots, Ourselves: Robotics and the Myths of Autonomy. Viking.  \r\nMichael J. Muller. 1995. Diversity and Depth in Participatory Design: Working with a Mosaic of Users and Other Stakeholders in the Software Development Lifecycle. In Conference Companion on Human Factors in Computing Systems (1995). ACM, 385–386.  \r\nLeonard I. Nakamura, Jon Samuels, and Rachel H. Soloveichik. 2017. Measuring the ’Free’ Digital Economy within the GDP and Productivity Accounts. ID 3058017 (2017). https://papers.ssrn.com/abstract=3058017  \r\nSafiya Umoja Noble. 2018. Algorithms of Oppression: How Search Engines Reinforce Racism. NYU Press.  \r\nChris Preist, Daniel Schien, and Eli Blevis. 2016. Understanding and Mitigating the Effects of Device and Cloud Service Design Decisions on the Environmental Footprint of Digital Infrastructure. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16 (2016). ACM Press, 1324–1337. https://doi.org/10.1145/2858036.2858378  \r\nMadhu C. Reddy, Paul Dourish, and Wanda Pratt. 2006. Temporality in Medical Work: Time Also Matters. Computer Supported Cooperative Work (CSCW) 15, 1 (2006), 29–53. https://doi.org/10.1007/s10606-005-9010-z  \r\nStuart Reeves and Jordan Beck. 2019. Talking about Interaction*. International Journal of Human-Computer Studies (2019), S107158191930059X. https://doi.org/10.1016/j.ijhcs.2019.05.010 arxiv:1903.03446  \r\nDaniela K. Rosner, Samantha Shorey, Brock R. Craft, and Helen Remick. 2018. Making Core Memory: Design Inquiry into Gendered Legacies of Engineering and Craftwork. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (2018). ACM, 531.  \r\nChristian Sandvig, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. 2016. Automation, Algorithms, and Politics | When the Algorithm Itself is a Racist: Diagnosing Ethical Harm in the Basic Components of Software. International Journal of Communication 10, 0 (2016). https://ijoc.org/index.php/ijoc/article/view/6182  \r\nChristine Satchell and Paul Dourish. 2009. Beyond the User: Use and Non-Use in HCI. In Proceedings of the 21st Annual Conference of the Australian Computer-Human Interaction Special Interest Group on Design: Open 24/7 - OZCHI ’09 (2009). ACM Press, 9. https://doi.org/10.1145/1738826.1738829  \r\nAri Schlesinger, W. Keith Edwards, and Rebecca E. Grinter. 2017. Intersectional HCI: Engaging Identity Through Gender, Race, and Class. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (2017) (CHI ’17). ACM, 5412–5427. https://doi.org/10.1145/3025453.3025766  \r\nNick Seaver. 2018. What Should an Anthropology of Algorithms Do?Cultural Anthropology 33, 3 (2018), 375–385.  \r\nBenjamin Shestakofsky. 2017. Working Algorithms: Software Automation and the Future of Work. Work and Occupations 44, 4 (2017), 376–423. https://doi.org/10.1177/0730888417726119  \r\nKatta Spiel, Alex Ahmed, Jennifer A. Rode, Jed R. Brubaker, Gopinaath Kannabiran, Os Keyes, Ashley Marie Walker, Michael A. DeVito, Jeremy Birnholtz, Emeline Brulé, Ann Light, Pınar Barlas, and Jean Hardy. 2019. Queer(Ing) HCI: Moving Forward in Theory and Practice. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems - CHI EA ’19 (2019). ACM Press, 1–4. https://doi.org/10.1145/3290607.3311750  \r\nAngelika Strohmayer, Mary Laing, and Rob Comber. 2017. Technologies and Social Justice Outcomes in Sex Work Charities : Fighting Stigma , Saving Lives. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems - CHI ’17 (2017).  \r\nLucy Suchman. 2006. Human-Machine Reconfigurations: Plans and Situated Actions. Cambridge University Press.  \r\nAlex Taylor. 2015. After Interaction. interactions 22, 5 (2015), 48–53. https://doi.org/10.1145/2809888  \r\nLinnet Taylor. 2017. Safety in Numbers? Group Privacy and Big Data Analytics in the Developing World. In Group Privacy, Linnet Taylor, Luciano Floridi, and Bart van der Sloot (Eds.). Springer International Publishing, 13–36. https://doi.org/10.1007/978-3-319-46608-8_2  \r\nKentaro Toyama. 2011. Technology As Amplifier in International Development. In Proceedings of the 2011 iConference(iConference ’11). ACM, New York, NY, USA, 75–82. https://doi.org/10.1145/1940761.1940772  \r\nPeter-Paul Verbeek. 2015. Beyond Interaction: A Short Introduction to Mediation Theory. interactions 22, 3 (2015), 26–31. https://doi.org/10.1145/2751314  \r\nMark Weiser and John Seely Brown. 1996. Designing calm technology. PowerGrid Journal 1, 1 (1996), 75–85.  \r\nSteve Woolgar. 1990. Configuring the User: The Case of Usability Trials. The Sociological Review 38, 1 (1990), 58–99. https://doi.org/10.1111/j.1467-954X.1990.tb03349.x ',1,'Comber','Rob Comber, Airi Lampinen, and Jesse Haapoja','Rob Comber *(KTH Royal Institute of Technology, Sweden)*<br>\r\nAiri Lampinen *(Stockholm University, Sweden)*<br>\r\nJesse Haapoja *(Aalto University, Finland)*','http://airilampinen.fi/files/httf2019-33.pdf',1,'10.1145/3363384.3363477','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,55,10,NULL,NULL,0,33),(40,'ashby-fourth-wave-hci-meets-the-21st-century-manifesto-creative-subversion-in-the-chi-verse','2019-09-02 15:24:57','2019-11-14 14:14:52','2019-09-02 15:24:57',NULL,1,'published','[]','Fourth-Wave HCI Meets the 21st Century Manifesto: Creative Subversion in the \'CHI-verse\'','We take up Bødker\'s challenge to ‘identify’ a fourth wave HCI, building on the work of Blevis et al. and others to shore up a new vision that places ‘politics and values and ethics’ at the forefront without abandoning the strengths of previous waves. We insist that a fourth wave must push harder, beyond measured criticism for actual (e.g. institutional) change. We present two studies performed at CHI’19, where we used our MANIFESTO! game to: 1) take the temperature of colleagues on adopting an activist stance, 2) test manifesto writing as a key activity in pushing HCI forward into the fourth wave, and 3) test our game for subsequent iterations, and as a probe for inspiring new digital tools. With the enthusiastic response received to gameplay, facilitated in part through a novel method using tableau vivant, we argue for taking political activism from the margins into mainstream HCI.','Simone Ashby, Julian Hanna, Sónia Matos, Callum Nash, and Alexis Faria. 2019. Fourth-Wave HCI Meets the 21st Century Manifesto: Creative Subversion in the \'CHI-verse\'. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 11 pages. [https://doi.org/10.1145/3363384.3363467](https://doi.org/10.1145/3363384.3363467 \"DOI for the article \'Fourth-Wave HCI Meets the 21st Century Manifesto: Creative Subversion in the \'CHI-verse\'\'\")','Fourth-Wave HCI Meets the 21st Century Manifesto\r\nCreative Subversion in the \'CHI-verse\'\r\nSimone Ashby\r\nMadeira ITI/LARSyS & University of Madeira, Funchal, Portugal, simone.ashby@m-iti.org\r\nJulian Hanna\r\nMadeira ITI/LARSyS, Funchal, Portugal, julian.hanna@m-iti.org\r\nSónia Matos\r\nMadeira ITI/LARSyS, Funchal, Portugal, sonia.matos@m-iti.org\r\nCallum Nash\r\nSchool of Design, Northumbria University, Newcastle upon Tyne, UK, callum.nash@northumbria.ac.uk\r\nAlexis Faria\r\nMadeira ITI/LARSyS & University of Madeira, Funchal, Portugal, alex.faria@m-iti.org\r\nABSTRACT We take up Bødker\'s [9] challenge to `identify\' a fourth wave HCI, building on the work of Blevis et al. [8] and others to shore up a new vision that places `politics and values and ethics\' at the forefront without abandoning the strengths of previous waves. We insist that a fourth wave must push harder, beyond measured criticism for actual (e.g. institutional) change. We present two studies performed at CHI\'19, where we used our MANIFESTO! game to: 1) take the temperature of colleagues on adopting an activist stance, 2) test manifesto writing as a key activity in pushing HCI forward into the fourth wave, and 3) test our game for subsequent iterations, and as a probe for inspiring new digital tools. With the enthusiastic response received to gameplay, facilitated in part through a novel method using tableau vivant, we argue for taking political activism from the margins into mainstream HCI.\r\nCCS CONCEPTS · Human-centred computing · Human-computer interaction (HCI) · HCI theory, concepts and models\r\nKEYWORDS Manifestos, Fourth-Wave HCI, Games, Tableau Vivant, Activism, Creative Subversion\r\n1 First Things First\r\nUsing a context sensitive and largely ethnographic approach to research, HCI\'s third wave has challenged an understanding of technology that is constrained by the earlier disciplinary canons of `efficiency\' [9]. Bødker, when asked about the potential of a fourth wave, responded: `HCI is in the middle of a chaos of multiplicity in terms of technologies, use situations, methods, and concepts. Hopefully something lies beyond that horizon, but for now, I\'ll leave it to others to identify\' [9]. In this paper, in line with other recent discussions [8], we take up the challenge of envisioning this next wave, seeking to demonstrate how a fourth-wave HCI/IxD - `distinguished ... by its primary focus on politics and values and ethics\' - is a necessary designation. While previous waves have remained `value-neutral\', a fourth-wave poses a means of `avoid[ing] the centrality of teleological, positivist notions of interaction design\', and emphasises `that being thoughtful about what to make and the implications of making are central concerns\' [8]. We would agree but go further still, insisting that a fourth wave must push harder for actual (e.g. institutional) change - it must go beyond measured criticism and a shift in `focus\' to embrace activism at all levels, from\r\n1\r\n\r\nquestioning corporate sponsorship, to increasing true accessibility and diversity, and addressing urgent existential threats such as climate change.\r\nTo this end, we will support our discussion with a presentation of an event that was organised as part of this year\'s CHI conference, in which we used the manifesto as a thought probe facilitated through the modality of a card game. We wanted to use our game MANIFESTO! to engage CHI attendees around the issues affecting all of us within the discipline and the world we live in, in order to: 1) take the temperature of our colleagues in the field on adopting a more activist stance, 2) test our notion of manifesto writing as a key activity in pushing HCI forward into the fourth wave, and 3) test our game for subsequent analogue iterations, and as a design probe for inspiring new digital authoring and learning environments. While we believe that the manifesto is an important tool in shaping ideas and articulating goals and principles, the short manifestos produced using our game at CHI were not intended to be viewed as finished texts ­ which is why they have not been published. Rather, the activity of manifesto writing was intended to ignite conversations and introduce the idea of increasing political activism in HCI. That said, the kinds of rough manifestos produced in this experimental session could be further workshopped and honed with more time - another hour, another day, another week - and published in finished form. Or for example extracts of the manifestos could be gathered together and fed into some larger HCI manifesto using a voting system to select the best tenets. Our session did not allow for this level of production, it rather hinted at possibilities and experimented with both ideas and forms - including more radical forms (e.g. manifestos as tableaux vivants and manifestos as algorithms or diagrams). In this sense it was a probe, and insofar as it was a success, with many of our colleagues saying that they would use the game in their own classrooms, we believe it paves the way for both deeper future engagement with manifesto writing as a practice in our discipline and taking political activism from the margins into the mainstream of HCI.\r\nWe agree with Bødker that we must not dispense wholly with the notions of second- (or third-) wave HCI; we must `strike the balance differently between individual experience (third wave), on the one hand, and sharing, learning from each other within communities of practice, and participation in shared development and appropriation of technology (second wave)\' [9]. We see the benefit of taking certain elements of the second wave, with its emphasis on systems and ecologies and the common, and the third wave, with its critical perspective, into the fourth wave - towards pressing issues such as tackling the climate emergency and growing inequality (e.g. [13]) through large-scale, values-driven systemic changes to the way we live.\r\n2 Until Now\r\n2.1 HCI Needs the Manifesto\r\nIn `Never mind the bollocks, i wanna be anarCHI: a manifesto for punk HCI\', [33] present `two fingers to the HCI establishment\'. In the spirit of `punk HCI\', their contribution unleashes the use of an unusual format, at least in the context of HCI. Although it is ring-fenced inside CHI\'s designated progressive section, alt.chi, this contribution, alongside other HCI and interaction design contributions [22, 35, 45, 20, 27, 1, 21, 39, 6, 24], uses the manifesto as a way of provoking a discussion around complex issues. In many of these manifestos one witnesses attempts by HCI researchers to perform a series of (often overlapping) moves: to speak collectively, build consensus, raise awareness, advocate for and accelerate change, speak for and from the margins, disrupt the status quo, unsettle stuck discourse, sidestep conventional modes, expose broken promises, and `circumvent ordinary ... avenues\' of redress if they are too slow in responding to urgent demands for change [34].\r\nAlthough manifestos do not necessarily entail an activist stance, the topic dovetails nicely into HCI work that attempts to tackle complex social and political design contexts. To this end, one can witness a growing desire within the field to address non-traditional contexts of performance and usability. For example, recent workshops have problematised the `use of design research and computing practice in resisting and reifying inequalities\' [18], while others have documented the rise of specific areas of activism within HCI such as health [47] and sustainability [42]. The field has also witnessed the rise of grassroots campaigning [46], as\r\n2\r\n\r\nwell as participatory action research through advocacy organisations [4]. Others take a more analytical stance by examining the role that digital technologies might play in the rise of social and political movements [5, 49]. Such contributions to the field resonate with [30] and their suggestion that `HCI is much broader than the study of interface design and input devices. It includes considerations of the social, political, ethical, and societal implications of computer systems\'. Or, perhaps - and by inspecting the mechanisms of computation more closely - these contributions reflect what [23] describes as the `social, cultural, and political role algorithms play\'.\r\nAs Bruno Latour notes in `An Attempt at a \"Compositionist Manifesto\"\', despite a fall from fashion of old notions of the `inevitable and irreversible\' flow of time that once governed the manifesto - the `modernist grand narrative of Progress\' - the form might still be rehabilitated: `Not as a war cry for an avant-garde to move even further and faster ahead, but rather as a warning, a call to attention, so as to stop going further in the same way as before toward the future\' [32]. In Latour\'s approach lies the true potential of the 21st century manifesto - not a war cry but a warning, a wakeup call, signalling that it is not (yet) too late to change direction, away from blind and `inevitable\' technological progress and towards a more harmonious, ecological, and inclusive future. Similarly, Ito\'s notion of a `seed essay\' expressed in `Resisting Reduction: A Manifesto\', which puts forth the idea that 21st century manifestos can be not only constructive but also iterative and collaborative in ways that were not possible in the pre-digital era, was also a source of inspiration for our project [31].\r\n2.2 Manifestos and the Words in Freedom Project\r\nAt its most basic, a manifesto is a `public declaration ... issued by a group or an individual\' declaring `aims and principles\' [29]. In this paper `manifesto\' refers broadly to the revolutionary model made famous by Marx and Engels\' The Communist Manifesto [37] and the social and artistic manifestos that followed, as well as the recent post-revolutionary variations mentioned above (e.g. [32, 31]). As Lyon argues, it is essentially a `tool for change\'; one that by `defining and enacting the identities of radical groups, individuals, and parties ... has galvanized revolutionary movements\' for centuries [34]. With the cultural and political upheavals of the nineteenth century, the manifesto became `the mode of agonism, the voice of those who are contra\' [40]. In the digital world revolutionary manifestos have been present since the earliest declarations by hackers, cyberfeminists, and techno-utopians. [25]. Many digital manifestos have been gathered into online repositories such as the Digital Manifesto Archive,1 Aaaarg,2 and 391.3\r\nBuilding on the latest `manifesto moment\' [14] heralded by the current era of online (and IRL) activism, the Words in Freedom (WiF) project4 analyses innovations in form, content, and dissemination signalled by the digital manifesto (and its analogue predecessor), maps what has been done in recent years, and expands the capacity for future interventions in the form of both digital and analogue tools for authoring manifestos, including a `Manifesto Machine\', a `Moving Type Machine\', and the MANIFESTO! card game. While we are designing tools for making manifestos, our purpose extends beyond simple technical facilitation and the fulfilment of what Dunne and Raby call `design\'s inbuilt optimism\' [17]. We want to encourage users to reflect critically ­ through collaboration, conscious expression, and public debate ­ on what they stand for and why, and how their beliefs might intersect with the beliefs of others. We also want to facilitate the creative dissemination of these views in manifesto form to promote critical thinking and positive change in wider contexts. We also hope to invite reflection on the productive and potentially undervalued role of criticality in HCI, in effect fusing two sub-disciplines: Design for Good [2] and Critical Design [16]. As Tonkinwise has argued (in a manifesto): `Designing that does not already Future, Fiction, Speculate, Criticize, Provoke, Discourse, Interrogate, Probe, [and] Play, is inadequate designing.\' [48]. Using the manifesto, we aim to do as many of these things as possible - to open up discursive spaces to benefit institutions, communities, and organisations of all kinds.\r\n1 https://www.digitalmanifesto.net 2 https://aaaaarg.fail/collection/51c592356c3a0ede0bcd2000 3 https://391.org/manifestos/ 4 https://www.wordsinfreedomproject.org\r\n3\r\n\r\n2.3 Games for Political Change\r\nGames, like all artifice, function as a kind of propaganda. They reproduce a world view, and normalise it within the confines of the game. Chess offers no winning condition other than defeat of an enemy through violence, accepting hierarchy and class as not only necessary but positive, with the monarchy forming the strategic centre. Some of the most popular children\'s games solidify conservative and reactionary world views, such as The Game of Life, which (aside from being uncritically heteronormative) declares the winner to be the person who has the most money before they die. Golf similarly enshrines class privilege through the relationship of caddy and player, and costly membership fees for use of privately owned land (the development of which often displaces local communities and destroys ecology). Under a banner of innocent escapism, games, like all designed objects, tend to reproduce the social relations and ideology of the society in which they were created.\r\nCan we create games that give players new frameworks in which to think, challenge entrenched ideas, and support meaningful social critique? The popular board game Monopoly was originally designed by Elizabeth J. Magie as a learning tool to critique landlordism and argue for progressive taxation, and that all land should be part of a common treasury [41]. Guy Debord\'s La Jue De La Guerre, in which `the two opponents can be considered as contesting interpretations of the topology of physical space under spectacular capitalism\', not only contains a critique of our society but offers itself as a training tool for the means of changing it [7].\r\nThere have been many attempts to directly leverage games, and the increased engagement offered by socalled `gamification\', to modify behaviour. In 2007, World Without Oil subjected 1700 players to a fictional oil-scarce world that included simulated news about an oil crisis. In the three years that followed, it was reported that most players kept up the fuel saving habits they had learned in gameplay [38]. Evoke, a game deployed by the World Bank in over-exploited economies, asks players to solve major natural catastrophes and epidemics, largely using profit and market-driven solutions [50]. Games like The Day We Left act to raise awareness. During the height of the Syrian war, this game placed players within a Syrian family trying to escape the war zone. Its aim was to act as a counternarrative to stories promoted by privately owned media corporations that Syrian refugees in the West were part of an undercover invasion by Islamic State [52].\r\nManifestos are like games in that they structure reality. But the manifesto structures the reality surrounding it, or attempts to, whereas the game creates a separate reality that can sit beside our own without ever interacting with it. Games, by their very nature, leave a wake of silence; whereas a manifesto ideally lays down a direction towards actual change. What we have done is to create a closed system in which the larger system can be safely smashed, but also questioned and reimagined. The outcome of the game is a manifesto. Players are allowed to act as revolutionaries, but also encouraged to create lines of reasoning and critique that can extend outwards, beyond the limits of the game, to address and unsettle real-world systems and institutions.\r\n3 MANIFESTO! The Game\r\nMANIFESTO! is a card game (Figure 1) for stimulating and supporting manifesto authoring. It stands alone as an analogue resource (e.g. for the classroom, organisational summits, etc.), as well as functioning as a design probe for expanding the WiF toolkit. The current iteration (also known as the \'Tech Edition\') was developed in 2019 as part of the WiF project. It was first deployed at CHI the same year. Given the setting, already rich in digital tools, we viewed CHI as an opportunity to set ourselves apart by engaging people through analogue and physical interactions.\r\n4\r\n\r\nFigure 1: MANIFESTO! (Tech Edition).\r\nTable 1: MANIFESTO! Tech Edition cards.\r\nThe simple rules are as follows: it is a game for individuals or groups of 2-6 players. In each round, player(s) are dealt one random card from each of four categories: Provocation, Orientation, Opening, and Tone (Table 1). One card substitution is allowed per round. The categories each define a different parameter or constraint of the overall objective. Provocation suggests a broad topic or theme (e.g. `Better for whom?\', `Challenge inequality\'); Orientation designates the type of manifesto players will create (e.g. `Diagram\', `Declaration\'); Opening offers the initial phrase (e.g. `We declare\', `Imagine\'); and Tone is the rhetorical register to be used in addressing the subject or audience (e.g. `Urgent\', `Hopeful\'). Players use their four constraints as a prompt to write or draw their manifesto individually or collectively. Each round can be timed (for example 10 minutes) or open-ended. When a round is complete players may vote for the\r\n5\r\n\r\n`winner\' - the most persuasive manifesto - and are encouraged to disseminate the resulting text either publicly via social media or privately among friends or colleagues as a means of continuing the discussion.\r\nThe basic concept of MANIFESTO! was inspired in part by Stuart Candy and Jeff Watson\'s design fiction game The Thing From The Future [12], which was made to be `hacked and customised\' and itself drew on Dator\'s framework of `four generic alternative futures\' [15]. Like The Thing From The Future, MANIFESTO! is distributed under a Creative Commons (BY-NC-SA) licence. Beyond the similar promptbased game structure, there are significant differences between MANIFESTO! and The Thing From The Future (TTFTF). While TTFTF encourages players to create an everyday object (e.g. a t-shirt) that tells a story about a possible future, MANIFESTO! seeks to focus players on thinking about real possibilities for change in the present (e.g. practical alterations to the way a conference such as CHI is run). MANIFESTO! uses roughly half as many cards (53 instead of 108), includes a modified game sheet with combined text/image authoring space and room to place actual cards, and has colour-coding on card backs to indicate the four categories, which are also different: our own Orientation, Opening, Provocation and Tone substituted for TTFTF\'s Arc, Terrain, Object and Mood. In designing MANIFESTO! we also tried to allow for productive friction between the four cards of a given hand - creative dissonance or even `dissensus\' [44] - inspired by the anarchic and chance-driven processes of 20th century avant-garde movements such as Dada, Surrealism, and Fluxus.\r\n4 Making Manifest at CHI\'19\r\nWe staged two interventions at CHI\'19 in Glasgow, Scotland for the purpose of testing our card game and engaging conference attendees around attitudes towards activism in HCI. For our initial intervention, we inhabited a vacant booth in the demonstrations hall and encouraged individual passersby to stop and share their reactions to a set of randomly drawn cards by composing a short manifesto. For our structured intervention, we initiated the session by modelling a manifesto of our own with the help of a megaphone for dramatic effect. We then introduced the card game and organised participants into small groups. In this event, we encouraged participant groups to warm up with a tableau vivant (Figure 4) before composing their paper-based manifesto. Both types of interaction were aided by the use of a sample completed MANIFESTO! gamesheet (Figure 5), which participants could access freely. After composing manifestos of their own, participants from both the guerrilla and structured events completed a short survey (Section 4.3). Participants completed an informed consent form, which was approved by the institutional review board of Madeira ITI, and were given a free deck of MANIFESTO! cards to take home. We describe each of these interventions more fully in the following sections.\r\n4.1 Guerrilla CHI\r\nThe guerrilla CHI event enabled us to pre-test the card game while focusing on individual manifesto authoring. We sought to capture the attention of conference-goers by wearing eye-catching hats and t-shirts that said `Ask me about MANIFESTO!\', while one of us walked around with an usherette tray full of card decks. In total, we tested the game with 14 CHI attendees, with an equal representation of female and male participants.\r\nAs indicated above, participation occurred freely and began with a brief introduction to the game. Participants were then dealt a random hand of cards - e.g. `There is not an app for that\' (Provocation), `Principles\' (Orientation), `Come, Comrades\' (Opening), and `Outraged\' (Tone) - and were instructed to use the cards as a prompt for writing and/or drawing a short manifesto on the gamesheet provided (Figure 2). Participants were able to sit or stand and could spend as long as they liked composing their manifesto. The shortest composition time was approximately five minutes and the longest was approximately 20 minutes. As a way of exploring possible new approaches to gameplay, participants were told that they were free to break the rules of the game if they desired. Just over half of the participants completed the follow-up survey (Table 2), which was an attempt to gauge their response to manifesto authoring and to further explore attitudes and beliefs around politics and the HCI discipline / CHI community.\r\n6\r\n\r\nFigure 2: Individually authored manifesto and corresponding game cards.\r\nIn terms of promoting our structured CHI session, generating enthusiasm for the game, and supporting reflection and discussion, the guerrilla event exceeded our expectations. This could in part be attributed to the `honeypot effect\', where passersby gather around an installation as a result of others interacting with it [11]. There was also an element of theatricality at play in keeping with manifesto style [43], whereby we drew attention to our unusual experiment with loud voices, costumes, and dramatic gestures. In most cases participants self-selected, freely approaching our makeshift booth and showing enthusiasm for the game; however, some others were approached by us at random and required more coaxing. Of the former group, these participants generally arrived with a desire to speak out about issues that concern them, and several conveyed gratitude for the opportunity to express themselves. One participant described the experience as `therapeutic\'. The latter group seemed to have more difficulty getting started and finding their `manifesto voice\', yet all participants replied positively that they would do it again when asked about the experience on the exit survey. Overall, participants required only minimal guidance with respect to gameplay, and succeeded in composing original and thoughtful manifestos (in effect, extended provocations) based on the prompts they were given. In a few cases participants asked to change cards, particularly the Provocation card, which was granted.\r\n4.2 Structured CHI Intervention\r\nThe 80-minute structured session at CHI was comprised of two separate manifesto writing exercises, and concluded with performances by participant groups for the sharing of results and processes. After modelling our manifesto [24] and explaining the basic rules of gameplay, along with rough guidelines for each activity (e.g. Figure 3), we divided the audience into random groups. There were 32 participants in total (18 female, 14 male); they formed seven groups with four to six participants each. The groups were asked to spread out: four groups made use of a nearby corridor, and three stayed in the meeting room. The purpose of this instruction was to give everyone sufficient space and freedom to plan and discuss their manifestos, as well as to introduce an atmosphere of lightly transgressive rule-breaking to the process again in keeping with the nature of revolutionary and avant-garde manifestos. Groups were instructed to spend approximately 10 minutes on the tableau vivant and 15 minutes on the written or drawn manifesto.\r\n4.2.1 Tableau vivant According to Lyon, manifestos represent `bodies in struggle rather than simply ideas in contention\' [34]. To reflect this physical aspect of the manifesto as manifestation, the first exercise in collective manifesto authoring in the structured session took the form of tableau vivant, a parlour game popularised in the Victorian era in which live actors create a `living picture\'. We drew inspiration for using tableau vivant as a\r\n7\r\n\r\ntool in this context from the Brussels-based arts laboratory FoAM, who use tableau vivant as part of their `futuring process\' in working with diverse groups to imagine and bring to life possible futures while embracing `collective spontaneity\' [19]. FoAM uses tableau vivant primarily as a warm-up exercise in their process, and this was also part of our intent: it was a morning session, and we felt participants would benefit from a kinaesthetic icebreaker and group bonding exercise. Moreover, we also wanted to explore tableau vivant as a physical variation distinct from more conventional paper-based manifesto authoring.\r\nFigure 3: Tableau vivant instructions presented during group interactions. Once situated, each group nominated a `director\' who worked with the `actors\' to organise a tableau vivant around a two-card prompt (one `Provocation\' and one `Tone\' card). They had 10 minutes to complete the assignment. For example, one of the groups that remained in the meeting room used the cards \'Increase access\' and `Radical\' to create their tableau vivant (Figure 4, top left). As a prop this group used chairs, which had to first be disassembled, to create a `barricade\'. Other groups composed their tableaux by standing on chairs or sofas, lying on the floor, or making symbolic use of a doorway. Participants used elaborate gestures, including facial expressions, and showed a high level of commitment to this activity. One participant described her group\'s tableau vivant (bottom-left) as follows: `The tableau represents (from left) the designer, the user, the manifesto writer, the critic, and the environment. We had to write a \"radical\" manifesto [i.e. Tone] so we decided to bring down the icon of the user.\' 4.2.2 Group manifesto authoring After the tableau vivant, the groups chose a scribe and used the MANIFESTO! gamesheet and a full hand of four cards to create paper-based compositions. As with the individually authored manifestos created during the guerrilla session, the group manifestos were successful in terms of engaging with important issues, using diverse rhetorical and visual styles, and exhibiting many typical manifesto features and tropes, e.g. list of tenets, use of irony (Figure 6), elevated tone, and so on. Unlike the individual exercise (which was untimed), groups had the added task of harmonising different viewpoints and reaching consensus. As a result, group manifestos tended to be shorter if no less interesting. As one group pointed out in their survey, the manifesto is ideally suited to group work, as it offers `a good mental exercise for generating creative thought and distilling opinions\'. However, not all groups reached consensus: when contemplating the Provocation card `Feminist everything\', one group decided to split in half, producing two different paperbased manifestos using the same cards. While some groups complained in their surveys about the limited timeframe, all managed to produce a manifesto by the end of 15 minutes.\r\n8\r\n\r\nFigure 4: Tableaux vivants using the Tone and Provocation cards from MANIFESTO! Counter-clockwise from top-left, the respective cards enacted were: \'Increase access\' and \'Radical\'; \'Challenge inequality\' and\r\n\'Outraged\'; \'We\'re in this together\' and \'Angry\'; \'Better for whom\' and \'Radical\'. Images have been rendered as line drawings to protect participant identities.\r\n4.2.3 Performance During the final 10 minutes of the structured CHI interaction, all groups reassembled in the meeting room. They took turns coming to the front of the room to describe their prompt cards and perform their tableau vivant and/or read out their paper-based manifesto with the megaphone in front of livestream cameras. Some of the groups also described their process for working as a team (e.g. reaching consensus) and interpreting the prompt cards in the form of both a `bodied interaction\' and a written manifesto. One of the most surprising aspects of the performance component was the lack of shyness. Groups quickly and eagerly volunteered to present their results and did so with dramatic flair in all cases. This could be attributed to successful group bonding during the tableau vivant, as well as the power of the manifesto to act as a `mask\' that permits uncharacteristic and unconventional behaviour (a topic we explore further in the Discussion).\r\n9\r\n\r\nFigure 5: Sample completed MANIFESTO! gamesheet.\r\nFigure 6: Group authored manifesto and corresponding game cards.\r\n4.3 Survey\r\nAs stated above, we asked participants from both types of interaction to complete a brief paper-based survey (Table 2). In total we collected 16 surveys: eight from the guerrilla session and eight from the structured CHI session, where we collected just one survey per team. Note that the additional survey was the result of the group split described in Section 4.2.2.\r\nTable 2: Survey questions.\r\nQ1 Do you think you expressed something important in your manifesto? Please elaborate. Q2 Would you write another manifesto? Why or why not? Q3 What would you most like to change about the CHI community / HCI discipline? Q4 Do politics belong in CHI? Please elaborate.\r\n10\r\n\r\nQ5 Did you subvert the rules of the game? If so, how? In response to Q1, participants all affirmed having expressed something important in their manifesto. Some went further in suggesting they would be willing to be more active in carrying these ideas through in their professional roles. One respondent stated: `I want to continuously engage communities and people and break out of our CHI elitist bubble. Tech should help people, reduce global negativity and should be accessible to all. Responsible and sustainable tech are in my heart, so is making the future more available to everyone.\' For Q2, all participants stated that they would be willing to write another manifesto; one individual reported that manifesto writing is already something they do `on a weekly basis to get my act together.\' Others described the manifesto as `empowering\', `more actionable and emotional\', giving `a different edge\', and a welcome respite from `academic blancmange\'. Responses to Q3 were wide-ranging and passionate, with participants making numerous suggestions for change within the HCI community. All respondents to Q4, apart from one, identified politics as an integral feature of the HCI discipline. In terms of subverting the rules of the game (Q5), most said they were content to play by the rules (`it works\'), with a few suggesting minor alterations, e.g. co-directing, rather than choosing one director/leader. We return to these and other insights in the following section.\r\nFigure 7: Notes from group interactions.\r\n11\r\n\r\n5 Discussion\r\n5.1 The Manifesto Mask and Bodied Interaction\r\n`Man is least himself when he talks in his own person. Give him a mask, and he will tell you the truth.\' - Oscar Wilde, `The Critic as Artist\' (1891) [51]\r\n`The mask is a motif that appears frequently in the drama of the manifesto\' [26], enabling the author to speak more boldly than social norms would usually allow. In an academic context, the manifesto\'s mask is useful as it lends the wearer symbolic authority (which they might not otherwise feel) and licence to express powerful emotions such as anger or outrage. We observed use of the mask across all of the individual and group artefacts we collected. In terms of the paper-based manifestos, participants used rhetorical and visual strategies that borrowed from and often directly referenced famous historical examples, such as The Communist Manifesto (e.g. `Stop the oppression of the user\') and the U.S. Declaration of Independence (e.g. `A Declaration of Non-Independence\'). This was, in part, encouraged by the cards, especially the Opening (`Come, Comrades\', `We declare\') and Tone cards (`Outraged\', `Angry\'), as well as the sample MANIFESTO! gamesheet (Figure 5). In the case of the structured CHI interaction, participants were also introduced to this theatrical style with our initial modelling of a manifesto using a megaphone.\r\nCommon rhetorical features appeared across the paper-based manifestos. Not surprisingly, all of the manifestos displayed a sustained elevated tone - whether apocalyptic (`We are on the brink of extinction\'), conspiratorial (`Ban the use of secretive algorithms now!\'), or militant (`Fight fascism\'). As mentioned above (Figure 6), one group adopted a playful, ironic stance, declaring `Death to co-design\' and `Quantity over quality\'. Other hallmarks of the manifesto were present, including a list of tenets, use of violent and destructive verbs (`challenge\', `attack\', `topple\', `break\'), exhortations and appeals (`Join us\' or `We request\' followed by a list, `Listen first\', `Be open\' ...), and broad declarations (`Everyone is a guru\'). In addition, we find the use of binaries and dichotomies (`academic mask\' vs. `true\' self), semantic and syntactic shifts (`In the past few years\'  `We must\'), and bilingualism (Chinese-English). The manifestos employed a diverse cast of agents and actors: from users, to the HCI community and the \'CHI-verse\', to corporations (including specific references to the CHI sponsors Facebook, Google, and Uber).\r\nThere were also numerous visual features shown in the paper-based manifestos. These included bright colours, colour-coding (e.g. for each demand), use of all caps for keywords and slogans, stick figures with speech bubbles, symbols (arrows, anarchy), user faces, stickers and other collage elements, and shorthand diagrams (the Earth, a classroom, institutional machinery). One manifesto used purely visual means to striking effect in conveying its simple revolutionary message: the `#CHI2019\' conference sign, used by attendees for taking selfies, burning with pink and blue flames, and a deck of MANIFESTO! cards reimagined as a box of matches.\r\nUse of the manifesto `mask\' and other dramatic effects also featured prominently in the tableau vivant and performance components of the structured session. Aside from the megaphone, groups made props from chairs and computer devices. The tableaux vivants created archetypal, iconic poses and compositions (Figure 4). Several participants chose to stretch out on the floor, and generally showed a willingness to take their work into public spaces (the corridor) and perform without shyness in front of passersby.\r\nThis `bodied interaction\' proved to be an essential method not just for breaking the ice, building trust, and facilitating group bonding, but also for overcoming difficulties that may come with expressing ideas verbally. While the groups discussed their compositions in advance, the kinaesthetic activity, interactional effects, and fun involved in achieving their tableaux enabled them to communicate non-verbally through space and to physically embody the different experiences being conveyed. According to one participant (Figure 4, top-left): `The basic message of the tableau vivant was the accessibility of CHI (or HCI conference more generally). The chairs represent a barrier that people are struggling with in order to reach CHI ­ a barrier that is seen as not needing to be there. This year the small rooms and layout of the\r\n12\r\n\r\nconvention centre made it difficult to reach some of the sessions for a lot of people. But, we were thinking also of other barriers, such as money, visas, time off work, etc. that prevent a lot of people from accessing the academic community in the same way as everyone else.\'\r\nReminiscent of the `Dance Your PhD\' contest in its unexpected crossing of boundaries,5 the raw and largely unmediated nature of the tableau vivant lent it force and immediacy, while providing a strong foundation for the group writing exercise that followed. This is a unique and effective tool for stimulating discussion and energising groups around a task. Its recursive power carries this enthusiasm forward into subsequent tasks - in our case, the paper-based manifesto and final performance - and ensures full participation by all group members. We plan to use this method in our future engagements, including testing, and recommend that it be added to the canon of user research methods.\r\n5.2 Implications for Gameplay\r\nThrough both interventions we gained useful insights about our new game, still in its first iteration, and wider insights of relevance to other types of interactions involving rule-based games or group work. Since the guerrilla sessions were individual and the structured interventions group-based, the former untimed and the latter timed, we were able to draw certain conclusions about these basic parameters. Surprisingly, neither time limitations nor individual vs. group authoring had a strong impact on the final product: the manifestos themselves showed similar results. The main differences were that (predictably) the untimed manifestos tended to be slightly longer and more detailed in execution, and the individual manifestos tended to be more personal or idiosyncratic in content as compared with consensus-based group manifestos.\r\nOf more interest to us were the `creative subversions\' and deviations we witnessed, and tacitly encouraged, in all forms of gameplay. These actions fell broadly under two main themes: taking control, and making the game more democratic. In terms of the former, there were several instances where players took control of various aspects of gameplay to make the game more interesting or better suited to their needs. For both guerrilla and structured interactions, some players wanted to choose the cards reflecting issues they care about, which was reasonable. In terms of making the game more democratic, one team chose to give every member a chance to direct and lend their voice, from the tableau vivant to completing the survey. Another group chose not to have a director at all for the tableau vivant (Figure 7).\r\nCreative subversion extended to our own interaction design and the planning of both interventions, where our intention was to disrupt conventional academic modes and facilitate discussions around institutional change. Our methods included: guerrilla canvassing, breaking free from the meeting room, and (mis)using spaces (e.g. an abandoned sponsor booth, an empty corridor) and objects (e.g. delivering a presentation through a megaphone). This spirit carried into gameplay, as participants felt permission to be angry and outspoken - which is rare in academic contexts. At the same time, we tried to maintain a `safe space\' for open discussion, keeping the mood light and playful through irony and theatricality. Ultimately, we encouraged creative subversion with the understanding that letting people break the rules can lead to new insights, for example, that players (and academics!) desire greater control over the ways in which they engage, and that some people prefer a more democratic process, even if it means an increase in organisational labour.\r\n5.3 Implications for Fourth-Wave HCI\r\nAs shown in Figure 8, the three major themes that emerge when considering our data with respect to fourthwave HCI were: using the manifesto as a tool for disrupting academic discourse, the role of politics in CHI and HCI (and technology generally), and expressions of a desire for change - spanning numerous issues (from corporate sponsorship, to digital privacy, inclusivity, challenging academic hegemony, etc.) - by members of the HCI community. If fourth-wave HCI is defined by a `primary focus on politics and values\r\n5 https://www.sciencemag.org/projects/dance-your-phd\r\n13\r\n\r\nand ethics\' [8], our findings both reinforce this definition and underline the desire for an even greater, more active engagement with real-world issues that goes beyond mere recognition or discussion into action and change. Moreover, as observed in the structured session at CHI (described above), people want agency in defining their community\'s values and practices. Numerous participants said they were glad to be given a voice in a community where they do not always feel empowered to speak, much less effect change. HCI needs a bold yet constructive and democratic intervention in the spirit of [32] and [31]; HCI needs the manifesto.\r\nFigure 8: Extract from thematic analysis. As the results of our activities at CHI\'19 demonstrate, manifesto writing as an individual or group activity is a fun and effective way to start conversations about future change. At the same time, one possible criticism of manifesto writing is that it represents a merely superficial engagement with serious issues. Manifestos are short and sharp, often emotionally-driven, and they rely on slogans and other forms of eyecatching communication drawn from advertising to convey their messages [28]. Producing an image of a burning CHI sign is certainly engaging on some level, and it works on social media, but arguably it does not lead to deeper discussions; it is the equivalent of a one-line joke, a meme. On the other hand, social media can be an effective tool for galvanising real-world action [3], and the manifesto as a genre is ideally suited to online communication. Moreover, when an image of the `burning CHI\' manifesto was presented recently at another conference [36], it did contribute to a deeper discussion around accessibility, with some CHI attendees and protesters6 describing the events and issues raised at CHI\'19 to others who had not attended. There were also examples in the completed manifestos of deeper questioning, serious criticism, and useful visions of the possible futures of CHI and HCI more broadly. Looking ahead to CHI\'20, and even further ahead to CHI\'30,7 there appears to be a growing desire to incorporate activism for positive change within the HCI community and to address larger political issues.\r\n6 https://twitter.com/jesskorte/status/1126088987108610048 7 http://chi2030.vision\r\n14\r\n\r\n6 MANIFESTO! Futures\r\nWe are currently testing the cards, along with our existing suite of online tools,8 in secondary school and university classrooms in Europe. Improvements to the next iteration of MANIFESTO! include: providing two options per Provocation card (doubling the choice of themes); introducing variations to gameplay instructions, including the tableau vivant; and designing new editions (e.g. Future of Europe and Higher Education editions). We are also developing a digitised version of MANIFESTO! with classrooms and organisations in mind. This will allow the infinite expansion of prompts, accommodating multiple domains, while enabling agile experimentation with new variations, the ability to link to existing examples of online digital manifestos, and smoother integration of social media sharing.\r\nACKNOWLEDGMENTS We gratefully acknowledge the support of LARSyS for funding this project.\r\nREFERENCES [1] Konstantin Aal, Anne Weibert, Reem Talhouk, Vasilis Vlachokyriakos, Karen Fisher, and Volker\r\nWulf. 2018. Refugees & technology: determining the role of HCI research. In Proceedings of the International Conference on Supporting Groupwork (GROUP \'18). ACM Press, New York, NY, USA, 362-364. DOI: 10.1145/3148330.3152160 [2] AIGA (American Institute of Graphic Arts). Design for good. Retrieved 23 May 2018 from http://www.aiga.org/designfor-good [3] Monica Anderson, Skye Toor, Lee Rainie, and Aaron Smith. Activism in the social media age. Pew Research Center. (July 11, 2018). Retrieved 16 June 2019 from https://www.pewinternet.org/ 2018/07/11/activism-in-the-social-media-age/ [4] Mariam Asad. 2018. Prefigurative design as an alternative approach to civic engagement. In Proceedings of the Conference on Computer Supported Cooperative Work & Social Computing (CSCW \' 18). ACM Press, New York, NY, USA, 97-100. DOI: 10.1145/3272973.3272983 [5] Mariam Asad and Christopher A. Le Dantec, 2015. Illegitimate civic participation: supporting community activists on the ground. In Proceedings of the Conference on Computer Supported Cooperative Work & Social Computing (CSCW \'15). ACM Press, New York, NY, USA, 1694-1703. DOI: 10.1145/2675133.2675156 [6] Simone Ashby, Julian Hanna, Sónia Matos, and Ricardo Rodrigues. 2018. Collaborative narrative visions and the Manifesto Machine. In Proceedings of the Conference on Computer Supported Cooperative Work & Social Computing (CSCW \'18). ACM Press, New York, NY, USA, 13-16. DOI: 10.1145/3272973.3272999 [7] Richard Barbrook. 2015. Class Wargames: Ludic Subversion Against Spectacular Capitalism. Minor Compositions, London, UK. [8] Eli Blevis, Kenny Chow, Ilpo Koskinen, Sharon Poggenpohl, and Christine Tsin. 2014. Billions of interaction designers. interactions 21, 6 (October 2014), 34-41. DOI: 10.1145/2674931 [9] Susanne Bødker. 2015. Third wave HCI, 10 years later. interactions 22, 5 (September-October 2015), 24-31. DOI: 10.1145/2804405 [10] Susanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic Conference on Human-Computer Interaction (NordiCHI \'06). ACM Press, New York, NY, USA, 1-8. DOI: 10.1145/1182475.1182476 [11] Harry Brignull and Yvonne Rogers. 2003. Enticing people to interact with large public displays in public spaces. In Proceedings of the IFIP International Conference on Human-Computer Interaction (INTERACT \'03). DOI: 10.1.1.129.603 [12] Stuart Candy. The Thing From The Future. The Sceptical Futuryst. (20 October 2015). Retrieved June 17, 2019 from https://futuryst.blogspot.com/2015/10/the-thing-from-future.html [13] Damian Carrington. \'Climate Apartheid\': UN expert says human rights may not survive. The Guardian. (25 June 2019). Retrieved 25 June 2019 from https://www.theguardian.com/\r\n8 https://www.wordsinfreedomproject.org\r\n15\r\n\r\n[14] Mary Ann Caws. 2001. Manifesto: A Century of Isms. University of Nebraska Press, Lincoln, NE, USA.\r\n[15] Jim Dator. 2009. Alternative futures at the Manoa School. Journal of Futures Studies, 14, 2, 1-18. [16] Anthony Dunne. 2005. Hertzian Tales (rev. ed.). MIT Press, Cambridge, MA. [17] Anthony Dunne and Fiona Raby. 2013. Speculative Everything: Design, Fiction and Social Dreaming.\r\nMIT Press, Cambridge, MA. [18] Melanie Feinberg, Sarah Fox, Jean Hardy, Stephanie Steinhardt, and Palashi Vaghela. 2019. At the\r\nintersection of culture and method: designing feminist action. In Proceedings of the Designing Interactive Systems Conference (DIS \'19). ACM Press, New York, NY, USA, 365-368. DOI: 10.1145/3301019.3319993 [19] FoAM (2015). A Futurist\'s Fieldguide. https://libarynth.org/futurist_fieldguide/start [20] Christopher Frauenberger, Judith Good, and Narcis Pares. 2016. Autism and technology: beyond assistance & intervention. In Proceedings of the Conference on Human Factors in Computing Systems (CHI \'16). ACM Press, New York, NY, USA, 3373-3378. DOI: 10.1145/2851581.2856494 [21] Ester Fritsch, Irina Shklovski, and Rachel Douglas-Jones. 2018. Calling for a revolution: an analysis of IoT manifestos. In Proceedings of the Conference on Human Factors in Computing Systems (CHI \'18). ACM Press, New York, NY, USA, Paper No. 302. DOI: 10.1145/3173574.3173876 [22] Anne C. Galloway, Jonah Brucker-Cohen, Lalya Gaye, Elizabeth Goodman, and Dan Hill. Design for hackability. 2004. In Proceedings of the Designing Interactive Systems Conference (DIS \'04. ACM Press, New York, NY, USA, 363-366. DOI: 10.1145/1013115.1013181 [23] Andrew Goffey. 2008. Algorithm. In Matthew Fuller (Ed.) Software Studies: A Lexicon. MIT Press, Cambridge, MA, USA, 15-20. [24] Julian Hanna, Simone Ashby, Sónia Matos, Alexis Faria, and Ricardo Rodrigues. 2019. Dissent by design: a manifesto for CHI manifestos. In Extended Abstracts of the Conference on Human Factors in Computing Systems (CHI \'19). ACM Press, New York, NY, USA, Paper No. alt11. DOI: 10.1145/3290607.3310423 [25] Julian Hanna. 2019. Future shock: manifestos in the digital age. Hyperrhiz: New Media Cultures 20. DOI: 10.20415/hyp/020.ex02 [26] Julian Hanna. 2017. \'BLAST First (from politeness) ENGLAND\': The manifesto in Britain and Ireland. Modernist Cultures 12, 2, 297-315. DOI: 10.3366/mod.2017.0172 [27] Julian Hanna, James Auger, and Enrique Encinas. 2017. Reconstrained design: a manifesto. In Proceedings of the Designing Interactive Systems Conference (DIS \'17). ACM Press, New York, NY, USA, 177-181. DOI: 10.1145/3064857.3079141 [28] Julian Hanna. 2014. Manifestos: a manifesto. Atlantic 24. (June 2014). Retrieved 4 June 2014 from https://www.theatlantic.com/entertainment/archive/2014/06/manifestos-a-manifesto-the-10-things-allmanifestos-need/372135/ [29] Julian Hanna. 2009. Key Concepts in Modernist Literature. Palgrave Macmillan, Basingstoke, UK. [30] Harry Hochheiser and Jonathan Lazar. 2007. HCI and societal issues: a framework for engagement. Int J of Human-Computer Interaction 23, 3, 339­374. [31] Joichi Ito. 2017. Resisting reduction: a manifesto. Retrieved 15 June 2018 from https://jods.mitpress.mit.edu/pub/resisting-reduction [32] Bruno Latour. 2010. An attempt at a \'compositionist manifesto\'. New Literary History 41, 471-490. [33] Conor Linehan and Ben Kirman. 2014. Never mind the bollocks, i wanna be anarCHI: a manifesto for punk HCI. In Proceedings of the Conference on Human Factors in Computing Systems (CHI \'14). ACM Press, New York, NY, USA, 741-748. DOI: 10.1145/2559206.2578880 [34] Janet Lyon. 1999. Manifestoes: Provocations of the Modern. Cornell University Press, Ithaca, NY, USA. [35] Clara Mancini. 2011. Animal-computer interaction: a manifesto. interactions 18, 4, 69-73. [36] Sónia Matos, Simone Ashby, Julian Hanna, and Ricardo Rodrigues. 2019. Youth, politics and civic participation: the \'Manifesto Machine\'. In Proceedings of the 9th International Conference on Communities and Technologies, ACM Press, New York, NY, USA, 5-8. DOI: 10.1145/3328320.3328374 [37] Karl Marx and Friedrich Engels. 2002. The Communist Manifesto. Penguin, London, UK. [38] Jane McGonigal. 2010. Gaming can make a better world. Video. (17 March 2010). Retrieved 26 June 2019 from https://www.ted.com/talks/\r\n16\r\n\r\n[39] Marianna Obrist, Patrizia Marti, Carlos Velasco, Yunwen (Tutu) Tu, Takuji Narumi, and Naja L. Holten Møller. 2018. The future of computing and food. In Proceedings of the International Conference on Advanced Visual Interfaces (AVI \'18). ACM Press, New York, NY, USA, Paper No. 5. DOI: 10.1145/3206505.3206605\r\n[40] Marjorie Perloff. 2003. The Futurist Moment. University of Chicago Press, Chicago, IL, USA. [41] Mary Pilon and Samuel Granados. 2015. The roots of Monopoly: how a left-wing game became a\r\npopular symbol of capitalism. Washington Post. Retrieved 12 June 2019 from http://www.washingtonpost.com/graphics/lifestyle/magazine/monopoly/ [42] Sebastian Prost, Johann Schrammel, and Manfred Tscheligi. 2014. \'Sometimes it\'s the weather\'s fault\': sustainable HCI & political activism. In Proceedings of the Conference on Human Factors in Computing Systems (CHI EA \'14). ACM Press, New York, NY, USA, 2005-2010. DOI: 10.1145/ 2559206.2581358 [43] Martin Puchner. 2000. Screeching voices: avant-garde: manifestos in the cabaret. European AvantGarde: New Perspectives. Dietrich Scheunemann (Ed.). Rodopi, Amsterdam, Netherlands, 113-35. [44] Jacques Rancière. 2010. Dissensus: On Politics and Aesthetics. Continuum, London, UK. [45] Dries de Roeck, Karin Slegers, Johan Criel, Marc Godon, Laurence Claeys, Katriina Kilpi, and An Jacobs. I would DiYSE for it!: a manifesto for do-it-yourself internet-of-things creation. In Proceedings of the 7th Nordic Conference on Human-Computer Interaction (NordiCHI \'12). ACM Press, New York, NY, USA, 170-79. DOI: 10.1145/2399016.2399018 [46] Angelika Strohmayer, Rosanna Bellini, Janis Meissner, Samantha Mitchell Finnigan, Ebtisam Alabdulqader, Austin Toombs, and Madeline Balaam. 2018. #CHIversity: implications for equality, diversity, and inclusion campaigns. In Proceedings of the Conference on Human Factors in Computing Systems (CHI EA \'18). ACM Press, New York, NY, USA, Paper No. alt03. DOI: 10.1145/ 3170427.3188396 [47] Reem Talhouk, Kellie Morrissey, Sarah Fox, Nadia Pantidi, Emma Simpson, Lydia Emma Michie, and Madeline Balaam. 2018. Human computer interaction & health activism. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Proceedings of the Conference on Human Factors in Computing Systems (CHI EA \'18). ACM Press, New York, NY, USA, Paper No. SIG15. DOI: 10.1145/3170427.3185369 [48] Cameron Tonkinwise. 2015. Just design: being dogmatic about defining speculative critical design future fiction. Medium. (5 October 2015). Retrieved 16 June 2019 from https://www.cryptoludology.com/?p=147 [49] Vasilis Vlachokyriakos, Rob Comber, Karim Ladha, Nick Taylor, Paul Dunphy, Patrick McCorry, and Patrick Olivier. 2014. PosterVote: expanding the action repertoire for local political activism. In Proceedings of the Conference on Designing Interactive Systems (DIS \'14). ACM Press, New York, NY, USA, 795-804. DOI: 10.1145/2598510.2598523 [50] David I. Waddington. 2013. A parallel world for the World Bank: a case study of Urgent: Evoke, an educational alternate reality game. Revue Internationale Des Technologies En Pédagogie Universitaire (International Journal of Technologies in Higher Education) 10, 3, 42­56. [51] Oscar Wilde. 1982. The Artist as Critic: The Critical Writings of Oscar Wilde. University of Chicago Press, Chicago, IL, USA. [52] Felix Wong. 2016. That day we left: a somber look at the Syrian refugee crisis. Cliqist. (2 August 2016). Retrieved 18 June 2019 from http://cliqist.com/2016/08/02/day-left-syrian-refugee-crisis/\r\n17\r\n\r\n',1,'Ashby','Simone Ashby, Julian Hanna, Sónia Matos, Callum Nash, and Alexis Faria','Simone Ashby *(Madeira ITI/LARSyS, Portugal and University of Madeira, Portugal)*<br>\r\nJulian Hanna *(Madeira ITI/LARSyS, Portugal)*<br>\r\nSónia Matos *(Madeira ITI/LARSyS, Portugal)*<br>\r\nCallum Nash *(School of Design, Northumbria University, UK)*<br>\r\nAlexis Faria *(Madeira ITI/LARSyS, Portugal and University of Madeira, Portugal)*','http://nrl.northumbria.ac.uk/40462/',1,'10.1145/3363384.3363467','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,65,10,NULL,NULL,0,23);
INSERT INTO `bolt_programme` VALUES (41,'altarriba-bertran-designing-for-play-that-permeates-everyday-life-towards-new-methods-for-situated-play-design','2019-09-02 15:24:57','2019-11-14 14:15:01','2019-09-02 15:24:57',NULL,1,'published','[]','Designing for Play that Permeates Everyday Life: Towards New Methods for Situated Play Design','In this paper we discuss strategies to support our design research agenda of promoting playful engagement within everyday activities and situations. We argue that this agenda is in alignment with the ethos of the third wave of HCI. To support design in this space, we build upon Situated Play Design, an open methodological frame that focuses on uncovering existing manifestations of contextual play as a starting point for designing playful technology. Towards further developing that approach, here we highlight a series of emergent methodological challenges, and speculate tactics to address them. Our contribution is a methodological reflection of how to support situated play design, as well as an invitation for designers to continue envisioning, articulating and sharing new methods in this emerging space.','Ferran Altarriba Bertran, Elena Márquez Segura, Jared Duval, and Katherine Isbister. 2019. Designing for Play that Permeates Everyday Life: Towards New Methods for Situated Play Design. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363400](https://doi.org/10.1145/3363384.3363400 \"DOI for the article \'Designing for Play that Permeates Everyday Life: Towards New Methods for Situated Play Design\'\")','1 INTRODUCTION\r\n\r\nDuring the last years we have witnessed how digital technology has been increasingly present in our lives. Human-Computer Interaction (HCI) has extended its focus from creating useful tools for task-related application domains to exploring how technology can support us experientially and respond to our socio-emotional needs, e.g. [27, 30, 32]. This experiential turn has characterized the so-called third wave of HCI [8].\r\n\r\nWithin this context, play and game design research has flourished within the HCI and Interaction Design (IxD) communities. A major strand of work has embraced play design knowledge to craft compelling experiences in application domains that are not purely entertainment activities [19, 24, 29, 33, 39]. Playful technologies now transcend the scope of entertainment games, and are more present in our lives [60] featuring in a variety of domains such as education (e.g., [49]), health (e.g., [56]), or the workplace (e.g., [43]). Given the broadening of the design space of play design and its application domains, we see a need to revisit play design approaches and methods.\r\n\r\nAddressing recent calls for new methods in HCI/IxD [62] and Participatory Design [7, 9], and building on User-Centered Design methods in play design [2, 3, 22], Situated Play Design (SPD) [1] was recently proposed as an approach to designing playful experiences intertwined with everyday activity. Rather than specifying and prescribing a fixed set of design methods and practices, SPD gives pointers to a diverse set of tools for designing for play—it is an evolving framework open for the play design community to appropriate and complete with new methods. To continue developing this approach, in this paper we highlight a series of methodological challenges we have encountered when designing for situated play, and highlight the need for future research that addresses them. We hope that our contribution will inspire play designers to create new design research methods, under the open frame of Situated Play Design, that respond to the emergent challenges of designing playful interventions that intertwine well with everyday activity.\r\n\r\n2 THE DESIGN SPACE OF SITUATED AND EMERGENT PLAYFUL TECHNOLOGY\r\n\r\nThe design space of situated and emergent playful technology, i.e. technology design that supports the emergence of play interwoven with everyday practices and activities, includes works that respond to diverse values and understandings the role of play in human life. One subset of non-entertainment play designs are those that leverage the motivational power of play to support utilitarian agendas. For example, gamification [12, 18, 61] uses game elements to make non-game activities more compelling, responding to the ultimate goal of motivating users to perform specific tasks that are necessary to achieve productive results in activities that are not intrinsically motivating enough by nature.\r\n\r\nAlthough popular in academia, and especially in the industry sector [61], approaches that focus on the power of play to fulfill productive agendas have received criticism for: reflecting a narrow understanding of play [41, 50]; being too designer-centric [45]; and focusing more on supporting productive outcomes rather than on the play experience itself [40], which has raised ethical concerns [11, 46]. Play designers have proposed inspiring alternatives that embrace a broader understanding of play, a more even focus on intrinsic and extrinsic motivation, and a better balance between the in-the-moment play experience and the productive outcomes. For example, Pearce advocates for the design of productive play [47] that is tied to a purpose beyond entertainment, yet one that is meaningful to users. Nicholson\'s meaningful gamification [45] advocates for player-generated content that emphasizes the experiential value of play. Playification [39, 50] embraces a more diverse and nuanced idea of play than gamification, advocates for playful rather than gameful behavior [39], and focuses on the design of meaningful playful experiences that are intrinsically compelling to players—it strives to make everyday tasks intrinsically fun through the emergence of meaningful situated play [55].\r\n\r\nWhile instrumenting play to support productive goals has received much attention in HCI, works that embrace a less utilitarian understanding of the role of play in human life are gaining traction as well. Those works respond to other values than productivity, e.g. promoting curiosity and exploration, facilitating social connections or, more generally, supporting well-being. For example, Sicart makes a “call to playful arms [...] against efficiency, seriousness, and technical determinism” [53, p. 5], and Gaver proposes that technology should allow us to “pursue our lives, not just work” [24, p. 1]. The idea of using technology to help people enjoy experiences they long for, and not only help them “get the chores done” [24, p. 1], is shared by others, e.g. Bekker et al.’s work on open-ended and tangible playful interaction [4, 5, 6, 57]. or Isbister et al. [34] and Márquez Segura et al.’s [37] work on the social affordances of co-located play.\r\n\r\n3 CHASING PLAY POTENTIALS TO INSPIRE INTERACTION DESIGN\r\n\r\nIn our design focus to support the emergence of open-ended playful engagement within everyday activity, we align more with playification than gamification approaches, as well as with less utilitarian everyday play interventions that focus on enriching everyday activities playfully with added social and emotional value. Situated Play Design (SPD) [1] was recently proposed as a novel approach to support that agenda. SPD focuses on uncovering existing manifestations of contextual play and using them as a starting point for design. These manifestations, framed as play potentials [1], emerge naturally as users engage in their everyday context and activities, and are presumably meaningful to them. SPD proposes three iterative steps to pursue and make design use of these play potentials: First, designers chase play potentials when interacting with users in (semi-) naturalistic settings; Second, a design intervention is created to support and enhance those potentials; Third, the intervention is deployed in the wild, where its impact can be evaluated.\r\n\r\nSPD builds on and extends existing User-Centered Design (UCD), Participatory Design (PD) or game and play design strategies. Similar to UCD, SPD includes users in the design process, but considers them as more active design contributors, and creative partners [20]. Regarding user participation, SPD is inspired by Participatory Design (PD) [21, 28, 44], but it is primarily concerned with play and playfulness. Instead of focusing on what stakeholders want, SPD focuses on what they do and, in particular, on how they engage playfully in their everyday activities. Further, while in SPD users take a prominent design role, solutions do not necessarily reflect a completely democratic process like in PD; the designer is responsible for identifying and building on the observed play potentials. The novelty of SPD is the proposal of chasing play potentials that naturally emerge in real-life activities as the starting point of play design—thereby supporting, rather than disrupting, real-life activities by realizing their play potentials.\r\n\r\n4 CHARTING THE WAY FORWARD: NEW METHODS TO REALIZE THE WORLD\'S PLAY POTENTIALS\r\n\r\nExisting design research methods can be useful to design for play that intertwines well with everyday activity. In our work, we found several of them useful, ranging from active interventions in direct interaction with stakeholders (e.g. embodied sketching [38]) to more passive non-disruptive observations (e.g. design ethnography [16]), and interventions with diverse degrees of designer involvement in between (e.g. cultural probes [23], provotypes [10], or tangible interviewing tools [15]).\r\n\r\nWe suspect that other game and play design works may be using participatory and situated strategies (e.g. some playification works, like [39]); yet many do not often fully elaborate on how this can be done. As a result, designers often lack methodological guidance and examples for how to uncover and use play potentials in design. We point to this area as one that needs attention from the play design research community. Here we highlight a number of unaddressed challenges we have encountered in our practice, which we argue are inherent to SPD.\r\n\r\nHow do we talk about play? Play is an abstract, elusive concept. It is often difficult to talk about it—not only do we lack a robust language for the aesthetic experience of play [52], but we also lack mechanisms to facilitate multi-stakeholder conversations about it. Design researchers have long been using tangible tools to facilitate conversations, e.g. [15]. However, those tools often explore issues other than play (e.g. business innovation [13] or stakeholder empowerment [59]) and focus more on the stakeholders’ pragmatic needs than on their playful cravings. We see a need for tangible conversation materials that focus specifically on play by bridging current tools with play-focused theories (e.g. [52]), frameworks (e.g. [2]) and taxonomies (e.g. [14]).\r\n\r\nHow can we chase play in the wild? Play potentials are often spontaneous and hard to predict. Their ephemeral nature challenges the task of chasing them and realizing them by design. We see a need for mechanisms that help designers respond effectively to the emergence of playful engagement. Inspired by existing methods for first-person research [36] and embodied ideation [58], we propose to create tools that empower designers to capture the play potentials emerging around them. We also suggest it might be interesting to crowd-source that process. Given the ubiquitous nature of social media, we wonder: could we use it to capture personal accounts of playful engagement, and share those play potentials so that they can be discussed through, and cross-referenced with, other people\'s very own personal experiences?\r\n\r\nHow can we ground playful inspiration in culture and traditions? We argue that culture and traditions are rich areas for chasing play that have not yet received enough attention. That is a missed opportunity, as play shapes and is shaped by culture, everyday practices are imbued with play [14], and societies can be understood by looking at how their members play [31]. We see a lack of actionable methods that help designers chase and make design use of play potentials embedded in traditions. We propose to explore how to leverage such latent knowledge. We wonder: how might play designers identify interesting manifestations of play that are culturally embedded, and unpack them so that they can become a useful design material?\r\n\r\nHow can we design for playful engagement within future activities and scenarios? The role of IxD is not only to design for today, but also to envision the technologies of the future. Speculative methods help designers and other stakeholders imagine technology futures and reflect on the human-technology interplay in those future scenarios. They typically result in design concepts that embody a critique of mainstream approaches to technology design. Although there are exceptions (e.g. [42]), those methods are often more critical and rhetorical than embodied and experiential—they are better suited to raise controversial issues than to explore the potential of technology to support novel and rich playful experiences. We propose to adapt existing speculative design methods to focus on projecting playful futures. That move can be inspired by existing design methods that put the focus on embodiment, improvisation and material engagement, e.g. embodied sketching [38], post-dramatic theatre [48], or LARPing as a platform for technology co-creation [17, 37, 51].\r\n\r\nHow can we realize the world\'s play potentials here and now? We argue that one of the limitations of contemporary play design research is that its outcomes are mostly disseminated within academia. That is at odds with the notion that play designers have both the opportunity and the responsibility to be political and address important social issues [26]. Inspired by recent calls to rethink Participatory Design [9], we argue that our research should have a direct impact on people\'s lives, here and now, and not only within academia. If we want to realize the world\'s play potentials, promoting playful transformations in the communities involved in our research should be as important as publishing academic work. Existing HCI dissemination forms hardly serve that purpose—even annotated portfolios [35], highly visual and inspirational, target researchers and designers as audience. Inspired by experimental forms of knowledge-transfer in art and design (e.g. Gaver\'s cultural commentaries [25] or Simon\'s participatory exhibitions [54]), we invite play designers to experiment with new forms of dissemination that make accessible to the general public the outcomes of situated play design, e.g. through public annotated exhibitions of their multi-stakeholder play design processes and the resulting designed artefacts.\r\n\r\n5 CONCLUSION\r\n\r\nIn this paper we focused on a research agenda of infusing play into everyday life, which aligns with the values of the third wave of HCI. Situated Play Design is an approach to design that proposes an open set of methods that can help designers chase play potentials and realize them by design. Here we discussed existing design research strategies that can be helpful for this purpose. Most importantly, we also: i) stressed the need for more methods to guide situated and emergent play design; and ii) highlighted a series of unaddressed challenges, speculating about their implications and relevance. While this paper does not cover all the methodological gaps within Situated Play Design, it serves as a provocation for playful interaction designers to share their own practices within the frame of SPD.\r\n\r\nREFERENCES\r\n\r\nFerran Altarriba Bertran, Elena Márquez Segura, Jared Duval, and Katherine Isbister. 2019. Chasing Play Potentials: Towards an Increasingly Situated and Emergent Approach to Everyday Play Design. In Proceedings of the ACM Conference on Designing Interactive Systems(DIS ’19). https://doi.org/10.1145/1858171.1858228  \r\nJuha Arrasvuori, Marion Boberg, Jussi Holopainen, Hannu Korhonen, Andrés Lucero, and Markus Montola. 2011. Applying the PLEX framework in designing for playfulness. In Proceedings of the 2011 Conference on Designing Pleasurable Products and Interfaces. ACM, 24.  \r\nTilde Bekker, Linda De Valk, and Berry Eggen. 2014. A toolkit for designing playful interactions: The four lenses of play. Journal of Ambient Intelligence and Smart Environments 6, 3(2014), 263–276.  \r\nTilde Bekker, Ben Schouten, and Mark de Graaf. 2014. Designing interactive tangible games for diverse forms of play. Handbook of digital games(2014), 710–729.  \r\nTilde Bekker, Janienke Sturm, and Berry Eggen. 2010. Designing playful interactions for social interaction and physical play. Personal and Ubiquitous Computing 14, 5 (2010), 385–396.  \r\nTilde M Bekker and Berry H Eggen. 2008. Designing for children\'s physical play. In CHI’08 extended abstracts on Human factors in computing systems. ACM, 2871–2876.  \r\nErling Bjögvinsson, Pelle Ehn, and Per-Anders Hillgren. 2012. Design things and design thinking: Contemporary participatory design challenges. Design Issues 28, 3 (2012), 101–116.  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 1–8.  \r\nSusanne Bødker and Morten Kyng. 2018. Participatory design that matters—Facing the big issues. ACM Transactions on Computer-Human Interaction (TOCHI) 25, 1(2018), 4.  \r\nLaurens Boer and Jared Donovan. 2012. Provotypes for participatory innovation. In Proceedings of the designing interactive systems conference. ACM, 388–397.  \r\nIan Bogost. 2016. Play anything: The pleasure of limits, the uses of boredom, and the secret of games. Basic Books.  \r\nBiran Burke. 2016. Gamify: How gamification motivates people to do extraordinary things. Routledge.  \r\nJacob Buur and Robb Mitchell. 2011. The business modeling lab. In Proceedings of the Participatory Innovation Conference. 368–373.  \r\nRoger Caillois. 2001. Man, play, and games. University of Illinois Press.  \r\nSimon Clatworthy, Robin Oorschot, and Berit Lindquister. 2014. How to get a leader to talk: Tangible objects for strategic conversations in service design. In ServDes. 2014 Service Future; Proceedings of the fourth Service Design and Service Innovation Conference; Lancaster University; United Kingdom; 9-11 April 2014. Linköping University Electronic Press, 270–280.  \r\nAndrew Crabtree, Mark Rouncefield, and Peter Tolmie. 2012. Doing design ethnography. Springer.  \r\nElla Dagan, Elena Márquez Segura, Ferran Altarriba Bertran, Miguel Flores, and Katherine Isbister. 2019. Designing ’True Colors’: A Social Wearable that Affords Vulnerability. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM.  \r\nSebastian Deterding. 2011. Meaningful play: Getting gamification right. Google Tech Talk 24(2011), 2011. \r\nSebastian Deterding, Staffan L Björk, Lennart E Nacke, Dan Dixon, and Elizabeth Lawley. 2013. Designing gamification: creating gameful and playful experiences. In CHI’13 Extended Abstracts on Human Factors in Computing Systems. ACM, 3263–3266.  \r\nAllison Druin. 2002. The role of children in the design of new technology. Behaviour and information technology 21, 1 (2002), 1–25.  \r\nPelle Ehn. 2017. Scandinavian design: On participation and skill. In Participatory design. CRC Press, 41–77.  \r\nTracy Fullerton. 2014. Game design workshop: a playcentric approach to creating innovative games. AK Peters/CRC Press.  \r\nBill Gaver, Tony Dunne, and Elena Pacenti. 1999. Design: cultural probes. interactions 6, 1 (1999), 21–29. \r\nWilliam Gaver. 2002. Designing for homo ludens. I3 Magazine 12, June (2002), 2–6.  \r\nWilliam Gaver. 2007. Cultural commentators: Non-native interpretations as resources for polyphonic assessment. International journal of human-computer studies 65, 4 (2007), 292–305.  \r\nWilliam Gaver. 2015. Homo ludens (subspecies politikos). In The gameful world: Approaches, issues, applications, Sebastian Deterding and Steffen P. Walz (Eds.). MIT Press Cambridge, MA.  \r\nLars Hallnäs and Johan Redström. 2001. Slow technology–designing for reflection. Personal and ubiquitous computing 5, 3 (2001), 201–212.  \r\nKim Halskov and Nicolai Brodersen Hansen. 2015. The diversity of participatory design research practice at PDC 2002–2012. International Journal of Human-Computer Studies 74 (2015), 81–92.  \r\nMads Hobye. 2014. Designing for Homo Explorens: open social play in performative frames. Faculty of Culture and Society Malmö University.  \r\nKristina Höök, Martin P Jonsson, Anna Ståhl, and Johanna Mercurio. 2016. Somaesthetic appreciation design. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 3131–3142.  \r\nJohan Huizinga. 1950. Homo Ludens. Boston: Beacon Press.  \r\nKatherine Isbister. 2011. Emotion and motion: games as inspiration for shaping the future of interface. Interactions 18, 5 (2011), 24–27.  \r\nKatherine Isbister. 2016. How games move us: Emotion by design. MIT Press.  \r\nKatherine Isbister, Elena Márquez Segura, and Edward F Melcer. 2018. Social Affordances at Play: Game Design Toward Socio-Technical Innovation. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 372.  \r\nJonas Löwgren. 2013. Annotated portfolios and other forms of intermediate-level knowledge.Interactions 20, 1 (2013), 30–34.  \r\nAndrés Lucero, Audrey Desjardins, Carman Neustaedter, Kristina Höök, Marc Hassenzahl, and Marta E. Cecchinato. 2019. A Sample of One: First-Person Research Methods in HCI. (2019), 385–388. https://doi.org/10.1145/3301019.3319996  \r\nElena Márquez Segura, James Fey, Ella Dagan, Samvid Niravbhai Jhaveri, Jared Pettitt, Miguel Flores, and Katherine Isbister. 2018. Designing Future Social Wearables with Live Action Role Play (Larp) Designers. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 462.  \r\nElena Márquez Segura, Laia Turmo Vidal, Asreen Rostami, and Annika Waern. 2016. Embodied sketching. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 6014–6027.  \r\nElena Márquez Segura, Annika Waern, Luis Márquez Segura, and David López Recio. 2016. Playification: The PhySeEar case. In Proceedings of the 2016 Annual Symposium on Computer-Human Interaction in Play. ACM, 376–388.  \r\nJoe Marshall and Conor Linehan. 2017. Misrepresentation of health research in exertion games literature. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 4899–4910.  \r\nJane McGonigal. 2011. Reality is broken: Why games make us better and how they can change the world. Penguin.  \r\nJoshua McVeigh-Schultz, Max Kreminski, Keshav Prasad, Perry Hoberman, and Scott S Fisher. 2018. Immersive Design Fiction: Using VR to Prototype Speculative Interfaces and Interaction Rituals within a Virtual Storyworld. In Proceedings of the 2018 Designing Interactive Systems Conference. ACM, 817–829. \r\nSherif Mekky and Andrés Lucero. 2016. An Exploration of Designing for Playfulness in a Business Context. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 3136–3143.  \r\nMichael J Muller. 2009. Participatory design: the third space in HCI. In Human-computer interaction. CRC press, 181–202.  \r\nScott Nicholson. 2015. A recipe for meaningful gamification. In Gamification in education and business. Springer, 1–20.  \r\nCasey O\'Donnell. 2014. Getting played: Gamification and the rise of algorithmic surveillance. Surveillance & Society 12, 3 (2014), 349–359.  \r\nCelia Pearce. 2006. Productive play: Game culture from the bottom up. Games and Culture 1, 1 (2006), 17–24.  \r\nMerja Ryöppy, Patricia Lima, and Jacob Buur. 2015. Design Participation as Postdramatic Theatre. In 4th Participatory Innovation Conference 2015. 47.  \r\nEric Sanchez, Shawn Young, and Caroline Jouneau-Sion. 2017. Classcraft: from gamification to ludicization of classroom management. Education and Information Technologies 22, 2 (2017), 497–513.  \r\nAaron Scott. 2014. Meaningful play: how playcentric research methods are contributing to new understanding and opportunities for design. In The Routledge companion to design research. Routledge, 416–430.  \r\nElena Márquez Segura, Katherine Isbister, Jon Back, and Annika Waern. 2017. Design, appropriation, and use of technology in larps. In Proceedings of the 12th International Conference on the Foundations of Digital Games. ACM, 53.  \r\nJohn Sharp and David Thomas. 2019. Fun, Taste, & Games: An Aesthetics of the Idle, Unproductive, and Otherwise Playful. MIT Press.  \r\nMiguel Sicart. 2014. Play matters. MIT Press.  \r\nNina Simon. 2010. The participatory museum. Museum 2.0.  \r\nMattia Thibault. 2017. Play as a Modelling System–a Semiotic Analysis of the Overreaching Prestige of Games. In Proceedings of the 1st International GamiFIN Conference. 105–110.  \r\nDebbe Thompson, Tom Baranowski, Richard Buday, Janice Baranowski, Victoria Thompson, Russell Jago, and Melissa Juliano Griffith. 2010. Serious video games for health: How behavioral science guided the development of a serious video game. Simulation & gaming 41, 4 (2010), 587–606.  \r\nRob Tieben, Tilde Bekker, and Ben Schouten. 2011. Curiosity and interaction: making people curious through interactive systems. In Proceedings of the 25th BCS Conference on Human-Computer Interaction. British Computer Society, 361–370.  \r\nLaia Turmo Vidal and Elena Márquez Segura. 2018. Documenting the Elusive and Ephemeral in Embodied Design Ideation Activities. Multimodal Technologies and Interaction 2, 3 (2018), 35.  \r\nMarleen Van Bergeijk, Bart Hengeveld, and Selma Otto. 2017. DOK: Enhancing Child Patient Empowerment. In Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction(TEI ’17). ACM, New York, NY, USA, 589–595. https://doi.org/10.1145/3024969.3025066  \r\nSteffen P. Walz and Sebastian Deterding. 2015. The gameful world: Approaches, issues, applications. MIT Press.  \r\nKevin Werbach and Dan Hunter. 2012. For the win: How game thinking can revolutionize your business. Wharton Digital Press.  \r\nJohn Zimmerman, Erik Stolterman, and Jodi Forlizzi. 2010. An analysis and critique of Research through Design: towards a formalization of a research approach. In proceedings of the 8th ACM conference on designing interactive systems. ACM, 310–319.  ',1,'Altarriba-Bertran','Ferran Altarriba Bertran, Elena Márquez Segura, Jared Duval, and Katherine Isbister','Ferran Altarriba Bertran *(Social Emotional Technology Lab, UC Santa Cruz, USA)*<br>\r\nElena Márquez Segura *(Uppsala University, Sweden)*<br>\r\nJared Duval *(Social Emotional Technology Lab, UC Santa Cruz, USA)*<br>\r\nKatherine Isbister *(Social Emotional Technology Lab, UC Santa Cruz, USA)*','https://www.researchgate.net/publication/335892590_Designing_for_Play_that_Permeates_Everyday_Life_Towards_New_Methods_for_Situated_Play_Design',1,'10.1145/3363384.3363400','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,80,5,NULL,NULL,0,16),(42,'mxr-panel','2019-09-02 15:24:58','2019-11-20 07:09:40','2019-09-02 15:24:58',NULL,1,'published','[]','Mixed Reality panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Steve Benford, Mike Fraser, Vera Lange, Nicolas LaLone, Joe Marshall, and Anders Lundström','Steve Benford *(Mixed Reality Lab, University of Nottingham, UK)*<br>\r\nMike Fraser *(Department of Computer Science, University of Bath, UK)*<br>\r\nVera Lange * (Centrum IT + Media, Hogeschool van Arnhem en Nijmegen, Netherlands)*<br>\r\nNicolas LaLone *(University of Nebraska Omaha, USA)*<br>\r\nJoe Marshall *(Mixed Reality Lab, University of Nottingham, UK)*<br>\r\nAnders Lundström *(Media Technology and Interaction Design, KTH Royal Institute of Technology, Sweden)*',NULL,0,NULL,NULL,NULL,0,NULL,85,20,NULL,NULL,0,0),(43,'spaces-panel','2019-09-02 15:24:58','2019-09-18 23:46:36','2019-09-02 15:24:58',NULL,1,'published','[]','Public & Private Spaces panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Christian Heath, Paul Luff, Daisy Yoo, Klaudia Çarçani, Dave Murray-Rust, and Oliver Bates','Christian Heath *(King\'s College London, UK)*<br>\r\nPaul Luff *(King\'s College London, UK)*<br>\r\nDaisy Yoo *(Aarhus University, Denmark)*<br>\r\nKlaudia Çarçani *(Faculty of Computer Science, Østfold University College, Norway)*<br>\r\nDave Murray-Rust *(University of Edinburgh, UK)*<br>\r\nOliver Bates *(Lancaster University, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,40,20,NULL,NULL,0,0),(44,'ai-humans-machines-panel','2019-09-02 15:24:58','2019-11-20 07:08:39','2019-09-02 15:24:58',NULL,1,'published','[]','Artificial Intelligence, Humans & Machines panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Lucy Suchman (attending via video link), Alex Taylor, Marina Jirotka, Katherine Isbister, Kashyap Todi, Saul Albert, and Barry Brown','Lucy Suchman *(Lancaster University, UK; attending via video link)*<br>\r\nAlex Taylor *(City, University of London, UK)*<br>\r\nMarina Jirotka *(Department of Computer Science, University of Oxford, UK)*<br>\r\nKatherine Isbister *(Computational Media, UC Santa Cruz, USA)*<br>\r\nKashyap Todi *(Department of Communication and Networking, Aalto University, Finland)*<br>\r\nSaul Albert *(School of Social Sciences, Loughborough University, UK)*<br>\r\nBarry Brown *(Department of Computer and System Sciences, Stockholm University, Sweden)*',NULL,0,NULL,NULL,NULL,0,NULL,85,20,NULL,NULL,0,0),(45,'ubicomp-panel','2019-09-02 15:24:58','2019-11-14 14:12:47','2019-09-02 15:24:58',NULL,1,'published','[]','Ubiquitous Computing panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Yvonne Rogers, Martin J Kraemer, Matthew Lee-Smith, Raphael Kim, Lucia Lupi, Conor Linehan','Yvonne Rogers *(UCL, UK)*<br>\r\nMartin J Kraemer *(Department of Computer Science, University of Oxford, UK)*<br>\r\nMatthew Lee-Smith *(Loughborough Design School, Loughborough University, UK)*<br>\r\nRaphael Kim *(Queen Mary University, University of London, UK)*<br>\r\nLucia Lupi *(DIST, Polytechnic of Turin, Italy and University of Turin, Italy)*<br>\r\nConor Linehan *(University College Cork, Ireland)*',NULL,0,NULL,NULL,NULL,0,NULL,90,20,NULL,NULL,0,0),(46,'arts-design-panel','2019-09-02 15:24:58','2019-11-18 19:10:48','2019-09-02 15:24:58',NULL,1,'published','[]','Arts & Design-led Approaches  panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Bill Gaver, Kristina Höök, Daphne Menheere, Miriam Sturdee, Ahmet Börütecene, Oğuz Turan Buruk, and Ruth Neubauer','Bill Gaver *(Goldsmiths, University of London, UK)*<br>\r\nKristina Höök *(KTH Royal Institute of Technology, Sweden)*<br>\r\nDaphne Menheere *(Industrial Design, Eindhoven University of Technology, Netherlands)*<br>\r\nMiriam Sturdee *(Lancaster University, UK)*<br>\r\nAhmet Börütecene *(Media and Information Technology, Linköping University, Sweden)*<br>\r\nOğuz Turan Buruk *(Gamification Group, Tampere University, Finland)*<br>\r\nRuth Neubauer *(Institute for Design Innovation, Loughborough University, London, UK)*',NULL,0,NULL,NULL,NULL,0,NULL,90,20,NULL,NULL,0,0),(47,'research-design-panel','2019-09-02 15:24:58','2019-11-14 16:09:38','2019-09-02 15:24:58',NULL,1,'published','[]','New Approaches to Research & Design panel','The keynote speaker and presenting authors will take part in a panel discussion with the symposium audience.',NULL,NULL,1,NULL,'Susanne Bødker, Susan Lechelt, Chris Elsden, Anna Ståhl, Airi Lampinen, Julian Hanna, and Ferran Altarriba Bertran','Susanne Bødker *(Aarhus University, Denmark)*<br>\r\nSusan Lechelt *(Design Informatics, University of Edinburgh, UK)*<br>\r\nChris Elsden *(Design Informatics, University of Edinburgh, UK)*<br>\r\nJakob Tholander *(Stockholm University, Sweden)*\r\nAiri Lampinen *(Stockholm University, Sweden)*<br>\r\nJulian Hanna *(Madeira ITI/LARSyS, Portugal)*<br>\r\nFerran Altarriba Bertran *(Social Emotional Technology Lab, UC Santa Cruz, USA)*',NULL,0,NULL,NULL,NULL,0,NULL,90,20,NULL,NULL,0,0),(48,'fratczak-understanding-human-behaviour-in-industrial-human-robot-interaction-by-means-of-virtual-reality','2019-09-03 08:29:56','2019-11-19 12:43:33','2019-09-03 08:29:56',NULL,1,'published','[]','Understanding Human Behaviour in Industrial Human-Robot Interaction by Means of Virtual Reality','As industry automation is evolving, the barriers between humans and machines are slowly disappearing. With humans and intelligent robots working closer together it is imperative to ensure not only physical safety but also the mental and emotional well-being of the workers. This paper uses the HTC Vive Virtual Reality headset to simulate different Human-Robot Interaction situations in which humans and robots constantly operate in a common workspace. It analyses the influence of an industrial robot\'s actions on human behaviour. The results show that the robot\'s behaviour does not influence the performance of human in a significant way, however, it has a large impact on their posture, focus and trust. It is shown that the human tends to naturally regain trust over time, however, the rate at which this takes place is variable and dependent on the robot\'s behaviour.','Piotr Fratczak, Yee Goh, Peter Kinnell, Andrea Soltoggio, and Laura Justham. 2019. Understanding Human Behaviour in Industrial Human-Robot Interaction by Means of Virtual Reality. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 7 pages. [https://doi.org/10.1145/3363384.3363403](https://doi.org/10.1145/3363384.3363403 \"DOI for the article \'Understanding Human Behaviour in Industrial Human-Robot Interaction by Means of Virtual Reality\'\")','1 INTRODUCTION\r\n\r\nIndustry 4.0 has the potential to enable greater use of robotics and autonomous systems in manufacturing. Until recently, conventional automation has usually focused on separating humans and robots for safety reasons. However, while machines excel at performing tasks that require high strength and high repeatability, humans still greatly surpass the capabilities of robots in terms of flexibility, intuition or adaptability to change. Rather than separating humans and robots, it is therefore beneficial to combine the potential of the two in a symbiotic relationship, where humans and robots can collaborate with each other [3]. This idea has led to the development of mechanically safe collaborative robots, commonly termed Cobots. However, for effective collaboration, there are other factors to consider besides physically safe interactions.\r\n\r\nFor a human and a robot to work effectively as a team, a significant level of trust and understanding needs to develop between them [5]. Trust in Human-Robot Collaboration (HRC) depends on the sense of safety, robot\'s reliability, its motion and speed [2]. Humans develop trust from their experience. They learn to adapt to new situations over time. If the robot\'s behaviour is very predictable and repetitive, given enough time, they should be able to collaborate with it. On the other hand, if the robot\'s behaviour changes too rapidly in a HRC scenario, the human\'s trust, workload and performance might suffer [8]. With industry being revolutionised, the concepts of smart manufacturing and flexible factories is becoming more common. Production is becoming more dynamic and individualised, and much work is focused on creating robots that are more autonomous and therefore potentially less predictable [12]. Given the potential for robots to become less predictable, teaching industrial robots to adapt to a human\'s mental and emotional states could potentially improve the quality of the collaboration [11].\r\n\r\nTo allow robots to effectively collaborate with humans, robots need to know how their actions influence their collaborators. Robots need models and strategies that allow them to adjust their own behaviour in a way that improves and sustains the human\'s trust level, mental-state and emotional well-being. For example, if a robot detects a lack of trust in a human-collaborator, it could respond by becoming slower and more predictable.\r\n\r\nDeveloping these models could potentially make machines consider not only the requirements of the task, but also the needs of the human-collaborator. By doing so, Human-Robot Interaction (HRI) could be optimised in terms of sustaining a sufficient quality of the product while finishing the task as quickly as possible and keeping the human mentally and emotionally safe.\r\n\r\nThe influence of an industrial robot\'s velocity and behaviour on humans has been studied by Bortot et al. [1], showing that people are comfortable with higher velocities as long as the behaviour does not change. Furthermore, Höcherl et al. [7] showed that if the robot is predictable, people start trusting it and get comfortable around it, which minimises their hesitation time. The problem with real HRI trials is that they are highly constrained as safety must always be guaranteed. Evoking and studying emotional responses or establishing a lack of trust, whilst making sure the participant is safe, is a difficult task. Additionally, setting up a testing environment requires expensive machines and dedicated space. One way of overcoming these limitations is the use of Virtual Reality (VR), which can be used to simulate a realistic, interactive and immersive industrial environment at a relatively low cost.\r\n\r\nVR has been used to analyse HRI before. Hansen et al. [6] used it to look at the industrial robot\'s speed profile preferences in collaborative meat processing. They found that adapting a robot\'s movement to the individual might be necessary, as different people prefer different speeds. Additionally, they predict that the preferences might change over time (with experience). Matsas et al. [9] used VR to test different control algorithms in industrial HRC to optimise the speed and safety of collaboration. They concluded that a mutual understanding of the intent and behaviour of both parties of the HRC is necessary. Oyekan et al. [10] researched how people react to unexpected robot motion in VR. They used human motion data to classify participants based on the strength of their reactions. However, very little research has been done on human behaviour in the situations, where an unsupervised industrial robot and a human are constantly operating in a common workspace.\r\n\r\nThis paper uses VR to analyse the influence of a robot\'s actions on a human\'s behaviour. It looks at how a virtual robot\'s movement velocity and acceleration and predictability influences a human\'s accuracy, speed and posture, as well as human physiological signals (cardiac and respiration activity). Instead of minimising HRI-related hazards, this paper generates them in order to study post-accident strategies. In particular, this paper analyses how humans react and adapt to the sudden, potentially threatening robot actions.\r\n\r\n2 METHOD\r\n\r\nThe described experiment measures participants’ motion and physiological signals while immersing them in a virtual HRI scenario. Human Participants wear a VR Head Mounted Display and a set of wearable sensors (see Fig. 1).\r\n\r\n2.1 Participants and Apparatus\r\n\r\nThis study was conducted on 32 participants (24 males, 8 females), aged from 19 to 36 years (M: 24.5, SD: 4.8). All of the participants were university students. Out of the 32 participants, 18 participants reported to have never tried VR before, 14 participants reported to have tried it once or twice before, and no participants reported owning (or working with) a VR headset. 19 participants had no experience with industrial robots beyond having seen images or videos of them, 11 participants had basic knowledge of them, 2 participants had working experience with them.\r\n\r\nAdditionally, a control experiment was conducted on 11 participants (7 males, 4 females), aged from 22 to 35 years (M: 25.82, SD: 4.19), 5 of whom have used VR before.\r\n\r\nParticipants were asked to wear a Zephyr Biomodule - a wearable chest-belt, capable of measuring Electrocardiogram (ECG) signals at 1000Hz and breathing waveform signals at 25Hz [13]. After the sensor was fitted correctly, they were helped to put on the HTC Vive VR headset. The full equipment setup can be seen in Fig. 1.\r\n\r\n\r\nFigure 1: Equipment setup.\r\n2.2 Experiment Protocol\r\n\r\nThe experiment was designed using the Unity engine. The idea behind the design of the experiment was to have human participants do a simple task that does not require any specific skills, but still needs some cognitive capability to perform. In the experiment, the participant was sitting on a stool in front of a virtual model of a Yaskawa Motoman SDA20D - an industrial dual arm robot. Participants were asked to keep their hands on their legs. Every few seconds a small sphere appeared in front of them. They were instructed to touch it with the correct hand as quickly as possible. Green spheres were supposed to be touched with the right hand, red spheres - with the left hand. Participants were told to avoid collisions with the robot at all costs. To illustrate the negative consequences of this, touching the robot would cause their vision to go red and blurry and the controllers to start shaking, which feels quite disorienting and unpleasant (see Fig. 2).\r\n\r\n\r\nFigure 2: Effect of touching the robot.\r\nIn the experiment, the robot shared the same workspace as the human. The robot had two speed profiles: slow (maximum velocity of the end effector reaches 1.3 m/s) and fast (maximum velocity of the end effector reaches 3.1 m/s). Additionally, it had two movement types: predictable - simple 1-armed pick and place movements in front of the participant (Fig. 3a) and chaotic - using two arms and moving above the participant\'s head (Fig. 3b). The experiment consisted of six 2-minute parts: 1. Idle robot, 2. Slow predictable robot, 3. Fast predictable robot, 4. Slow chaotic robot, 5. Fast chaotic robot, 6. All random (movement and speed could change at any time). In the middle of the 3rd part, the robot makes a sudden unexpected movement and touches the participant\'s head (such that a collision is impossible to avoid). Around the 30th and the 90th second of the 5th part, the robot makes another sudden unexpected movement and suddenly drops both arms from above the participant\'s head to the table-level (without hitting the participant).\r\n\r\n\r\nFigure 3: Robot Movements.\r\nThe experiment was designed with three assumptions. First of all, a real collaborative robot would be mechanically safe and unable to damage a human. The task of the virtual robot was not to harm the participants, but to make them feel uncomfortable. Secondly, in real life, new workers would always get the time to adapt to slower and predictable robots before they start working in the most extreme situations. In the experiment, the difficulty increased over time and the protocol was not randomised. The final assumption of the design of the experiment was that participants would focus on doing their task as quickly as possible, while still trying to stay safe by avoiding collisions with the robot. Previous research has shown gamification as an approach that successfully motivates people to do their job and improve their performance [4]. With that in mind, participants were scored based on their speed of touching the spheres. Their score and the score of the two closest participants was shown on a leaderboard. To make participants wary of the robot, they would lose points every time they made contact with it.\r\n\r\nIn the control experiment participants were asked to do the same task, however, the robot was idle all the time.\r\n\r\nTo preserve immersion, participants were undisturbed during the whole duration of the experiment. After completing the simulation, participants were asked to remove the VR headset and answer a questionnaire about their thoughts regarding the experiment. Participants were asked fourteen questions (see Table. 1). The first four questions asked about the level of immersion and experience during the whole experiment. Questions 5-7 asked about participants’ motivation as the result of the gamification of the experiment. Questions 8-11 ask about the their thoughts about the robot. The last 3 questions asked about their center of attention.\r\n\r\nThe questions were answered on a monitor by dragging a slider on a continuous scale between strongly disagree (0) and strongly agree (1). Additionally, participants could (but did not have to) write comments about each question individually to justify their answer.\r\n\r\n3 RESULTS\r\n\r\nThree types of results were collected. Self-reports - using a post-test questionnaire, as well as motion data and physiological data captured during the experiment.\r\n\r\n3.1 Self-reports\r\n\r\nTable. 1 shows the answers to the fourteen questions asked after the experiment. According to the answers, the experiment seemed natural and real, however, over time, several participants started feeling less physically comfortable. In the comments, these participants stated that this is due to them leaning backwards after the robot became less predictable.\r\n\r\nTable 1: Mean results of the answers to the questionnaire.\r\n\r\nEven though participants reported being highly committed to getting the best score, they also reported that over time, their focus slightly shifted from the task towards the robot. According to the results of the questionnaire, as the robot became faster and less predictable, people tended to follow it more.\r\n\r\nParticipants reported to be rather focused on the robot (especially in the later parts of the experiment), however, they did not find it to be scary. Several participants commented that the robot was annoying or confusing, but not scary. According to the results, the robot made the task the most difficult, and was the most distracting, not when it was the fastest and the movement was the most overwhelming, but when speed and movement were changing all the time - when they did not know when or how it is going to behave next.\r\n\r\n3.2 Motion data\r\n\r\nDuring the experiment, the position and orientation of the headset and controllers were tracked and saved in real-time. This allowed the extraction of multiple motion features, which describe participant\'s behaviour. Extracted features include velocities/accelerations of the controllers (participant\'s hands), angular velocity/acceleration of the headset (participant\'s head), the ratio of the time when the participant was moving the headset (looking around) to the time when the headset was still, and displacement of the headset in the z-axis (leaning away from the robot). Additionally, by matching the motion data with the events in the experiment (times when the spheres appear in front of the participant), it was possible to extract the participant\'s accuracy (defined as the path length needed to reach the target in comparison to the shortest path length).\r\n\r\nAs mentioned in section 2.2, the experiment consisted of six 2-minute parts, each with slightly different behaviour of the industrial robot. The analysis of the results was done by comparing the features extracted during each of the parts in relation to the first part (baseline, when the robot was idle). The initial analysis of participants’ behaviour, especially of head displacement after the robot made the sudden unexpected movement and hit the participant (middle of the third part), clearly showed how differently the participants reacted to the same events. This led to the division of participants into two groups: the group of 16 responders (R), who strongly responded to the robot\'s sudden unexpected movement and moved away from it by at least 0.06 meters, and 16 non-responders (N-R), who barely responded to the robot\'s sudden unexpected movement. Table 2 shows the results of the feature analysis for the R group, N-R group, and control (C) group individually.\r\n\r\nTable 2: Mean results of the analysis of the motion features.\r\n\r\nAs seen in Table 2, the robot\'s behaviour highly influenced the participants’ posture. All the participants sat straight when the robot was idle or moved slowly. However, as the robot sped up, the average responder leaned backwards by 0.06 meters. When the robot became chaotic, that value increased to 0.09 meters and participants never recovered from this postural change. Non-responders behaved in a similar way, however their reaction was much weaker. Control participants showed no postural change during the whole experiment. Fig. 4 shows more detailed analysis of this data; in the figure, lines labeled ”M” in the middle of FastPredictable and FastChaotic parts indicate the moment when the robot made a sudden unexpected movement. As seen in Fig. 4, it is not the robot\'s velocity, but the robot\'s sudden unexpected movements that induce the strong response. After the first sudden unexpected movement, participants sharply move away from the robot and then slowly get closer to the robot; however, sudden changes of movement and later the subsequent sudden unexpected movement made participants lean backwards again.\r\n\r\n\r\nFigure 4: Comparison of head displacement of three testing groups.\r\nFurthermore, Table 2 shows that both non-responders and responders moved their heads faster as the robot increased speed in Part3 and Part5, and slower when the robot slowed down in Part4. Additionally, they moved their heads more often as the robot started moving. This is in contrast to the control participants, who moved their heads slower and less often over time. It can also be seen that the robot\'s sudden unexpected movements did not influence the participants’ head movement.\r\n\r\nHand-movement velocity and acceleration of all three participant groups show the same trend where it increased over time. The relative movement overshoot feature describes the additional distance (in percents) that the participant\'s hand travelled to reach the target. No obvious trend is visible in that feature. While for the responders group this feature constantly decreases, for non-responders and control group it increases and decreases randomly.\r\n\r\n3.3 Physiological data\r\n\r\nDuring the experiment participants had their ECG and breathing waveform measured. ECG signal allowed the extraction of the normal-to-normal intervals (NN) signal - an irregularly sampled signal that describes the interval between two successive heart beats. NN signal was then used to extract time-domain features such as heart rate (HR), standard deviation of NN signal (SDNN), root mean square of NN signal (RMSNN) and the percentage of successive NN intervals that differ by more than 20 ms (pNN20). Additionally, using Fast Fourier transform (FFT) on the NN signal allowed extraction of frequency-domain features such as absolute power of the low-frequency band (LF), absolute power of the high-frequency band (HF) and the ratio of the two (LF/HF). The breathing waveform signal was first filtered using a 2nd order Butterworth bandpass filter, which passed frequencies between 0.01 Hz and 1 Hz. After filtering, it was used to extract breathing rate (BR) and standard deviation of the filtered breathing signal (SDBR). The heart rate feature was extracted using 10-seconds windows, while all the other features were extracted using 60-seconds windows.\r\n\r\nTable 3 shows the results of the analysis of the physiological features over the duration of the experiment. Heart rate and pNN20 of non-responders and control participants did not change much during the whole duration of the experiment. However, responders’ HR increased by up to 5.6% while pNN20 decreased by up to 12.8% as the robot started behaving in a more dangerous way. SDNN and RMSNN were the lowest when the robot was moving in an unpredictable way, however, they decreased even for the control group, which makes them unreliable.\r\n\r\nFrequency-domain features were slightly more influenced by the changes in the robot\'s behaviour. Compared to the baseline, LF and HF decreased for all the groups, however, the change is bigger for the groups which had to interact with the robot. Relative LF/HF stayed negative only for the control group. For the non-responders group, it initially raised and then decreased towards the end. For the responders group, this feature shows higher variability. It increased when the robot sped up, a decreased when the robot slowed down, then increased again as the robot sped up again.\r\n\r\nThe robot\'s behaviour did not influence the breathing rate in a distinctive way. Although initially, as the robot started moving, responders’ BR increased by up to 9.6%, it decreased over time, even when the robot became chaotic. N-R and C groups showed the same rate of BR decrease over time. The Standard deviation of breathing was significantly influenced by the robot\'s predictability. It stayed relatively constant for the control group, where the robot was not moving at all, while it increased by up to 34.9% for the N-R group and 22.5% for the R group when the robot\'s movement became completely random.\r\n\r\nTable 3: Mean results of the analysis of the physiological features.\r\n\r\n4 DISCUSSION\r\n\r\nIn this study a VR environment was designed to immerse participants in a virtual Human-Robot Interaction scenario. The aim of this was to study how erratic behaviour of the robot affects the human participants. Through the questionnaire it was evident that the experience felt real, participants were well engaged with the specified task, and their focus of attention was shifted as a result of the robot\'s increasingly erratic behaviour. This reported change of attention, with greater focus on the robot, was also evident in the participants’ posture and head movement, as monitored by the VR headset. Specifically, as the robot moved faster and in a more erratic way, the headset movement ratio also increased. This would be consistent with the participants constantly adjusting their line of sight to track the increasingly erratic robot behaviour; and with a shift in attention towards the robot.\r\n\r\nAdditionally, in approximately half of the participants (the responders group) there was also a significant head displacement in z-axis (the head backing away from the robot), observed in response to a sudden unexpected robot movement. This defensive behaviour is thought to indicate a decrease in the sense of safety and robot\'s reliability, which leads mistrust or even fear. This postural change is significant as the stool, on which participants were sitting on during the experiment, was immobile with no back support. Therefore, the observed head displacement comes mostly from leaning backwards and, without any back-support, this posture is unergonomic. So the participants mistrust was so strong that they chose an uncomfortable position over getting closer to the virtual robot. It is expected, that a real robot could evoke an even stronger response and influence a larger group of participants. Over time, participants started to correct this postural change by slowly getting closer to the robot, which could indicate that their trust was being regained. However, the robot\'s subsequent sudden movements made them lean backwards even more than before. It can be speculated, that the first unexpected movement left them in high alert state, which made them more responsive to the future threats. A physiological response was also measured in the responders group. Their average HR and pNN20 changed significantly in comparison to the non-responders and the control group. These features changed in response to the same robot actions that resulted in the change of the head displacement, which also indicates an increase level of physical or emotional stress, and is consistent with a reduction in trust.\r\n\r\nThese findings can be used to improve the design of future experiments and potential real-life HRI in three ways.\r\n\r\nSome participants show strong physical reactions to the actions of the industrial robot. People who show strong responses should not be constrained in doing so. If a human loses trust in a robot, moving away from ”the danger” should not decrease physical comfort.\r\nAs the proximity to the robot can indicate a human\'s trust level, it might be beneficial for the collaborative robots to sometimes view the increased distance from the human not as the permission to move faster, but literally the opposite - as the indicator of the danger or mistrust, which requires the robot to slow down and wait for the trust to be regained.\r\nIt might be beneficial to design the collaborative robot\'s movement in such a way that its end effector never gets outside of the human\'s field of view. While doing so might not necessarily reduce the monitoring rate, however, it should make it less time and energy consuming.\r\nThis study has certain limitations. Although the use of Virtual Reality removes most of the safety or financial limitations, prolonged use of the headset might be exhausting. Additionally, as the participants’ task was rather simple and ”brainless”, they could lose interest if they were to do it for too long. To avoid fatigue and boredom, the experiment had to be kept short, which limits the scope of what could have been tested. It would be interesting to see how people adapt to robots over an 8-hour shift. Especially in a situation where their performance changes not their score on a scoreboard, but their salary. Additionally, to preserve immersion, participants had to be kept undisturbed during the whole duration of the experiment, which means the questionnaire had to be answered in retrospect. Finally, the whole experiment was done in a virtual world. Even though participants reported that the experience felt real, it is uncertain whether they would behave in the same way if the robot was real. While validating the proposed approach in a real-life situation would provide plenty of valuable data, one of the main reasons for using VR in the first place is the fact that conducting these trials in the physical world would be difficult or even impossible. Instead, it would be beneficial for this field of study to further develop Virtual Reality technology to the point, where it is indistinguishable from the real reality.\r\n\r\n5 CONCLUSION\r\n\r\nThis paper analyses the influence of an industrial robot\'s actions on human behaviour in Human-Robot Interaction scenarios. It uses Virtual Reality to study how humans react to potentially threatening actions of the industrial robot, which would be extremely difficult to replicate in a physical test. Although the proposed approach has certain limitations, the results show the tremendous potential of using VR for designing and testing HRI scenarios. It has been demonstrated that at least 50% of participants show a strong response to the virtual industrial robot, and four key findings can be identified in this study:\r\n\r\nIn a situation, where a human and an industrial robot operate at the same time in the same workspace, participants tend to monitor the robot and get distracted by it, especially when movements of the robot become erratic.\r\nThe participants were shown to move away from the robot in response to the sudden unexpected movements of the robot, even if that means putting themselves in an uncomfortable position, which implies lack of trust.\r\nAfter people lose trust in the robot, they tend to naturally regain it over time as indicated by the correction of their posture. However, robot\'s post-accident behaviour can easily jeopardise that attempt.\r\nEven though participants become more cautious of the robot, distracted by it or possibly even scared by it, their short-term performance does not appear to be influenced by the robot\'s actions.\r\nThis study shows how easily humans can be influenced by a robot\'s actions, driving them to non-optimal and potentially unhealthy states. It discusses multiple approaches that could potentially reduce the negative consequences of removing physical barriers between humans and industrial robots. For robots to be able to adapt to humans, more HRI data needs to be collected. This paper shows that VR has the potential to significantly assist this important area of research.\r\n\r\nREFERENCES\r\n\r\nDino Bortot, Hao Ding, Alexandros Antonopolous, and Klaus Bengler. 2012. Human motion behavior while interacting with an industrial robot. Work 41, 1 (Jan 2012), 1699-1707.  \r\nGeorge Charalambous, Sarah Fletcher, and Philip Webb. 2016. The development of a scale to evaluate trust in industrial human-robot collaboration. International Journal of Social Robotics 8, 2 (Nov. 2015), 193-209. \r\nPedro Ferreira, Stefanos Doltsinis, and Niels Lohse. 2014. Symbiotic assembly systems–A new paradigm. Procedia Cirp 17, 1 (Jan. 2014), 26-31.  \r\nJuho Hamari. 2017. Do badges increase user activity? A field experiment on the effects of gamification. Computers in human behavior 71, 1 (Jun. 2017), 469-78.  \r\nPeter A. Hancock, Deborah R. Billings, Kristin E. Schaefer, Jessie Y. Chen, Ewart J, De Visser, and Raja Parasuraman. 2011. A meta-analysis of factors affecting trust in human-robot interaction. Human factors 53, 5 (Sep. 2011), 517-527.  \r\nLærke I. N. Hansen, Niklas Vinther, Lukas Stranovsky, Mark P. Philipsen, Haiyan Wu, and Thomas B. Moeslund. 2018. Collaborative Meat Processing in Virtual Reality. In Proceedings of the 1st International Workshop on Virtual, Augmented, and Mixed Reality for HRI (VAMHRI). Chicago, USA, 96-100.  \r\nJohannes Höcherl, Britta Wrede, and Thomas Schlegl. 2017. Motion Analysis of Human-Human and Human-Robot Cooperation During Industrial Assembly Tasks. In Proceedings of the 5th International Conference on Human Agent Interaction. Bielefeld, Germany, 425-429.  \r\nMarkus Koppenborg, Peter Nickel, Birgit Naber, Andy Lungfiel, and Michael Huelke.. 2017. Effects of movement speed and predictability in human-robot collaboration. Human Factors and Ergonomics in Manufacturing & Service Industries 27, 4 (Jul. 2017) 197-209.  \r\nElias Matsas, George-Christopher Vosniakos, and Dimitris Batras. 2018. Prototyping proactive and adaptive techniques for human-robot collaboration in manufacturing using virtual reality. Robotics and Computer-Integrated Manufacturing 50, 1 (Apr. 2018) 168-180.  \r\nJohn O. Oyekan, Windo Hutabarat, Ashutosh Tiwari, Raphael Grech, Min H. Aung, Maria P. Mariani, Laura López-Dávalos, Timothé Ricaud, Sumit Singh, and Charlène Dupuis. 2019. The effectiveness of virtual environments in developing collaborative strategies between industrial robots and humans. Robotics and Computer-Integrated Manufacturing 55, 1 (Feb. 2019), 41-54.  \r\nAlessandra Sciutti, Martina Mara, Vincenzo Tagliasco, and Giulio Sandini. 2018. Humanizing human-robot interaction: On the importance of mutual understanding. IEEE Technology and Society Magazine 37, 1 (Mar. 2018), 22-29.  \r\nKlaus-Dieter Thoben, Stefan Wiesner, and Thorsten Wuest. 2017. “Industrie 4.0” and smart manufacturing-a review of research issues and application examples. International Journal of Automation Technology 11, 1 (Jan. 2017), 4-16.  \r\nZephyr Technology. 2016. BioHarness 3. Log Data Descriptions. Retrieved 15 Jan. 2018 from www.zephyranywhere.com/media/download/bioharness-log-data-descriptions-07-apr-2016.pdf. ',1,'Fratczak','Piotr Fratczak, Yee Goh, Peter Kinnell, Andrea Soltoggio, and Laura Justham','Piotr Fratczak *(Loughborough University, UK)*<br>\r\nYee Goh *(Loughborough University, UK)*<br>\r\nPeter Kinnell *(Loughborough University, UK)*<br>\r\nAndrea Soltoggio *(Loughborough University, UK)*<br>\r\nLaura Justham *(Loughborough University, UK)*',NULL,0,'10.1145/3363384.3363403','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,19),(49,'jenkins-careful-devices-a-design-manifesto-for-humane-domestic-healthcare-technology','2019-09-03 08:29:56','2019-12-27 21:25:55','2019-09-03 08:29:56',NULL,1,'published','[]','Careful Devices: A design manifesto for humane domestic healthcare technology','This short paper offers a rationale and manifesto for a design-led research project called careful devices—domestic healthcare technologies that seek to bridge the gap between the lived experience of a person and the abstracted medical knowledge of a health practitioner. The rationale places careful devices at the intersection of contemporary trends in self-tracking and health care technology, and explains how and why this intersection is relevant for future interaction design. This is followed by a manifesto that articulates design goals for producing devices linking these trends, creating a space for interaction design research. We end with a discussion of Ovum, an example of a careful fertility tracking device.','Tom Jenkins, Anna Vallgarda, Laurens Boer, Sarah Homewood, and Teresa Almeida. 2019. Careful Devices: A design manifesto for humane domestic healthcare technology. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 5 pages. [https://doi.org/10.1145/3363384.3363474](https://doi.org/10.1145/3363384.3363474 \"DOI for the article \'Careful Devices: A design manifesto for humane domestic healthcare technology\'\")','1 INTRODUCTION\r\n\r\nCareful Devices is a design-led research project designing humane approaches to bodily self-tracking and in-home healthcare technology. This project looks to reframe contemporary understandings of that technology as being part of a practice of health that centers on personal experience and judgement rather than medicalized definitions of sickness or disease. We believe that design research offers a set of techniques that can join different disciplinary threads to create novel care devices.\r\n\r\nThis project operates at the intersection of two major trends in technology and health care. The first is growing interest in gathering health data through consumer technologies that offer biosensing, sleep tracking, fertility tracking and more. A disparate group of people participate in this trend: some are motivated by simple curiosity, some seek a sense of control and optimization, and some need to manage chronic conditions [9, 14]. The second is a shift towards at-home medical practices such as telemedicine and eHealth. In these, the site of medical care moves into private space, and gathering health data is initiated and analyzed by doctors while being managed and possibly interpreted by patients [1].\r\n\r\nBoth trends are rooted in the possibilities that come with cheaper and more widely available sensor technology. We already see some convergence in how domestic healthcare technologies are designed. Current designs are limited in terms of their variety of use (their ability to meet the many different types of users/patients), in their variety of aesthetics (either gray plastic and steel or Apple\'s sleek take on devices), and in their ability to let data travel from the private sphere to the medical profession regardless of where or how it was initially collected (among private self-tracking technologies, the data is seldom recognized by doctors [12]; in medical devices the data is seldom interpretable by patients). How these technologies and the infrastructures that accompany them are designed going forward will have an extensive impact on larger healthcare systems, and could fundamentally reframe how we understand our bodies and their health.\r\n\r\n\r\nFigure 1: Foodmarble\'s Aire (left) measures qualities of digestion and informs a user of any potential digestive issues.\r\n\r\nFigure 2: AliveCor\'s Kardia Mobile is an EKG monitor for when you need to know your heart\'s status on the go.\r\nThis confluence of health care concerns, smart technologies, and infrastructural investment calls for a careful and critical exploration in order to shed light on the many ways they can impact everyday life. This topic is not a new one in HCI—the intersection of technological advancement and health care techniques has been approached from many different perspectives across the broader subject of health informatics, specifically in participatory and critical approaches to home health-care [5, 17, 18, 24] and self-monitoring [10, 23]. Our approach builds from these ideas, emphasizing the role of design in integrating broader contexts and personal idiosyncrasies, and has led us to focus on the capacities of design to address two challenges in the already burgeoning field of domestic health tracking and reporting.\r\n\r\nWe see a challenge in use when the person whose data is being measured is excluded at both the data gathering stage, when their body is simply a body, as well as when interpreting their data, where specific knowledge is needed to understand what is happening there. Medical professionals are trained to assess the condition of a patient based on a combination of experience and training to recognize how illnesses present through both clinical tests and bodily indicators—producing what Foucault called the medical gaze [6]. When medical practices enter private sphere, personal data is more likely to be understood through a correspondingly narrow perspective [2]. In keeping with this reductive tendency, as health and care become part of a growing personal relationship with domestic technology, a fear of overdiagnosis is not unreasonable [7]. Just as Google has challenged the GP\'s monopoly on diagnosing, so has self-tracking devices—like Google, the most common outcome is still faulty self-diagnosis or hypochondria.\r\n\r\nOne challenge with data is how contemporary data practices that come with smart technologies and at-home medical devices [13] often provide context-free information about an activity, and act as though revealing that data to a user empowers them to make stronger or more knowledgeable decisions about a condition than they could before. Simply exposing data is not the same as helping people to understand and interpret that data, and places responsibility on a person to make an expert decision that they may feel uncomfortable doing on their own [16, 22]. At the same time, having people using the lived experience of their own bodies to interpret their data seems like an obvious advantage. The technologies—and the data they produce—are not held accountable for the quality of their data, which leaves the people using them without real grounds to respond.\r\n\r\nThe first challenge might be understood as a problem of acknowledging situatedness, while the second as a problem of response-ability—having the capacity to respond to health concerns [15]. Our goal is to create humane devices that reimagine the relationship between domestic life, medical care, and health data. Avoiding clear feedback such as numeric values, graphs, and algorithmic responses to whether the results are “good” or “bad” and instead work with slow or in other ways ambiguous feedback [8, 11, 19, 21] could support a different conception around in-home health care based on a person\'s knowledge of their health as a practice to be maintained instead of a condition to be diagnosed. Aesthetic perspectives from design research offer insights toward producing care devices that ”encourage close, personal engagement with systems” by leveraging ambiguity of relationship to foster interpretation with the aim of helping users understand themselves in different ways [4, 19, 20].\r\n\r\nWe acknowledge that there are dangers in designing this kind of technology. Our intention is not to force people into being their own doctor or create a false sense of security. Instead, our goal is to produce devices that are reflective—operating alongside existing medical practice, and creating opportunities to share information that might otherwise be unavailable. To both outline and make explicit our commitments in producing careful devices, we offer a manifesto integrating our proposed design-led approach with current domestic health care research.\r\n\r\n2 A design manifesto for careful devices\r\n\r\nCareful devices should be interpretive first, and analytical second. Meaning should come from a combination of experience and material interaction.\r\nCareful devices should produce data that represent the body in thoughtful, considered ways that do not reduce to a set of medicalized parameters.\r\nCareful devices should be situated in sociocultural and aesthetic contexts of domesticity and private personal life.\r\nCareful devices should produce data that acts as a discussant in creating new doctor/patient relationships around health and care.\r\nCareful devices should foster new means of response-ability within its area of responsibility.\r\nCareful devices should prompt new ways of reflecting on and understanding the self.\r\nCollaborating with users, potential users, and medical practitioners, this research project will use design-based HCI research to co-speculate how we can create careful devices. Our aim in this project is to use the manifesto to design across three inflection points: creating variation in use, variation in aesthetics, and variation in the response-ability of data. To illustrate how this manifesto can inform the design of humane domestic health technologies, we offer Ovum, a careful fertility tracker.\r\n\r\n\r\nFigure 3: Ovum in its packaging.\r\n\r\nFigure 4: Ovum being held.\r\n3 A design case: Ovum\r\n\r\nOvum is a careful ovulation-tracking device for couples seeking to conceive. Detecting and monitoring fertility in the home is complex, knowledge intensive and highly personal [3], which warrants carefulness when designing tracking devices. There are various ways of tracking ovulation: charting the menstrual cycle, testing for the luteinizing hormone in urine, measuring sharp increases in basal body temperature, and tracking an increase of electrolytes in saliva. Existing fertility tracking devices are available for each of these methods, and include smartphone applications to track the menstrual cycle, thermometers to measure basal body temperature, chemical tests for urine, and microscopes to inspect saliva. These devices are typically designed for an individual and represent clinical instruments, even though fertility tracking and sexual intercourse are not medical procedures and involve mostly two people. Further, urine and temperature tracking use binary representations of the body as either fertile or infertile, black-boxing data interpretation and re-enacting the clinician/patient relationship.\r\n\r\nOvum is based on the saliva-tracking method of detecting fertility. We chose to track saliva because it presents the only unmediated form of fertility tracking: as the body approaches ovulation, drying saliva reveals fern-shaped crystals that are no longer present after ovulation has taken place. Through magnification and illumination of a saliva sample, typically using a microscope, this form of tracking allows for a real-time, direct reading and interpretation of the body\'s fertility.\r\n\r\nWe designed Ovum to be part of a shared private environment. Two people are typically involved in the act of conception: emotionally, relationally, and sensually. It projects a saliva sample on to the wall or ceiling of a bedroom. This approach inverts the act of individually peering into a microscope, making the process visible to more than just the partner who will become pregnant. The projection resembles the moon and requires a dimmed room, creating a shared aesthetic and romantic experience that draws it closer to the intimacy that is meant to follow its use.\r\n\r\n\r\nFigure 5: In use, Ovum materializes a physical quality of the body and enables it to be shared.\r\n\r\nFigure 6: Ovum projecting on a ceiling.\r\nOvum is designed as a domestic object instead of a clinical instrument. Commercial saliva self-tracking devices typically have a plastic appearance—lipstick style—containing a lens that magnifies a drop of saliva placed on it as well as a LED to enable inspection. We deliberately abandoned the lipstick form, which is strongly gendered towards female users. Instead, Ovum’s shape was designed for use in the bedroom by replacing the typical hard plastic with ceramic, and giving it a cone like shape to resemble the projection it produces.\r\n\r\nWe see Ovum as an example of a Careful Device. Based on the manifesto, reading the saliva sample directly reads the body, and meaning emerges as a natural consequence of the emotional experience from the material interaction. Its form is designed to take into specific consideration the private domestic context where health self-tracking occurs. Ovum does not analyze and translating bodily data itself. Instead, it creates data that is interpretable, and can be part of discussions with a doctor. The magnified saliva, with its poetic and romantic appearance invites for ways of seeing the body beyond clinical representation, and acknowledges the interpretive potential of the body\'s inner workings.\r\n\r\n4 CONCLUSION\r\n\r\nWe believe that critical interaction design in the context of home health devices can strike a balance between medical knowledge and the lived experience of health. Design research can produce humane devices that support reflection about experiences of the self and the body. We believe that this can offer a different perspective on the self than would be possible in a purely clinical setting. This vantage opens the frame of health to include more perspectives than would otherwise be taken into account, including those who have been excluded from medical trajectories, taking insights from knowledge that medicine is uncertain about, and providing a site for people to actively participate in issues of their own care.\r\n\r\nREFERENCES\r\n\r\nNitesh V. Chawla and Darcy A. Davis. 2013. Bringing Big Data to Personalized Healthcare: A Patient-Centered Framework. Journal of General Internal Medicine 28, 3 (Sept. 2013), 660–665. https://doi.org/10.1007/s11606-013-2455-8  \r\nPeter Conrad. 2007. The Medicalization of Society: On the Transformation of Human Conditions into Treatable Disorders(1 edition ed.). Johns Hopkins University Press, Baltimore.  \r\nMayara Costa Figueiredo, Clara Caldeira, Tera L. Reynolds, Sean Victory, Kai Zheng, and Yunan Chen. 2017. Self-Tracking for Fertility Care: Collaborative Support for a Highly Personalized Problem. Proc. ACM Hum.-Comput. Interact. 1, CSCW (Dec. 2017), 36:1–36:21. https://doi.org/10.1145/3134671  \r\nPaul Dourish, Janet Finlay, Phoebe Sengers, and Peter Wright. 2004. Reflective HCI: Towards a Critical Technical Practice. In CHI ’04 Extended Abstracts on Human Factors in Computing Systems(CHI EA ’04). ACM, New York, NY, USA, 1727–1728. https://doi.org/10.1145/985921.986203 event-place: Vienna, Austria.  \r\nGeraldine Fitzpatrick. 2011. New challenges for health IT–Design fit for life. In Proceedings of the 1st European Conference on Design 4 Health. Sheffield, UK, 121–135.  \r\nMichel Foucault. 1994. The Birth of the Clinic: An Archaeology of Medical Perception (36401st editioned.). Vintage, New York.  \r\nKatleen Gabriels and Tania Moerenhout. 2018. Exploring Entertainment Medicine and Professionalization of Self-Care: Interview Study Among Doctors on the Potential Effects of Digital Self-Tracking. Journal of Medical Internet Research 20, 1 (2018), e10. https://doi.org/10.2196/jmir.8040  \r\nWilliam W. Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity As a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’03). ACM, New York, NY, USA, 233–240. https://doi.org/10.1145/642611.642653 event-place: Ft. Lauderdale, Florida, USA.  \r\nHenner Gimpel, Marcia Nißen, and Roland A. Görlitz. 2013. Quantifying the Quantified Self : A Study on the Motivations of Patients to Track Their Own Health. https://publikationen.bibliothek.kit.edu/1000077620  \r\nErik Grönvall and Nervo Verdezoto. 2013. Beyond Self-monitoring: Understanding Non-functional Aspects of Home-based Healthcare Technology. In Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing(UbiComp ’13). ACM, New York, NY, USA, 587–596. https://doi.org/10.1145/2493432.2493495 event-place: Zurich, Switzerland.  \r\nLars Hallnäs and Johan Redström. 2001. Slow Technology – Designing for Reflection. Personal and Ubiquitous Computing 5, 3 (Aug. 2001), 201–212. https://doi.org/10.1007/PL00000019  \r\nBjørn Hofmann. 2016. Medicalization and overdiagnosis: different but alike. Medicine, Health Care and Philosophy 19, 2 (June 2016), 253–264. https://doi.org/10.1007/s11019-016-9693-6  \r\nHenriette Langstrup. 2019. Patient-reported data and the politics of meaningful data work. Health Informatics Journal 25, 3 (Sept. 2019), 567–576. https://doi.org/10.1177/1460458218820188  \r\nDeborah Lupton. 2016. The Quantified Self(1 edition ed.). Polity, Cambridge, UK.  \r\nAryn Martin, Natasha Myers, and Ana Viseu. 2015. The politics of care in technoscience. Social Studies of Science 45, 5 (Oct. 2015), 625–641. https://doi.org/10.1177/0306312715602073  \r\nKaren Dam Nielsen and Henriette Langstrup. 2018. Tactics of material participation: How patients shape their engagement through e-health. Social Studies of Science 48, 2 (April 2018), 259–282. https://doi.org/10.1177/0306312718769156  \r\nFrancisco Nunes. 2019. From Medicalized to Mundane Self-care Technologies. Interactions 26, 3 (April 2019), 67–69. https://doi.org/10.1145/3319374  \r\nFrancisco Nunes, Nervo Verdezoto, Geraldine Fitzpatrick, Morten Kyng, Erik Grönvall, and Cristiano Storni. 2015. Self-Care Technologies in HCI: Trends, Tensions, and Opportunities. ACM Trans. Comput.-Hum. Interact. 22, 6 (Dec. 2015), 33:1–33:45. https://doi.org/10.1145/2803173  \r\nWilliam T. Odom, Abigail J. Sellen, Richard Banks, David S. Kirk, Tim Regan, Mark Selby, Jodi L. Forlizzi, and John Zimmerman. 2014. Designing for Slowness, Anticipation and Re-visitation: A Long Term Field Study of the Photobox. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’14). ACM, New York, NY, USA, 1961–1970. https://doi.org/10.1145/2556288.2557178 event-place: Toronto, Ontario, Canada.  \r\nPhoebe Sengers, Kirsten Boehner, Shay David, and Joseph ’Jofish’ Kaye. 2005. Reflective Design. In Proceedings of the 4th Decennial Conference on Critical Computing: Between Sense and Sensibility(CC ’05). ACM, New York, NY, USA, 49–58. https://doi.org/10.1145/1094562.1094569 event-place: Aarhus, Denmark.  \r\nPhoebe Sengers and Bill Gaver. 2006. Staying Open to Interpretation: Engaging Multiple Meanings in Design and Evaluation. In Proceedings of the 6th Conference on Designing Interactive Systems(DIS ’06). ACM, New York, NY, USA, 99–108. https://doi.org/10.1145/1142405.1142422 event-place: University Park, PA, USA.  \r\nTamar Sharon. 2017. Self-Tracking for Health and the Quantified Self: Re-Articulating Autonomy, Solidarity, and Authenticity in an Age of Personalized Healthcare. Philosophy & Technology 30, 1 (March 2017), 93–121. https://doi.org/10.1007/s13347-016-0215-5  \r\nKatta Spiel. 2019. Body-positive Computing As a Means to Counteract Normative Biases in Fitness Trackers. XRDS 25, 4 (July 2019), 34–37. https://doi.org/10.1145/3331065  \r\nCristiano Storni. 2010. Multiple Forms of Appropriation in Self-Monitoring Technology: Reflections on the Role of Evaluation in Future Self-Care. International Journal of Human–Computer Interaction 26, 5 (April 2010), 537–561. https://doi.org/10.1080/10447311003720001  ',1,'Jenkins','Tom Jenkins, Anna Vallgårda, Laurens Boer, Sarah Homewood, and Teresa Almeida','Tom Jenkins *(IxD Lab, Digital Design Department, IT University of Copenhagen, Denmark)*<br>\r\nAnna Vallgårda *(IxD Lab, Digital Design Department, IT University of Copenhagen, Denmark)*<br>\r\nLaurens Boer *(IxD Lab, Digital Design Department, IT University of Copenhagen, Denmark)*<br>\r\nSarah Homewood *(IxD Lab, Digital Design Department, IT University of Copenhagen, Denmark)*<br>\r\nTeresa Almeida *(IxD Lab, Digital Design Department, IT University of Copenhagen, Denmark)*\r\n\r\n','https://pure.itu.dk/ws/files/84703912/HttF_Careful_Devices_Final.pdf',1,'10.1145/3363384.3363474','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,30),(50,'westling-the-technological-gaze-how-we-see-audiences-and-the-unmodern-sublime','2019-09-03 08:29:56','2019-11-20 10:14:37','2019-09-03 08:29:56',NULL,1,'published','[]','The Technological Gaze: How we see audiences, and the unmodern sublime','In addressing the question of how we think and model the participant, user or audience for interactive systems, we initiate an interrogation of who we think we are, and what we think technology is in relation to who we think we are. Future-proofing innovation in design thinking must involve serious thought about conceptual models for how we see ourselves as makers and audiences, since they precede design solutions. Here, lessons and transferable insights from live performance and experience design can inform design thinking in digital materialities. This paper will explore the nature and direction of the technological gaze on audiences or human system users and interrogate its influence on design. Subsequently, it introduces observations from live event design that modifies techne with metis to invite the sublime as an integral part of immersive experience.','Carina E. I. Westling. 2019. The Technological Gaze: How we see audiences, and the unmodern sublime. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 7 pages. [https://doi.org/10.1145/3363384.3363471](https://doi.org/10.1145/3363384.3363471 \"DOI for the article \'The Technological Gaze: How we see audiences, and the unmodern sublime\'\")','1 Introduction: Technology as mirror and stage\r\n\r\nAs virtual scenographies expand into our everyday lives via open computational networks, distinctions between knowing and naïve audiences and users, and between applications designed for entertainment and a wide range of services are blurred or even erased. This is a critical enquiry in the present moment, and networked technologies face simultaneous scrutiny and expansion as increased awareness of their potential for use and misuse signals the end of the digital modern. Rather than focusing exclusively on the handling of personal data, an under-researched line of enquiry is the form of our representation as data objects. Our ‘performance’ within always-on interactive systems that gather data more or less continuously collapse the private into the public [16] with now-known consequences for privacy, transparency and public discourses. The wider ramifications include the nature of discourse, and questions around the ethical and functional viability of the present paradigm for user modeling. How participation is conceptualized in performance and live events has profound effects for aesthetic as well as pragmatic dimensions of experience. Design for digital platforms is similarly affected, although the immediacy of this relationship between concept and experience is reduced by mediation. Understanding the implications of how the role of human participants is conceptualised and shaped through representation is critical, as it scales to the extent of networked distribution.\r\n\r\n1.1 Technology as mirror and stage\r\n\r\nTechnology holds up a mirror in which we see and imagine ourselves as agents of modernity and change. Information technology, at least from the book to the present, has informed prevailing visions of what it is to be human. Outlining a history of how the subject position was inflected by technology in the twentieth century, Kittler describes how the image of ‘so-called-Man’ changed as we moved from the continuity of written longhand to demassified thought by way of technologies of discretization, storage and distribution [10]. The hand-written book or letter embodies continuous thought as it is expressed, in contrast with the typewriter\'s percussive rhythm. Later, digitized communication made the basic elements of articulated thought discrete and open to remediation. Through inflecting modes of expressing and receiving mediated communication, technology shapes the experience of thinking through materials and reflects back an image of who or what we think we are.\r\n\r\nSuperficially, the digital modern suggests - or suggested - malleability; shape-shifting and liberation from the “weight of reality” [19], but events in recent years have raised concerns about the accumulation of personal data and unfettered ‘cybertyping\' [7, 9]. The apparent fluidity of form at the interface level seems dichotomous to the ever-tighter descriptions and definitions of identities [19] at the infrastructure level of interactive systems, as well as the wider polarization of identitarian tribes in digitally mediated discourses. The business models of social media platforms and other free-at-the-point-of-use interactive systems incentivize both; the data economy depends on thin-sliced demographic categorization and churn, making these phenomena features, not bugs [9]. Privacy concerns and emerging regulation of data collection and storage are terminally at odds with predominant business models in the data economy. The present dependency on data brokering and exploitation, and the malpractices that are gradually becoming public knowledge, will not abate through regulation unless alternative models for both data representation of system users and monetization are developed; it is an ethical issue as much as it is economic and technological.\r\n\r\nAnother representational legacy exists that may offer alternatives that are functional in these dimensions. Design for performance and theatre and the effects it seeks to produce on stage and in the auditorium have long been subject to critiques of representation. Its theories and practices are anchored and informed by embodiment which, when thought through participatory performance, yields useful models for incorporating audiences as ‘moving parts’. This is meticulously explored in Punchdrunk, who produce experience design across physical and blended reality that can be analysed as interactive systems. The vision of their founder, Felix Barrett, is based on multi-sensory theatrical spaces and the company is now expanding their digital R&D activities in the UKRI-funded Audience of the Future programme. Based on in-depth ethnographic research with Punchdrunk and live audiences 2011-2014, the study discussed here [21] investigates how their live practice can inform the conceptualization of audiences in design for blended and virtual scenographies. Punchdrunk\'s rich background in embodied design and experience presents an unparalleled foundation for the new R&D facilities that they are creating for StoryFutures Industry Centre of Excellence in Immersive Narrative at their premises in Tottenham, London.\r\n\r\nThis new research centre and contingent activities in the broader creative and academic sectors herald new perspectives on participatory audiences in interaction design. The critical framework introduced here for thinking and representing audiences (or system users) beyond the present paradigm for software infrastructures and monetization models is informed by theories of representation in theatre and performance. It is based on analyses of the relationship between stage and auditorium as a window on the moving present in theatre and performance to interrogate ways of being that are relevant to interactive systems.\r\n\r\n1.2 The subject, the event, and the subject-event relationship\r\n\r\nAs interfaces become less screen-bound, the focus for design has turned towards embodied interaction. Philosopher Elizabeth Grosz reminds us that the living body is the seat of inventive practice [8]: the viscous continuity of embodiment resists the modern, and grounds the creation and reception of meaning. Critical methodologies from theatre makers can enrich perspectives on experience design, particularly with regard to how participation is conceptualized and modelled. Punchdrunk and other theatre companies that create immersive productions have expanded scenography to not just envelop but include the living bodies of their audiences.\r\n\r\nPunchdrunk audiences move freely within the scenography for three hours, interacting with the performance environment and its actors at close range, as opportunities to do so unfold. Their audiences move at pace, with intent, and in intimate proximity to the set, props and the actors, and typically have strong emotional experiences in response to the performance. The representation of audiences to themselves, and how the conditions of possibility for the audience role within the broader scenography (including the auditorium) is usefully understood through the distinction between Artaud\'s Theatre of Cruelty and the Verfremdungseffekt of Piscator-Brecht\'s Epic Theatre. Deleuze\'s critique of the latter in favor of the former [6] recognizes that Artaud challenges the subject position of audience members through positioning them within the work, or immanent to the event, while Piscator-Brecht\'s work allows a critical distance to the event. Punchdrunk position their audiences and their actors in immanent subject-event relationships to each other, sharing both frame and plane. Other makers of immersive experience design that work with immanence include Blast Theory, creators of Desert Rain (1999), A Machine to See With (2011), and Operation Black Antler (2016) and The Mill, who produced 6 x 9 (2016) for Guardian VR under the direction of Francesca Panetta. These works position the audience in an immanent subject-event relationship to the designed environment.\r\n\r\nThe Chinese Room, makers of Dear Esther (2012) and Everybody\'s Gone to the Rapture (2015) work with screen-based interfaces and design the subject position as an absence that invites audiences to project themselves within. While they are designers of mediated rather than live experience, The Chinese Room share many methodological approaches with designers like Punchdrunk, notably the extreme attention to narrative detail and the design of the audience subject position as one of absence. This approach allows the participant or player to enter the hyperreal storyworlds unencumbered by avatars, imperfectly rendered human representations or other superficial identities. In large masked Punchdrunk shows, audiences yield their everyday identity while within the performance space through separation from the company they arrived with and wearing identical while masks [21]. In both cases, participation \'beyond\' identity is central to the designed affordance for emergence at the site of the participant.\r\n\r\nMisconceptions of the creative potential of audiences in live events, whether in alignment with the designed affordances of their envisioned role, or engaged in the kind of fertile caprice that de Certeau calls ‘delinquency’ [4], produces immediate consequences. Networked and mediated at scale these are harder to predict and locate, but the impact of social media on democratic processes as they are instrumentalised for the ongoing ‘information war’ gives us some examples. Most, if not all of these flow from the idea of \'identities\', whether fake or real. Whichever aspect of this wider problem is interrogated, inspection suggest that changes are unlikely to originate within the industry. The problems associated with the present paradigm for representation of human system users have multiple dimensions. Representation of \'identities\' is so central to interaction design and its monetization that changes at this level would bring profound change.\r\n\r\nThe objectification – i.e. the rendering-as-objects – of human system ‘parts’ in the design process and its implementations creates in-built, systemic flaws. The conceptualization and modelling of agency as agents in interactive systems, rather than as an element in its own right, is an ontological misstep. It fails to accommodate the dynamic volatility of human components when they form crowds, or when the social identities and compacts that hold individuals are loosened. These and other effects of scaling and perspective on \'system users\' are intuitive to designers of live events. In such a comparison, it is clear that the practice of modeling human participants in interactive systems as cumulative data objects is not based on an empirical understanding of human audiences at scale, but is an ideological methodology at root.\r\n\r\n1.3 The technological gaze\r\n\r\nThe problem of thinking aesthetically, functionally and ethically about participation as a feature in interaction design must start with an interrogation of gaze; its point of origin and relation to its object, and how its nature and directionality informs design processes.\r\n\r\nIn live performance where the maker and audience share the same plane and frame in time and space, they are immanent to each other and any actions that occur in interaction are equally ‘real’ to both designer and audience member. This perspective shapes the design process; every decision is informed by the experience and knowledge that the designed encounter will need to include emergence within its scope, and its immediate impact on unfolding events.\r\n\r\nBy contrast, a remote vantage position in relation to the audience allows for their reduction, by way of gaze, with the precise and unfolding detail and consequence of the designed situation similarly reduced. This can be thought as a transcendent relationship between the subject and the observed event, where the designer occupies a \'gods-eye\' point-of-view, removed from the event. In a traditional performance situation on a proscenium stage, the transcendent subject-event relationship is also possible between the auditorium and stage, as the audience is afforded a safe distance to any drama that takes place within the frame of the proscenium. The reductive view that is produced by distance affords a sense of containment and the illusion of control, but with this also a reduction of the impact of variability and consequence.\r\n\r\nThe inherent radicalism of the immanent subject-event relationship, in comparison with the transcendent one, lies in the immediacy of consequence. Neither party in the exchange or interaction is afforded the illusion of complete control over the other. The modelling of audiences with this in mind underscores the need for tactical response capacity in the designed experience and shapes every subsequent decision. We might call this metis; tactical skill or even cunning; a readiness for pragmatic and emergent responses.\r\n\r\nAnother skill; techne, is broadly the skill of craft, applied to a material that can be known and understood. A remote or transcendent perspective on audiences in interaction design, i.e. one where the designer and the audience or system user do not share the same frame in time and space, affords what might be called a technological gaze. Its logic is driven by techne, with a view on its materials (which include the audience) that assumes knowability and at least some degree of control. A perspective on live audience as they are perceived by designers of live events presents a challenge to techne that can contribute to a paradigmatic shift in design thinking and design solutions by way of audience modeling.\r\n\r\n1.4 Objectification as a product of gaze\r\n\r\nThe technological gaze that is embedded in digital networks and infrastructures relies on objectification, i.e. the rendering of components in the design schema as data objects, sufficiently defined and stable for the present paradigm. In interaction design including human components, legacy heuristics skew towards agent-based modeling, i.e. understanding audiences as stereotypes with extended characteristics based on past behaviours [2]: The digitization of system users or audiences thus objectifies them by default already at the functional level, by and through their rendering as data objects.\r\n\r\nIn the physical world, objectification occurs through ongoing representational and socio-economic processes and transactions that confer status and power from the objectified to the objectifier. It does not occur because the objectified are regarded as less than human; the act of objectification is powerful precisely because they are human. The most brutal examples of how the transactional aspect of objectification confers status are slavery and human sacrifice, but digital interactive systems also objectify: trivially at the local level, but scaled globally. The power transfer, much like the revenue generated within the attention economy, is incremental and systematic. It reaches critical mass by scale, and distributes the effects of this transfer across the population at large. Each transaction is small, and occurs as an exchange between ‘users’ or participants who submit their human ability to perceive, interpret and process to a system that instrumentally reduces them to a data object, more narrowly defined with every transaction, which is subsequently aggregated and brokered. Each individual transaction is small but yields power to the objectifier.\r\n\r\nMeanwhile, the computational capacity that is embedded within the system to survey, order and objectify human participants constitutes an executive position, exercised through the placing and holding its object within a conceptual frame and form. At scale, the systemic rendering of human participants as data objects becomes an expression of power, embedded within digital infrastructures.\r\n\r\nThe objectification that occurs through ever-tighter demographic modeling is obscured by naturalization within the design schema. Even though the misuse of personal data is now relatively well known, it remains widely accepted for a perceived want of alternatives. Since the issue flows from a central approach to user modeling, alternatives are likely to be found outside of the present paradigm. In a pervasive media environment, it is even difficult to trace the outline of the problem space. This is perhaps more easily grasped when contrasted with prevailing forms of resistance, e.g. various approaches to gaming the system based on \'shape-shifting\' or identity fraud. Digitization renders the representation of human users uniquely open to abstraction both as data objects and online actors, vanishing the consequential body. A key aspect of power is the capacity for changing your circumstances, and in digital and administrative milieus, this includes form and location. The system environment is diffuse in both these aspects, making the technological gaze on human system participants near-ubiquitous; \'omnipresent\' or god-like. Resistance narratives in the digital milieu typically seek to reverse this power relationship by way of shape-shifting, which can be understood as an illicit \'power grab\' within the system environment and in relation to the technological gaze.\r\n\r\nDeprioritizing identity within the art-work as in the work of Punchdrunk and other artists employing similar devices fulfils twin objectives; it affords agency a fluid shape so that audiences may ‘shape-shift’ and it destabilizes the audience subject position. Instability of form and a destabilized subject position are key to immersion as a function of vertigo in relation to the subjective experience of possibility space [21]. The dynamic expression of agency within the overarching design scheme is an expression of force or power. Framed as shape-shifting, it is also a reversal of the subject-event relationship that dominates the present paradigm in digital interaction design. The idea of shape-shifting in relation to power is clarified in contrast with its opposite, i.e. conditions of possibility that bind the subject to place and in form. If digital infrastructures are to support dynamic expression of agency, such as can be observed in the live \'interactive systems\' of Punchdrunk, we might rethink the idea of agents, and instead think participation as agency. Towards realizing this, the technological gaze on human participation within interactive systems might turn to physics rather than social science. To designers of live events, agency manifests as a dynamic fluid as audiences move within designed spaces and conduits for action and interaction. The shape and properties of agency, thought this way, might be articulated as pressure, velocity, and volatility as analogues of movement and experience.\r\n\r\n2 The sublime and immersive experience\r\n\r\nImmersive experience in an artwork, especially where this involved embodied interaction, can be understood as self-abduction, building on the work of Chow [5] and Bishop [3]. Chow argues that the audience enters into voluntary \'capture\' within the artwork, thereby completing it. Bishop introduces the idea of self-exploitation, underscoring the \'work\' undertaken by audiences in, particularly, participatory and relational art. Both perspectives are informed by Artaud\'s vision of a Theatre of Cruelty, which Machon draws explicitly on in her discussion of the phenomenology of immersion in Punchdrunk [14]. A framework, informed by Artaud, for comparing virtual and physical immersive scenographies can be found in Deleuze\'s discussion of the transcendent vs. the immanent subject-event relationship and the dogmatic image of thought in Difference and Repetition [6]. In Deleuze\'s analysis, Artaud\'s destabilization of the auditorium and the subject position of the spectator brings the critique of representation to the self in ways that the Verfremdungseffekt and its associated critique of representation do not. This perspective comes to renewed relevance in interactive design schema in the immersive aesthetic; a category that in its broadest understanding incorporates virtual reality (VR), blended (XR) or augmented reality (AR), and arguably also service design platforms such as social media. Alternative ways of thinking and modeling the human \'component\' are salient to issues of privacy and monetization in service design, but the main focus in this section is the type of production or application where audience experience is central to the design.\r\n\r\nA comparison between live audiences in performance events and remote audiences on digital platforms shows profound differences in thinking and practice in the two fields, as well as obvious similarities. Central to their differences is the relationship between connectivity and exposure, and its directionality. In live performance, audiences are viscerally immediate as a force of motion and emotion, and their cohesion, velocity and direction change with attention, elation and arousal, giving visible form to Klossowski\'s argument in Living Currency [11] that mediated passion not just underpins, but drives production and exchange. This is explicit in Punchdrunk\'s immersive theatre, where experience is produced by the extension of agency as embodied interrogation and articulation of space, driven towards encounters, often by frustrated desire.\r\n\r\nExposure is two-way in the encounter: the interface, i.e. the scenography across which audiences connect with the work of the company, exposes both to each other. As immersion is regarded here as the voluntary submission to such exposure, the cultures that make this possible and desirable on both sides of Punchdrunk\'s interfaces are included in the research. Punchdrunk famously require their audiences to participate actively within ‘theatre machines’, but agency within a coordinating structure is also at the heart of the culture behind the scenes. The company extends significant agency to the hundreds of makers that are involved in each production, from set building to acting and stage management. The complexity that this way of distributing agency affords makes possible the creation of deeply layered scenography that resolves in further detail the closer you look or explore. Like mise-en-abîme creates the illusion of an endlessly repeating space in art, this possibility space creates uncertainty of how far the illusion extends in Punchdrunk\'s work and supports immersion. Company and audience members discuss this particular aspect of the company\'s work in terms of vertigo and awe, suggesting the sublime, and underscore how it invites the extension of agency on both the company and the audience side of the experience.\r\n\r\nThis engagement mediates connectivity and exposure in Punchdrunk\'s work. As networked technologies become enmeshed with the social and physical realities of the unbound world, exposure follows connectivity also in the digital domain. Now facing the end of the digital modern, we are beginning to see how this is manifested in digital systems and their social contexts. Code infrastructures are vulnerable to cumulative entropies that create security risks in their social context [20], and pervasive networked computation exposes societal infrastructures and the body politic to agencies of technological and human origin. Digital technologies has immense capacity for innovation, but the tension between connectivity and exposure remains one of critical concern. Underscoring the dependency of innovation on stability, Grosz says: “It is this relative stability and orderliness, predictability, that is the very foundation or condition for a life of invention and novelty, a life in which pure repetition is never possible.” [8]. Paradoxically, we may find more stable representation of the human component in interactive systems by accepting, embracing even, its fundamentally unstable nature. Conceptualised as agency, its containment and boundary conditions can be interrogated in Punchdrunk\'s masked performances and other designed experiences based on crowd scenography that can be modeled as conduits and spaces\r\n\r\nThe aesthetic dimension of design in relation to boundary conditions can be explored in the sublime, an experience outside of conventional beauty that is made aesthetic by being bounded or ‘removed’ by frames or distance. In the context of interactive systems, their very extent and the smallness of the human participant within them invite reflection that highlights the contrast between the sublime discussed by Kant, and that described by Lyotard. This comparison hinges on subject-event perspective in ways that elucidate the nature of immersive experience; \'within\', subsumed, and at the cusp of being overwhelmed. In Rancière\'s analysis, Lyotard reverses the Kantian sublime that frames and contains the threat of dissolution or oblivion in vastness with reason [18]. This analysis of the sublime in Lyotard vs. that of Kant is broadly symmetric with the tension between an immanent perspective (‘within’ the moment or event, on the same plane) and a transcendent one, i.e. from a removed vantage point that allows for the idea of dominion and comprehension.\r\n\r\nThe distinction sheds light on the relationship between makers, players and audiences in live events and that between digital makers and players and their remote, digitally mediated audiences. The shared frame in live events disallows the occlusion of exposure as an inevitable consequence of connection, whereas the perspective on audiences in digital design affords the illusion of control as it removes the maker from both the instantiation and immanent consequence of their work.\r\n\r\n3 Affording audiences dynamic representation\r\n\r\nPunchdrunk and other producers of durational live events work with audience agency as a critical, dynamic and unstable material, which places demands on their scenography to have the response capacity to meet and negotiate the force of free-roaming audiences in their hundreds, night after night for extended runs. First-hand accounts from company and audience members show that the craft and detail on the producer side of the interface supports immersion as an active state on the audience side – not because it fools audiences into believing the illusion, but because it tells them, as it unfolds throughout the performance, that their suspension of disbelief and commitment of agency to the experience will be met and supported. Even in near-darkness, audiences perceive the commitment to and creative investment in the storyworld by the company and rise to meet it. Even though they are new to the experience, they are able to read the social dimension of the material, and it informs their embodied experience of space. Chiming with Grosz, their living bodies, sensate and social, produce experiential space. The social dimension is central, as immersion is a state of voluntary entrapment, reliant on the perception of support by and in the joint art-work.\r\n\r\nAcknowledging agency as a force that cannot be controlled but rather invited, shaped and directed with the active, emergent consent of the audience produces immersive conditions of possibility. In Punchdrunk\'s ‘theatre machines’, the social is present in every detail through attention to detail. Interviews with audiences reveal that it is legible even where the scenography is practically subsumed in darkness. Digital work such as that by The Chinese Room exemplify how detail attention communicates also across screens. Although the space is virtual, the idea of scenography applies, particularly in the frame of environmental scenography.\r\n\r\nThe history of theatre and performance usually focuses on the stage, but if we look at scenography and performance with the audience in mind, we can also trace how their role has been configured and negotiated almost as clearly as if it were spoken out loud. In The History and Theory of Environmental Scenography [1], Aronson describes the spatial-architectural arc within which immersive theatre sits, while McKinney and Palmer\'s edited volume Scenography Expanded [15] At this junction, the relationship between makers and their audiences becomes one of critical importance. The immediacy of live performance reminds all who are involved in the production of a play or spectacle that proceedings occur within a space of readiness that is accommodated and supported by the interest and compliance of audiences. Immediacy, with immanent consequences, creates persuasive incentives to be prepared and to have response capacity, in case events do not unfold as planned or desired. It encourages an empirically grounded way of thinking about audiences; what draws their attention, how they respond, and what they might do in the emergent present.\r\n\r\n3.1 Challenges in and to software engineering\r\n\r\nThrough rendering as data objects, the representational form of digital audiences is almost infinitely flexible. Data objects and forms can be replicated and have no natural end-time. Their fluidity and distance from gravitational consequences afford near-unlimited and instantaneous scaling, extended through distributed networks. In a transcendent subject-event relationship, a reductive perspective on system users or audiences is inevitable. ‘Seen from afar’ due to scaling, only crude features of the object of study stand out, and so the general dominates the particular: the nuance disappears. When the event comprises human users or audiences, this poses critical questions.\r\n\r\nFrom an empirical point of view, crowds are, for the purpose of interaction design, arguably better treated as a different ontological object than individuals, real or modeled. Consider the case of big data, which is used to model and predict the behavior of individuals. Subdivision of crowd behavior yields little insight into how constituent individuals might act at a local level. Conversely, the multiplication of information about the actions of individuals at the local level will not yield a particularly useful picture of how a theoretical crowd that they form might act. Big data produces information that is neither fish nor fowl, as far as insight into individual or crowd behaviours goes. It is also dependent on circular queries, as it is typically gathered on platforms designed to harvest information that is a) useful to the platform owner and b) ‘harvestable’ and ‘processable’ within the means and affordances offered by the platform. When applied to interaction with remote audiences via the platforms that generated the data, the margin for error in the quality of the information is significant, increased by linear scaling, and unchecked by immanent feedback. By contrast, errors that result from overly reductive (i.e. simplified, crude, and lacking in complexity and nuance) understanding and modeling of audiences in live performance will be immediate and evident to those delivering the performance.\r\n\r\nMoving away from the idea of modular identity towards the continuities and flows that can be observed in crowds might enhance user modelling ethically and functionally. Properties like volatility, viscosity, force and pressure, expansion and flow are consequential to the quality of designed interactions. In live events, the audience component is often discussed as a fluid or force: an empirically grounded perspective that can demonstrably produce experiences of a high aesthetic and functional quality. Similarly, the human component in interactive systems could be modeled as a dynamic fluid. Such a paradigm shift in user modeling would present opportunities and challenges to software engineering and digital design, with potentially profound and benign consequences.\r\n\r\nThe new facilities being developed for the StoryFutures Academy may see enhanced methods both for R&D and audience modelling. It will be a lab and storyworld in one, where design for audiences is researched against the background of Punchdrunk\'s rich experience with live performance. There and in other labs, the design process must include human agency and cognition in the consideration of critical materials. From there, ontological questions about the nature of the human component in interaction arise that might be guided by Latour\'s definition: “A weaver of morphisms – isn\'t that enough of a definition?” [13].\r\n\r\n4 Conclusion\r\n\r\nWhile technologically extended and blended storyworlds offer vertiginous possibilities for makers and designers in theatre, performance and games, the present paradigm for modeling agents within digital infrastructures is stultifying, both at the technical level and in the sense implied by Rancière [19]. Alternative ways of thinking and modeling audiences are possible, viable, and demonstrated by Punchdrunk (and others) in their work with large live audiences. These methods are rooted in observing and approaching audience agency as a critical material and an essential component of both the design process and the outcome.\r\n\r\nThe influence of this perspective on audiences on design comes to expression in every aspect of scenography and interaction. It invites close engagement with storyworlds and holds designers and audiences within a shared frame of meaning that supports joint commitment to the art-work. Considering audiences immanently opens a critical space in which the exposure that is inherent to connectivity can be negotiated on an emergent basis. This negotiation, teetering on the fault line of reason, is central not only to the sublime, but to immersion. With human agency a core component of interactive systems, modeling it without mediation by the idea of individual agents is arguably more empirically grounded. Furthermore, conceptualising audiences as dynamic and unstable within physical and digital scenographies might aid creative management of both experience and risk. Inviting metis to experience design where human participants are intrinsic ‘moving parts’ draws focus to the tension between connectivity and exposure, otherwise easily occluded in digital design.\r\n\r\nInterrogating the technological gaze thus asks designers to think of audiences not as known, but as unknown entities and sources of force. The emphasis in Punchdrunk\'s design process is on meeting, engaging with, and holding this force as it unfolds in real time. With an immanent understanding of audience agency, interaction design for embodied and remote participation may fold digital technologies into the cultural fabric of making in history. The interdisciplinary techne that Jussi Parikka calls for in experience design spans a continuum of materialities from “hard” or physical components to “soft” or symbolic “signs, meanings, attractions, desires” including the “processual” [17], work of human cognition.\r\n\r\nIn live interaction design, the processual, human component is manifest as an embodied force. A technological gaze on this component that borrows from the metis of live experience design would do well to relinquish the idea of modular personalities in favour of one that considers crowds as a different object, and a differential force.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nI would like to thank the generous access to their work by Punchdrunk, and the opportunity to work with them as a researching designer 2012-2014. The work of other artists mentioned here, including Blast Theory, The Chinese Room, and The Mill has also inspired this analysis, and I would like to thank Adam Grint at The Mill and Dan Pinchbeck at The Chinese Room for conversations and discussion of this research in relation to the work of their companies.\r\n\r\nREFERENCES\r\n\r\nArnold Aronson. 2018. The History and Theory of Environmental Scenography. Bloomsbury Methuen Drama, London.  \r\nDavid Benyon, Peter Innocent & Dianne Murray. 2014. System Adaptivity and the Modelling of Stereotypes. In: Proceedings of the Second IFIP Conference on Human-Computer Interaction. University of Stuttgart, Germany, pp. 245-253. Elsevier.  \r\nClaire Bishop. 2012. Artificial hells. 1st ed. Verso Books, London.  \r\nMichel de Certeau. 1988. The Practice of Everyday Life. University of California Press, Berkeley.  \r\nRey Chow. 2012. Entanglements, or Transmedial Thinking about Capture. Duke University Press, Durham. \r\nGilles Deleuze. 2014. Difference and Repetition. Bloomsbury, London.  \r\nAlexander Galloway. 2012. The Interface Effect. Polity, Cambridge.  \r\nElizabeth Grosz. 2011. Becoming Undone: Darwinian Reflections on Life, Politics, and Art. Duke University Press, Durham.  \r\nTanya Kant. 2020. Making it Personal: Algorithmic personalization, identity and everyday life. Oxford University Press., Oxford.  \r\nFriedrich Kittler. 1999. Gramophone, film, typewriter. Stanford University Press, Stanford, California.  \r\nPierre Klossowski. 2017. Living Currency. Bloomsbury, London.  \r\nAlfred Kobsa. 2001. Generic User Modeling Systems. User Modeling and User-Adapted Interaction. Volume 11, Issue 1, pp. 49-63\r\nBruno Latour. 1993. We Have Never Been Modern. Cambridge, Massachusetts: Harvard University Press. \r\nJosephine Machon. 2013. Immersive Theatres: Intimacy and immediacy in contemporary performance. Palgrave Macmillan., Houndsmills, Basingstoke, Hampshire.  \r\nJoslin McKinney and Scott Palmer. 2017. Scenography Expanded: An introduction to contemporary performance design. Bloomsbury Methuen Drama, London.  \r\nJoshua Meyrowitz. 1985. No sense of place. Oxford University Press, New York.  \r\nJussi Parikka. 2012. New Materialism as Media Theory: Medianatures and dirty matter. Communication and Critical/Cultural Studies. Vol. 9, No. 1, March 2012, pp. 95-100.  \r\nJacques Rancière. 2004. The sublime from Lyotard to Schiller: Two readings of Kant and their political significance. Radical Philosophy. Issue no. 126, July/August 2004, pp. 2-15.  \r\nJacques Rancière. 2009. The Emancipated Spectator. Verso, London.  \r\nJames Smithies et al. 2019. Managing 100 Digital Humanities Projects: Digital scholarship and archiving in King\'s Digital Lab. Digital Humanities Quarterly 13 (1).  \r\nCarina E.I. Westling. 2020. Immersion and Participation in Punchdrunk\'s Theatrical Worlds. Bloomsbury, London. ',1,'Westling','Carina E. I. Westling','Carina E. I. Westling *(School of Media and Communication, University of Sussex, UK)*','http://eprints.bournemouth.ac.uk/32986/',1,'10.1145/3363384.3363471','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,27),(51,'ramirez-gomez-exploring-the-sensed-and-unexpected-not-looking-in-gaze-interaction','2019-09-03 08:29:56','2019-11-19 12:20:31','2019-09-03 08:29:56',NULL,1,'published','[]','Exploring the Sensed and Unexpected: Not Looking in Gaze Interaction','Gaze interaction paradigms rely on the user needing to look at objects in the interface to select them or trigger actions. ”Not looking” is an atypical and unexpected interaction to perform, but the eye-tracker can sense it. We illustrate the use of ”not looking” as an interaction dynamic with examples of gaze-enabled games. We created a framework containing a spectrum of five discrete categories for this unexpected use of gaze sensing. For each category, we analyse games that use gaze interaction and make the user look away from the game action up to the extent they close their eyes. The framework is described based on whether specific game events mean the player might not; cannot; should not; must not; or does not look. Finally, we discuss the outcomes of using unexpected gaze interactions and the potential of the proposed framework as a new approach to guide the design of sensing-based interfaces.','Argenis Ramirez Gomez and Hans Gellersen. 2019. Exploring the Sensed and Unexpected: Not Looking in Gaze Interaction. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 7 pages. [https://doi.org/10.1145/3363384.3363479](https://doi.org/10.1145/3363384.3363479 \"DOI for the article \'Exploring the Sensed and Unexpected: Not Looking in Gaze Interaction\'\")','1 INTRODUCTION\r\n\r\nThe design of sensing-based interactions is often guided by the use of sensing technologies considering what is sensed and expected [2]. Benford et al. define what is sensed as what the computer system or sensor can measure. What is expected is referred to as the interactions the users might be expected to perform, and such interactions are natural to the interface. For example, the act of touching in a touchscreen or touchpad; speaking into a microphone; looking at a screen with eye-tracking sensing, etc. Unexpected interactions are less usual and often performed when the interface is used in an atypical way or context.\r\n\r\nInterfaces using the space of unexpected actions are uncommon and underexplored in Human-Computer Interaction (HCI) because they are ambiguous and create tension. One could think that not touching a touchscreen to select makes no sense. It might create an incompatible context that disrupts preconceptions of how the sensing technology is used [8], and yields unexpected interactions. On the other hand, Gaver et al. [8] see in this Ambiguity of Context an opportunity to enable designers to go beyond the limits of technology and to craft interactive designs that are engaging and thought-provoking.\r\n\r\nAccordingly, we analyse gaze interaction with eye-tracking systems, exploring ”not looking” as the unexpected interaction and incompatible context. We investigate the use of ”not looking” mechanics in gaze-enabled game applications to define the space of unexpected gaze interactions. We reflect on the state of the art interaction dynamics to illustrate the ”not looking” spectrum and provide a discussion of the lessons learned and the opportunities beyond play and gaze sensing.\r\n\r\nOur work contributes a design framework developed on two levels. Firstly, it builds on the design of unexpected sensing-based interactions drawn from users’ behaviour. These interactions are guided by the users deciding they might not; cannot; should not; must not; or do not interact as expected. Secondly, the framework defines the design space for ”not looking” in gaze interaction.\r\n\r\n2 AMBIGUITY AND PLAY\r\n\r\nApplications using ambiguous sensing-based interactions are mostly represented in art-related, performative or playful contexts, to create a landscape of provocative and unconventional experiences inviting reflection [2]. In HCI, ambiguity is seen as a problem, but it is introduced as a resource for design [25]. The range of applications using the contextual ambiguity of the sensor is less crowded but present in examples like the POUTs [20]. Usually, pins are designed so the user can attach them to a pinboard, and it is unexpected for the pin to eject itself. POUTs are pins designed with this unexpected space of the interaction in mind: they pop out. This application created the opportunity to link physical and digital documents [21], which is useful, for instance, when removing a document in the digital space, the POUT will eject the documents from the physical pinboard.\r\n\r\nSimilarly, applications using gaze interaction are designed using eye-tracking technology information on where the user is looking. Therefore, what is unexpected is that the users stop looking. We take this opportunity to showcase how the use of ambiguity and exploration of the unexpected space of gaze sensing can create opportunities in the HCI design space.\r\n\r\nFurthermore, ambiguity of context can be found in game applications and research. For instance, games using eye-tracking for interaction but penalise you for looking at the game objects [24, 34]; or a game that challenges the player to control two characters at the same time coordinating both halves of a single game controller[29]. Play offers ambiguity of context a safety net to explore the unexpected space of sensing-based interaction without disrupting the preconceived context by posing challenges. Given the unconventional use of gaze to ”not look”, we chose game applications that showcase this unexpected paradigm to analyse the space that it provides for interaction with eye-tracking systems.\r\n\r\nBenford et al. [2] have already defined examples of unexpected interactions using the computer mouse, head-mounted displays or tangible interfaces, among others. They focused on different properties of movement or physical form of the interface, inviting designers to think of extremes, and bizarre scenarios. However, it is not obvious for the ubiquitous sensing of eye-trackers how those properties could be applied. To understand the space of unexpected gaze interactions, we created a framework illustrated by state of the art applications that make the user ”not look” at the interface.\r\n\r\n3 DEFINING THE UNEXPECTED IN GAZE INTERACTION\r\n\r\nGaze interaction is coupled with looking. Eye trackers provide information about where exactly the user is looking to enable interaction, for instance on a screen desktop, following the dynamic ”What you look at is what you get” [12]. We look at the objects we want to interact with [38] because gaze signals interest [28]. Therefore, looking becomes the expected action in eye-tracking sensing technology.\r\n\r\nContrary to that, we can think about the other extreme of interaction and unexpected use of the sensor. An eye tracker can sense when and where we are looking, but also when we are not, and when the gaze signal is absent. However, not looking could take many forms, such as looking away with the eyes open; looking elsewhere; blinking, or closing our eyes.\r\n\r\nIn interaction, ”not looking” is mostly associated with meditation apps in which users are asked to close their eyes, and they are guided through different exercises. In gaze interaction, not looking is an unexpected dynamic, only used in accessibility contexts with eye blinks to indicate a gaze selection [13, 37]; or to ”look away” coupled with behaviour metaphors in games to avoid eye contact with avatars [5].\r\n\r\nNevertheless, in gaze-enabled games, not looking is used to provide novel playful experiences. In the following sections, we analyse a set of games with gaze interaction dynamics. We propose five discrete categories in a framework based on the spectrum between directly looking to interact and the opposite extreme.\r\n\r\n4 WHAT YOU LOOK AT IS WHAT YOU GET\r\n\r\nEye gaze interaction leverages the use of gaze as a natural pointer to trigger events by aligning where our eyes focus on the screen with objects of interest. In games, gaze interaction has been used to replace or complement controllers [1, 11] explicitly, or implicitly control the movement and effects of the game camera view [9, 18].\r\n\r\nJust by looking, players can tag enemies [31]; aim weapons [7, 27]; fire [17]; signal which objects in the scene they want to select [4, 37], and make their character move to where they are looking [26, 27]. Gaze pointing is enough to trigger those explicit outcomes, but it could also be used to indicate the object of interest and confirm the selection with hand gestures  [3]; voice [22, 32]; keyboard; mouse, or touch [16, 23].\r\n\r\nWhen looking directly, gaze interaction becomes explicit to the user, and the effects that are triggered are expected and desired outputs of the interaction. For example, when players look at an enemy to attack, they are aware of what is going to happen. On the other hand, the effects of implicit gaze are not noticeable, because the change has no consequences on the gameplay. E.g., blurring the scene where the player does not look for realistic graphics rendering fostering immersion [9].\r\n\r\n5 NOT LOOKING: FIVE CATEGORIES\r\n\r\nThe looking to not looking spectrum could be considered binary, but it can also be explained in different categories. ”Not looking” as a concept can mean different things: not being able to look because it is physically impossible; looking away or elsewhere; blinking, or keeping your eyes shut. We illustrate in the following framework five discrete categories based on interactive gaze-enabled game designs. They demonstrate a range of potential interaction dynamics that play with the spectrum defined from looking to its unexpected use of the eye-tracking sensor (see Figure 1). In the framework, we describe examples of games and reflect on their position in the ”not looking” space from directly looking for interaction to closing your eyes. In line with the definition of unexpected interactions, we define each category based on the users’ decision to look away and their behaviour.\r\n\r\n\r\nFigure 1: Unexpected Gaze Interaction Framework defining in 5 categories the spectrum from looking to ”not looking”. Each iteration is illustrated by examples that showcase the use of gaze, their looking dynamic, and the outcome of the paradigm.\r\n5.1 First: Gaze Effects (Might not look)\r\n\r\nThe Royal Corgi [36]. In the game, the player needs to network and talk to the king\'s counsellors to win their favour and become the royal corgi instructor. The game is presented in a first-person view and uses the keyboard to navigate through the different dialogue options, but where the player looks influences the character\'s reactions. Therefore, the player needs to be careful and pay attention to where they look not to upset the character with whom they interact. E.g., when talking to the Military Advisor, players need to show respect by maintaining eye contact. Moreover, when talking to the Budget Advisor, they need to be careful and not glance at his wife, or he will get offended.\r\n\r\nDying Light [30]. This example is a survival horror and adventure game set in a dystopian post-apocalyptic world. The player needs to infiltrate a quarantine zone while battling human enemies but also zombies. In the gaze-enabled version of the game, the player can aim firearms at gaze; automatically climb where they look and control a flashlight with gaze; all while moving around zombies. However, zombies will notice your presence when they are looked at, making them responsive to gaze interaction.\r\n\r\nThese two examples demonstrate that looking can create unintended outcomes. We look to explore the scene, and we also use looking for interaction (Dying Light). However, characters react to our attention and looking behaviour triggering what could be unwanted and unintended consequences. Accordingly, we might decide to stop scanning the scene and stop looking around not to promote these undesired gaze effects. In The Royal Corgi we might decide to only look at the character we are talking to when we notice they get upset when we look elsewhere, hence not looking at the scene. Similarly, in Dying Light, we might choose not to glance around in a space full of zombies, and keep our gaze low, to not draw the dying\'s attention to you.\r\n\r\n5.2 Second: Gaze Attention (Cannot look)\r\n\r\nShynosaurs [35]. In Shynosaurs, the player needs to save the cuties by dragging and dropping them into safety with the mouse. During the task, the shynosaurs (dinosaur-like enemies) come from the woods to take the cuties away. However, if the player glances at the shynosaurs, they will feel intimidated and act like a shy naughty kid. They will stop and pretend they are not doing anything wrong. The longer the player looks at them, the shyer they become, until they cannot stand being looked at and run away crying.\r\n\r\nLimus and the eyes of the Beholders [15]. The hero, Limus, needs to escape a dark cellar by using a magic portal. The challenge is that the enemies called Spikees will try to catch Limus when they see him, going towards his position. However, if Limus looks at the Spikees, they will freeze and stop moving. In the game, the player controls Limus with a gamepad, whereas gaze interaction is used for the player to look at the Spikees. To make this chasing enemies stop, both the avatar (Limus) and the player need to look at them, disrupting the task of getting to the end of the level.\r\n\r\nThese two examples illustrate how looking can be challenging because we cannot look at two things simultaneously, introducing playing with ”attention dilemmas”. Both in Shynosaurs and Limus’ games, the player faces a challenge in gaze attention and a constant dilemma. They need to either solve the main task: saving cuties or reaching the end of the level; or looking at the enemies to freeze them. This ”not looking” dynamic makes the users stop looking at the game scene and focus their attention on the enemies. Although this dynamic might be difficult to extrapolate to other less playful domains, it offers an insight into how playing with this level of not being able to look can create greater awareness of the user\'s gaze attention and how to balance it.\r\n\r\n5.3 Third: Gaze Awareness (Should not look)\r\n\r\nScreencheat [14]. In this competitive split-screen First-Person Shooter multiplayer game, players are invisible and need to look at each other\'s screens to win. Each player needs to find the other and kill them first. To do this, they are encouraged to look at the half of the screen where the other player is playing. In the scene, they can see where the player is but also where they are looking.\r\n\r\nTicket to Ride [19]. Ticket to Ride is a board game in which players need to build train routes between cities across North America to gain points. Target routes are predefined by goal connection cards that are only visible for the corresponding player, and if incomplete will make the players lose points. The challenge becomes planning train networks carefully to minimise the risk that the opponent will block the path and take over the route. In the gaze-enabled digital version of the game, the gaze point is visualised to the opponent, spoiling the player\'s strategy.\r\n\r\nIn Screencheat the player is forced to look somewhere else to figure out where the other player is and win. However, the opponent player knows where you look in the game and might react accordingly. Similarly, in Ticket to Ride, the player is aware that the other player can see where she is looking at, and might decide to fool and deceive the opponent by looking somewhere else. Both examples show how the player knows that the opponents are aware of where they are looking. As players, we might decide that we should not look at the scene, not to spoil our strategy. Therefore, we might choose to look away deliberately to trick the other player.\r\n\r\n5.4 Fourth: Gaze Aversion (Must not look)\r\n\r\nVirus Hunt [34]. In this arcade game, players win points by removing viruses by touching them on the screen. However, if the player looks at the virus, it duplicates, spreading the infection.\r\n\r\nSuperVision [24]. This game is a collection of three mini-games exploring the use of gaze aversion and peripheral vision. In the games, players need to overcome mouse manipulation tasks and challenges in perception in peripheral vision of objects with different size; colour; and form. When players look at the game objects, they are penalised, and they are forced to look away and work only with what they can see in their peripheral vision.\r\n\r\nThese two game examples are designed to explore two main concepts: touch or mouse manipulation, and the use of peripheral vision with gaze interaction. Further, SuperVision expands on just playing with what can be seen in the periphery, and the three mini-games leverage perception capabilities by proposing visual challenges in peripheral vision. Both SuperVision and Virus Hunt establish rules that make the players stop looking or look away. The player is penalised when looking at the objects in the scene that need to be sorted by using gaze aversion dynamics. In other words, looking is not permitted, but it is still possible (it is not required to close the eyes). Through the games, players are unsuccessful at overcoming the challenges, because the eyes are attracted to objects that pop up. They might look and fail, making them understand that to succeed, they must not look but need to figure out how to do things by looking elsewhere.\r\n\r\n5.5 Fifth: Gaze Absence (Eyes Closed)\r\n\r\nInvisible Eni [6]. This game uses gaze interaction; pupil dilation (size); and blinking, to affect different game states. The goal of the game is to move Eni close to butterflies so she can guide them to flowers and feed them with nectar to be free. Eni must complete this task avoiding the nightmare monsters that chase her. However, when the players close their eyes, Eni does too, and disappears into a puff of smoke, evading the monsters and protecting herself.\r\n\r\nThis last example illustrates the extreme of not looking that happens when the user shuts their eyes, and the eye-tracker loses the gaze information. Overall, looking is not physically possible, because we cannot see with our eyes closed. Because of how unexpected closing one\'s eyes is in gaze interaction, there are not many examples that showcase this category of ”not looking”.\r\n\r\n6 BEYOND PLAY: LESSONS LEARNED\r\n\r\nOur exploration of the unexpected space of gaze interaction through new playful game dynamics helped to shape opportunities that could be extrapolated in other genres and applications within the HCI field. Figure 1 extends on the defined framework towards the design of unexpected gaze interactions. It shows each category in the ”not looking” spectrum; how they relate to the type of gaze concept; the game dynamic illustrated in the examples; and the resulting generalised themes.\r\n\r\n6.1 Social Gaze and Awareness\r\n\r\nThe games using gaze effects, introduce to some extent the Midas Touch [33] during gaze pointing. This is related to the trigger or selection of objects when we look at them without the intention to interact with them. In HCI, the Midas Touch is a problem and it is often avoided. For example, in desktop applications in which to select with gaze, we would use the eyes to indicate the object of interest and another input, such as the keyboard, to confirm the selection. In games, it can be leveraged, not only to introduce dynamics for not looking but also to introduce the use of Social Gaze. The Royal Corgi [36] uses social gaze behaviours in a virtual world that led to more practical applications of gaze and greater immersion in a playful experience. However, Social Gaze is not unique to the gaming context. For instance, in 3D virtual world online communities, or meeting spaces of the future, gaze behaviour could be useful to recreate real-life situations. E.g. users could know if they are looked at; where another user is looking at; or avoiding to make eye contact to not engage in starting a conversation accordingly.\r\n\r\nOn the other hand, in both Screencheat [14] and Ticket to Ride [19], gaze visualisation is presented as a way to share the opponent\'s experience, and it has been demonstrated to have a positive effect in social presence [14]. Moreover, although the examples are set in a competitive context, this visualisation could also be used to add a new layer of non-verbal communication between two parties. This showcases that gaze could be used in the digital space, e.g. in remote collaborative work-spaces. Further, this category in the ”not looking” framework allowed players to predict and try to understand their opponent\'s strategy and behaviour. Gaze patterns are a good asset for systems to predict intentions [10]. However, systems need to be aware that such intentions might not always be real, and the user could also try to ”fool” when aware that she is being observed. This presents opportunities, not only to explore deciding not to look in the play space but also to consider this possibility to train the recognition systems of the future.\r\n\r\n6.2 Peripheral Vision and Metaphors\r\n\r\nThe use of gaze aversion allowed the exploration of peripheral vision perception in games, leading to potential applications to train peripheral awareness [24]. Greater peripheral awareness can be useful, for example, to pick up notifications without looking at them. In a way, this paradigm could also solve the ”Attention Dilemma” posed in Shynosaurs [35], as the player might be able to focus their attention on the enemies while performing the task in peripheral vision. Moreover, using gaze aversion as the ”not looking” gaze interaction dynamic could train users to resist the impulse of looking at things that pop up. Playing with ”not looking” could train inhibition control [24]. In turn, this could guide the design of the interfaces of the future that do not disturb the user from the main task. For example, GPS and navigation systems that do not need to be looked at, creating safer driving environments.\r\n\r\nOn the other hand, ”not looking” enhanced the use of metaphors to guide the gaze interaction through the narrative of the game. In Invisible Eni [6], when the tracker loses the eyes once they are closed, the player character disappears. This example uses blinks as a means or metaphor to escape dangerous situations or to close the eyes to protect ourselves from intimidating events. In other words, not looking by closing the eyes creates new design opportunities to explore gaze metaphors. For instance, closing one\'s eyes to avoid danger as we would do in real life; or a ”blind faith” that with our eyes shut, nothing wrong can happen, and we need to trust the system. Other examples could use closing the eyes as a sign for concentration; resting, or to disappear from the scene for a moment. New metaphors could guide the design of future applications, for instance, for meditation. In meditation apps, the user is guided to close their eyes, but detecting the action could signal that the user is ready to trust the system to guide them, and wait for further instructions. On the other hand, opening one\'s eyes could signal the system that we need to do something else and have a break. Overall, novel metaphors considering the ”not looking” space can inform future systems to customise the experience based on users’ behaviour.\r\n\r\nMoreover, metaphors are not exclusive of the fifth category of the framework but present throughout the different examples of the spectrum. ”Not looking” created the space for new gaze interactions guided by a narrative, such as looks that challenge or defy or looks with social meaning [36]; looks that intimidate [35]; looks that freeze [15]; and looks that could petrify, kill or charm [24]. This showcases the potential of exploring the spectrum of the proposed framework for interaction design.\r\n\r\nOverall, exploring the unexpected space of gaze interaction in playful scenarios has led to solutions that could influence the future design of other application genres. However, it is not clear how to generalise the different categories of the spectrum defined and how they could be applied to other sensing-based interactive systems.\r\n\r\n7 DISCUSSION\r\n\r\n7.1 Understanding Looking Away\r\n\r\nBased on the defined categories, we could understand the unexpected use of gaze interaction as a framework based on the users’ decision not to look and modulation of their gaze behaviour. Each category of the spectrum must not be treated in chronological order but as a set of dynamics that move towards the complete absence of sensed gaze input. Nevertheless, between them, we can identify a consistent pattern: the user is in control of looking away, while the game engine is in control of the challenge and influences the user\'s decision to look elsewhere. We can define two sets of behaviours. First, when the users might realise through reflection on the game outcomes that they might not, cannot and should not look at the game scene (A). Second, the scenarios in which the game system pushes the users to look away, either with rules that they must obey or mechanics that make them stop looking (B).\r\n\r\nOne take of the first group (A) is to consider them closer to the space of the expected looking interaction. It is the game engine that introduces an effect or a challenge to gaze interaction. On the other hand, the user decides that looking is no longer suitable for the game context, and therefore falls on the ”not looking” paradigm. Although in the second category (cannot look), the system is designed so the users cannot attend to simultaneous tasks, it is still the user who decides to look away and balance the attention to the different challenges of the game.\r\n\r\nOn the other hand, the second behaviour (B) introduces less flexible rules, posing challenging gaze interactions that present looking away as a ”must” to be successful in the experience. Moreover, the users are also introduced to metaphors that require them to stop looking and to close their eyes. Both actions are the users’ will, but the game engine challenge can influence them. They no longer offer an open space for reflection and decision but set the behaviour as a rule.\r\n\r\nIn contrast to the definition of what is sensed and not expected, current applications using gaze interactions and the ambiguity of looking away are not defined by the atypical use of the interface. This could be sometimes encouraged by the system itself. ”Not looking” could either be a decision of the player created by the interface outcomes to the users’ gaze, or a direct consequence of the application\'s rules. Therefore, ”not looking” as an unexpected interaction could be originated in design; and designers could follow the proposed framework to trigger this not so ”unexpected” users’ behaviours.\r\n\r\n7.2 Designing Unexpected Interactions\r\n\r\nAlthough the different categories of the presented framework are centred around applications of gaze interaction, it is not clear how to generalise them to define the unexpected interactions space for other HCI genres. Moreover, whether the proposed categories are suitable to be used to design applications and interfaces with sensors beyond eye-tracking could shape the research agenda for this new design approach. We can only hypothesise how the framework can illustrate new uses of sensors for interaction.\r\n\r\nFirstly, we could think of unexpected interactions with sensors. For instance, not moving or shaking a device with an accelerometer; not pressing a button; not speaking into a microphone; not touching a touchscreen with your fingers or a pen. Secondly, each stage of the spectrum could be different to each sensor, and it is up to the designer to introduce the effects to trigger the unexpected behaviour in each category.\r\n\r\nWe can take as an example pressing a button. Not pressing it might be applied in an interface that requires pushing it consistently and then a release for interaction (e.g. Dead man\'s switch). This system could also be considered a somehow switched input binary state, where pressing is the null signal. The button could also be inside a box, making it physically impossible to be pressed. Further, a red button with an alarm sign might suggest to the user that they must not press it. On the other hand, another one with a ”please do not press” sign could be an instance of a button that should not be pressed. Moreover, the designer can think of situations in which the user might not press the button (when it is required). Maybe it is because it makes an uncomfortable noise, or because it gives you a low and not dangerous static shock. Another example could tackle a button that cannot be pressed. It might be a broken button; one that moves away; or one that pushes itself when the hand approaches.\r\n\r\nSimilarly, the lack of pen input in a tablet could lead to the design of mid-air gestures that might indicate the users’ intention when they might not touch the surface, such as in a sorting task or an option selection. Moreover, we could also think of voice sensing systems that you need to whisper or even be silent to activate them. More pragmatically, silence could be the indicator of written spaces in speech-to-text systems. These examples could illustrate, for instance, learning opportunities for interfaces using buttons that fail; or novel pen and touch gestures on touchscreens. However, the framework and defined spectrum might also need to be fine-tuned for each technology.\r\n\r\nWhereas this approach is useful when designing gaze-enabled interfaces, further research is needed to validate and generalise the model for other sensing technologies. Overall, the presented framework encourages designers to think with a focus on the users’ behaviour in the unexpected interaction space.\r\n\r\n8 CONCLUSION\r\n\r\nWe explored the concept of ”not looking” as an ambiguous and atypical way of using eye-tracking technologies for gaze interaction. We defined a framework to design unexpected gaze interaction that could potentially be generalised to other sensing technologies. This offers a new design approach based on system rules and users’ behaviour; and a potential tool for designers to explore the limitations of the technology and their implications.\r\n\r\nREFERENCES\r\n\r\nRichard Bates, Stephen Vickers, and Howell O Istance. 2010. Gaze interaction with virtual on-line communities: levelling the playing field for disabled users. Universal Access in the Information Society 9, 3 (2010), 261–272.  \r\nSteve Benford, Holger Schnädelbach, Boriana Koleva, Rob Anastasi, Chris Greenhalgh, Tom Rodden, Tom Rodden, Jonathan Green, Ahmed Ghali, Tony Pridmore, et al. 2005. Expected, sensed, and desired: A framework for designing sensing-based interaction. ACM Transactions on Computer-Human Interaction (TOCHI) 12, 1(2005), 3–30.  \r\nMarcus Carter, Joshua Newn, Eduardo Velloso, and Frank Vetere. 2015. Remote gaze and gesture tracking on the microsoft kinect: Investigating the role of feedback. In Proceedings of the Annual Meeting of the Australian Special Interest Group for Computer Human Interaction. ACM, 167–176.  \r\nEmiliano Castellina and Fulvio Corno. 2008. Multimodal gaze interaction in 3D virtual environments. COGAIN 8(2008), 33–37.  \r\nMatthieu Perreira Da Silva, Vincent Courboulay, and Armelle Prigent. 2007. Gameplay experience based on a gaze tracking system. In ”Gaze-based Creativity, Interacting with Games and On-line Communities” INPROCEEDINGS in proceedings of COGAIN 2007 (Communication by Gaze Interaction IST FP6 European Project). 25–28.  \r\nInger M Ekman, Antti W Poikola, and Meeri K Mäkäräinen. 2008. Invisible eni: using gaze and pupil size to control a game. In CHI’08 extended abstracts on Human factors in computing systems. ACM, 3135–3140.  \r\nMassive Entertainment. 2019. Tom Clancy\'s The Division 2. Game.  \r\nWilliam W Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a resource for design. In Proceedings of the SIGCHI conference on Human factors in computing systems. ACM, 233–240.  \r\nSébastien Hillaire, Anatole Lécuyer, Rémi Cozot, and Géry Casiez. 2008. Using an eye-tracking system to improve camera motions and depth-of-field blur effects in virtual environments. In Virtual Reality Conference, 2008. VR’08. IEEE. IEEE, 47–50.  \r\nChien-Ming Huang, Sean Andrist, Allison Sauppé, and Bilge Mutlu. 2015. Using gaze patterns to predict task intent in collaboration. Frontiers in psychology 6 (2015), 1049.  \r\nPoika Isokoski, Markus Joos, Oleg Spakov, and Benoît Martin. 2009. Gaze controlled games. Universal Access in the Information Society 8, 4 (2009), 323–337.  \r\nRobert J. K. Jacob. 1990. What you look at is what you get: eye movement-based interaction techniques. In Proceedings of the SIGCHI conference on Human factors in computing systems: Empowering people(CHI ’90). ACM, New York, NY, USA, 11–18. https://doi.org/10.1145/97243.97246  \r\nAleksandra Królak and Paweł Strumiłło. 2012. Eye-blink detection system for human–computer interaction. Universal Access in the Information Society 11, 4 (2012), 409–419.  \r\nMichael Lankes, Bernhard Maurer, and Barbara Stiglbauer. 2016. An eye for an eye: Gaze input in competitive online games and its effects on social presence. In Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology. ACM, 17.  \r\nMichael Lankes, Thomas Mirlacher, Stefan Wagner, and Wolfgang Hochleitner. 2014. Whom are you looking for?: the effects of different player representation relations on the presence in gaze-based games. In Proceedings of the first ACM SIGCHI annual symposium on Computer-human interaction in play. ACM, 171–179.  \r\nMichael Lankes and Barbara Stiglbauer. 2016. GazeAR: Mobile gaze-based interaction in the context of augmented reality games. In International Conference on Augmented Reality, Virtual Reality and Computer Graphics. Springer, 397–406.  \r\nLennart Erik Nacke, Michael Kalyn, Calvin Lough, and Regan Lee Mandryk. 2011. Biofeedback game design: using direct and indirect physiological control to enhance game interaction. In Proceedings of the SIGCHI conference on human factors in computing systems. ACM, 103–112.  \r\nLennart E Nacke, Sophie Stellmach, Dennis Sasse, and Craig A Lindley. 2010. Gameplay experience in a gaze interaction game. arXiv preprint arXiv:1004.0259(2010).  \r\nJoshua Newn, Fraser Allison, Eduardo Velloso, and Frank Vetere. 2018. Looks can be deceiving: Using gaze visualisation to predict and mislead opponents in strategic gameplay. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 261.  \r\nKher Hui Ng, Steve Benford, and Boriana Koleva. 2005. PINS push in and POUTS pop out: creating a tangible pin-board that ejects physical documents. In CHI’05 Extended Abstracts on Human Factors in Computing Systems. ACM, 1981–1984.  \r\nKher Hui Ng, Boriana Koleva, and Steve Benford. 2007. The iterative development of a tangible pin-board to symmetrically link physical and digital documents. Personal and Ubiquitous Computing 11, 3 (2007), 145–155.  \r\nJ O\'Donovan, J Ward, S Hodgins, and V Sundstedt. 2009. Rabbit run: Gaze and voice based game interaction. In Eurographics Ireland Workshop, December.  \r\nKen Pfeuffer, Jason Alexander, and Hans Gellersen. 2016. GazeArchers: Playing with Individual and Shared Attention in a Two-player Look&Shoot Tabletop Game. In Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia(MUM ’16). ACM, New York, NY, USA, 213–216. https://doi.org/10.1145/3012709.3012717  \r\nArgenis Ramirez Gomez and Hans Gellersen. 2019. SuperVision: Playing with Gaze Aversion and Peripheral Vision. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. ACM, 473.  \r\nPedro Sanches, Kristina Hook, Corina Sas, and Anna Stahl. 2019. Ambiguity as a resource to inform proto-practices: The case of skin conductance. ACM Transactions on Computer-Human Interaction (TOCHI) (2019).  \r\nC Schaefer, R Menges, K Schmidt, M Kuich, and T Walber. 2014. Schau genau! an eye tracking game with a purpose. Applications for Gaze in Games(2014).  \r\nJ David Smith and TC Graham. 2006. Use of eye movements for video game control. In Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology. ACM, 20.  \r\nIndia Starker and Richard A. Bolt. 1990. A Gaze-responsive Self-disclosing Display. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’90). ACM, New York, NY, USA, 3–10. https://doi.org/10.1145/97243.97245  \r\nStarbreeze Studios. 2013. Brothers: A Tale of Two Sons. Game.  \r\nTechland. 2018. Dying Light: Bad Blood. Game.  \r\nUbisoft Montreal and Ubisoft Toronto. 2018. Far Cry 5. Game [Xbox][Windows][PlayStation].  \r\nMUHTAR ÇAĞKAN ULUDAĞLIand CENGİZ ACARTÜRK. 2018. User interaction in hands-free gaming: a comparative study of gaze-voice and touchscreen interface control. Turkish Journal of Electrical Engineering & Computer Sciences 26, 4(2018), 1967–1976.  \r\nBoris Velichkovsky, Andreas Sprenger, and Pieter Unema. 1997. Towards gaze-mediated interaction: Collecting solutions of the ”Midas touch problem”. In Human-Computer Interaction INTERACT’97. Springer, 509–516.  \r\nEduardo Velloso, Carl Oechsner, Katharina Sachmann, Markus Wirth, and Hans Gellersen. 2015. Arcade+: A Platform for Public Deployment and Evaluation of Multi-Modal Games. In Proceedings of the 2015 Annual Symposium on Computer-Human Interaction in Play(CHI PLAY ’15). ACM, New York, NY, USA, 271–275. https://doi.org/10.1145/2793107.2793145  \r\nMelodie Vidal. 2014. Shynosaurs: A Game of Attention Dilemma. In Proceedings of the First ACM SIGCHI Annual Symposium on Computer-human Interaction in Play(CHI PLAY ’14). ACM, New York, NY, USA, 391–394. https://doi.org/10.1145/2658537.2662979  \r\nMelodie Vidal, Remi Bismuth, Andreas Bulling, and Hans Gellersen. 2015. The Royal Corgi: Exploring Social Gaze Interaction for Immersive Gameplay. In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems(CHI ’15). ACM, New York, NY, USA, 115–124. https://doi.org/10.1145/2702123.2702163  \r\nTom Wilcox, Mike Evans, Chris Pearce, Nick Pollard, and Veronica Sundstedt. 2008. Gaze and voice based game interaction: the revenge of the killer penguins.SIGGRAPH Posters 81(2008).  \r\nShumin Zhai, Carlos Morimoto, and Steven Ihde. 1999. Manual and gaze input cascaded (MAGIC) pointing. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems. ACM, 246–253.  \r\n',1,'Ramirez-Gomez','Argenis Ramirez Gomez and Hans Gellersen','Argenis Ramirez Gomez *(Lancaster University, UK)*<br>\r\nHans Gellersen *(Lancaster University, UK)*',NULL,0,'10.1145/3363384.3363479','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,35),(52,'schubert-ambiguity-as-a-means-for-triggering-civic-participation','2019-09-03 08:29:56','2019-11-19 14:06:00','2019-09-03 08:29:56',NULL,1,'published','[]','Ambiguity as a Means for triggering Civic Participation','This paper builds on the dimensions of ambiguity, as stated in the article by Gaver et al. It proposes to transfer the phenomenon of ambiguity to the domains of Social and Public Design, which are not only in need of generating attention in public spaces but also in funnelling long-term interest to deploy citizen participation. This paper discusses the categories of ambiguity on a theoretical level and adds relevant Research-Through-Design case studies that examine design knowledge in practice.','Jennifer L. Schubert. 2019. Ambiguity as a Means for triggering Civic Participation. In *Proceedings of the Halfway to the Future Symposium 2019 e (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 3 pages. [https://doi.org/10.1145/3363384.3363484](https://doi.org/10.1145/3363384.3363484 \"DOI for the article \'Ambiguity as a Means for triggering Civic Participation\'\")','1 Introduction\r\n\r\nAmbiguity – as stated in the paper of Gaver et al. [1] – should become a further elaborated concept for design (research). By doing this, it would be possible to intentionally implement ambiguous elements in design artefacts, services, systems or other assemblages. Especially for Social Designers working in public spaces, ambiguity can be seen as a means to focus the public\'s attention in overstimulated spaces and environments. Through this intended irritation and provocation, curiosity arises. This use of ambiguity can work as a trigger for a long-term commitment in a give-and-take process that tackles local socio-political issues. In this way, citizens have the opportunity to contribute to public opinions, build alliances with their surroundings [2], and change their current living conditions to preferred ones [3]. The growing need for cooperation, involvement, and inclusiveness [4, 5] needs to be satisfied by new forms of participation – and ambiguity is one specific element to create meaningful ways of engagement. This kind of involvement is experimental, informal, and playful. Individuals who do not feel addressed by certain types of long-term participation, like community work in associations, churches or parties [6, 7], which is mainly based on verbal communication, can often feel motivated to contribute to new experimental and mixed-media forms of participation.\r\n\r\nThis paper hypothesizes that the curiosity triggered and nurtured by ambiguity should not be exploited to the extent that the created commitment results in a lack of understanding, or a degree of mistrust, and demotivation. These consequences occur faster than trust, and positive attitudes [8]. In order to avoid these frustrating interactions, this paper aims to fulfil Gaver et al.’s [1] goal of creating a better understanding of the dimensions of ambiguity.\r\n\r\nAdditionally, ambiguity in public spaces tackles the challenge of involving participants who are randomly confronted with ambiguity in an unforeseen way, in contrast with the context of museums, in which visitors expect various kinds of irritation, and Duchamp\'s urinal is a good example of this [1]. In order to obtain a deeper understanding of how ambiguity works in public spaces, in the context of Social Design and in relation to advanced digital technology (in comparison to Gaver et al.’s [1] considerations in 2003, when smart phones were not yet available), two case studies are provided that include open source artefacts and activities, and which were part of a bilateral research project between the Berlin University of Arts and the Bezalel Academy of Arts and Design in Jerusalem. The Berlin case studies were situated in a neighbourhood called Mehringplatz in Berlin-Kreuzberg.\r\n\r\n1.1 The Neighbourhood\r\n\r\nSince 2005, the Mehringplatz neighbourhood has been designated as an area with special needs.1 Therefore, a federally financed neighbourhood management was established, which initiates and finances local social activities. Friedrichstraße, the well-known luxury shopping street that starts in the centre of Berlin, turns into a car-free street with abandoned shops, and finally ends in the neighbourhood. High rise buildings built in the 1970s surround the most dominant characteristic of this neighbourhood: a three-level circular social housing complex. After German reunification in 1990, the neighbourhood lost much of its appeal and so those inhabitants who could afford it moved to other areas of Berlin. Investments in building infrastructure as well as in public spaces have remained absent since then.\r\n\r\n2 Ambiguous Artefact #1: Public Projection\r\n\r\nThe case study started with an intensive citizen-based workshop open to the public. During this meeting, an open-source app called Pinpoint Mehringplatz (fig. 1),2 was presented. With the app, the surroundings could be photographed and commented upon individually. The participants walked their route through the neighbourhood and marked the places they appreciate (#like), they avoid (#dontlike), and those they would like to change (#change). After coming back from the walk, all routes and pictures were gathered in a collective digital mapping (fig. 2), which served as a basis for mutual discussion.\r\n\r\nThe mapping also helped the participants to confidently present and discuss their personal experiences and perspectives (fig. 3). The smartphone, which is a familiar and ubiquitous communication tool, helped to connect private and public matters. Additionally, it convinced especially the younger residents to take part in the activity, since in research activities in the past, analogue means such as Cultural Probes, had not enjoyed much success in this neighbourhood.\r\n\r\nFig. 1-3:\r\nFig. 1-3: The open-source Pinpoint app, the collective mapping, the personal route presentation.\r\nAll pictures, statements, and anti-statements were collected and combined in a public projection, which was installed in a shop window of a neighbourhood café for two weeks (see fig. 4-6). Through the moving pictures and the unexpected place, attention was created through the “ambiguity of context”. Additionally, the projection contained a mixture of known places in the neighbourhood – shown in the pictures – and an anonymous statement that was only contextualized by hashtags. Through this mix, “ambiguity of information” was created. Observations showed that people stopped their stroll through the pedestrian passage, read on average four statements and then continued their walk (fig. 4). When participants arrived in groups, they started talking to each other (fig. 5). Through the “ambiguity of information”, questions were raised and discussed together. Therefore, this kind of ambiguity can also be seen as a conversation starter.\r\n\r\nThe purpose of this installation was not only to share the collected information amongst a broader public of the neighbourhood but also to funnel the attention that had been produced into involvement in the overall process. It is crucial to set anchors of information, which lead the users – after initial irritation – to an enlightening result. The users receive the power to decide on their own how to continue the interaction (getting in contact, receiving more detailed information, participating in the next meeting). The possibility of continuation gives a reward for dealing with the ambiguous artefact, system, or assemblage.\r\n\r\nFig. 4-6:\r\nFig. 4-6: The public projection in the neighbourhood café, overview of pictures and statements.\r\nAlthough so many anchors of contact information were offered in this activity, the projection itself did not trigger as much commitment as expected. However, the personal experience of the workshop\'s participants laid a more profound basis for further involvement. Overall, the projection fulfilled the goal of opening up the results to the local population. In future activities, the impact of the public projection can be possibly increased through a regular re-appearance in public spaces or through a direct link to face-to-face activities in workshops.\r\n\r\n3 Ambiguous Artefact #2: Soundbox\r\n\r\nAfter an open discussion about the commonly identified local issues, one topic that affected all age groups and social backgrounds living in the neighbourhood was selected. It was a long-term construction site in the centre of the neighbourhood that had been blocking the green area for several years. The construction was led by the “Berliner-Verkehrsbetriebe” (BVG) public transportation company. To strengthen the neighbourhood\'s standing with the construction company and political decision-makers, a new public installation was conceptualized. Based on experiences in pre-tests, the most suitable means of communication – especially for the migrant teenage residents – was sound-recording. In order to connect this way of communication with the goal to strengthen the residents’ voice against the “powerholders” [10 p.216], the concept of the soundbox was developed.\r\n\r\nThe box was a mash-up of a service hotline for complaints (represented by the old-fashioned telephone holder), as well as an emergency and information call point of the Berlin public transportation provider (represented by the colours). Through the fusion of two known communication elements into a new artefact, irritation was triggered. This artefact introduced the fourth category of ambiguity: the “ambiguity of combination”. Through the combination of known and new elements, the threshold to interact with the artefact is lowered as it provides known interaction patterns. The soundbox was the primary device for recording individual statements. After they had been submitted, the contributions were transferred to an animated projection set up next to the box, which randomly showed and played the submitted sound files (fig. 9). This way, the participants needed to hear statements of other neighbours first, before their own contribution was available. Through this intentionally designed delay – which can be placed in the “ambiguity of relationship” category – an awareness of other local perspectives was raised.\r\n\r\nIn three hours of the installation, forty statements were collected. Mainly teenage residents participated in the activity, but also older people, parents and new residents. These involved citizens were willing to state their personal and investigate other perspectives.\r\n\r\nFigure 7-10:\r\nFigure 7-10: The different dimensions of the soundbox (interface, telephone handset, projection, participants)\r\nIn the end, all statements were summarized in a manifesto which was put online,3 disseminated in the neighbourhood in the form of a handy booklet as well as through an oversized poster in the neighbourhood café. Finally, the manifesto was handed over to the construction company, with an explanation of the overall process and future possibilities.\r\n\r\nThough many residents took part in the different activities, it was not possible to build up an independent group that would, for example, hand over the manifesto to the company on its own. It still needed the support from us researchers. Nevertheless, the activity resulted in the construction company changing their information policy regarding the residents: a newsletter was initiated, the current process of construction was made transparent on posters along the construction site, and the shop owners were offered personal meetings with the construction company.\r\n\r\nWhen evaluating the public projection and the soundbox – and comparing them to the examples stated in Gaver et al. [1] – the attribute that all objects have in common is a particular way of openness in terms of possible interpretations and interactions. Through that feature, the user or visitor undergoes a form of appropriation and learning takes place [11]. The different interaction options give space for interpretations and a unique way of acquisition. Especially through the “ambiguity of relationships”, the individual perspective is compared with that of others. This constant comparison can lead to a more open attitude when dealing with other opinions.\r\n\r\nConcluding, the two site-specific case studies have shown how ambiguity can be used, especially for raising interest in and awareness of local issues in public spaces and with the help of open source technology. Ambiguity can make users curious about new interactions and ways of communication, which is one way to counteract the digital divide. Ambiguity can produce a playful effect, which often creates motivation and interest. This paper argues that this attention should be funnelled constructively so that a long-term engagement can result. But the paper also shows that ambiguity needs to be well-integrated and critically thought through, so that it reaches the effects which were intended.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThe case studies were part of the bilateral research project »Community Now?« (2013-2017) between Berlin University of Arts (UdK), the German Society of Design Theory and Research (DGTF e.V.) and Bezalel Academy of Arts and Design, Jerusalem, funded by the German-Israeli Future Forum (DIZF).\r\n\r\nREFERENCES\r\n\r\nBill Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI \'03). ACM, New York, NY, USA, 233-240. https://doi.org/10.1145/642611.642653  \r\nNoortje Marres. 2005. Issues spark a public into being – A key but often forgotten point of the Lippmann-Dewey debate. In Making Things Public (1st ed.). Bruno Latour and Peter Weibel (eds.). MIT Press, Cambridge MA, USA, 208-217.  \r\nHerbert A. Simon. [1969]1996. The sciences of the artificial. Cambridge, MA: MIT Press.  \r\nEzio Manzini. 2006. Creative communities, collaborative networks and distributed economies. Promising signals for a sustainable development. DIS.Indaco. Politecnico di Milano, Italy  \r\nSaskia Sassen. 2015. Stadtentwicklung – Erobert die Stadt zurück. (July 2015). In Zeit Online. Dirk Herzog (ed.). Retrieved October, 2015 from zeit.de/video/2015-07/4336085421001/stadtentwicklung-erobert-die-stadt-zurueck  \r\nRobert D. Putnam, Eva Cox, Peter Hall, Tagashi Inoguchi, Claus Offe, Susanne Fuchs, Victor Perez-Diaz, Bo Rothstein, Theda Skocpol, Jean P. Worms, and Robert Wuthnow. 2001. Gesellschaft und Gemeinsinn (1st ed.). Robert D. Putnam (ed.). Bertelsmann Stiftung. Gütersloh, Germany  \r\nFranz Walter, Felix Butzlaff, Stine Marg, and Lars Geiges. 2013. Die neue Macht der Bürger: Was motiviert die Protestbewegungen? (1st ed.). Franz Walter (ed.). Rowohlt Verlag. Reinbek, Hamburg, Germany  \r\nHartmut Rosa, Lars Gerstenbach, Henning Laux, and David Strecker. 2010. Theorien der Gemeinschaft (1st ed.). Junius Verlag. Hamburg, Germany  \r\nChristine Piwek. 2014. Integriertes Handlungs- und Entwicklungskonzept 2015-2017. Quartiersmanagement am Mehringplatz. Retrieved from , http://www.qm-mehringplatz.de/fileadmin/user_upload/Integriertes_Handlungs-und_Entwicklungskonzept_2015-2017.pdf\r\nSherry R. Arnstein. 1969. A Ladder of Citizen Participation. Journal of the American Institute of Planners (JAIP), vol 35.4., 216–224.  \r\nRichard Sennett. 2009. The Craftsmen (1st ed.). Yale University Press, USA  \r\nA APPENDICES\r\n\r\nAll pictures were taken by the author or the research team at the Berlin University of Arts.\r\n\r\nFOOTNOTE\r\n\r\n135% of all inhabitants and 70% of the children and teenagers receive federal income support like housing subsidy [9].\r\n\r\n2Open Source code: github.com/DRLabCivic/pinpoint [last view 26.6.2019]\r\n\r\n3All detailed information can be found here: mehringplatz.community-now.org [last view 24.6.2019]',1,'Schubert','Jennifer L. Schubert','Jennifer L. Schubert *(Faculty of Design and Art, Free University of Bozen-Bolzano, Italy)*',NULL,0,'10.1145/3363384.3363484','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,40),(53,'stals-urbanixd-from-ethnography-to-speculative-design-fictions-for-the-hybrid-city','2019-09-03 08:29:56','2019-11-19 12:37:59','2019-09-03 08:29:56',NULL,1,'published','[]','UrbanIxD: From Ethnography to Speculative Design Fictions for the Hybrid City','This paper presents research in the field of Urban Interaction Design which seeks to understand how people\'s personal, emotional relationships with urban places could potentially inform the design of new technological devices and services. A Speculative Design approach is taken by creating Speculative Design Fictions informed by the data gathered using the ethnographically-informed Walking & Talking method. However, creating the crucial link between themes in the data corpus and possible future scenarios for Speculative Design Fictions can be challenging. Building outwards from a sophisticated understanding of the approach, this paper presents a case study which focuses on the step-by-step process of designing and creating this crucial link for a Speculative Design Fiction in the form of a short film, using design techniques such as Tactics for Ambiguity, PACT-analysis and SCAMPER.','Shenando Stals, Michael Smyth, and Oli Mival. 2019. UrbanIxD: From Ethnography to Speculative Design Fictions for the Hybrid City. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 10 pages. [https://doi.org/10.1145/3363384.3363486](https://doi.org/10.1145/3363384.3363486 \"DOI for the article \'UrbanIxD: From Ethnography to Speculative Design Fictions for the Hybrid City.\'\")','1 Background\r\n\r\nThe vision of ubiquitous computing [52] is becoming increasingly realized through smart city solutions, the Quantified-Self movement and the proliferation of smartphones and smart watches. This adds a new technological layer to the pre- existing infrastructure of the urban environment, creating a hybrid city in which the physical world and the digital world come together. This technological layer offers novel opportunities to augment our experience of the urban environment [8]. Complementary to the traditional technology-driven, top-down smart city approach, Urban Interaction Design takes a bottom-up, human scale design approach to designing smart cities. It aims to identify the needs, desires, routines, behaviours and experiences of people in the smart city of the (near) future, to inform the design of innovative technological devices and services [45,44] The focus is on city making; people as engaged citizens using technology to create pleasant cities economically, socially and culturally [18]. Therefore, there is a growing need to create better understanding of the relationship between person, place and technology [46].\r\n\r\nThere has been an increased focus in the field of Urban Interaction Design on emotion and affect, to create a better understanding of people\'s experience of the urban environment, and to inform how technology could play a role in augmenting people\'s urban lived experience. This is illustrated by propositions for an affective framework for smart cities [21], route planning applications attempting to determine the most quiet, beautiful or happy walking routes through a city [38], and a multitude of urban HCI studies and applications. These studies aim to mediate feelings of personal safety [5,34,41], traffic safety [39], or to assist situated remembering in an urban context [15,29].\r\n\r\nInspired by artist Christian Nold\'s work on bio-mapping [32] and emotional cartography [33] and the rise of the Quantified-Self movement [24], there is an increased interest in exploring how mobile, wearable and Quantified-Self technology could be used to capture and collect people\'s emotional experiences of urban places [28,38,39,40,47]. There is also potential for sharing this personal data with other people using innovative technological devices and services [1,22,29,31,32,33,48,49]. Based on social science studies on the concept of place attachment [16,27,42] and these urban HCI studies attempting to leverage people\'s emotional experience of the urban environment, it can be argued that places that are meaningful on a personal level could provide a suitable lens for further investigation, as these personally meaningful places are typically the places that a person has a strong emotional bond with [48].\r\n\r\n2 Exploring Emotion and Person-Place relationships in the Urban Environment\r\n\r\nIn the social sciences, research has centred on various person-place related concepts. Place is often defined as a meaningful location [23], with place meaning developing from people\'s positive and negative experiences and emotions in places [27]. This can result in place attachment, a multidimensional concept which characterises the emotional relationship between individuals and their important places [26]. This paper outlines ongoing work where the overall aim is to understand how people\'s experiences of places in the urban environment that are meaningful to them on a personal level, for example the pub where they have met their partner, or the dark alley where they got mugged, and in particular their personal stories and emotions connected to those places, could potentially inform the design of future technological devices and services. The ongoing work investigates (1) the variety of personal emotional meanings connected to people\'s personally significant places in the urban environment; (2) how to collect, represent and communicate those personally meanings (i.e. the different forms this data can take); (3) the potential for sharing this personal emotion data with others (e.g. strangers, friends, and family); and (4) and how these emotional person-place relationships could potentially inform the design of future technological devices and services using Speculative Design Fictions.. This paper we will focus on the fourth objective as the first three have already been addressed and discussed in previous work.\r\n\r\n2.1 Methodology\r\n\r\nTo meet the overall aim, an ethnographically-informed Walking & Talking method was designed and implemented to investigate people\'s current emotional person-place relationships with personally significant places in the urban environment to create a better understanding of the urban context [46]. Subsequently, a Speculative Design approach was taken to explore how the trends and themes that emerged from the qualitative data could potentially inform the design of future technological devices and services. Speculative Design Fictions were created by projecting those trends and themes into multiple possible future scenarios.\r\n\r\nTo investigate people\'s emotional person-place relationships with personally significant places in the urban environment, semi-structured interviews were conducted, consisting of three parts. In the first part, an evaluative map technique was used to identify where people\'s personally significant places are located in the city and to articulate the type of experiences participants had in these places that make them personally meaningful. On a paper map of the city, participants were asked to indicate the location of five personally significant places, their home, workplace and typical routes they would take to traverse the city. Based on the outcome, a walking route was generated for the second part of the interview.\r\n\r\nThe second part of the interview used the ethnographical-informed Walking & Talking method [46] to elicit qualitative measurements, in-situ, of the subjective emotional experiences that participants had in their personally significant places and to further contextualize their personal stories connected to those places. The participant would take the researcher on a walking tour along the personally significant places selected by the participant. Being in-situ allowed the use of environmental cues to act as a catalyst for the memory to recreate and relive in-place experiences and made it easier for participants to identify the emotions connected to their personally significant place. The Plutchik Emotion Wheel [35] was used to enable the in-situ identification of emotions and to help participants to verbalize them (Figure 1). Semi-structured interview questions were used to investigate how participants would like to represent their experience of a place, the different forms this data could take, and the types of social relationships where participants would be willing to share this data with.\r\n\r\nFigure 1: Plutchik Emotion Wheel\r\nFigure 1: Plutchik Emotion Wheel, a visual lightweight tool containing the eight basic human emotions (joy, trust, fear, surprise, sadness, disgust, anger & anticipation), at three different intensity levels. Redrawn from [36].\r\nAfter completing the walking interview, the third step took a Speculative Design approach. Based on data collected during a pilot study, an emotion map containing different types of emotions connected to places in the city, from people that the participant has different types of social relationships with (e.g. strangers, anonymous friends, identifiable friends and their partner), was presented to the participant as a provocation (Figure 2). The aim was to investigate the influence of different types of social relationships connected to a place, and the different types of emotions connected to places, on people\'s curiosity when exploring this personal data.\r\n\r\nFigure 2: Emotion Map of Edinburgh\r\nFigure 2: Emotion Map of Edinburgh, used as a provocation in a Speculative Design approach. Emotions depicted on the map, using their corresponding colours on the Plutchik Emotion Wheel, include Distraction, Anger, Serenity, Optimism, Love, Acceptance, Joy, Surprise and Sadness.\r\n2.2 Results\r\n\r\nA study was conducted with 8 participants in Edinburgh (UK) over a period of eight months, which resulted in a study of 40 personally significant places in the urban environment. Participants were recruited using a networking procedure following the recommendations and eligibility criteria defined by Manzo, demographically diverse and had been living in Edinburgh for periods ranging from 3 years up to their entire lifetime [27]. The interviews were recorded on video (with audio) using a GoPro camera, resulting in over 23 hours of video transcribed. The gathered data corpus consisted of rich, contextualized and intimate qualitative data regarding participants’ emotional person-place relationships in Edinburgh. The quote below illustrates the personal relationship that one of the participants has with a specific bridge in the city centre.\r\n\r\n“The thing about Edinburgh is a lot of people leave. It\'s great for a year, experience – then people move. So I\'ve had to reinvent myself several times. I\'ve lived with seven different housemates and arrangements in housing, so it\'s a lot of change. I wasn\'t enjoying it, and I felt trapped because of the PhD because I had to stay. And I remember there was the Christmas markets and the castle was lit up. I remember just standing on the bridge and thinking, ‘snap out of this’. So whenever I feel like I want to go home, I think of that viewpoint. […] It was the first time I felt like I belonged. I felt part of something. [..] You\'ll have me in tears at the end thinking of all my lovely memories of Edinburgh!”- P5, Irish, 27, female, PhD student, on North Bridge\r\nThe data corpus was subsequently analysed using a thematic analysis, resulting in trends and themes clustered around the following topics: past and present emotional experiences connected to personally significant places; the evolving meaning and relationship with personally significant places over time; the different representations of person-place relationships (i.e. different forms data could take); and the potential for capturing, sharing and exploring data in the (near) future using innovative technological devices and services. The quote above illustrates a trend in the emotional experiences of personally significant places identified in the data, namely an experience of not belonging and feeling homesick, and the viewpoint from a particular place (i.e. a visual representation) being able to alleviate those feelings. The focus in this paper is on how the trends and themes identified in the data corpus gathered by the ethnographically-informed Walking & Talking method, could potentially inform the design of future technological devices and services, by projecting those trends and themes into multiple possible future scenarios using Speculative Design Fictions.\r\n\r\n3 From Ethnography to Speculative Design Fictions\r\n\r\nSpeculative Design is a critical, discursive design practice, based on critical thinking and dialogue, which questions the practice of design and its modernist definition, and envisions possible future scenarios [30]. Speculative Design and, specifically, Critical Design and Speculative Design Fictions have been extensively employed in HCI as a way to reflect on future technologies or critique current practice [6,7,12,17,37,43]. This study applies a Critical Design lens to the Speculative Design by creating a suite of Speculative Design Fictions in the field of Urban Interaction Design. This enables reflection on current practices around people\'s urban places that are meaningful to them on a personal level, and to speculate on the potential desirable and undesirable implications of innovative technological devices and services on our emotional experience of, and relationship with, urban places in smart cities of the (near) future.\r\n\r\nThere are three key elements to Speculative Design as identified by Auger [2]. Firstly, we need to move away from the constraints of commercial practice steered by the market and industry, meaning the focus should not be on the applications of technology, but the implications of technology. Secondly, the use of fiction to speculate on future products, services, systems, and worlds; reflectively examining the role and impact of new technologies on everyday life. Finally, the ability to initiate a dialogue between experts, such as scientists, engineers and designers, and the audience, as the users of these new technologies [2].\r\n\r\nSpeculative Design Fictions (also often referred to as “design fictions” or “fictions”) are a specific genre of Speculative Design which finds its origins in science fiction [4]. Bruce Sterling defined them as the creation of stories that speculate about social practices that may be constructed around and through designed artefacts and systems (i.e. diegetic prototypes) [50]. The Netflix series Black Mirror could be seen as an example of Speculative Design Fictions. Each episode is based on a current technological trend and that trend is projected into the (near) future by creating an often dystopian science fiction story in the form of an episode of a series. However, unlike Black Mirror episodes which depict a dystopian future for dramatic effect, Speculative Design Fictions do not need to be dystopian. They could also be utopian or anything in between.\r\n\r\nMore importantly, Speculative Design Fictions need to be grounded in science fact. A key aspect is the construction of the perceptual bridge by which designers engage their audiences and provoke an emotional response, which requires careful crafting and management of the speculation [2]. The creation of this link between science fact (trends and themes) and science fiction (the projection of trends and themes) is a crucial step in the creation of Speculative Design Fictions and can be a challenging task, especially without a team of designers at hand. Speculative Design Fictions tend to remain black boxes, leaving them vulnerable to criticism that they are “made up” [25]. This paper focuses on the step-by-step process of creating this perceptual bridge. Several design techniques will be discussed that can be used to project trends and themes grounded in science fact into possible future scenarios, and to create the provocation that aims to evoke an emotional response to engage the audience in a discussion. A case study will be presented in which these design techniques are used to create a Speculative Design Fiction in the form of a short film.\r\n\r\n3.1 Why Speculative Design?\r\n\r\nThere were several reasons for taking a Speculative Design approach. The philosophy and approach of Speculative Design and Urban Interaction Design align. As Speculative Design aims to move away from the commercial practice steered by the market and industry, Urban Interaction Design aims to move away from the constraints of industry and their traditional top-down, technology-driven smart city approach. Instead, Urban Interaction Design is a bottom-up human-centred design approach which focuses on the needs, desires, rituals, human activities, experiences and behaviours of the citizens in the smart city of the (near) future, where the smart citizens are in control. Therefore, the focus is on implications of technology rather than the applications. In addition, both Speculative Design and Urban Interaction Design focus on problem finding, rather than problem solving. Urban Interaction Design aims to create a better understanding of the triangular relationship between person, place and technology to understand how technology could augment the urban experience. Furthermore, Speculative Design and Urban Interaction Design both aim to engage the public and non-experts with an unfamiliar design space. A survey conducted by the Institution of Engineering and Technology (IET) in May 2016, showed that 82% of British people do not know what a smart city is [13,19]. A Speculative Design approach enables the public to engage with this unknown, future world.\r\n\r\nA Speculative Design approach also enables the exploration of multiple themes that emerge in the data corpus to explore the design space [4]. A key aspect of Speculative Design is that there is not just one future but a whole taxonomy of multiple different futures [10]. Speculative Design uses Gaver, Beaver and Benford\'s concept of ambiguity about the future as a resource for design [14], by crafting multiple futures that are engaging and thought provoking. These multiple future scenarios enable designers to go beyond the limits of current technology and speculate about what kind of interactive devices and services we might have in each of those futures, and what the implications and consequences might be. People are required to interpret these possible future scenarios for themselves, encouraged to start making sense of those future technologies and their contexts conceptually, and what the meanings and implication of those technologies might be for them personally. The ambiguity is in the interpretive relationship and requires people to participate in making meaning, without imposing a result, solution or outcome [14]. The fact there are multiple futures instead of just one, means people can more freely react positively or negatively to each of the possible future scenarios in the Speculative Design Fictions.\r\n\r\nIndeed, not all possible futures are equal. As defined by Dunne and Raby [10], there is the probable future, which is the traditional design space; the plausible futures, which are alternative futures linked to how the world is today but are perhaps less probable; and the possible futures, which are more extreme scenarios of what the future might be like which are still scientifically possible (Figure 3). Each of the trends and themes identified in the data corpus can be projected into one of these future scenarios. A Speculative Design approach is used to discuss with the general public and non-experts which would be preferable and which would be undesirable [10].\r\n\r\nFigure 3: Taxonomy of multiple futures.\r\nFigure 3: Taxonomy of multiple futures. Redrawn from [10].\r\n3.2 Crafting the Speculative Design Fiction\r\n\r\nThis section discusses how one of the themes identified in the data corpus was projected into a future scenario using Critical Design. Critical Design is a specific approach to Speculative Design, which uses design as a medium to engage audiences, evoke an emotional response and ask carefully formulated questions as a catalyst for discussion [9]. These conversation pieces aim to provoke thought, reflection and discussion on both the present and potential futures. This section demonstrates how several design techniques such as Gaver, Beaver and Benford\'s (2003) Tactics for using Ambiguity, PACT-analysis and the SCAMPER-technique could be used to this end.\r\n\r\nThis case study discusses a theme that emerged from the data corpus, gathered using the ethnographically-informed Walking & Talking method, namely the desire of participants to represent their emotional relationship with places using non-visual representations (e.g. smell, taste, audio, tactile). Of all these non-visual modalities, smell was the most popular among participants, with half of the participants indicating a desire to represent at least one of their emotional experiences with a smell if there would be a future technology available. Therefore, smell will be the focus in this study. During the walking interviews, participants had identified and selected nine different smells connected to personally significant places; the smell of flowers in general, daffodils, wet grass, an “autumnal” smell, cannabis, the “smell of summer”, cherry blossoms, Greek food, and the smell of mulled cider. This led to the creation of a Speculative Design centred on innovative smell technology that would enable people to capture, consume and share these smells with others in the urban environment.\r\n\r\n3.2.1  Using PACT-analysis for the design of the speculative smell technology. To develop a Speculative Design Fiction around this speculative smell technology and ensure the design would be grounded in and informed by the analysis of the data corpus, a method called PACT-analysis was designed. This method for analysis and design activities is often used in UX design and interaction design to scope out the problem and the variety of the different elements of PACT, (People, Activities, Contexts and Technologies) that are possible or likely in the domain. This is done by using brainstorming and envisionment techniques, typically combined with data gathered through observations, interviews or workshops [3]. This provided a framework for envisioning what this speculative smell technology might be like based on the data, who would use such technology, the different places and contexts it could be used in, and to what end.\r\n\r\nLooking closer at the ‘Contexts’ element of PACT, seven of the smells were connected to a specific park that is popular among locals, but is not well-known by tourists. One smell was connected to a Greek restaurant (the smell of Greek food) and one was connected to the local Christmas market (smell of mulled cider). These smells evoked emotions of joy, ecstasy and relaxation among participants. Further analysis revealed that some of these smells were linked to a specific season (e.g. autumnal smells, smells like summer, wet grass, flowers, and mulled wine). Examining the data corpus through the ‘Activities’-lens of the PACT-analysis revealed that the smells were typically encountered while socializing with friends in the park (e.g. having BBQ), or while doing activities on their own (e.g. walking the dog or going for a run), which grounded them and enhanced their experience of that place. However, some smells where linked to a different location, for example the smell of daffodils was linked to Ireland and the smell Greek food was linked to Greece. These connections alleviated the feeling of homesickness, enabling participants to mentally escape the place they were in. Further analysis of the ‘People’-component revealed that three of the four participants who would like to represent their relationship with a personally significant place with smells, were not originally from the UK. These smells would make them feel like they were back in their home country, as illustrated by the following participant quote:\r\n\r\n“In springtime, there\'s lots of daffodils [in the Meadows]. I would have picked the smell of a daffodil. They remind me of home in Ireland, so there you go. And because I\'m from the countryside as well, in the Meadows I feel like I\'m away from the city again.” - P7, 29, Irish, female, PhD student, in the Meadows park.\r\nThis inspired and informed a future scenario, where innovative smell technology would be used to either enhance the experience of the place a person is in, or to consume smells of other times and places to mentally escape the place the person is currently in.\r\n3.2.2  Using Tactics for Ambiguity and the SCAMPER-technique for creating provocation. Having the Speculative Design Fiction firmly grounded in the analysis of the data corpus and projected into a future scenario is not sufficient. An important part of Critical Design is to provoke the audience and evoke an emotional response, which will enable the Speculative Design Fiction to act as a conversation piece for discussion, provoking thought and reflection on both the present and the potential future it depicts. To do this, the SCAMPER-technique and Gaver, Beaver and Benford\'s Tactics for using Ambiguity were used. The motivation for using the SCAMPER technique, is that it is a creative brainstorming technique which is typically used in interaction design to develop atypical solutions to problems and spark creativity [11,20]. First, ‘Substitute’ enables the removal of part of an accepted concept, device, or situation and replacing it with something else. ‘Combine’ encourages the joining or forcing of two elements together and consider ways in which this combination might work towards a solution. ‘Adapt’ encourages the adaptation of part of the problem so that it works where it did not work before. ‘Modify’ (sometimes known as ‘Maximize and Minify’) encourages the modification of an attribute, randomly if necessary. Any attribute could be modified, such as size, shape, colour, texture, history, attitude, position, etc. ‘Purpose’ (sometimes known as ‘Put to other use’) relates to changing the intention or use of the subject. ‘Eliminate’ refers to the (potentially arbitrary) removal of any or all elements of the subject, to simplify or reduce it to the core functionality. Finally, ‘Reverse’ or ‘Rearrange’ changes the direction, orientation, order or hierarchy in which the subject was going to go or intended to be used [11,20].\r\n\r\nThe motivation for using Gaver, Beaver and Benford\'s Tactics for using Ambiguity is that it has been used in interaction design to encourage close personal engagement with interactive systems. It discusses three types of ambiguity, namely ambiguity of information, of context, and of relationship. It provides several heuristics or tactics for achieving each of these types of ambiguity to help designers recognize, understand and use ambiguity. Enhancing the ambiguity of information focuses on tactics for creating or reflecting uncertainties that are noticeable by people. This tactic could be used to make the device or service look mysterious or impressionistic, but more importantly it can engage people into making sense of the technological device or service and the context and environments in which it operates. Creating ambiguity of context is a tactic which blocks the interpretation of a technological device or service in terms of an established discourse. This enables people to approach a particular technological device or service with an open mind and to question the assumptions they have about this technology. Finally, provoking ambiguity of relationship is a tactic which creates the conditions for a deeply personal projection of imagination and values onto the design of the technological device or system. This allows technological devices and systems to enable self-reflection by letting people take on new roles or new identities to change perspectives and question their own values and activities [14].\r\n\r\nIn this specific case study, the Technology element of PACT is used to create the perceptual bridge which links the familiar present with the unfamiliar future. This perceptual bridge is used to engage audiences and provoke an emotional response, which requires careful crafting and management of the speculation. The initial idea was to simply add a speculative smell sensor to existing smartphones, allowing people to capture smells alongside pictures and videos. This would link familiar smartphone technology with the unfamiliar future smell technology. However, to make this particular Speculative Design Fiction more provocative, the SCAMPER-technique of “Put to other use” was used along with the tactic of creating ambiguity of context, by blocking expected functionality to comment on a familiar technological device [14]. A future scenario was created where all smartphones and cameras are replaced by “smellsticks”, without explaining why. This sole focus on smells without offering an explanation as to why smartphones have been replaced by this speculative technology is a tactic to provoke ambiguity in the relationship, and encourages the audience to reflect on the meaning of smells in their environment; aesthetically, culturally and personally [14]. The perceptual bridge is created by linking the use of this unfamiliar, future smellstick technology to the use of the familiar, present technology of smartphones. In this future scenario people use their smellsticks to capture, consume, share and relive their emotional experiences connected to personally significant urban places using smells instead of pictures and videos. Also, by setting the future scenario in the same city (Edinburgh) as the intended local audience and balancing the familiar present with the unfamiliar future, this ambiguity is designed to attract the audience to engage with this future scenario [14].\r\n\r\nIt is important to stress that Speculative Design is not about the application of (smell) technology, but about the potential implications of (smell) technology. It is not a prediction that there will be such smell technology in the future, nor that there should be smell technology in the future. This is just one of many possible future scenarios, which may or may not be probable or plausible. It is up for discussion if such a future scenario would be desirable or not. Using the tactic of provoking ambiguity of Relationship, disturbing side effects of speculative smell technology are introduced alongside positive aspects. Using the “Reverse” and “Put to other use” of the SCAMPER-technique, we have not only introduced the use of smellsticks in the future scenario to alleviate feelings of homesickness, but also how the excessive use of smellsticks to escape reality could lead to addiction. Sticking to the perceptual bridge linking the use of smartphones to the use of smellstick technology, this is based on trends in the data corpus, where participants indicated not using smartphones to take pictures or videos as this would “break” the flow of their experience. Including potential positive and negative implications of this speculative smell technology creates an ambiguity around the desirability of this future scenario, enabling this Speculative Design Fiction to act as a conversation piece leading to discussion.\r\n\r\n3.3 From Future Scenario to Short Film\r\n\r\nWith the framework for the future scenario created, informed by trends and themes identified in the data corpus, the perceptual bridge has been crafted linking the familiar present with the unfamiliar future. The provocation to engage audiences and provoke an emotional response has been created and the next step is to decide the specific form this Speculative Design Fiction should take. Several different formats were considered, such as a perfume line based on the smells in a city captured using smellsticks or creating a prototype of a speculative interactive smellstick device. However, inspired by the success of the Netflix series Black Mirror and to be able to communicate the main findings of this research to non-experts for further speculation and discussion, it has taken the form of a short film as this is an easily accessible format.\r\n\r\nFirst, based on the future scenario, a script was written by the researcher based on the stories of participants during the Walking & Talking phase. These stories were used to inspire the characters and events in the script, adding details and depth based on science fact. For the creation of the short film, the researcher collaborated with a small team of digital media students experienced in directing, filming, sound design and VFX design. For each of the key scenes in the future scenario, the researcher and digital media students created a storyboard as a graphic representation of how the short film would unfold to communicate the specific trends and themes in the data corpus that should be visualized and represented in each of the scenes (Figure 4).\r\n\r\nFigure 4: Storyboard\r\nFigure 4: Part of the storyboard for the creation of the Speculative Design Fiction in the form of a short film. © Shenando Stals\r\nTo help bring the story to life and speculate about social practices that may be constructed around and through this speculative smell technology, diegetic prototypes of an interactive “smellstick” device and disposable smellsticks were designed as artefacts and props for the short film (Figure 5). Following the established perceptual link between smartphone use and smellstick use, the interactive smellstick device is the same size as a smartphone and will be used to replace smartphones in the future scenario depicted in the short film. Just as smartphones are widely owned and used to capture, watch and share pictures and videos in the present, the interactive smellstick device are widely owned and used in the future scenario to capture new smells and consume and share already collected smells. Besides the interactive smellstick device, there are also diegetic prototypes in the form of disposable smellsticks which can be used to consume or share one specific smell related to one specific place, time or event in the past. This represents the trend in the data corpus that smells are often linked to the experience of another place or to a specific time, season or event in the past. For example, in Figure 5, one disposable smellstick holds the smell of the beach in Thessaloniki in Greece, while the other smellstick holds the smell of Christmas 1987. These two examples are informed by stories in the data corpus, however, what the specific smell of the beach in Thessaloniki and of Christmas 1987 might be is up for discussion.\r\n\r\nFigure 5: Diegetic prototypes of an interactive “smellstick” device\r\nFigure 5 - Diegetic prototypes of an interactive “smellstick” device, and two disposable smellsticks labelled “Greece/Beach” and “Christmas 1987”, used as props for the short film. © Shenando Stals\r\nBased on the future scenario, the diegetic prototypes and the storyboard informed by the data corpus, the Speculative Design Fiction in the form of a Black Mirror-style short film called “Smellification\" has been created in collaboration with three digital media students and eight actors. This short film appropriates standard Hollywood techniques which have previously been used to make Speculative Design Fictions more convincing [51].\r\n\r\nThe 3-Act story structure is used which consists of the following key scenes: the opening scene (setup), the middle scene (confrontation) and the end scene (resolution).\r\n\r\nIn the opening scene depicted in Figure 6, a family of tourists uses their interactive smellstick devices to capture their experience of their summer holiday in Edinburgh. This scene establishes the perceptual bridge, linking the familiar use of smartphones to take pictures and videos of one\'s holiday location, to the unfamiliar future smellstick technology used to capture smells of the holiday location. This scene shows the family trying to capture the gunpowder smells related to the ceremonial firing of a canon at Edinburg Castle, as the smoke descents on the city below.\r\n\r\nFigure 6: Opening scene\r\nFigure 6 – Opening scene: Creating the perceptual bridge, by linking use of unfamiliar, future smellstick technology to the familiar, current use of smartphones. © Shenando Stals\r\nThe middle scene depicts a group of student characters consisting of two local students from Edinburgh and two exchange students from Greece, who sit down in the grass to hang out and relax. The two Greek exchange students try to alleviate their feelings of homesickness by consuming and sharing the smell of the Greek beach in their hometown of Thessaloniki using a disposable smellstick, evoking strong emotions of ecstasy and relaxation which causes them to zone out. This disposable smellstick is passed around the group in a similar way that the data corpus revealed participants would pass around a cigarette or joint, while relaxing in the park with a group of friends (Figure 7). The other Greek student and one of the local students decide to partake and quickly zone out as well. However, one local student kindly refuses as she prefers to stay in the moment and decides to capture the smells of daffodils nearby, so that she can use this smell to enhance her experience of the park on a rainy day.\r\n\r\nFigure 7 - Middle scene\r\nFigure 7 – Middle scene: Greek and local students share a disposable smellstick containing the smell of the beach in Thessaloniki (Greece) used by the Greek exchange students to alleviate feelings of homesickness. © Shenando Stals\r\nThe middle scene explores the trends identified in the data corpus, that certain smells are linked to the same place at a certain moment in time (e.g. a season), while others smells are linked to the experience of another place (e.g. the beach in Greece). It aims to raise a discussion around what other smells might be connected to the experience of urban places, what the technology and process for capturing, consuming and sharing the experience of place using smells might look like, and the potential implications of such technology on our relationship with place.\r\n\r\nIn the closing scene, which takes place a few months later, we again see the local student who uses the captured smell of daffodils during the summer day to enhance her experience of walking the dog in the same park on a rainy autumn night. As she walks through the park, she encounters a homeless “smell addict” lying on the ground. He is taking a sniff of a disposable smellstick labelled “Christmas 1987”, attempting to escape the harsh reality of life on the streets (Figure 8). On the ground lies a newspaper with the headline: “SMELLSTICK ADDICTION ON THE RISE, NATIONAL HEALTH SERVICE ISSUES WARNING!” This end scene uses the tactic of provoking ambiguity of relationship, to explore the potential undesirable elements of the speculative smellstick technology, by raising concerns regarding potential health issues related to smellstick use, such as addiction.\r\n\r\nFigure 8: Closing scene\r\nFigure 8 – Closing scene: Addicted homeless man uses a disposable smellstick with the smell of “Christmas 1987” to escape the harsh reality of life on the streets. © Shenando Stals\r\n4 Conclusions and Future Work\r\n\r\nThis paper presents research in the field of Urban Interaction Design, which takes a human-centred design approach to investigate how people\'s emotional relationship with places in the urban environment that are meaningful to them on a personal level, could potentially inform the design of new technological devices and services. A Speculative Design approach is taken where the data corpus gathered using the ethnographically-informed Walking & Talking method is used to inform the creation of Speculative Design Fictions. These Speculative Design Fictions speculate about what creating, capturing, collecting, representing, consuming and sharing emotional person-place relationships mediated by innovative technology might look like in smart cities of the (near) future.\r\n\r\nThe main contribution of this paper is building outwards from a sophisticated understanding of the approach, using several design techniques to create the crucial link between between trends and themes in an ethnographically-gathered qualitative data corpus, and the design and creation of Speculative Design Fictions. The case study presented in this paper describes the process of designing and creating a Speculative Design Fiction which uses speculative “smellstick” technology to capture, represent, consume and share personal relationships with urban places using smells. It describes the step-by-step process starting with the gathering of ethnographic data to inform the design of the Speculative Design Fiction, to the use of design techniques such as Tactics for Ambiguity, PACT-analysis and the SCAMPER-technique to design and create the speculative future scenario, to the articulation of this Speculative Design Fiction in the form of a short film.\r\n\r\nThe next step in this research will be to conduct a series of focus groups where the suite of Speculative Design Fictions, including the short film, will be used as conversation pieces to engage non-experts and members of the general public in a discussion around what the implications of such innovative technology might be for our experience of and relationship with urban places.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nSpecial thanks to the Public Engagement Fund of the School of Computing at Edinburgh Napier University, for funding the production of the short films that are part of the suite of Speculative Design Fictions.\r\n\r\nREFERENCES\r\n\r\nLuluah Al-Husain, Eiman Kanjo, and Alan Chamberlain. 2013. Sense of Space: Mapping Physiological Emotion Response in Urban Space. In Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication (Ubicomp’13 Adjunct) (UbiComp ’13 Adjunct), 1321–1324. https://doi.org/10.1145/2494091.2499213  \r\nJames Auger. 2013. Speculative design: crafting the speculation. Digital Creativity 24, 1: 11–35. https://doi.org/10.1080/14626268.2013.767276  \r\nDavid Benyon. 2014. Designing Interactive Systems: A comprehensive guide to HCI, UX and Interaction Design. Pearson, Edinburgh.  \r\nJulian Bleecker. 2009. Design Fiction: A Short Essay on Design, Science, Fact and Fiction. Near Future Laboratory, 49. Retrieved from http://www.nearfuturelaboratory.com/2009/03/17/design-fiction-a-short-essay-on-design-science-fact-and-fiction/  \r\nJan Blom, Divya Viswanathan, Mirjana Spasojevic, Janet Go, Karthik Acharya, and Robert Ahonius. 2010. Fear and the City: Role of Mobile Services in Harnessing Safety and Security in Urban Use Contexts. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI ’10 (CHI ’10), 1841–1850. https://doi.org/10.1145/1753326.1753602  \r\nMark Blythe. 2017. Research Fiction: Storytelling, Plot and Design. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ’17), 5400–5411. https://doi.org/10.1145/3025453.3026023  \r\nMark Blythe and Elizabeth Buie. 2014. Chatbots of the Gods: Imaginary Abstracts for Techno-Spirituality Research. Proc. NordiCHI 2014: 227–236. https://doi.org/10.1145/2639189.2641212  \r\nPaul Dourish and Genevieve Bell. 2007. The infrastructure of experience and the experience of infrastructure: Meaning and structure in everyday encounters with space. Environment and Planning B: Planning and Design 34: 414–430. https://doi.org/10.1068/b32035t  \r\nAnthony Dunne and Fiona Raby. 2001. Design Noir: The Secret Life of Electronic Objects.  \r\nAnthony Dunne and Fiona Raby. 2013. Speculative Everything: Design, Fiction, and Social Dreaming. The MIT Press.  \r\nBob Eberle. 1996. Scamper: Games for imagination development. Prufrock Press, Waco.  \r\nChris Elsden, David Chatting, Abigail C Durrant, Andrew Garbett, Bettina Nissen, John Vines, and David S Kirk. 2017. On Speculative Enactments. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI ’17), 5386–5399. https://doi.org/10.1145/3025453.3025503  \r\nJiska Engelbert, Liesbet van Zoonen, and Fadi Hirzalla. 2019. Excluding citizens from the European smart city: The discourse practices of pursuing and granting smartness. Technological Forecasting and Social Change 142: 347–353. https://doi.org/10.1016/J.TECHFORE.2018.08.020  \r\nWilliam W Gaver, Jacob Beaver, and Steve Benford. 2003. Ambiguity as a Resource for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’03), 233–240. https://doi.org/10.1145/642611.642653  \r\nDoménique van Gennip, Elise van den Hoven, and Panos Markopoulos. 2015. Things That Make Us Reminisce. Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI ’15: 3443–3452. https://doi.org/10.1145/2702123.2702460  \r\nPer Gustafson. 2001. Meanings of Place: Everyday Experience and Theoretical Conceptualizations. Journal of Environmental Psychology 21, 1: 5–16. https://doi.org/10.1006/jevp.2000.0185  \r\nIngi Helgason, Michael Smyth, Soren Rosenbak, and Ivica Mitrovic. 2015. Discoure, Speculation and Disciplinarity: Designing Urban Futures. 6, 6: 1–10.  \r\nDan Hill. 2013. Essay: On the smart city; Or, a “manifesto” for smart citizens instead. Retrieved March 1, 2015 from http://www.cityofsound.com/blog/2013/02/on-the-smart-city-a-call-for-smart-citizens-instead.html  \r\nIET. 2016. Smart cities. Time to involve the people? An insight report from the Institute of Engineering and Technology. Retrieved December 27, 2017 from http://www.theiet.org/sectors/thought-leadership/future-cities/articles/smart-cities-involve.cfm?utm_source=redirect&utm_medium=any&utm_campaign=smartcities  \r\nInteraction-Design.org, Rikke Dam, and Teo Siang. 2018. learn-how-to-use-the-best-ideation-methods-scamper @ www.interaction-design.org. Retrieved April 9, 2018 from https://www.interaction-design.org/literature/article/learn-how-to-use-the-best-ideation-methods-scamper  \r\nMichiel de Lange. 2013. The smart city you love to hate. The 2nd Hybrid City Conference - Subtle rEvolutions: 77–84.  \r\nLucian Leahu, Steve Schwenk, and Phoebe Sengers. 2008. Subjective Objectivity: Negotiating Emotional Meaning. In Proceedings of the 7th ACM Conference on Designing Interactive Systems (DIS ’08), 425–434. https://doi.org/10.1145/1394445.1394491  \r\nMaria Lewicka. 2011. Place attachment: How far have we come in the last 40 years? Journal of Environmental Psychology 31, 3: 207–230. https://doi.org/10.1016/j.jenvp.2010.10.001  \r\nIan Li, Jon Froehlich, Jakob Eg Larsen, Catherine Grevet, and Ernesto Ramirez. 2013. Personal Informatics in the Wild: Hacking Habits for Health & Happiness. In CHI ’13 Extended Abstracts on Human Factors in Computing Systems (CHI EA ’13), 3179–3182. https://doi.org/10.1145/2468356.2479641  \r\nJoseph Lindley and Paul Coulton. 2016. Peer Review and Design Fiction: “Great Scott! The Quotes Are Redacted.” In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA ’16), 583–595. https://doi.org/10.1145/2851581.2892568  \r\nSetha M Low and Irwin Altman. 1992. Place Attachment: A Conceptual Inquiry. In Place Attachment, Irwin Altman and Setha M Low (eds.). Springer US, Boston, MA, 1–12. https://doi.org/10.1007/978-1-4684-8753-4_1  \r\nLynne C. Manzo. 2005. For better or worse: Exploring multiple dimensions of place meaning. Journal of Environmental Psychology 25, 1: 67–86. https://doi.org/10.1016/j.jenvp.2005.01.002  \r\nAssunta Matassa. 2013. Wearable Accessories for Cycling : Tracking Memories in Urban Spaces. Ubicomp’13 Adjunct: 415–423. https://doi.org/http:/doi.acm.org/10.1145/2494091.2495973  \r\nAssunta Matassa and Amon Rapp. 2015. Map: Making: Designing a Mobile Application for Enhancing Memories’ Retrieval. In Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct (MobileHCI ’15), 994–1001. https://doi.org/10.1145/2786567.2794318  \r\nIvica Mitrovic. 2015. Introduction to Speculative Design Practice – Eutropia, a Case Study.  \r\nRuturaj N Mody, Katharine S Willis, and Roland Kerstein. 2009. WiMo: Location-based Emotion Tagging. In Proceedings of the 8th International Conference on Mobile and Ubiquitous Multimedia (MUM ’09), 14:1–14:4. https://doi.org/10.1145/1658550.1658564  \r\nChristian Nold. 2004. Bio mapping / Emotion Mapping by Christian Nold. Bio Mapping. Retrieved March 19, 2017 from http://biomapping.net/  \r\nChristian Nold. 2009. Emotional Cartography - Technologies of the Self. Creative Commons.  \r\nEric Paulos and Elizabeth Goodman. 2004. The familiar stranger: anxiety, comfort, and play in public places. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI ’04) 6, 1: 223–230. https://doi.org/10.1145/985692.985721  \r\nRobert. Plutchik. 2005. Emotions and life : perspectives from psychology, biology, and evolution. American Psychological Association, Washington.  \r\nRobert. Plutchik. 2011. Plutchik Emotion Wheel. Creative Commons. Retrieved January 7, 2017 from https://commons.m.wikimedia.org/wiki/File:Plutchik-wheel.svg  \r\nLarissa Pschetz, Kruakae Pothong, and Chris Speed. 2019. Autonomous Distributed Energy Systems: Problematising the Invisible Through Design, Drama and Deliberation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI ’19), 387:1–387:14. https://doi.org/10.1145/3290605.3300617  \r\nDaniele Quercia, Rossano Schifanella, and Luca Maria Aiello. 2014. The Shortest Path to Happiness: Recommending Beautiful, Quiet, and Happy Routes in the City. Proceedings of ACM HyperText. https://doi.org/10.1145/2631775.2631799  \r\nBernd Resch, Anja Summa, Günther Sagl, Peter Zeile, and Jan-Philipp Exner. 2015. Urban Emotions — Geo-Semantic Emotion Extraction from Technical Sensors, Human Sensors and Crowdsourced Data. Progress in Location-Based Services 2014: 199–212. https://doi.org/10.1007/978-3-319-11879-6  \r\nJohn Rooksby, Mattias Rost, Alistair Morrison, and Matthew Chalmers Chalmers. 2014. Personal Tracking As Lived Informatics. In Proceedings of the 32Nd Annual ACM Conference on Human Factors in Computing Systems (CHI ’14), 1163–1172. https://doi.org/10.1145/2556288.2557039  \r\nChristine Satchell and Marcus Foth. 2011. Welcome to the jungle: Hci after dark. Proceedings of CHI 2011: 753–762. https://doi.org/10.1145/1979742.1979630  \r\nLeila Scannell and Robert Gifford. 2010. Defining place attachment: A tripartite organizing framework. Journal of Environmental Psychology 30, 1: 1–10. https://doi.org/10.1016/j.jenvp.2009.09.006  \r\nMichael Smyth and Ingi Helgason. 2013. Tangible possibilities—envisioning interactions in public space. Digital Creativity 24, 1: 75–87. https://doi.org/10.1080/14626268.2013.769454  \r\nMichael Smyth, Ingi Helgason, Martin Brynskov, Ivica Mitrovic, and Gianluca Zaffiro. 2013. UrbanixD: Designing Human Interactions in the Networked City. In CHI ’13 Extended Abstracts on Human Factors in Computing Systems (CHI EA ’13), 2533–2536. https://doi.org/10.1145/2468356.2468823  \r\nAndrey Somov, Corentin Dupont, and Raffaele Giaffreda. 2013. Supporting Smart-city Mobility with Cognitive Internet of Things. 1–10.  \r\nShenando Stals, Michael Smyth, and Wijnand IJsselsteijn. 2014. Walking & Talking: Probing the Urban Lived Experience. In Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational (NordiCHI ’14), 737–746. https://doi.org/10.1145/2639189.2641215  \r\nShenando Stals, Michael Smyth, and Oli Mival. 2017. Sharing & Exploring Quantified-Self Data on In-Place Experiences and Emotions. In CHI 2017. Retrieved from https://openlab.ncl.ac.uk/datarelationships/accepted-papers/  \r\nShenando Stals, Michael Smyth, and Oli Mival. 2017. Exploring People\'s Emotional Bond with Places in the City: A Pilot Study. In Proceedings of the 2017 ACM Conference Companion Publication on Designing Interactive Systems (DIS ’17 Companion), 207–212. https://doi.org/10.1145/3064857.3079147  \r\nShenando Stals, Michael Smyth, and Oli Mival. 2018. Capturing, Exploring and Sharing People\'s Emotional Bond with Places in the City using Emotion Maps. Airea: Arts & Interdisciplinary Research 1: 47–62. Retrieved from http://journals.ed.ac.uk/airea/article/view/2799/3871  \r\nBruce Sterling. 2012. Sci-Fi Writer Bruce Sterling Explains the Intriguing New Concept of Design Fiction. Slate.com. Retrieved June 26, 2019 from https://slate.com/technology/2012/03/bruce-sterling-on-design-fictions.html  \r\nPhil Turner. 2016. Digital Make-Believe. https://doi.org/10.1007/978-3-319-29553-4  \r\nMark Weiser. 1999. The Computer for the 21st Century. SIGMOBILE Mob. Comput. Commun. Rev. 3, 3: 3–11. https://doi.org/10.1145/329124.329126 ',1,'Stals','Shenando Stals, Michael Smyth, and Oli Mival','Shenando Stals *(Centre for Interaction Design, Edinburgh Napier University, UK)*<br>\r\nMichael Smyth *(Centre for Interaction Design, Edinburgh Napier University, UK)*<br>\r\nOli Mival *(Centre for Interaction Design, Edinburgh Napier University, UK)*',NULL,0,'10.1145/3363384.3363486','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,42),(54,'xu-5-percent-piano-an-augmented-piano-with-playful-audio-response','2019-09-03 08:29:56','2019-11-19 12:39:02','2019-09-03 08:29:56',NULL,1,'published','[]','5 Percent Piano: An Augmented Piano with Playful Audio Response','Inspired by the practice of street art, we speculated on a scenario of non-visual street art, in which everyday objects are augmented with audio responses. We used ubiquitous computing technologies to augment an idle piano in a university building lobby with a motion-triggered, novel audio response that aims to surprise and engage passers-by in a playful way. The resulting installation, titled ‘5 Percent Piano’, was deployed in its original setting for half a day. It received both positive and negative reactions from naive passers-by. We concluded that the augmented audio response has the potential to raise awareness about ignored everyday objects and can elicit playful social engagement around it, however, when designing for such installations, more contextual factors need to be taken into account.','Dan Xu and Gijs Huisman. 2019. 5 Percent Piano: An Augmented Piano with Playful Audio Response. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363397](https://doi.org/10.1145/3363384.3363397 \"DOI for the article \'5 Percent Piano: An Augmented Piano with Playful Audio Response\'\")','Figure 1: The original piano used as a table substitute; the augmented piano with motion detection sensor and surface transducer; a curious passer-by.\r\n1 INTRODUCTION\r\n\r\nThe urban environment that preserves potentials for spontaneous encounters allows playful appropriations, creative expressions, and formal and informal cultural activities to flourish in public spaces [19]. Street artists employ tools like spray cans or stencils to claim public spaces by creating something surprising or something that can make passers-by smile, think, or react to their otherwise mundane urban surroundings [18] (See Figure 2). Street art moves art out of museums and provides passers-by new perspectives on taken-for-granted everyday objects with artistic sensitivity. Appropriating elements of the street is thought central to street art practices, which stimulates passers-by to ponder the meanings and symbolism behind the ordinary and the everyday [12]. Modern lives usually result in repetitive routines, as Lefebvre stated in his discourse on everyday life, for most of us, we often “look but we are unable to see” [9, p.132].\r\n\r\nIt is not just our eyes that are used to ignoring everyday objects, our ears too are filtering out incoming signals without conscious reflection [13]. The sounds of traffic, construction work, and human voices are merged into a stream of ambient noise that our ears rarely tune into. In Lefebvre\'s [9] wording, this represents ‘we listen but we are unable to hear’. Attentive listening, which often occurs in the appreciation of music, requires deliberate efforts in directing attention to the qualities of sound [5]. The experience of everyday listening, however, focuses less on examining aesthetic qualities of sound but more on the information it carries about the audio source, which is vital for us to make sense of the world [5].\r\n\r\nA form of street art that creates an interesting mix of musical listening and everyday listening experiences is the street piano [17]. Much like visual street art moves paintings out of museums, street pianos free music from concert halls and open up opportunities for serendipitous encounters to occur: hidden musicians are enticed to play, urban commuters stop to listen, passers-by linger and casual conversations are initiated [11].\r\n\r\nOr, this would be the case were street pianos not, in some cases, placed in unsuitable environments. An example is a piano placed in a university building lobby, which usually serves as a meeting place for students and staff. Rarely do we encounter impromptu performances. The piano gradually fades into the background of university inhabitants’ everyday lives and has often been repurposed as a piece of furniture, such as a table (See the first picture in Figure 1). The piano has become an everyday object ignored by eyes and ears alike.\r\n\r\nTo (re-) draw attention to this particular street piano the current project uses ubiquitous computing technologies to augment the piano with a motion-triggered, novel audio response that aims to surprise and playfully engage passers-by. In doing so, we aim to increase people\'s awareness and stimulate creative appropriations of taken-for-granted everyday objects, the immediate environment, and each other.\r\n\r\n\r\nFigure 2: Writings on walls in the streets of Amsterdam.\r\n2 THE DESIGN OF 5 PERCENT PIANO\r\n\r\nThe design of 5 Percent Piano was inspired by street art - street pianos in particular - and other works that explore augmented audio responses. For example, The world\'s deepest bin looks indistinguishable from other trash bins in the park, but is augmented with a long, howling sound of the trash falling into the abyss, which not only surprised and amused the naive passers-by but also encouraged more responsible actions in cleaning up the environment [15]. In Rainforest, audio transducers and contact microphones were affixed to solid everyday objects, through which sound was played and modulated [4]. Baloica is an interactive sound installation that transformed a swing set into a musical instrument, by using a Kinect camera to track participants’ swing motion to trigger different sounds, and induced collaborative playful experiences [2]. In exploring the design space of play, others have created sensor-augmented seats with playful audio responses and noted that, in a conference setting, the reactions to the seats spanned from positive to negative [6].\r\n\r\nWe augmented the previously-mentioned idle piano with a novel audio response that is triggered by passers-by\'s movement. The piano attracted our attention as an instrument situated in a social space that affords play and possibilities for spontaneous gatherings [11]. We observed that the piano was mostly idle and ignored, which provided opportunities to investigate whether augmented novel audio responses could change passers-by\'s reaction to the instrument. We chose to detect passers-by\'s movements with a hidden sensor as an unobtrusive way to trigger the audio response. A fragment of speech was used as the output because humans are especially sensitive to human voices and can extract rich socially-relevant information from vocal utterances [8], in addition to being a potentially more surprising audio response from a piano.\r\n\r\nStreet artists and graffiti writers sometimes create expressions related to political issues so that alternative voices have the chance to enter and inspire public discourses, as on the famous Berlin Wall [14]. The audio fragment we used was extracted from the Trump-May news conference on June 4th 2019 when the US president Donald Trump visited the UK. The chosen clip lasts about 4 seconds, and transcribes into “5 percent, to 10 percent, to 15 percent, to 20 and then to 25 percent” referring to the tariff rates President Trump was suggesting to impose on Mexico [16]. Considering the socio-political significance of President Trump, we hope that the audio clip can raise awareness about his claimed policies and stir relevant discussions in a way similar to political graffiti writings.\r\n\r\nWe edited the timing of audio clip so that every playback decision occurs in between each phrase. It often resulted in a remix effect of ‘5 percent’ being repeated again and again. Thus we adopted the name ‘5 Percent Piano’.\r\n\r\n\r\nFigure 3: All components to augment the piano, from left to right: the surface transducer; the added amplifier; the Arduino Uno with the MP3 shield plugged in.\r\n2.1 Technical components\r\n\r\nA passive infrared sensor (PIR sensor) was used to detect levels of movement within a certain area [10]. We shorted the pin3 and pin4 on the on-board processing chip to minimize the time duration of the sustained output pulse so that it can be more responsive [3]. The detecting range was adjusted to the lowest setting covering about 3 meters in radius. (See central picture in Figure 1)\r\n\r\nAn Arduino Uno board was used to relay the sensor data with a MP3 player shield to control the audio playback [1]. We sampled PIR sensor data at 1000 Hz, the sum of every 1000 readings was used as a proxy to quantify the level of movements. Once there was movement detected, the audio clip would be played back only if the current reading exceeds or is equal to the previous one.\r\n\r\nThe audio response was played through a large surface transducer [7]. To produce audible sound the transducer needs to be affixed to a rigid object. The resulted sound is amplified and coloured by the attached object, and creates the impression of the object being the source of the sound.\r\n\r\n\r\nFigure 4: The finished 5 Percent Piano (the lower-right corner); the PIR sensor attached under the keyboard (the upper-left corner); the processing unit (the upper-right corner); the transducer (the lower-left corner). To see and hear 5 Percent Piano in action: https://vimeo.com/342984933\r\n3 PRELIMINARY STUDY\r\n\r\nThe 5 Percent Piano was deployed in two consecutive sessions at the Kohnstammhuis building lobby from Amsterdam University of Applied Sciences. The first session lasted for an hour starting from 9:36 and the second session started from 11:55 with a duration of 2 hours. Inspired by the spirit of street artists, we did not inform any facility service staff of the university about this project. After installing the system (See Figure 4), we withdrew to observe passers-by\'s reaction.\r\n\r\nIn the first session, the transducer was directly driven by the MP3 shield with a maximum output power of 3 Watts. The audio produced in this way was only audible within touching distance of the piano.\r\n\r\nBefore the second session, we added an external amplifier to increase the output volume (See Figure 3). As a result, the audible range of the audio fragment covered the PIR sensor\'s detecting range (+/- 3 meters) which ensured that more people would notice the audio response.\r\n\r\n4 FINDINGS\r\n\r\nDuring the first session, most of passers-by appeared busy commuting and often wore headphones with little attention to the immediate surroundings, no one seemed to notice the (lower volume) augmented audio response.\r\n\r\nIn the second session, the unsettling voice coming from the piano did not go unnoticed. The first to approach the piano was a man working on the build-up of a project right next to the piano. He first bent down to listen more attentively, after a while he started inspecting around the piano but did not seem to discover the components that we installed. Then, one of his coworkers, who were attracted by the repetitive shouting of ‘5 percent’ triggered by the constant movement, joined him. The two started collaboratively investigating and speculating on what might trigger the sound, with actions like examining the keyboard, peeking through the lid, and tapping on the case. Later, they introduced the augmented piano to others, one of them eventually sat down and played a simple tune on the piano (Snapshots of the interaction in Figure 5).\r\n\r\nDuring the second session, many passers-by at least took an attentive look at the piano in a surprised manner. Some stopped, bent over with their ears closer to the piano, probing the source of the audio response. One man lingered while staring at the piano for a while. A group of three went by, laughed at the sound and started making fun with the phrase ‘5 percent’. After two hours one of the students who was setting up a project in the lobby remarked that “the piano is getting too annoying” and they contemplated “throwing out the piano”. With these remarks, we concluded our first exploration with 5 Percent Piano.\r\n\r\n5 DISCUSSION AND FUTURE WORKS\r\n\r\nOur brief in-the-wild deployment showed that the novel audio response of 5 Percent Piano succeeded in attracting passers-by\'s attention. The hidden technology created a surprise factor that evoked passers-by\'s curiosity to explore how the system worked and to interact with the piano in alternative, playful ways. The augmented audio response also encouraged acts of creative expressions like the conventional play of the piano. Similar to a street concert where social gathering occurs, 5 Percent Piano served as a probe through which people started to engage with each other.\r\n\r\nThe most obvious playful exploration occurred when the workers were on their lunch break, during which they were more open for distraction. For those who were commuting or working, the repetitive audio went unnoticed or became a source of irritation. As others also observed [6], these type of contextual factors should be more carefully considered in explorations with augmented audio installations, though getting a diversity of responses (positive and negative) could also be an interesting aim of such installations.\r\n\r\nWhat is more, no one seemed to make sense of the logic behind the playback of the audio response and the playback did not appear very intuitive to passers-by\'s movement. This was likely due to a combination of false positive readings from the sensor, the chaos from the environment, and the transient encounters most passers-by had with 5 Percent Piano. In addition, since the transducer was attached close to the rear of the piano, most passers-by lingered close to the sound source. If more intuitive interactions with audio augmented objects are desired, it could be considered to attach the sensor next to where the sound is generated.\r\n\r\nFinally, despite the fact that people picked up on the content of the audio response in their conversations, we did not observe any obvious reactions to the content. In order to stir discussions about the implied political issue, we suggest that more contextual information needs to be provided along with the audio response.\r\n\r\nInspired by the practice of street art, we speculated on a scenario of non-visual street art, in which objects are augmented with audio responses. 5 Percent Piano is just the onset of our exploration of how augmented audio responses alter the reception of often ignored everyday objects and how it can create opportunities for social engagement with others. For our future work, instead of using a pre-scripted audio clip, we intend to incorporate an input device, like a microphone, to invite passers-by to ‘tag’ the objects with their voice. We ponder whether the talking objects of the future will not just make us be able to listen, but hear again.\r\n\r\n\r\nFigure 5: Passers-by reacting to 5 Percent Piano.\r\nACKNOWLEDGMENTS\r\n\r\nTo Adi, from whom we got the Arduino shield used in this project, for your generosity among many other things.\r\n\r\nREFERENCES\r\n\r\nAdafruit music maker shield 2018. Adafruit music maker shield guide. Retrieved June 21, 2019 from https://cdn-learn.adafruit.com/downloads/pdf/adafruit-music-maker-shield-vs1053-mp3-wav-wave-ogg-vorbis-player.pdf  \r\nBaloica 2013. Art project ’Baloica’ description. Retrieved August 29, 2019 from http://www.claudiaoliveira.net/baloica/  \r\nBISS0001 datasheet 2019. BISS0001 micro power PIR motion detector IC. Retrieved June 21, 2019 from http://www.ladyada.net/media/sensors/BISS0001.pdf  \r\nNicolas Collins. 2014. Handmade electronic music: the art of hardware hacking. Routledge.  \r\nWilliam W Gaver. 1993. What in the world do we hear?: An ecological approach to auditory event perception. Ecological psychology 5, 1 (1993), 1–29.  \r\nAnnakaisa Kultima, Timo Nummenmaa, Heikki Tyni, Kati Alha, Jaakko Stenros, Ville Kankainen, Jussi Holopainen, and Frans Mäyrä. 2018. Playful furniture: breaching a serious setting with interactive seats. Games and Culture 13, 3 (2018), 301–321.  \r\nLarge surface transducer with wires - 4 Ohm 5 Watt 2012. Large surface transducer product page. Retrieved June 21, 2019 from https://www.adafruit.com/product/1784  \r\nMarianne Latinus and Pascal Belin. 2011. Human voice perception. Current Biology 21, 4 (2011), R143–R145.  \r\nHenri Lefebvre. 1991. Critique of everyday life: Foundations for a sociology of the everyday. Vol. 2. Verso. \r\nPIR sensor 2018. PIR sensor datasheet. Retrieved June 21, 2019 from https://cdn-learn.adafruit.com/downloads/pdf/pir-passive-infrared-proximity-motion-sensor.pdf  \r\nPlay Me, I\'m Yours 2019. Art project ’Play Me, I\'m Yours’ description. Retrieved June 21, 2019 from http://www.streetpianos.com/about/  \r\nNicholas Alden Riggle. 2010. Street art: The transfiguration of the commonplaces. The Journal of Aesthetics and Art Criticism 68, 3 (2010), 243–257.  \r\nBarbara G Shinn-Cunningham and Virginia Best. 2008. Selective attention in normal and impaired hearing. Trends in amplification 12, 4 (2008), 283–299.  \r\nMary Beth Stein. 1989. The politics of humor: the Berlin Wall in jokes and graffiti. Western Folklore 48, 2 (1989), 85–108.  \r\nThw world\'s deepest bin 2009. The world\'s deepest bin - Thefuntheory.com - Rolighetsteorin.se. Video. Retrieved August 26, 2019 from https://youtu.be/cbEKAwCoCKw  \r\nTrump-May news conference 2019. Trump-May news conference in full - BBC News. Video. Retrieved June 26, 2019 from https://youtu.be/xnKOtSDJp2E?t=1337  \r\nWikipedia 2019. Street Piano. Retrieved June 21, 2019 from https://en.wikipedia.org/wiki/Street_piano  \r\nAndrzej Zieleniec. 2016. The right to write the city: Lefebvre and graffiti. Environnement urbain 10(2016).  \r\nAndrzej Zieleniec. 2018. Lefebvre\'s politics of space: Planning the urban as oeuvre. Urban Planning 3, 3 (2018), 5–15.  \r\n',1,'Xu','Dan Xu and Gijs Huisman','Dan Xu *(Digital Society School, Amsterdam University of Applied Sciences, Netherlands)* <br>\r\nGijs Huisman *(Digital Society School, Amsterdam University of Applied Sciences, Netherlands)*',NULL,0,'10.1145/3363384.3363397','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,13),(55,'candello-teaching-robots-to-act-and-converse-in-physical-spaces-participatory-design-fictions-with-museum-guides','2019-09-03 08:29:56','2019-11-19 12:44:10','2019-09-03 08:29:56',NULL,1,'published','[]','Teaching Robots to Act and Converse in Physical Spaces: Participatory Design Fictions with Museum Guides','This paper reflects on the expectations of museum guides regarding companion AI-powered robots in a science museum space. We employed Design Fiction as a technique to explore machine teaching of future technologies in public spaces. The fiction is illustrated by an open-ended “imaginary abstract” which showcases the dilemma of buying AI robots to work as floor guides in a science museum. Forty-seven museum guides participated in a study in which they were asked to write the end of a fictional story. Participants described their impressions and implications of teaching robots who would do their jobs. This design fiction activity is expected to help grounding the debate on machine teaching paradigms, values, and social dilemmas which new technologies bring to physical spaces.','Heloisa Candello, Mauro Pichiliani, Mairieli Wessel, Claudio Pinhanez, and Michael Muller. 2019. Teaching Robots to Act and Converse in Physical Spaces: Participatory Design Fictions with Museum Guides. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363399](https://doi.org/10.1145/3363384.3363399 \"DOI for the article \'Teaching Robots to Act and Converse in Physical Spaces: Participatory Design Fictions with Museum Guides\'\")','1 INTRODUCTION\r\n\r\nToday, building AI-powered systems requires specialized professionals who often translate information acquired from domain experts to the machines [26, 28, 30]. Although domain experts (DEs) are usually familiar with the content, and able to teach other humans to do their tasks, they are usually not familiar with computer programming languages, machine learning training systems, and the hidden logic of machines. AI systems are commonly built with the help of intermediaries (ML experts) who mediate the transfer of knowledge from DEs to machines. Recent work in machine teaching has explored how DEs can teach machines directly without the mediation of ML experts [16, 27], with the help of new interfaces and systems [14, 16, 17, 19, 27].\r\n\r\nIn this paper, we examine the expectations of a particular group of DEs, science museum guides, to teach future robot guides to act in a physical space. In particular, we look into how the museum guides expect to transfer their knowledge about the content of the museum to an AI system. Similarly, cultural heritage studies have highlighted DEs and museum visitors importance as active actors in the design process of interactive technologies [8, 10, 23].\r\n\r\nWe applied Design fiction [2, 3, 9, 12, 15, 18, 20, 22, 24] as a participatory method [7, 25] for future configurations of DEs teaching AI-powered robots in physical spaces. In this fiction, we describe a scenario in which museum managers buy AI robots for acting as helpers and/or guides to answer visitor requests and how those robots would be expected to learn from DEs guides that currently work in the museum.\r\n\r\nSuch AI robots do not exist yet and they are illustrated by an open-ended “imaginary abstract” [2] inspired by previous publications in the field [7, 25]. The fiction was grounded by empirical facts of how new employees are taught to attend the visitors. We asked 47 museum guides to read the fiction and act as storytellers answering questions to ground the end of the fiction. Our participants move from passive readers[11] to become active writers [7, 25]. We analyzed the data by applying a thematic-network analysis [1, 6, 21].\r\n\r\n2 THE SETTING: A SCIENCE MUSEUM\r\n\r\nCatavento is a science museum located in São Paulo, Brazil. It encompasses more than 250 exhibits. The museum receives more than 2,500 visitors daily with most of its audience being families, children, and teenagers. Besides traditional walk-in visitors, the museum also provides visit tours for groups.\r\n\r\nThe training process to be a guide includes initial observations of tours led by senior guides, study of selected content, joint guides with experienced guides, solo guidance of school groups, and, finally, the training of new guides.\r\n\r\n3 METHODOLOGY\r\n\r\nIn February of 2019, we conducted a participatory design fiction workshop with 47 guides at the museum. They were undergraduate students in Chemistry and Biology with ages between 19 to 25. Half of the participants were working in the museum for more than ten months and the remainder for less than six months.\r\n\r\nParticipants were invited to participate in a research study about the future of robots in museums; and their attendance was optional. The education manager gave a day off for the guides who attended the study. Each participant answered the survey individually on a computer. Participants answered a survey covering demographic questions, did an open-ended design fiction task, and responded to questions to understand their expectations about and possible implications of having robots acting as human guides. Participants did not have any programming or AI skills.\r\n\r\n4 THE FICTION\r\n\r\nEvery guide who works in this museum can train their robots, so the robots become their assistants. Camila is a museum employee specialized in the Life area of the museum. Her job is to answer visitors’ questions regarding the first living organisms, human beings, life in the oceans, evolution theories, cells, and other topics. Learning a new topic requires two to three weeks of study, review of related materials, and following experienced museum employees. Camila deals with the preparation and rehearsal of her role every day, so she can provide an outstanding experience to the visitors. Besides, Camila is also responsible for training her assistant robot. She will keep teaching the robot until it can answer visitors’ questions.\r\n\r\nJohn is an education manager at the museum. He is responsible for handling the fluctuation of the number of museum guides. The guides are young students and, for the most part, this is their first job. It is a well-known fact that other museums already have machines with artificial intelligence capabilities which provide information to visitors and that this practice increased the visitation in those museums. John is thinking to buy more robots (AI machines). Camila and John are worried that the human touch could be a factor which will affect the visitors’ experience in the museum.\r\n\r\n\r\nFigure 1: Result of the thematic network analysis of the design fiction process.\r\nWhat would John do and what are the consequences? Who would be affected by John\'s decision?\r\nHow will the John\'s decisions affect the people involved?\r\nAnd how will John solve that?\r\nWho should be consulted when taking these decisions?\r\nWhat would you do if you were John?\r\nWhat would happen if a visitor asked Camila how the robot works? How will Camila explain this to the visitor?\r\nHow about you, what do you think this robot is capable of doing? Give examples or draw how you think this robot is.\r\nHow does Camila know that the robot is ready to answer the visitor\'s questions and be an assistant?\r\nWhat would be not adequate for a robot to do?\r\nWhich functions did you think Camila can transmit to a robot?\r\nHow would Camila teach the robots the features she wants it to perform?\r\nWhat do Camila and John mean by this: “the human touch could be a factor that will impact the experience of the museum visitors.” Are there any other worries that you think Camila would have?\r\nWhat would happen if a visitor makes a question and the robot don\'t know what to answer?\r\nHow could Camila teach the robot to answer correctly?\r\nHow can Camila train this robot in such a way that it could handle the visitor\'s questions?\r\nHow much time do you think it would take to prepare a robot?\r\nWhich is Camila\'s favorite ways to teach a robot?\r\nHow would you like to teach this robot?\r\n4.1 Thematic network analysis\r\n\r\nParticipants’ answers were coded by two researchers to determine the main themes on the expectations about the future of teaching a companion AI-powered robot. The open-coding scheme emerged from the data. The two researchers discussed the codes to build a thematic network. The thematic network aimed to depict the themes and better understand the main patterns in the data [1, 6, 21].\r\n\r\nIn total, 268 emergent codes were derived from the open-coding analysis. The codes became basic themes [1] according to the issues which were being handled. The basic themes were grouped, when connected, and organized into 6 organizing themes (Agency; Information ownership; Accountability; Surveillance; The machine capabilities; The choice of teaching patterns). Those were further grouped into one global theme: Teaching machines will change the dynamic of the workplace. In the next session, we discuss briefly our thematic network, depicted in Fig. 1.\r\n\r\n5 RESULTS AND DISCUSSION\r\n\r\nThe data analysis helped us to envision the end of the story proposed by the guides. For about two-thirds of participants, John would buy more robots for the museum, and more human guides would be necessary to train those bots and teach visitors to interact with those new machines, increasing the workload of humans. For the other third, the feeling of being substituted by machines was present, and some of them also mentioned the reactions visitors might have as illustrated by P8 quote, “Camila might be worried about the possibility to lose her internship, as well as the concern about how visitors would react to this technology.”\r\n\r\nThe first impressions in human-agent virtual encounters might have an impact on visitors decisions to approach and initiate interaction with the exhibit as previous studies show [4]. As a consequence, more education courses for future human guides would also be a requirement to work in the museum to show visitors how to interact with robots. Human guides expected the robots to have the capability to adapt to different kinds of users, for instance, personalizing their answers according to visitors age and education as reported by some participants. Guides expect robots to have smartphone-like capabilities (multimedia functionalities, memory capacity) to be able to teach them.\r\n\r\nThey expressed that the future dynamic of the museum with AI-machines to attend visitors would change and impact the humans’ agency. Humans would have more free time to study, enrich guided tours and would be accountable to answer interesting, complex, and challenging questions from visitors while machines would help with functional and objective questions as mentioned by P44 “John would buy the robots not for them to answer questions about the sessions themselves, content about biology or history, but for them to answer basic questions like: Where is X session? Where is the bathroom? The water cooler?”. Participants reported they spend most of their day answering similar, not so interesting questions about the location of exhibits, opening times, and facilities questions. Therefore, machines also would assist with that. The presence of robots would attract more visitors, and they would serve as entertainment exhibit themselves. The robots should also be tailored to each session of the museum.\r\n\r\nRobots would also be expected to have intelligence capabilities to connect everyday examples to their answers to visitors. This basic theme relates to the way human guides deliver information to grasp visitors’ attention to explain new science concepts. Also, when robots were not be able to answer a question, they would have proactive capabilities to ask for the answer from a human guide or recommend visitors to find a human guide.\r\n\r\nIt is clear from the analysis that the intervention of a new technology in the museum ecosystem brings the importance of Information ownership, Human agency [29] and Accountability  [13]. Those organizing themes were also evident when participants mentioned behaviors and actions which the robots should not perform, as exemplified by some of the participants’ comments that robots should not curse, be aggressive, give wrong answers, leave visitors without answers, or discuss polemic issues. Also, this surveillance of the robots should be done by human guides.\r\n\r\nMost of the participants reported the robots should be trained frequently, and for some of them, the frequency should be everyday. New information should be incorporated mainly by the human guides, who would evaluate the performance of robots by observing their interaction with visitors and asking ground truth questions. The majority of guides reported they would like to teach using natural language, although two of them mentioned the need for programming skills for teaching. The choice of teaching patterns will also affect the dynamic of the workplace. The five teaching paradigms (TP) mentioned in previous work [5], also emerged in this research: Multiple-choice question (TP1); Pairs of examples (TP2); Text interpretation (TP3); Key-words (TP4); and Incremental technology (TP5). Participants also suggested another two paradigms. In one paradigm human guides could teach the robots by playing with them (TP6); and in another pattern teaching could happen by conversation demonstration (mimicry), where the guide would speak and the robot would copy and record the information (TP7).\r\n\r\nThey also expected to teach the robots machine capabilities such as making critical questions, and to help visitors to think about science topics. Almost all participants mentioned that robots should learn the visitors’ questions on the museum floor and store those in a database. Participants expected to teach the answers using one or a combination of the teaching paradigms (TP1-TP7) mentioned previously. Tone, language, and accountable behaviour were also traits participants expected to be responsible to teach robots, because those elements, in their view, are essential to the guided visit. According to P28, “Camila can teach the robot to use informal and cordial language using her experience gained from contact with visitors of different ages so that the robot has a more friendly behavior.”.\r\n\r\nWe hope those insights from our participants’ reflections about the future can assist designers, roboticists, developers, and managers to pay attention to what experts think would be expected when training robots for physical spaces.\r\n\r\n6 FUTURE WORK\r\n\r\nWe plan to conduct role-playing activities with a prototype robot to understand those expectations situated on the museum floor and examine human guides subsequent actions towards teaching the robot to validate results of this speculative study.\r\n\r\nREFERENCES\r\n\r\nJennifer Attride-Stirling. 2001. Thematic networks: an analytic tool for qualitative research. Qualitative research 1, 3 (2001), 385–405.  \r\nMark Blythe. 2014. Research Through Design Fiction: Narrative in Real and Imaginary Abstracts. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’14). ACM, New York, NY, USA, 703–712. https://doi.org/10.1145/2556288.2557098  \r\nBarry Brown, Julian Bleecker, Marco D\'Adamo, Pedro Ferreira, Joakim Formo, Mareike Glöss, Maria Holm, Kristina Höök, Eva-Carin Banka Johnson, Emil Kaburuan, Anna Karlsson, Elsa Vaara, Jarmo Laaksolahti, Airi Lampinen, Lucian Leahu, Vincent Lewandowski, Donald McMillan, Anders Mellbratt, Johanna Mercurio, Cristian Norlin, Nicolas Nova, Stefania Pizza, Asreen Rostami, Mårten Sundquist, Konrad Tollmar, Vasiliki Tsaknaki, Jinyi Wang, Charles Windlin, and Mikael Ydholm. 2016. The IKEA Catalogue: Design Fiction in Academic and Industrial Collaborations. In Proceedings of the 19th International Conference on Supporting Group Work(GROUP ’16). ACM, New York, NY, USA, 335–344. https://doi.org/10.1145/2957276.2957298  \r\nAngelo Cafaro, Hannes Högni Vilhjálmsson, and Timothy Bickmore. 2016. First Impressions in Human–Agent Virtual Encounters. ACM Transactions on Computer-Human Interaction (TOCHI) 23, 4(2016), 24.  \r\nHeloisa Candello, Mauro Pichiliani, Claudio Pinhanez, and Paulo Cavalin. 2019. Teaching Chatbots to Show Science: A Study with Museum Guides. In Proceedings of Human-Centered Machine Learning Perspectives Workshop.  \r\nHeloisa Candello, Claudio Pinhanez, Mauro Pichiliani, Paulo Cavalin, Flavio Figueiredo, Marisa Vasconcelos, and Haylla Do Carmo. 2019. The Effect of Audiences on the User Experience with Conversational Interfaces in Physical Spaces. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI ’19. ACM Press, New York, New York, USA, 1–13. https://doi.org/10.1145/3290605.3300320  \r\nEunJeong Cheon and Norman Makoto Su. 2018. Futuristic Autobiographies: Weaving Participant Narratives to Elicit Values Around Robots. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction(HRI ’18). ACM, New York, NY, USA, 388–397. https://doi.org/10.1145/3171221.3171244  \r\nLuigina Ciolfi. 2012. Place-centred interaction design: situated participation and co-creation in places of heritage. In Proceedings of the Museum and design principles. Fondazione di Venezia.  \r\nLuigina Ciolfi and Eleanor Lockley. 2019. Exploring flash fiction for the collaborative interpretation of qualitative data. In Proceedings of 17th European Conference on Computer-Supported Cooperative Work. European Society for Socially Embedded Technologies (EUSSET).  \r\nLuigina Ciolfi and Daniela Petrelli. 2015. Walking and Designing with Cultural Heritage Volunteers. Interactions 23, 1 (Dec. 2015), 46–51. https://doi.org/10.1145/2848979  \r\nHeather Draper, Tom Sorell, Sandra Bedaf, Dag Sverre Syrdal, Carolina Gutierrez-Ruiz, Alexandre Duclos, and Farshid Amirabdollahian. 2014. Ethical dimensions of human-robot interactions in the care of older people: Insights from 21 focus groups convened in the UK, France and the Netherlands. In International Conference on Social Robotics. Springer, 135–145.  \r\nEnrique Encinas and Mark Blythe. 2016. The solution printer: magic realist design fiction. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 387–396. \r\nBatya Friedman, Peter H Kahn, and Alan Borning. 2008. Value sensitive design and information systems. The handbook of information and computer ethics (2008), 69–101.  \r\nShang Guo, Jonathan Lenchner, Jonathan Connell, Mishal Dholakia, and Hidemasa Muta. 2017. Conversational Bootstrapping and Other Tricks of a Concierge Robot. In Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction - HRI ’17. ACM Press, New York, New York, USA, 73–81. https://doi.org/10.1145/2909824.3020232  \r\nEllie Harmon, Chris Bopp, and Amy Voida. 2017. The Design Fictions of Philanthropic IT: Stuck Between an Imperfect Present and an Impossible Future. 7015–7028. https://doi.org/10.1145/3025453.3025650  \r\nTasneem Kaochar, Raquel Torres Peralta, Clayton T Morrison, Ian R Fasel, Thomas J Walsh, and Paul R Cohen. 2011. Towards understanding how humans teach robots. In International Conference on User Modeling, Adaptation, and Personalization. Springer, 347–352.  \r\nTodd Kulesza, Simone Stumpf, Margaret Burnett, Sherry Yang, Irwin Kwan, and Weng Keen Wong. 2013. Too much, too little, or just right? Ways explanations impact end users’ mental models. In Proceedings of IEEE Symposium on Visual Languages and Human-Centric Computing, VL/HCC. https://doi.org/10.1109/VLHCC.2013.6645235  \r\nJoseph Lindley, Paul Coulton, and Emmett L Brown. 2016. Peer Review and Design Fiction: “Honestly, they\'re not just made up.”. CHI Extended Abstracts (Alt. CHI). ACM(2016).  \r\nMartin Lindvall, Jesper Molin, and Jonas Löwgren. 2018. From machine learning to machine teaching: the importance of UX. Interactions 25, 6 (2018), 52–57.  \r\nConor Linehan, Ben J Kirman, Stuart Reeves, Mark A Blythe, Joshua G Tanenbaum, Audrey Desjardins, and Ron Wakkary. 2014. Alternate endings: using fiction to explore design futures. In CHI’14 Extended Abstracts on Human Factors in Computing Systems. ACM, 45–48.  \r\nEwa Luger and Abigail Sellen. 2016. “Like Having a Really Bad PA”: The Gulf between User Expectation and Experience of Conversational Agents. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems - CHI ’16 (2016). https://doi.org/10.1145/2858036.2858288  \r\nEllen Lupton. 2017. Design is storytelling.  \r\nLaura A. Maye, Fiona E. McDermott, Luigina Ciolfi, and Gabriela Avram. 2014. Interactive Exhibitions Design: What Can We Learn from Cultural Heritage Professionals?. In Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational(NordiCHI ’14). ACM, New York, NY, USA, 598–607. https://doi.org/10.1145/2639189.2639259  \r\nMichael Muller and Thomas Erickson. 2018. In the Data Kitchen: A Review (a Design Fiction on Data Science). In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems(CHI EA ’18). ACM, New York, NY, USA, Article alt14, 10 pages. https://doi.org/10.1145/3170427.3188407  \r\nMichael Muller and Q Vera Liao. 2017. Exploring AI Ethics and Values through Participatory Design Fictions. Human Computer Interaction Consortium(2017). https://www.slideshare.net/traincroft/hcic-muller-and-liao-participatory-design-fictions-77345391  \r\nPatrice Y Simard, Saleema Amershi, David M Chickering, Alicia Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, et al. 2017. Machine teaching: A new paradigm for building machine learning systems. arXiv preprint arXiv:1707.06742(2017).  \r\nPatrice Y. Simard, Saleema Amershi, David Maxwell Chickering, Alicia Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, and John Robert Wernsing. 2017. Machine Teaching: A New Paradigm for Building Machine Learning Systems. CoRR abs/1707.06742(2017).  \r\nSimone Stumpf, Vidya Rajaram, Lida Li, Margaret M. Burnett, Thomas G. Dietterich, Erin Sullivan, Russell Drummond, and Jonathan L. Herlocker. 2007. Toward harnessing user feedback for machine learning. In IUI.  \r\nLucy Suchman. 2007. Human-machine reconfigurations: Plans and situated actions. Cambridge University Press.  \r\nAndrea Lockerd Thomaz and Cynthia Breazeal. 2008. Teachable robots: Understanding human teaching behavior to build more effective robot learners. Artif. Intell. 172(2008), 716–737.  ',1,'Candello','Heloisa Candello, Mauro Pichiliani, Mairieli Wessel, Claudio Pinhanez, and Michael Muller','Heloisa Candello *(IBM Research, Brazil)*<br>\r\nMauro Pichiliani *(IBM Research, Brazil)*<br>\r\nMairieli Wessel *(IBM Research, Brazil)*<br>\r\nClaudio Pinhanez *(IBM Research, Brazil)*<br>\r\nMichael Muller *(IBM Research, USA)*<br>',NULL,0,'10.1145/3363384.3363399','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,15),(56,'lintunen-latent-spaces-the-high-dimensional-infosphere','2019-09-03 08:29:56','2019-11-19 12:19:57','2019-09-03 08:29:56',NULL,1,'published','[]','Latent Spaces: The High-Dimensional Infosphere','Briefly considering distributed informational environments as latent spaces for the construction of meaning and knowledge, I explore the concept of the infosphere and the phenomenology of such high-dimensional abstract space in the context of social systems. Spaces such as the internet require radically imaginative tools for meaningful interpretation, as real-world applications powered by big data, an unparalleled infrastructure of digital connectivity and machine learning, are emerging across our social space. Throughout this paper, I construct a narrative that forms a speculative definition of latent social space, opening up avenues for future research into understanding how meaning and knowledge are produced, acquired, collectively made, or otherwise emerge, through new media.','Erik Lintunen. 2019. Latent Spaces: The High-Dimensional Infosphere. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363395](https://doi.org/10.1145/3363384.3363395 \"DOI for the article \'Latent Spaces: The High-Dimensional Infosphere\'\")','1 PHANTASMS INTO BEING\r\n\r\nLeisurely I retraced my way through the lounge and bedrooms, scanning the empty floors, running my hands over the smooth plastex walls, bracing myself to feel again the impact of Gloria Tremayne\'s personality. Blissfully, her presence would be everywhere in the house, a thousand echoes of her distilled into every matrix and senso-cell, each moment of emotion blended into a replica more intimate than anyone, apart from her dead husband, could ever know. The Gloria Tremayne with whom I had become infatuated had ceased to exist, but this house was the shrine that entombed the very signatures of her soul [3].\r\nJ. G. Ballard\'s short story The Thousand Dreams of Stellavista speculates a future that includes surprising forms of sentience, such as architecture that learns from its inhabitants as depicted in the excerpt above. This serves as a provocative starting point for unravelling the concept of latent social space — a fictional future augmented with radically intelligent materials and new means of communication.\r\n\r\n2 THE INFOSPHERE\r\n\r\nDon\'t you like your work?\r\n\r\nNah. What\'s to enjoy? It\'s all pretty meaningless. I find a good restaurant. I write it up for a magazine. Go here, try this. Why bother? Why shouldn\'t people just go where they feel like and order what they want? Why do they need someone to tell them? What\'s a menu for? And then, after I write the place up, the place gets famous and the cooking and service go to hell. It always happens. Supply and demand get all screwed up. And it was me who screwed it up. I do it one by one, nice and neat. I find what\'s pure and clean and see that it gets all mucked up. But that\'s what people call information [26].\r\nThe first and perhaps most important precondition for any critical analysis to take place is a metaphysical presumption: information is never disembodied [10]. It exists in time and space, physically manifesting as events encoded into matter [7]. The second precondition which is also imperative to consider expands on the first: information is a difference which makes a difference [6]. Meaning that the nature of information is temporal and hence experiential.\r\n\r\nSubsequent to the digital revolution, particularly in response to knowledge synthesised at the intersections of critical theory, information theory, game theory and computer science, we have been able to devise models and establish discoursal frameworks that deconstruct complexity in both artificial and biological systems, through which we further ‘understand the evolution of emergent intelligence in real-world organisms’ [20]. In fact philosophical posthumanism has come to the fore as an onto-epistemological framework in which the previously differentiated areas of “artificial” and “natural” have dissipated into an ambiguous wider landscape. Through technology we are able to simulate and predict, as well as manipulate, behaviours in weather, finance and politics. It seems reasonable to suggest that a hybrid construct of human and machine – the cyborg – has emerged: ‘[it] is our ontology; it gives us our politics’ [16].\r\n\r\nIn this way, the cyborg is ‘a condensed image of both imagination and material reality’ [16] through which transformation happens, acting across our social space, offline and online. The posthuman experience of interconnectivity and social construction has been augmented by optical fibre and radio waves, which have exponentially increased the scope of accessible knowledge as well as radically reconfigured the ways in which we interact with one another. The Matrix (a fictional simulated virtual reality construct of the world) [32] is very real, but more in the sense that ‘we are not stand-alone and unique entities, but rather informationally embodied organisms (inforgs), mutually connected and embedded in an informational environment, the infosphere, which we share with both natural and artificial agents similar to us in many respects’ [11], thus an environment analogous to our extended reality powered by inventions and innovations such as transistors, the internet, data mining and smart fridges.\r\n\r\nThe momentary paranoia of Rick Deckard (a replicant hunter and character of fiction) [9] doubting his mortality is warranted, as is the psychotic rage and confusion of Dolores Abernathy (an artificial host and fictional character) [22] throughout her voyage of self-discovery – learning that she is a generic android host with a programmable personality and implanted memories, brought to “life” to entertain guests at an exclusive theme park. The boundary between our real identities and data selves [19] is hazy if not entirely indistinguishable. There exists no universal ethical framework within which to operate, ‘particularly regarding the principles of informed consent – not least because of the ethical concerns arising from the Facebook “emotional contagion” study, where the mood of unwitting participants was observed and manipulated in response to status updates’ [23]. Targeted ads converge on us within the infosphere much like the fictional projections (dreamed images projected by the sleeping subject\'s subconscious mind) [28] targeting the manipulative dreamer. Digital media, ‘even in their most banal or quotidian forms, speak to issues of power and to the relationship between our individual biographies and the larger tides of history’ [14]. The thought of Facebook or Google forecasting my behaviour is anxiety-inducing, but only because there is practically no regulation on what the data can and cannot be used for. In an exploitative playground for free market capitalism, data is used across the political spectrum for mass surveillance, censorship and oppression.\r\n\r\nCan these systems be disrupted, or have they outgrown the reaches of top-down control? What is the level of complexity and intelligence swarming within a global internet of things? In order to understand something about the ontogenesis [24] of postdigital topologies and networked information systems, we should consider emergence as an investigative framework: ‘the movement from lower-level rules to higher-level sophistication’ [21] that in one way serves to ‘deepen our understanding of what it means to be in a world rather than apart from it, co-maker rather than dominator, participants in the complex dynamics that connect “what we make” and “what (we think) we are”’ [17].\r\n\r\nThe emergence of swarm intelligence is embodied in the movement of information within the system – simple communications between constituent elements, that on a larger scale form its complex feedback mechanisms. Collective jurisdiction is realised through smaller bodies of decentralised governance that permeate larger parts to form unexpected wholes [2]. Consequently in making meaning, ‘statements are not mere utterances of the originating consciousness of a unified subject; rather, statements and subjects emerge from a field of possibilities’ [4]. However, this field is ‘not a static or singular but rather is a dynamic and contingent multiplicity’ [4]. The infosphere matters, both physically as ‘iterative reconfigurings of topological manifolds of spacetime-matter relations’ [5], and as something to consider in terms of ethics. It is important because it comes to matter in onto-epistemological construction (of meaning and knowledge). Exploring this space through art and design is justified: ‘we can\'t really write about the present directly, since we need to frame the present in terms of the immediate past’ [15], whereas we can experience the world in a playful, imaginative and speculative fashion – together performing things that are yet to be made sense of.\r\n\r\n3 LATENT SPACE\r\n\r\nMy room has sound behind its walls, under its floorboards and on top of its ceiling. They make it shrink and expand, move and be still. What is in the room is visible, present, objectively here. The sound is invisible, not here, but present all the same. […] Unseen protagonists, who might really be there or just invented by me, play out fantastic scenarios that might be real, involving alien space ships, cats, dogs and microwaves [30].\r\nIn the context of artificial neural networks, latent space is an abstract, high-dimensional space which makes the information existing in that space rather inaccessible; presumably the physical universe exists in three dimensions, disregarding time. Mathematically space can be represented as a common geometric three-parameter model with spatial coordinates of x, y, and z, but latent space resembles a more complex vector space due to the number of its dimensions. Latency, as a concept, has a multitude of meanings across different fields of knowledge: in computing it refers to the time interval between cause and effect, like the time it takes to load a website. More generally, latency can be understood as something hidden or not yet fully developed, as in an unrealised ability to perform. Voegelin, in her blog entry quoted above, refers to the latent properties of sound – sonic possible worlds [31]. The latent space of an artificial neural network contains a compressed representation of the input data [8] – the only information the model has access to and therefore knows: it is its ontology.\r\n\r\nSpatial coordinates in our three-dimensional space provide useful notations of distance and magnitude that help us construct an understanding of the shape, size and form of things. Latent space is illegible in the same way as our physical space, so we have to develop tools to make sense of it. Using digital colour images sized 1,024x1,024 pixels would mean working in a space of 3,145,728 dimensions (total number of pixels multiplied by the number of colour channels – three in the case of RGB images). As the number of dimensions increases, the computing power and amount of data required to build stable networks is also increased [13]. A major challenge in this approach is that there is no explicit meaning for the dimensions in latent space, meaning that nothing in relation to position or distance is clearly defined. We as humans have the intellectual ability to interpret and differentiate images based on existing knowledge and context. In a high-dimensional space every image is ‘mixed together and surrounded by noisy, meaningless nonsense’ [29]; but we can learn about the contents of that space by studying connectivity patterns using latent space models [18].\r\n\r\nLow-dimensional representations of latent space not only depict the internal world constructed by an artificial neural network but are also reflections of the external world – reconstructions of familiar beliefs and hierarchies [1]. When we discuss algorithmic bias, we refer to inherited values from our social space. The importance of developing models to interpret this abstract space (or interpretable models in the first place) is crucial for many scientific fields that study network data, like social networks, biological networks and information networks. Through interactive new media and information experience design across physical and virtual space, we can start exploring latent space in the context of social space: latent social spaces. These are complex informationally embedded, interconnected, abstract, and high-dimensional spaces in which information, meaning and knowledge entangle, waiting to be constructed and further reconstructed through experience – collisions of energies causing uncanny emergences somewhere in the ambient space of the infosphere.\r\n\r\n4 ARTIFICIAL DREAMSCAPES\r\n\r\nWe do not even have a raft, but drowning in obscurities is not an option [12].\r\nThe images in Figure 1 are generated by a deep artificial neural network model that has been trained on real landscape images. The result is a haunting reinterpretation of the original dataset. Similarly, in his short story, Ballard conjures psychotropic houses that embody a haunting tele-presence of their past inhabitants. At a metaphorical level, the infosphere is an eerie action space for “Chinese whispers,” in which representations, abstractions, concepts and ideas travel through various systems of information processing. On the other hand, something that may seem ineffable is probably lacking the appropriate means through which to materialise or is missing a coherent framework for communication.\r\n\r\nWe may not have a raft, as Floridi writes, paraphrasing a metaphor from the late philosopher Otto Neurath [27], but sensible solutions have to be found. Peering into high-dimensional latent space may provide a glimpse into the unknown.\r\n\r\nWe can speak ineffable things. When we say we can\'t speak the ineffable, there we are, speaking it. Secrecy means not totally unspeakable or unknown. You know there is a secret. When philosophy puts a foot in its mouth, its mouth full of itself, tasting slightly different than itself, philosophy starts to smile [25].\r\n\r\nFigure 1: 6x6 Latent Space Vectors (above) and Arithmetic Landscape Collage (below). Produced by the author.\r\nREFERENCES\r\n\r\nMemo Akten. 2017. Learning to See. Memo Akten. Retrieved September 21, 2019 from http://www.memo.tv/portfolio/learning-to-see  \r\nPhilip Warren Anderson. 1972. More is Different: Broken Symmetry and the Nature of the Hierarchical Structure of Science. Science 177.4047(1972), 393–396.  \r\nJames Graham Ballard. 1962. The Thousand Dreams of Stellavista. In Amazing Stories Vol. 36 No. 3. Ziff-Davis Publishing Company, New York, NY, 48.  \r\nKaren Barad. 2007. Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning. Duke University Press, Durham, NC, 147.  \r\nKaren Barad. 2007. Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning. Duke University Press, Durham, NC, 178–178.  \r\nGregory Bateson. 1972. Steps to an Ecology of Mind. University of Chicago Press, Chicago, IL, 14.  \r\nSarah Cook. 2016. Information. Whitechapel Gallery and The MIT Press, Cambridge, MA, 18.  \r\nJulien Despois. 2017. Latent Space Visualization: Deep Learning Bits No. 2. Hacker Noon. Retrieved September 21, 2019 from https://hackernoon.com/latent-space-visualization-deep-learning-bits-2-bd09a46920df  \r\nPhilip Kindred Dick. 1968. Do Androids Dream of Electric Sheep?Doubleday, New York, NY.  \r\nTristan Farrow. 2019. Introduction to Quantum Entanglement. Talk at Oxford University.  \r\nLuciano Floridi. 2012. Turing\'s Three Philosophical Lessons and the Philosophy of Information. Philosophical Transactions of the Royal Society A 370 (2012), 3536–3542.  \r\nLuciano Floridi. 2014. The Fourth Revolution: How the Infosphere is Reshaping Human Reality. Oxford University Press, Oxford, UK, Introduction: x.  \r\nIan Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press, Cambridge, MA.  \r\nKaren Gregory. 2017. Structure and Agency in a Digital World. In Digital Sociologies. Policy Press, Bristol, UK, 3–4.  \r\nEd Halter. 2014. Foreword. In You Are Here: Art After the Internet. HOME and SPACE, Manchester, UK, 13.  \r\nDonna Haraway. 1991. A Cyborg Manifesto. In Simians, Cyborgs, and Women. Free Association Books, London, UK, 150.  \r\nNancy Katherine Hayles. 2005. My Mother Was a Computer: Digital Subjects and Literary Texts. University of Chicago Press, Chicago, IL, 279–280.  \r\nPeter Hoff, Adrian Raftery, and Mark Handcock. 2002. Latent Space Approaches to Social Network Analysis. J. Amer. Statist. Assoc. 97.460 (2002), 1090–1098.  \r\nRob Horning. 2012. The Rise of the Data Self. PopMatters. Retrieved September 21, 2019 from https://www.popmatters.com/153721--2495892321.html  \r\nSteven Johnson. 2002. Emergence: The Connected Lives of Ants, Brains, Cities and Software. Scribner, New York, NY, 63.  \r\nSteven Johnson. 2002. Emergence: The Connected Lives of Ants, Brains, Cities and Software. Scribner, New York, NY, 18.  \r\nLisa Joy and Jonathan Nolan. 2016. Westworld. Motion Picture.  \r\nAlison Mayne. 2017. Virtually ethical. In Digital Sociologies. Policy Press, Bristol, UK, 62.  \r\nHarold Morowitz. 2004. The Emergence of Everything: How the World Became Complex. Oxford University Press, Oxford, UK. 224 pages.  \r\nTimothy Morton. 2016. Dark Ecology: For a Logic of Future Coexistence. Columbia University Press, New York, NY, 112.  \r\nHaruki Murakami. 1988. Dance Dance Dance. Vintage, New York, NY, 116.  \r\nOtto Neurath. 1959. Protocol Sentences. In Logical Positivism. The Free Press, New York, NY, 201.  \r\nChristopher Nolan. 2010. Inception. Motion Picture.  \r\nZachary Singer. 2018. Understanding High Dimensional Spaces in Machine Learning. Towards Data Science. Retrieved September 21, 2019 from https://towardsdatascience.com/understanding-high-dimensional-spaces-in-machine-learning-4c5c38930b6a  \r\nSalomé Voegelin. 2011. SoundWords. Salomé Voegelin. Retrieved September 21, 2019 from soundwords.tumblr.com  \r\nSalomé Voegelin. 2014. Sonic Possible Worlds: Hearing the Continuum of Sound. Bloomsbury, London, UK, 216.  \r\nLana Wachowski and Lilly Wachowski. 1999. Matrix. Motion Picture. ',1,'Lintunen','Erik Lintunen','Erik Lintunen *(artist, UK)*',NULL,0,'10.1145/3363384.3363395','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,11),(57,'benerradi-exploring-machine-learning-approaches-for-classifying-mental-workload-using-fnirs-data-from-hci-tasks','2019-09-03 08:29:56','2019-11-19 12:45:14','2019-09-03 08:29:56',NULL,1,'published','[]','Exploring Machine Learning Approaches for Classifying Mental Workload using fNIRS Data from HCI Tasks','Functional Near-Infrared Spectroscopy (fNIRS) has shown promise for being potentially more suitable (than e.g. EEG) for brain-based Human Computer Interaction (HCI). While some machine learning approaches have been used in prior HCI work, this paper explores different approaches and configurations for classifying Mental Workload (MWL) from a continuous HCI task, to identify and understand potential limitations and data processing decisions. In particular, we investigate three overall approaches: a logistic regression method, a supervised shallow method (SVM), and a supervised deep learning method (CNN). We examine personalised and generalised models, as well as consider different features and ways of labelling the data. Our initial explorations show that generalised models can perform as well as personalised ones and that deep learning can be a suitable approach for medium size datasets. To provide additional practical advice for future brain-computer interaction systems, we conclude by discussing the limitations and data-preparation needs of different machine learning approaches. We also make recommendations for avenues of future work that are most promising for the machine learning of fNIRS data.','Johann Benerradi, Horia A. Maior, Adrian Marinescu, Jérémie Clos, and Max L. Wilson. 2019. Exploring Machine Learning Approaches for Classifying Mental Workload using fNIRS Data from HCI Tasks. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 11 pages. [https://doi.org/10.1145/3363384.3363392](https://doi.org/10.1145/3363384.3363392 \"DOI for the article \'Exploring Machine Learning Approaches for Classifying Mental Workload using fNIRS Data from HCI Tasks\'\")','1 INTRODUCTION\r\n\r\nAssessing mental workload in users is a long established concern and well evaluated concept in HCI and human factors, especially in safety critical domains like air traffic control [38]. Past work developed and relied on self-reporting methods like NASA-TLX [18], which can retrospectively judge the workload involved in a task. One of the longstanding goals for the future is that technology will be able to reliably identify people that are at risk of becoming overloaded, and automatically adjust their task demand accordingly. So far, existing research into workload estimation has focused on more established physiological sensors such as eye-tracking devices or EEG. More recently, functional Near-Infrared Spectroscopy (fNIRS) has shown promise as an alternative technique for measuring brain activity in HCI [1, 24, 27, 41, 48], because measures of blood oxygenation are more tolerant of physical movement than electrical activity in the brain measured by EEG, whilst still being just as portable [25, 42]. fNIRS, however, has received less attention in terms of MWL classifications using machine learning and it is not clear that established approaches for other brain data will work for fNIRS data.\r\n\r\nWhile some examples of prior work use machine learning to classify mental workload levels from fNIRS data [1, 48], they typically provide very little information about the machine learning models, and do not compare different approaches for generating them. Here, we specifically explore three different approaches for classifying mental workload from fNIRS data:\r\n\r\nApproach 1: a logistic regression model\r\nApproach 2: Support Vector Machines (SVM), a standard supervised learning approach\r\nApproach 3: Convolutional Neural Networks (CNN), a deep learning approach\r\nThe first approach is a simple linear model, while the SVM and the CNN are standard shallow and deep approaches in the literature. To support the use of fNIRS data in the future of brain-computer interaction, we provide code samples for all of our processing pipeline stages and machine learning techniques.\r\n\r\nOur investigation is guided by these Research Questions:\r\n\r\nHow should data be prepared and how should features be selected for these approaches?\r\nHow well do these approaches perform at classifying mental workload?\r\nDo personalised models outperform generalised models for fNIRS data?\r\n2 RELATED WORK\r\n\r\nMental workload is a well established concept based upon the multiple resources model from human factors [47], where mental workload levels increase significantly when a user has to cognitively process large amounts of information within one modality (spatial or verbal), and within the same stage of cognitive processing. A user, for example, will struggle to hold two number sequences in their head, but can scan a piece of text for a particular keyword while rehearsing a single number sequence, or can do so while processing spatial information. More broadly for HCI, Sharples & Magaw [38] describe mental workload as “the relationship between primary task performance and the resources demanded by the primary task”, where task performance drops if a user has too little to do to remain cognitively engaged in the task, or where task demand is too high for the user to perform it at a suitable level of performance. Similar concepts are captured within the cognitive load literature [33], and this term is often used synonymously in publications (e.g. [14, 17]).\r\n\r\nWell established approaches to evaluating mental workload have traditionally depended on subjective reporting. NASA TLX [18] is perhaps the most established one for retrospectively assessing an entire task for both mental and physical workload, where papers vary on whether they report overall differences, or differences in individual subscales like mental demand and effort. With more desire for understanding the current mental workload that a user is experiencing during a task, like when the workload is becoming too much for an air traffic controller, the Instantaneous Self Assessment (ISA) [9, 23] scale was developed to allow participants to quickly report mental workload on a simple Likert scale. A recognised consequence of this technique is that self-reporting mental workload during a task can act as a secondary task that itself impedes the performance of the primary task [45]. Consequently, much work has focused on physiological measurements to estimate mental workload.\r\n\r\n2.1 Mental workload and physiological measures\r\n\r\nMany psycho-physiological changes have been observed to correlate with mental workload changes. An observable change, which is sometimes built into eye-tracking products, is pupil dilation, where dilation in a consistently lit environment is an indication of increased mental workload [5, 21, 29]. Skin temperature changes are also observable from a thermal camera, where Marinescu et al. [28, 29] have shown that nose temperature often decreases with increased mental workload. On the body, galvanic skin response [11, 39, 40] and fluctuations in cardiac activity [7, 17, 31, 44] (measured from e.g. the wrist), have often been correlated with mental workload changes.\r\n\r\nA more direct approach, often used to estimate mental workload, is to take measurements of brain activity. Electroencephalography (EEG) is now a consumer-grade technology for estimating mental workload [3], where changes in EEG data have been shown to correlate highly with working memory load, integration of information and analytical reasoning [6]. The commercialisation of EEG has also meant that very cheap EEG devices (<$200) can be easily integrated into brain-computer interaction responsive systems [34, 36].\r\n\r\nIn the last decade, however, an increasing amount of research has investigated the use of fNIRS in the field of HCI [25, 35, 42] due to its better spatial resolution and tolerance to movements than EEG, even though it has a slightly lower temporal resolution [32]. fNIRS measures blood oxygenation levels, and is typically applied to the prefrontal cortex due to the involvement of this brain area in working memory [20]. Blood oxygenation change is a reliable indicator of the prefrontal cortex activation which reflects an increase in the amount of oxygenated haemoglobin (HbO) and changes in the de-oxygenated haemoglobin (Hb). These changes are affected by both a) the individuals underlying bodily blood oxygenation levels (which may be higher for a healthier person, or indeed for someone that is currently more alert), and b) the Blood Oxygen Level-Dependent (BOLD) delay, where the body can take 2-6 seconds (varying across individuals) to fulfil oxygen demands from the brain. This type of brain activation (oxygen in regions of the brain) correlates to the activation observed in fMRI studies [12]. While not yet as commercialised as EEG, fNIRS devices can be fully portable (via e.g. Bluetooth), and are worn in a similar way to non invasive EEG sensors. This portability in addition to its tolerance to movements thus makes fNIRS well suited for the evaluation of real-world HCI tasks such as computer usage [26, 35, 42].\r\n\r\n2.2 Machine learning of mental workload\r\n\r\nSupervised learning is a subcategory of machine learning where data is labelled with some measure of interest that we are trying to estimate, and classification is a subcategory of supervised learning where that label is a category. Typical approaches to workload classification involve either two (low and high) or three classes (low, medium, and high). We start by reviewing machine learning models of physiological data, and then more specific examples as applied to fNIRS data.\r\n\r\n2.2.1 Machine learning with physiological data. Because it can be computed using a camera and is thus less intrusive than most other sensors, the most common set of features for mental workload estimation is the position and dilation of the pupils. Zhang et al. [49] used a decision tree classifier, with 2 classes (low and high), on a vehicle driving task. They used summary statistics (mean and standard deviation) on gaze data (pupil diameter, detection of the direction of gaze) as well as driving data, e.g. velocity, lane position, steering angle and acceleration and achieved significant results using all features.\r\n\r\nMarshall [30] compared neural networks with discriminant function models, and found that neural network models performed as good or better in all cases on a binary classification task where the classes are relaxed/engaged. Haapalainen et al. [17] used a naive Bayes classifier on a binary classification problem, mixing a variety of sensors in order to determine their relative usefulness: eye-tracker (eye movement and change in pupil size), ECG armband (used to collect galvanic skin response (GSR), heat flux (rate of heat transfer) and median absolute deviation (MAD - measure of variability) of the ECG), EEG headset (EEG signal converted into two mental state outputs, attention and meditation), HR monitor (HR and HRV). Chen and Epps [10] used eye-tracking data (pupil size, blink number) to detect the level of mental workload during a mental arithmetic task. They labelled the amount of work on a 5 point scale, and then grouped those in either 2 classes (1 and 2 versus 4 and 5) or 3 classes (1 versus 4 versus 5) to generate different classification tasks. They then used a Gaussian mixture model classifier to perform the classification. Solovey et al. [43] performed an evaluation of multiple learning algorithms: decision trees, logistic regression, 1-nearest neighbour, multilayer perceptron, and naive Bayes using heart rate and heart rate variability as physiological data as well as data extracted from the vehicle that was being driven. Fridman et al. [14] compared a hidden Markov model with their 3D CNN model on a 3 class classification problem using a working memory task.\r\n\r\n2.2.2 Machine learning with fNRIS data. Comparatively little work has been done on classifying mental workload using fNIRS data. Early work used the task of counting the coloured faces of a cube [15, 37] as a way to generate low, medium and high mental workload, and then trained machine learning algorithms to perform multi-class classification. Firstly using a 3-nearest neighbours approach [37], classification accuracy was then much improved using a multilayer perceptron with a sliding window [15] which brought the performance to the 41.15% - 69.7% range.\r\n\r\nBecause most of the existing research has focused on a batch processing method, which is flawed for realistic applications of mental workload estimation, later work then focused on bringing this performance to a real-time setting. It was first done by Girouard et al. [16] using an unspecified sequence classification algorithm to categorise tasks in a 3-class classification problem. Afergan et al. [1] used this approach to adapt the difficulty of a UAV piloting task by estimating the mental workload associated with the current reaction, and Yuksel et al. [48] used these estimations for a brain-computer system enhancing piano learning, which enabled learners to play faster and with a higher accuracy.\r\n\r\nOur investigation below builds on this kind of prior work to specifically investigate the value of different machine learning approaches with fNIRS data for the use in brain-computer interaction applications.\r\n\r\n3 MENTAL WORKLOAD DATASET\r\n\r\nIn this paper we sought to investigate, compare, and release the software for three alternative ways of analysing and classifying various levels of mental workload based on the measurements coming from fNIRS. We generated a dataset consisting of performance data, subjective workload information, and physiological responses during a controlled experiment. The study design, described below, closely follows the study performed by Marinescu et al. [29].\r\n\r\n3.1 Dataset task\r\n\r\nA specific computer-based task was designed to impose different levels of mental demands on participants. As shown in Figure 1, the task consists of aiming at the target balls using a joystick, and shooting them using a button on the joystick, before the balls reach the yellow line; reaching the yellow line drags it down. The yellow line moved down the screen with the lowest missed target, or moved up the screen if all targets were destroyed. The position of the joystick is indicated by a red circular cursor that turns green once it is within range of the target. We preferred this task in favour of a n-back task because it is a more naturalistic and continuous task that allows us to easily model and understand the task demands imposed on the individuals.\r\n\r\n\r\nFigure 1: Study task of shooting red balloons.\r\nParticipants played this task three times, each lasting approximately 10 minutes. As presented in Figure 2, demand increased and decreased within each task. This demand was set by incrementally increasing the number of targets from 3 to a maximum of 13 at the mid-point of each round, then reducing the number of targets back to 3. During Type 1, the participant had to shoot all red balls. To increase Mental Workload, Type 2 involved shooting only the balls with odd numbers on them regardless of the colour. Sample screen recordings of the task are available online1.\r\n\r\n\r\nFigure 2: Variation in demand during study tasks.\r\n3.2 Data collection protocol\r\n\r\nEleven students and staff from the University of Nottingham took part in the study (6 men and 5 women; mean age = 29 years; SD = 6.8; range = 19-42). Each participant was invited to read the information sheet and provide consent. They then played a training version of the stimulus task until they became familiar with the rules and the controls. After the training was finished, the physiological sensors were placed upon the participants. When ready, participants performed each condition with the corresponding stimulus task. Every 45 seconds during the tasks, the participant was asked to verbally rate their level of mental workload using the Instantaneous Self-Assessment (ISA) technique [22]. Participants were compensated with a £20 voucher as remuneration for their time. This protocol was approved by the Ethics Committee.\r\n\r\n3.2.1 fNIRS measurements. Measures of brain activity were recorded using an fNIRS300 device and the associated Cognitive Optical Brain Imaging (COBI) Studio hardware integrated software platform provided Biopac Systems Inc [4]. The headband shaped device is a sixteen-channel transducer for continuous Near-Infrared Spectroscopy (NIRS). The headband consists of four infrared (IR) emitters operating on a range between 700 to 900 nm, and ten IR detectors. See Figure 3 for how the headband is positioned. The acquisition rate of the device is 2 Hz.\r\n\r\n\r\nFigure 3: Sensor layout for the Biopac fNIRS used 2\r\n3.2.2 ISA scores: category labels. To capture subjective workload information, participants were surveyed during the tasks on a regular interval of 45 seconds using the 5-point ISA scale. The mean ISA score levels were then split within a number of classes in order to label the fNIRS data for: 2 classes (high and low), and 3 classes (high, medium and low). In order to translate this information from a 5-point score into a 2, respectively 3 levels of workload we had to split the data such that we keep a balanced number of labels in each class. Figure 4 illustrates how scores were split.\r\n\r\n\r\nFigure 4: 5-point ISA score split into a 2 (high and low), respectively 3 classes (high, medium and low) of workload.\r\n3.2.3 Data exclusions. Due to the limitations of the equipment (one headband does not fit all) some pieces of data are missing or is heavily corrupted with noise. Therefore, the data from two participants (p01 and p10) was excluded for certain analyses.\r\n\r\n4 PRE-PROCESSING PIPELINE\r\n\r\nIn the following two sections, we present a software pipeline developed to pre-process, process, analyse and classify mental workload from fNIRS data (code is made available online3). This section describes our pre-processing pipeline necessary for preparing the data for classification.\r\n\r\n\r\nFigure 5: fNIRS refined workload measure vs ISA subjective workload technique with correlation coefficient.\r\n1 - Modified Beer-Lambert Law (MBLL). Using a typical fNIRS sensor, an important pre-processing step is needed in order to transform raw data from the device into oxygenated (oxy-Hb) and deoxygenated (deoxy-Hb) haemoglobin levels using the Modified Beer-Lambert Law (MBLL) [46]. Thereafter, filtering algorithms remove high-frequency noise, and physiological artefacts such as heartbeats and other motion related artefacts. These steps are usually performed by the recording software that comes with the sensor, and the two resulting values are provided to use for real-time and offline monitoring and analysis.\r\n\r\n\r\nFigure 6: Correlation table of ISA subjective workload and fNIRS workload measure per channel and participant.\r\n2 - Correlation Based Signal Improvement (CBSI). Cui et al. addresses the challenge of improving the signal quality in fNIRS data and propose the CBSI Filter [13]. Designed for fNIRS in particular, this technique filters the signal from movement artefacts, even those induced by head motion. Carefully studying how such artefacts affect the fNIRS measurements of oxy-Hb and deoxy-Hb, the two which are typically strongly negatively correlated, were found to become more positively correlated in the presence of movement artefacts. Therefore, the proposed method for filtering fNIRS signal reduces noise based on the principle that the concentration changes in oxy-Hb and deoxy-Hb should be negatively correlated [13]. In practice, the filtering function takes as input the oxy-Hb and deoxy-Hb measurements and provides a resulting measure (that we simply call CBSI) that indicates changes in activity over the targeted region of the brain. This filter is useful for both real-time and offline use.\r\n\r\n3 - Resulting CBSI data. Based on the CBSI filtering technique, Figure 6 shows the strong link between the resulting fNIRS data and the workload experienced by participants, where stronger correlations were observed on different channels. We correlated each channel of the resulting CBSI filtered data with the Mean ISA scores of participants subjective workload reports. Further, we normalised the ISA scores and normalised and averaged the fNIRS data such that they are comparable, and Figure 5 shows the strong connection between the two.\r\n\r\n4 - Normalising the resulting data. Because fNIRS is a relative rather than absolute measure, it is typically used in a within-participants study design, therefore, ideally comparing different study conditions on a single-continuous recorded session. That means there are certain limitations when comes to using fNIRS to compare between participants, or when comes to multiple recordings lets say over multiple days.\r\n\r\nOne straight forward way to overcome this limitation is to normalise the fNIRS data, such that at any point the fNIRS measurements are relative to the previous measurements and states, and will always vary in the range of 0 and 1. This technique can be useful in both, offline and real time scenarios, and we have implemented a version using Python, available in the links provided with this paper.\r\n\r\n5 LEARNING APPROACHES AND RESULTS\r\n\r\nThree approaches to detect user workload levels are presented. An approach to classify workload levels using a logistic regression model, and two machine learning techniques are detailed, each being representative of the state of the art in their specific category - Support Vector Machines (SVM), for shallow classifiers, and Convolutional Neural Networks (CNN), which are a category of deep neural networks. Across our three approaches, we also consider two techniques based on: personalised and generalised learning. Personalised learning. These techniques build a model that is specific to one person. Their main advantage is that personalised models are usually better able to perform predictions on the person they were learned on. Their main drawback, however, is that they need to be trained for every new participant, requiring to gather enough data before being able to classify mental workload. Our analysis achieves this by learning on the two first tasks and tests are made on the remaining one, for each participant.\r\n\r\nGeneralised learning. Generalised learning refers to machine learning techniques used to build a model over a population. Its main advantage is to be able to generalise from multiple users in order to be usable for a new user without any new data to train on. Its main drawback is that unless given enough data, it tends to perform generally worse than a personalised model for a user. In our analysis, the training of generalised models was done by holding out data from one participant for testing and the remaining for learning. We repeated the process through to test the data from all the participants, this way performing k-fold cross validation.\r\n\r\n5.1 Approach 1: logistic regression\r\n\r\nThe first proposed method classifies mental workload levels based on a logistic regression for ordinal responses model that is trained with the labelled normalised CBSI filtered fNIRS data. Logistic regression is a type of classification algorithm used when the response variable is categorical. Logistic regression uses a maximum likelihood estimation to determine the regression coefficients of the linear model. The sigmoid function is used to output the probability of a predictor variable belonging to one of the classes, in our case one of the levels of subjective workload. This approach was chosen to demonstrate the classification results that can be obtained by using a simple approach.\r\n\r\n5.1.1 Data and feature selection. Both, the personalised and generalised logistic regression models use the same input features. They consisted of the mean CBSI values during each of the task blocks.\r\n\r\n5.1.2 Results. A personalised model was trained for each participant on the first two tasks and tested on the third. Table 1 shows the accuracy of the prediction made by the model on new data from the third task. In the same way, a generalised model was trained on the data from all participants except for one that it was tested on. This process was repeated for each participant and table 2 shows the resulting accuracy.\r\n\r\nTable 1: Personalised logistic regression using normalised fNIRS data: classification accuracy.\r\nParticipant    2 classes    3 classes\r\np02    69.23 %    61.53 %\r\np03    46.15 %    30.76 %\r\np04    84.61 %    46.15 %\r\np05    69.23 %    38.46 %\r\np06    76.92 %    61.53 %\r\np07    76.92 %    53.84 %\r\np08    92.30 %    46.15 %\r\np09    76.92 %    46.15 %\r\np11    84.61%    30.76 %\r\nAverage    75.21 %    46.15 %\r\nTable 2: Generalised logistic regression using normalised fNIRS data: classification accuracy. Training on 8 participants testing on 1.\r\nTest on    2 classes    3 classes\r\np02    69.23 %    53.85 %\r\np03    61.54 %    43.59 %\r\np04    71.79 %    56.41 %\r\np05    66.67 %    33.33 %\r\np06    74.36 %    51.28 %\r\np07    74.36 %    66.67 %\r\np08    71.79 %    58.97 %\r\np09    69.23 %    56.41 %\r\np11    53.85 %    38.46 %\r\nAverage    68.09 %    50.99 %\r\n5.2 Approach 2: support vector machines\r\n\r\nSupport Vector Machines [19] (SVMs) are maximal margin classifiers. They work by finding a hyperplane that can accurately separate the data while simultaneously maximising the distance of this hyperplane from each of the data points which are closest to it. SVMs then progressed with the introduction of the kernel trick [8], which consists in replacing the dot product part of the optimisation process by simple functions defined on pairs of input patterns.\r\n\r\nThey achieve a high generalisation power by introducing a slack variable in the optimisation process which allows the SVM to tolerate some misclassification if it results in a significantly smoother hyperplane. That trade-off is controlled by a regularisation parameter which can be manually tuned to each problem. In the context of our experiments, this parameter was fixed and not optimised.\r\n\r\n5.2.1 Data and feature selection. Both, the personalised and generalised SVMs use the following features:\r\n\r\nCBSI mean, by averaging the values for each set of four connected channels as per figure 3. This results in a vector of four means, where the first value corresponds to the mean of channels 1, 2, 3 and 4, the second value to channels 5, 6, 7 and 8, and so on. This correspond for the whole headset to 4 values per time sample.\r\nCBSI standard deviation, by taking the standard deviation calculated similarly to the previous feature, corresponding again to 4 values.\r\nCBSI gradient, computed as the slope of the linear regression on the 5 previous seconds of each CBSI mean, as describe above, which yet again corresponds to 4 values.\r\nThe mean is used to lessen noise that can be present in some channels and the standard deviation enables to still keep information about variability between the averaged channels. Those features enable to create a training set of size 2160x12, respectively 25920x12 for the personalised, respectively generalised learning and a testing set of size 1080x12, respectively 3240x12 for the personalised, respectively generalised learning. The labels used for classification are those described in figure 4. The learning dataset was shuffled before training each model.\r\n\r\n5.2.2 Results. Table 3 shows the SVM accuracy for two classes (high, low workload) and three classes (high, medium, low workload) using a linear kernel with personalised learning on each participant. The k-fold cross-validation average accuracy is 72.81 % for 2 classes and 48.56 % for 3 classes.\r\n\r\nTable 4 on the other hand shows the SVM accuracy for two classes and three classes using a linear kernel with generalised learning. The k-fold cross-validation average accuracy is here 71.27 % for 2 classes and 53.90 % for 3 classes.\r\n\r\nTable 3: Personalised SVM (linear kernel): classification accuracy. Training on 2 tasks testing on 1.\r\nParticipant    2 classes    3 classes\r\np02    58.70 %    46.57 %\r\np03    66.67 %    41.20 %\r\np04    81.94 %    47.50 %\r\np05    81.57 %    45.46 %\r\np06    66.02 %    45.65 %\r\np07    81.57 %    43.61 %\r\np08    72.04 %    55.65 %\r\np09    73.33 %    64.81 %\r\np11    73.43 %    46.57 %\r\nAverage    72.81 %    48.56 %\r\nTable 4: Generalised SVM (linear kernel): classification accuracy. Training on 8 participants testing on 1.\r\nTest on    2 classes    3 classes\r\np02    75.15 %    54.38 %\r\np03    51.57 %    29.07 %\r\np04    77.78 %    59.32 %\r\np05    66.60 %    44.57 %\r\np06    67.59 %    52.41 %\r\np07    76.36 %    63.73 %\r\np08    76.70 %    61.76 %\r\np09    68.18 %    59.26 %\r\np11    81.54 %    60.68 %\r\nAverage    71.27 %    53.90 %\r\n5.3 Approach 3: convolutional neural network\r\n\r\nNeural networks are a function approximator built from the succession of layers of computational units (neurons) where each unit is connected to every unit from the previous layer, and produces an output from the non-linear transformation to the weighted sum of the outputs of the units in the previous layer, weighted by the strength of their respective connection to the unit. This layering produces an incremental transformation of the data until a linear classifier (typically a logistic regression) is run on the output of the last layer, producing a prediction. A neural network is fully differentiable, and therefore the training process occurs by modifying the weights of the connections between units using the gradient of the error produced from the prediction with respect to the current weight of the connection. The process of computing the gradient of the error with respect to each weight, starting from the last layer and going backwards toward the first layer, is called backpropagation.\r\n\r\nConvolutional Neural Networks (CNNs) are deep neural networks containing one or more convolutional layers. Convolutional layers are layers with specific space-invariant property which makes them useful in analysing raw data such as sensor data and images.\r\n\r\nAs this type of neural network typically requires large amounts of data, we here describe only generalised learning, enabling to perform training on multiple participants.\r\n\r\n5.3.1 Data and feature selection. The CNN uses the following features:\r\n\r\nCBSI mean, by averaging the values for each set of four connected channels as per figure 3. This results in a vector of four means per time sample as described for the SVM approach.\r\nCBSI standard deviation, by taking the standard deviation calculated similarly to the previous feature, corresponding again to 4 values per time sample.\r\nComputing the CBSI mean and standard deviation enables us to filter through and remove data channels that are too noisy while keeping the same data matrix for every input (see Figure 6). Inputs of 10 sec (20 time points) of those features were used for the model with a 9 sec overlapping. No overlap was made between inputs from different classes. This creates training inputs of size 2x20x4 corresponding to [average and standard deviation] x [10sec of 2Hz data] x [spatial locations of averages and standard deviations]. This shape enables to perform convolutions more easily across time and space. In order to show the evolution of the performance with data increase we used respectively 4, 6 and 8 participants to train the model, corresponding to respectively 51844, 7776 and 10368 inputs. Testing was made on one participant corresponding to 1296 inputs. Again, the labels used for classification are those described in figure 4.\r\n\r\n5.3.2 CNN architecture. The model architecture is described in figure 7. The CNN is composed of two convolutions (one across time and channels, the other across time only), each followed by max-pooling down sampling. Those convolutions are then followed by a fully connected layer with a ReLU activation function, which is then fed into another smaller fully connected layer. The output of that final layer is passed through a Log-Softmax normalisation in order to produce a vector of class probabilities, which is used to compute the cross-entropy error and perform the training by backpropagation. The learning rate was set to 0.001 and the momentum to 0.8.\r\n\r\n\r\nFigure 7: CNN architecture for 2 and 3 classes classification.\r\n5.3.3 Results. In the same training configuration as the other approaches for generalised learning (train on 8 participants test on 1), the CNN performed quite well with a k-fold cross-validation average accuracy of 72.77 % for 2 classes and 49.53 % for 3 classes.\r\n\r\nIn Table 5 we present the results from the CNN with an increasing size of the training dataset. Even though it appears that an increasing the train set size may improve the model performance, no statistical test could highlight any correlation between the number of training samples and the accuracy with a confidence level of 5 %.\r\n\r\nTable 5: CNN k-fold cross-validation average accuracy with increasing number of data. Training on n-1 participants testing on 1 (with n number of participants in the dataset).\r\nNumber of    Accuracy    Accuracy\r\nDataset size    training data    2 classes    3 classes\r\n5 participants    5184    67.52 %    42.61 %\r\n7 participants    7776    71.76 %    42.68 %\r\n9 participants    10368    72.77 %    49.53 %\r\n5.4 Approach comparison\r\n\r\nThe models were compared using paired-sample Student t-tests and the thresholds for significance levels were set at 5 %.\r\n\r\n5.4.1 Models based on personalised learning. When it comes to the models based on personalised learning we could only compare between the logistic regression and the SVM approaches as CNN could only be trained using generalised learning. Table 6 shows how the logistic regression and the SVM performed quite similarly with respectively 75.21 % and 75.81 % of k-fold cross-validation average accuracy for 2 classes. Those accuracies were respectively 46.15 % and 48.56 % for 3 classes. No statistically significant differences were shown between those two approaches either for 2 or 3 classes.\r\n\r\n5.4.2 Models based on generalised learning. Models based on generalised learning allowed all of the investigated techniques to be compared. As shown in table 6 the best performances were achieved by the CNN and the SVM for 2 classes with k-fold cross-validation average accuracies of respectively 72.77 % and 71.27 %. Even though no significance is shown, it appears that the CNN outperforms the logistic regression (68.09 % accuracy) with a p-value of 0.0967. For 3 classes the highest accuracy is achieved by the SVM with 53.90 % which appears to be better than the CNN with a p-value of 0.0758.\r\n\r\nTable 6: k-fold cross-validation average accuracies for each approaches to classify mental workload levels based on generalised (training on 8 participants, testing on one) and personalised learning.\r\nClasses    Approach    Personalised    Generalised\r\nLogistic regression    75.21 %    68.09 %\r\n2 classes    SVM    72.81 %    71.27 %\r\nCNN    N/A    72.77 %\r\nLogistic regression    46.15 %    50.99 %\r\n3 classes    SVM    48.56 %    53.90 %\r\nCNN    N/A    49.53 %\r\n5.4.3 Personalised vs. generalised learning. Wilcoxon tests were performed to evaluate the difference between personalised and generalised learning for logistic regression and SVM. No statistical differences were found for 2 and 3 classes, which means that generalised models perform similarly to personalised ones.\r\n\r\n6 DISCUSSIONS AND PRACTICAL ADVICE\r\n\r\nWe begin our discussion by explaining feature selection and addressing the research questions, before addressing practical considerations for using these approaches for different situations.\r\n\r\n6.1 Data preparation and feature selection\r\n\r\nRQ1 aimed at finding how the data should be prepared and features selected for each approach. The first step of the pre-processing was to apply a CBSI filtering in order to remove head motion artefacts. However, some channels may be affected more severely by noise for various reasons. For example, the brain scanner did not fit every participant perfectly. Those noisy channels were removed by visual inspection and this is why we decided to use the mean signal between each 4 nearby channels, in order to have the same input size for every participant and task. The standard deviation of those same 4 nearby channels was also computed as it could reflect differences between those channels that can be a good insight on oxygenation differences across space. Those are the two features that we decided to feed to the CNN as those kind of models have the specificity to learn patterns by themselves. The SVM on the other hand is more dependant on features that can lead to split data into the different classes. We decided to introduce a third feature which was the slope of the linear regression on 5 sec worth of CBSI means. This feature is a good indicator of the evolution of brain oxygenation across time which can give insight on the mental workload. Indeed, an increase in mental workload will lead to a an increase of oxygenated blood which can be highlighted by an increase in the slope of the linear regression of CBSI means.\r\n\r\n6.2 Model specificities\r\n\r\nRQ2 was concerned the performance, here reflected by the accuracy, of our approaches at classifying correctly mental workload into different classes. Besides accuracy, several important factors have to be kept in mind about the convenience of each model in real-world use which links this second research question to RQ3 about differences between personalized and generalized models. From one perspective, an ideal candidate would be a model based on generalised learning, such that it could be trained on a large dataset, and then freely applied to new participants. This would mean that no training period would be needed for each new participant which is more convenient, and the results points toward the fact that those generalised approaches can be suitable for mental workload classification.\r\n\r\nBelow we discuss some of the practical advantages and disadvantages of each approach with further detail.\r\n\r\n6.2.1 Logistic regression. The model based on a logistic regression was a more simplistic approach to classifying workload levels. Table 6 shows how this approach proved to perform in a close range to the SVM for both personalised and generalised models. By order of simplicity and speed to train, however, the logistic regression model is the fastest of the three, making it a realistic candidate for situations where quick starting, without much training data, is desired.\r\n\r\n6.2.2 SVM. The SVM approach especially stands out on 3 classes classification with generalised learning as shown in table 6. The dataset is substantial but not too large which enables the SVM to be trained relatively quickly with a linear kernel, which makes it also usable for personalised learning. In comparison to a CNN model, SVM would work faster and with a smaller dataset. This model is also more reliable and the training is less affected by randomness than the CNN. One limiting factor of the SVM however is that it can less easily learn temporal patterns if specific features enabling to relate them are not used. We tried to reflect this temporal evolution by including the linear regression slope on the 5 previous seconds but this doesn\'t reflect more complex patterns that can be observed with physiological data.\r\n\r\n6.2.3 CNN. The CNN approach really stands out for 2 modalities classification with generalised learning as shown in table 6. A benefit of deep learning approaches like CNNs, is that they don\'t need a lot of specific features to develop their own understanding of the data. There is significant scope, however, developing the complexity of the CNN through the number of layers. So while CNNs continue to show promise for eventually better models, they require both complex development and large amounts of training data. The choice of this specific deep learning model was oriented by the fact that it could allow to make both spatial and temporal convolution to find features from those two modalities that are crucial for mental workload assessment with fNIRS data.\r\n\r\nThe main issue of this kind of deep learning approach is that it is data hungry and gets better over time as it learns from thousands of samples. Indeed, we are convinced that the CNN has a good potential for classifying mental workload from fNIRS but would benefit from larger datasets. In this study, we decided to use 10 sec input samples with a 9 sec overlap for two reasons. The first is that overlapping enables to have more data and the second is that it then makes the model predict mental workload every second, which would be useful for real-time classification. The training set size might also be the explanation for lower performance compared to other models with 3 classes. Indeed, in this configuration, the training is made on approximately a third of the training set for each class (because of the way labels were made) instead of a half for 2 classes. The fact that the dataset size is at the low end for CNN requirements could also explain that no significant improvement was found with the dataset size increase that we performed which was at maximum with 8 training participants. Further analysis with more participants would help justifying this assumption.\r\n\r\n6.3 Other choices\r\n\r\n6.3.1 ISA scores. Subjective techniques for assessing users’ mental workload are useful ways to capture the subjective experiences of participants experiencing various levels of work demands. In this experiment we used the real-time, continuous ISA technique to survey participants verbally, on a regular interval of 45 seconds, about their perceived mental workload changes during the tasks.\r\n\r\nWe collected this information in order to be able to correctly label participants fNIRS data with the corresponding low, medium or high workload state. As subjective measures such as ISA rely on the user\'s ability to self-judge and report the state throughout the task (which requires not only extra effort, but also skill and potential training), we averaged and used all participants’ ISA scores as labels for each participant fNIRS data. This was only possible as all participants experienced the exact same level of task demands.\r\n\r\n6.3.2 Normalising data. Normalising data was a stage of our pre-processing pipeline, but its less practical to do this in real-time. In real-time, normalisation can only occur by using max and min values within a sliding window, rather than retrospectively with the whole data sample.\r\n\r\n6.4 Future work\r\n\r\nThere is a significant amount of scope for developing the complexity and increasing the accuracy of machine learning classification approaches for fNIRS, which might warrant a significant amount of future research.\r\n\r\nOne, perhaps obvious, starting point would be to investigate further the potential accuracy that a CNN could reach with larger data samples. On the one hand, more work can be done to gather larger fNIRS datasets in order to take full advantage of deep learning models such as CNN. On the other hand, the model type as well as the model structure can be further investigated in order to be less data hungry and perform on-shot learning or few-shot learning.\r\n\r\nAnother consideration would be to investigate a universal background models approach, in which a long term generalised CNN is developed and used as a starting point to reduce the training time needed to produce a personalised model for each person. Similarly, a transfer learning approach could be explored, in which different archetype models are created to then be selected to best match each user.\r\n\r\nIt is also important to note that our investigation was based upon a primarily spatial task that invoked a certain kind of mental workload changes. Future research would benefit from investigating data that is created from different forms of cognitive activity, that might manifest in different ways in the prefrontal-cortex. Indeed, much research into the use of fNIRS considers full-scalp measurements that might benefit from observing concurrent changes in other regions of the brain.\r\n\r\nMore broadly, both shallow and deep learning models typically benefit from multiple data comparison points, and a large opportunity exists to build stronger models that augment fNIRS data with e.g. facial thermography or galvanic skin response data. Indeed, previous work by Ahn et al. [2] integrate fNIRS and EEG in their models to classify state of restfulness, and find that the multimodal input significantly improve their accuracy.\r\n\r\nFinally, in this paper we performed offline analysis which enabled to benefit from CBSI filtering as well as normalisation. Future work will aim at implementing and testing those models for real time analysis. This will require to perform pre-processing on a sliding window which duration will need to be investigated in order to still have good performance while making predictions often enough to be suitable for a real-time neuro-feedback.\r\n\r\n7 CONCLUSIONS\r\n\r\nWhile some sensor data solutions, such as step identification from gyroscope data, are now relatively mature, the classification of mental workload from brain data is still largely an unsolved problem. Examples of SVMs have been used in related work, but little work has evaluated the different machine learning approaches that will work best for the task, especially adapting the features used to fit the best specificities of each model. We considered three types of models, including a) a logistic regression, b) a Support Vector Machine (SVM), and c) a Convolutional Neural Network (CNN). While a CNN would typically be expected to work better with large numbers of training samples, we accounted for this factor by restricting its depth. We also considered personalised and generalised models within these three approaches, given that fNIRS produces a relative measure of blood oxygenation that is widely reported as being subject to individual differences. Generalised models are practically beneficial for removing the need to train personalised models for each user, and our results show that such approach can achieve good performance, especially when simply classifying between low and high workload. There is vast opportunity, however, for future research to investigate more advanced deep learning techniques that generate better and more accurate generalisable models.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis work was supported by the EPSRC [grant numbers EP/G037574/1, EP/N50970X/1, EP/M000877/1]. We would also like to thank Siyang Song, Dr. Enrique Sánchez-Lozano and Dr. Michel Valstar for their advice on the application of machine learning and more specifically deep learning for fNIRS data.\r\n\r\nData Access Statement: Consent was not gained from participants for this dataset to be made available to other researchers.\r\n\r\nREFERENCES\r\n\r\nDaniel Afergan, Evan M Peck, Erin T Solovey, Andrew Jenkins, Samuel W Hincks, Eli T Brown, Remco Chang, and Robert JK Jacob. 2014. Dynamic difficulty using brain metrics of workload. In Proc. SIGCHI. ACM, 3797–3806.  \r\nSangtae Ahn, Thien Nguyen, Hyojung Jang, Jae G Kim, and Sung C Jun. 2016. Exploring neuro-physiological correlates of drivers’ mental fatigue caused by sleep deprivation using simultaneous EEG, ECG, and fNIRS data. Frontiers in human neuroscience 10 (2016), 219.  \r\nAurélien Appriou, Andrzej Cichocki, and Fabien Lotte. 2018. Towards Robust Neuroadaptive HCI: Exploring Modern Machine Learning Methods to Estimate Mental Workload From EEG Signals. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, LBW615. \r\nHasan Ayaz and Banu Onaral. 2005. Analytical software and stimulus-presentation platform to utilize, visualize and analyze near-infrared spectroscopy measures. Drexel University.  \r\nJackson Beatty. 1982. Task-evoked pupillary responses, processing load, and the structure of processing resources.Psychological bulletin 91, 2 (1982), 276.  \r\nChris Berka, Daniel J Levendowski, Michelle N Lumicao, Alan Yau, Gene Davis, Vladimir T Zivkovic, Richard E Olmstead, Patrice D Tremoulet, and Patrick L Craven. 2007. EEG correlates of task engagement and mental workload in vigilance, learning, and memory tasks. Aviation, space, and environmental medicine 78, 5 (2007), B231–B244.  \r\nGeorge E Billman. 2011. Heart rate variability–a historical perspective. Frontiers in physiology 2 (2011).  \r\nBernhard E Boser, Isabelle M Guyon, and Vladimir N Vapnik. 1992. A training algorithm for optimal margin classifiers. In Proceedings of the fifth annual workshop on Computational learning theory. ACM, 144–152.  \r\nSD Brennan. 1992. An experimental report on rating scale descriptor sets for the instantaneous self assessment (ISA) recorder. Portsmouth: DRA Maritime Command and Control Division. DRA Technical Memorandum (CAD5) 92017(1992).  \r\nSiyuan Chen and Julien Epps. 2013. Automatic classification of eye activity for cognitive load measurement with emotion interference. Computer methods and programs in biomedicine 110, 2(2013), 111–124.  \r\nC Collet, E Salvia, and C Petit-Boulanger. 2014. Measuring workload with electrodermal activity during common braking actions. Ergonomics 57, 6 (2014), 886–896.  \r\nXu Cui, Signe Bray, Daniel M Bryant, Gary H Glover, and Allan L Reiss. 2011. A quantitative comparison of NIRS and fMRI across multiple cognitive tasks. Neuroimage 54, 4 (2011), 2808–2821.  \r\nXu Cui, Signe Bray, and Allan L Reiss. 2010. Functional near infrared spectroscopy (NIRS) signal improvement based on negative correlation between oxygenated and deoxygenated hemoglobin dynamics. Neuroimage 49, 4 (2010), 3039–3046.  \r\nLex Fridman, Bryan Reimer, Bruce Mehler, and William T. Freeman. 2018. Cognitive Load Estimation in the Wild. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 652, 9 pages. https://doi.org/10.1145/3173574.3174226  \r\nAudrey Girouard, Erin Treacy Solovey, Leanne M Hirshfield, Evan M Peck, Krysta Chauncey, Angelo Sassaroli, Sergio Fantini, and Robert JK Jacob. 2010. From brain signals to adaptive interfaces: using fNIRS in HCI. In Brain-Computer Interfaces. Springer, 221–237.  \r\nAudrey Girouard, Erin Treacy Solovey, and Robert JK Jacob. 2013. Designing a passive brain computer interface using real time classification of functional near-infrared spectroscopy. International Journal of Autonomous and Adaptive Communications Systems 6, 1(2013), 26–44.  \r\nEija Haapalainen, SeungJun Kim, Jodi F Forlizzi, and Anind K Dey. 2010. Psycho-physiological measures for assessing cognitive load. In Proceedings of the 12th ACM international conference on Ubiquitous computing. ACM, 301–310.  \r\nSandra G Hart and Lowell E Staveland. 1988. Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research. Human mental workload(1988).  \r\nMarti A. Hearst, Susan T Dumais, Edgar Osuna, John Platt, and Bernhard Scholkopf. 1998. Support vector machines. IEEE Intelligent Systems and their applications 13, 4(1998), 18–28.  \r\nYoko Hoshi, Brian H Tsou, Vincent A Billock, Masato Tanosaki, Yoshinobu Iguchi, Miho Shimada, Toshikazu Shinba, Yoshifumi Yamada, and Ichiro Oda. 2003. Spatiotemporal characteristics of hemodynamic changes in the human lateral prefrontal cortex during working memory tasks. Neuroimage 20, 3 (2003), 1493–1504.  \r\nShamsi T Iqbal, Xianjun Sam Zheng, and Brian P Bailey. 2004. Task-evoked pupillary response to mental workload in human-computer interaction. In CHI’04 extended abstracts on Human factors in computing systems. ACM, 1477–1480.  \r\nJordan and Brennen. 1992. Instantaneous self-assessment of workload technique (ISA). Retrieved from http://www.skybrary.aero/bookshelf/books/1963.pdf. (1992).  \r\nCS Jordan. 1992. Experimental study of the effects of an instantaneous self assessment workload recorder on task performance. Report No. DRA/TM (CAD5)/92011. Farnborough: Defence Evaluation & Research Agency (1992).  \r\nKristiyan Lukanov, Horia A Maior, and Max L Wilson. 2016. Using fNIRS in usability testing: understanding the effect of web form layout on mental workload. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 4011–4016.  \r\nHoria A Maior, Matthew Pike, Sarah Sharples, and Max L Wilson. 2015. Examining the reliability of using fNIRS in realistic hci settings for spatial and verbal tasks. In Proceedings of CHI, Vol. 15. 3807–3816.  \r\nHoria A Maior, Matthew Pike, Max L Wilson, and Sarah Sharples. 2014. Continuous detection of workload overload: an FNIRS approach. In Contemporary Ergonomics and Human Factors 2014: Proceedings of the international conference on Ergonomics & Human Factors 2014, Southampton, UK, 7-10 April 2014. CRC Press, 450.  \r\nHoria A Maior, Max L Wilson, and Sarah Sharples. 2018. Workload Alerts - Using Physiological Measures of Mental Workload to Provide Feedback During Tasks. ACM Transactions on Computer-Human Interaction (TOCHI) 25, 2(2018), 9.  \r\nAdrian Cornelius Marinescu. 2018. Facial thermography for assessment of workload in safety critical environments. Ph.D. Dissertation. University of Nottingham.  \r\nAdrian Cornelius Marinescu, Sarah Sharples, Alastair Campbell Ritchie, Tomas Sánchez López, Michael McDowell, and Hervé P Morvan. 2017. Physiological parameter response to variation of mental workload. Human factors (2017), 0018720817733101.  \r\nSandra P Marshall. 2007. Identifying cognitive state from eye metrics. Aviation, space, and environmental medicine 78, 5 (2007), B165–B175.  \r\nPeter Nickel and Friedhelm Nachreiner. 2003. Sensitivity and diagnosticity of the 0.1-Hz component of heart rate variability as an indicator of mental workload. Human Factors: The Journal of the Human Factors and Ergonomics Society 45, 4(2003), 575–590.  \r\nRyota Nishiyori. 2016. fNIRS: An emergent method to document functional cortical activity during infant movements. Frontiers in psychology 7 (2016), 533.  \r\nFred Paas, Alexander Renkl, and John Sweller. 2003. Cognitive load theory and instructional design: Recent developments. Educational psychologist 38, 1 (2003), 1–4.  \r\nMatthew Pike, Max L Wilson, Steve Benford, and Richard Ramchurn. 2016. # Scanners: A BCI Enhanced Cinematic Experience. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. ACM, 293–296.  \r\nMatthew F Pike, Horia A Maior, Martin Porcheron, Sarah C Sharples, and Max L Wilson. 2014. Measuring the effect of think aloud protocols on workload using fNIRS. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems. ACM, 3807–3816.  \r\nRichard Ramchurn, Max L Wilson, Sarah Martindale, and Steve Benford. 2018. # Scanners 2-The MOMENT: A New Brain-Controlled Movie. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, D210.  \r\nAngelo Sassaroli, Feng Zheng, Leanne M Hirshfield, Audrey Girouard, Erin Treacy Solovey, Robert JK Jacob, and Sergio Fantini. 2008. Discrimination of mental workload levels in human subjects with functional near-infrared spectroscopy. Journal of Innovative Optical Health Sciences 1, 02 (2008), 227–237.  \r\nSarah Sharples and Ted Megaw. 2015. Definition and Mesurement of Human Workload. In Evaluation of human work, John R Wilson and Sarah Sharples (Eds.). CRC Press.  \r\nYu Shi, Natalie Ruiz, Ronnie Taib, Eric Choi, and Fang Chen. 2007. Galvanic skin response (GSR) as an index of cognitive load. In CHI’07 extended abstracts on Human factors in computing systems. ACM, 2651–2656.  \r\nYoshihiro Shimomura, Takumi Yoda, Koji Sugiura, Akinori Horiguchi, Koichi Iwanaga, and Tetsuo Katsuura. 2008. Use of frequency domain analysis of skin conductance for evaluation of mental workload. Journal of physiological anthropology 27, 4 (2008), 173–177.  \r\nErin Solovey, Paul Schermerhorn, Matthias Scheutz, Angelo Sassaroli, Sergio Fantini, and Robert Jacob. 2012. Brainput: enhancing interactive systems with streaming fNIRs brain input. In CHI. ACM, 2193–2202. \r\nErin Treacy Solovey, Audrey Girouard, Krysta Chauncey, Leanne M Hirshfield, Angelo Sassaroli, Feng Zheng, Sergio Fantini, and Robert JK Jacob. 2009. Using fNIRS brain sensing in realistic HCI settings: experiments and guidelines. In Proc. UIST. ACM, 157–166.  \r\nErin T Solovey, Marin Zec, Enrique Abdon Garcia Perez, Bryan Reimer, and Bruce Mehler. 2014. Classifying driver workload using physiological and driving performance data: two field studies. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 4057–4066.  \r\nKazushi Taoda, Masanori Kawamura, Kinzou Wakara, Yasuma Fukuchi, and Katsuo Nishiyama. 2001. Heart rate variability during long truck driving work. Journal of human ergology 30, 1-2 (2001), 235–240. \r\nAndrew J Tattersall and Penelope S Foord. 1996. An experimental evaluation of instantaneous self-assessment as a measure of workload. Ergonomics 39, 5 (1996), 740–748.  \r\nArno Villringer and Britton Chance. 1997. Non-invasive optical spectroscopy and imaging of human brain function. Trends in neurosciences 20, 10 (1997), 435–442.  \r\nChristopher D Wickens. 2008. Multiple resources and mental workload. The Journal of the Human Factors and Ergonomics Society 50, 3(2008), 449–455.  \r\nBeste F Yuksel, Kurt B Oleson, Lane Harrison, Evan M Peck, Daniel Afergan, Remco Chang, and Robert JK Jacob. 2016. Learn piano with BACh: An adaptive learning interface that adjusts task difficulty based on brain state. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 5372–5384.  \r\nYilu Zhang, Yuri Owechko, and Jing Zhang. 2004. Driver cognitive workload estimation: A data-driven perspective. In Intelligent Transportation Systems. Citeseer, 642–647.  \r\nFOOTNOTE\r\n\r\n⁎University of Nottingham, School of Computer Science, Nottingham, UK,\r\n\r\n1T1 sample: https://goo.gl/uiimKg ; T2 sample: https://goo.gl/2FVxA2\r\n\r\n2Image by Hyosun Kwon\r\n\r\n3 https://gitlab.com/HanBnrd/fnirs-learning',1,'Benerradi','Johann Benerradi, Horia A. Maior, Adrian Marinescu, Jérémie Clos, and Max L. Wilson','Johann Benerradi *(IDMC, University of Lorraine, France)*<br>\r\nHoria A. Maior *(Mixed Reality Lab, University of Nottingham, UK)*<br>\r\nAdrian Marinescu *(Faculty of Engineering, University of Nottingham, UK)*<br>\r\nJérémie Clos *(School of Computer Science, University of Nottingham, UK)*<br>\r\nMax L. Wilson *(Mixed Reality Lab, University of Nottingham, UK)*',NULL,0,'10.1145/3363384.3363392','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,8),(59,'lawo-towards-a-network-of-practices-identifying-central-elements-to-inform-design','2019-09-03 08:29:56','2019-11-19 12:42:43','2019-09-03 08:29:56',NULL,1,'published','[]','Towards a Network of Practices: Identifying Central Elements to Inform Design','For over a decade researchers from the HCI community are taking social practices as a unit of design. While the first generation focused on social practice in isolation, more recent work argues for the interrelatedness of mutually influencing practices as the primary unit of analysis. We discuss these current approaches to motivate the notion of a network of practices. We argue that network theory presents a promising method to create more detailed and sophisticated models of social practices, that raise awareness about central elements and their connecting characteristics. Further on, our work identifies open questions that should be addressed in future work, to increase the benefits of the method.','Dennis Lawo, Philip Engelbutzeder, Margarita Esau, and Gunnar Stevens. 2019. Towards a Network of Practices: Identifying Central Elements to Inform Design. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 4 pages. [https://doi.org/10.1145/3363384.3363470](https://doi.org/10.1145/3363384.3363470 \"DOI for the article \'Towards a Network of Practices: Identifying Central Elements to Inform Design\'\")','1 INTRODUCTION\r\n\r\nBeginning with the third wave of HCI and its turn from workplaces towards everyday life and culture [2] evermore elements of social practice theory find application within HCI research [10]. With this theme, the interest in consumption and the design of technologies to solve sustainability and health problems has grown steadily [1].\r\n\r\nIn recent years the scope of HCI applications has increasingly come to use a practice theoretical lens to better understand the linkage of different consumption practices and derive design relevant knowledge from this understanding [13]. Early theories of practice [14, 16, 17] emphasized that the smallest units of analysis are not the individual subjects, objects or social structures, but social practices. A practice presents a “routinized pattern of human action which is not only encompassed by mental and physical forms of activity but that is also greatly imprinted by objects, especially by tools, media, and their usage” [22, p.2]. One major downside of current approaches is, that they do not address the relationship of the different practices based on their constituting nexuses. In particular, studies of consumer practices [4, 20, 21] have shown that the focus on single practices is too narrow, since the complexity originates from the fact that everyday practices are entangled.\r\n\r\nThe research of social practices as networks contributes to future practice theoretical research in general, by providing new means to identify central elements and their dynamic relationships, that otherwise would remain unexplored. Triggering such elements could help to abandon existing practices to then do things completely different [9]. This is especially true with regard to our example of food consumption practices and the question of how to change them: “Designing interventions requires a consideration of the complex nexus of interconnected practices (dispersed and integrated) that define food practices” [4, p.21].\r\n\r\n2 MODELLING THE INTERCONNECTEDNESS OF PRACTICES\r\n\r\nTo understand and structure the complex entanglements of practices, several constitutional concepts have been suggested (see Figure 1): Some authors follow a kind of follow-the-actor [11] approach, where the actor is not the human consumer, but the non-human, consumed good [12, 18]. Tracing the various steps in the consumption of a good has led to linear [18] and cyclic [12] models respectively. Besides those approaches, Warde[20] and Ganglbauer et al.[4] use the notion of dispersed and integrative practices, which suggest a hierarchical, tree-like structure of top- and sub-practices.\r\n\r\n\r\nFigure 1: Structuring the Linkage of Consumption Practices: a) Linear Sequence of Practices with Branches [18]; b) Practices structured by the Consumption Lifecycle [12]; c) Shared Element of two Practices [17]; d) Network of Practices [7].\r\nTo better capture the complexity of consumer practices and to generate more “natural models”, more recent work [7] argues for a network of practice(s). Here, the questions arise, how nodes are defined and how edges are constituted and are conceptualized as fixed, weighted, hierarchical ordered, and, especially, how the semantics of these structures are defined with regard to practice theoretical concepts (e.g. [19]).\r\n\r\n2.1 Linear and Cyclic Structure\r\n\r\nResearching consumer food handling behavior, with a focus on storage and disposal practices, Terpestra et al. use a linear model that “shows [...] the route followed by food after its purchase by the customer”[18, p.2]. They do not provide any empirical or literature-based source for their model, but it seems to be founded by personal experience of a typical process, that follows the actor “food” (see Figure 1a). Such an approach proves to be beneficial to identify critical moments within food practices [18], but it excludes different perspectives on practices, by focusing solely on processes of handling food. While their approach draws upon the relationship of practices as chronologically organized, they do not account for the key elements of a practice.\r\n\r\nStill following a process-based approach, the food consumption lifecycle by Ng et al.[12], already accounts for different entry points and the repetitive nature of consuming food (see Figure 1b). An advantage of their view is to include motivational factors, as well as tools being utilized within the different practices. But due to the “following the actor” approach conducted by equipping the participants with sense cams [12], their model implicitly relies on a weak-linear order based on the chronological order of practices. In addition, the model suggests that planning is the underlying central practice governing all food consumption practices: from procurement to disposal. This implies an individual agency making rational decisions and thereby neglects a fundamental notion of social practice theory, namely that an individual merely acts as the carrier of a practice (see [14, 16]). Such a view is insufficient because it does not take into account, for instance, the explanation of food waste as a typically unintended behavior that is not planned in advance. Moreover, it falls short with regard to the performance of practices in two dimensions. On the one hand, practices like shopping, cooking, etc. are not performed in isolation, but are influenced by other practices like nursing children, driving to work/home, etc. On the other hand, certain practices are making use of other practices, like reading (recipe) books, showing a YouTube tutorial, etc.\r\n\r\nBriefly spoken, a “follow the actor” methodology results in linear [18] and cyclic [12] models respectively. While such approaches are helpful for a rough orientation, the view is implying linear decision making as well as it neglects other practices (contiguous or dispersed practices) that are also influencing consumption. Therefore, the method is too simplistic and does not meet the standards of common practice theory.\r\n\r\n2.2 Dispersed & Integrative Practices\r\n\r\nIn the highly influential work of Theodor Schatzki on social practice theory, we can find the first distinction between dispersed and integrative practices. For Schatzki integrative practices are “the more complex practices found in and constitutive of particular domains of social life”[16, p.98], while dispersed practices are rather tacit practices that appear in many realms of social life and solely require understanding resp. some form of know-how. Dispersed practices are actions such as “describing, ordering, following rules, explaining, questioning, reporting, examining, and imagining”[16, p.91], which are usually themselves elements of different integrative practices [15]. Ganglbauer et al.[4], as well as Warde [20] use the notion of dispersed and integrated practices to structure food consumption. According to Ganglbauer et al. integrative practices in the food domain are, e.g. “cooking practices and eating practices, where the embodied actions of the cook or the diner are often habitual, informed by histories and cultures of performance, but also adapted to an unfolding social and environmental context”[4, p.5]. For Warde[20] consumption cannot be considered an integrative practice itself but rather a dispersed practice that is required and entailed in most integrative practices. Within this scheme, Ganglbauer et. al.[4] argue that food disposal, as non-consumption, is a dispersed practice as well. It is not by chance that Ganglbauer et al. [4] do not apply a follow-the-good-as-an-actor methodology, but use open-ended interviews in order to make use of people\'s competences to express relations among practices and integrate their experiences.\r\n\r\nBriefly spoken, the notion of dispersed and integrative practices helps to identify the relationships of consumption, non-consumption and the several chronological integrative practices (such as shopping, storing or cooking). Still, it remains unclear which elements, constituting the practices are central to food consumption.\r\n\r\n3 TOWARDS A NETWORK OF CONSUMPTION PRACTICES\r\n\r\nThe logical next step in theory development is to move from linear and hierarchical models to network-like structures, which raises the question of how elements (or more formally: nodes) and links (or more formally: edges) are defined.\r\n\r\n3.1 Linking Practices by their shared Elements\r\n\r\nShove et al.[17] draw upon a model of social practices, that contains three key elements, (1) materials, (2) meanings and (3) competences. Their model mainly focuses on the triangle of these key elements, constituting the practices in the form of a proto-practice, practice, and ex-practice, depending on the status of the links. If a link between certain elements has not been made yet, we talk about a proto-practice, while yet existing links constitute a practice, and links that have existed in the past are described as ex-practices [15]. Shove et al.[17] also started to explore elements that are shared by different practices (Figure 1c). For instance, both practices, driving and repairing, share the “meaning” element of masculinity. Such sharing, however, is not static, but evolving when practices are changing. As a result, the network of practices is dynamic, in which the sharing and linking of practice elements evolve over time [17].\r\n\r\n\r\nFigure 2: Adapted Practice Model by Kuijer [8].\r\nKuijer[8] slightly adapts the Shove et al.[17] triangle model, to distinguish between practice-as-entity and practice-as-performance. Thereby a practice-as-entity is visualized by the different varieties of performances (see Figure 2). The practice-as-performance is then only constituted by a subset of elements and the links connecting them. Further on, Kuijer[8] draws upon the importance of certain links, by visualizing them with more strength. Strength reflects the importance of a link, whereby it is stronger when the connection is observable within more performances. Similarly, the size of the bubble represents the importance of a certain element [8].\r\n\r\n\r\nFigure 3: Understanding Laundry as a Network of Practice [7].\r\nBased on Shove\'s triangle model, Higginson et al.[7] develop a network representation for social practices (see Figure 1d & Figure 3). Within the network of laundry practices, for instance, the meaning of environmental awareness might be tied to the competence of handwashing rather than to other competences, such as machine settings. Thus, the type of the element, either material, meaning or competence is given by its color instead of its position, as in [8]. To increase the information gain of the visualization, Higginson et al.[7] draw the size of the nodes, based on the node\'s degree, which is an important measure within network theory [3].\r\n\r\n3.2 Zoom-out\r\n\r\nShove et al.[17], as well as Higginson et al.[7] suggest to zoom-out to study the connections among practices on a different scale. Higginson et al.[6] attempt to zoom-out, but leave the ground of theoretical considerations, by first abandoning the connection of equally essential elements (see Shove et al.[17]) and second shifting the burden of interpreting these connections towards their participants. However, a more exact elaboration, both, regarding the theoretical foundation and visual presentation, is missing so far. We expect that such “zooming out” techniques are quite helpful to identify central elements of consumption practices as well as their (shared) relationship to other elements. Such knowledge helps to uncover elements with a high centrality within the nexus, in order to design interventions in such a way that the whole network of practices can be reached and influenced. Drawing on the notion of ex-practices, proto-practices, and practices by Shove et al.[17], zooming-out in combination with historical and long-term data helps to evaluate stability and changes within practices at a different scale if an intervention is (about to be) introduced. In particular, one might identify sweet spots for intervention, where a smaller change in the local context of a practice has a strong effect on other practices over time, due to the linkage between them.\r\n\r\nBut, since such “zooming out” has not been conducted so far, two main questions for future research emerge:\r\n\r\nFrom a methodological stance, the question arises how to populate and then analyze a network of practices at a different scale. Higginson et al.[6, 7] work of linking practices by its constitutive elements give some orientation on how to generate the network. While their work provides first insights in the methods used to gather the empirical data, the visualization and analysis of the network is yet not researched in detail.\r\nFrom a design stance, the question arises how the knowledge of a network of practices helps to inform and inspire design interventions and design evaluations. Especially interesting for the HCI community are questions around the emergence, development, and disappearance of technological devices, as well as their relationship to meanings and competences within social practices ordered across space and time [4, 5].\r\n4 CONCLUSION\r\n\r\nMotivated by a more complex understanding of consumption practices and their relationship, our work discusses current approaches within HCI and social science to structure and model social practices, their advantages, downsides and underlying empirical approaches. Further on we want to discuss how network theoretical approaches and data science methodologies might support research as well as design attempts. Thereby we want to discuss arising questions from two angles. First, from a methodological perspective: How networks of practices can be empirically captured, designed and analyzed. Second from a design perspective: How networks of practices can inform design decisions by still taking people\'s everyday performances into account.\r\n\r\nIn future work, we aim to address these questions by populating a network of food consumption practices and discuss it with experts to understand how they derive relevant knowledge from such an approach. Further on, we want to find out how we can apply such a method in a reliable way that allows for more insights. We hope to inspire researchers utilizing social practice theory to, on the one hand, use network theory within their projects and, on the other hand, work on methods that are more suitable to social practice theory in general.\r\n\r\nREFERENCES\r\n\r\nFerran Altarriba Bertran, Samvid Jhaveri, Rosa Lutz, Katherine Isbister, and Danielle Wilde. 2018. Visualising the landscape of human-food interaction research. In Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems. ACM, 243–248.  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 1–8.  \r\nCarter T Butts. 2008. Social network analysis: A methodological introduction. Asian Journal of Social Psychology 11, 1 (2008), 13–41.  \r\nEva Ganglbauer, Geraldine Fitzpatrick, and Rob Comber. 2013. Negotiating food waste: Using a practice lens to inform design. ACM Transactions on Computer-Human Interaction (TOCHI) 20, 2(2013), 11.  \r\nAnthony Giddens. 1984. The Constitution of Society (Cambridge, Polity). (1984).  \r\nSarah Higginson, Tom Hargreaves, Eoghan McKenna, Jason Chilvers, Murray Thomson, and Sarah Higginson. 2016. Diagramming Commuting Practices: The connections within and between practices and their relevance for the shifting of energy demand in time. (2016), 19.  \r\nSarah Higginson, Eoghan McKenna, Tom Hargreaves, Jason Chilvers, and Murray Thomson. 2015. Diagramming social practice theory: An interdisciplinary experiment exploring practices as networks. Indoor and Built Environment 24, 7 (2015), 950–969.  \r\nLenneke Kuijer. 2014. Implications of social practice theory for sustainable design. Ph.D. Dissertation. TU Delft.  \r\nLenneke Kuijer, Annelise de Jong, and Daan van Eijk. 2013. Practices as a unit of design: An exploration of theoretical guidelines in a study on bathing. ACM Transactions on Computer-Human Interaction (TOCHI) 20, 4(2013), 21.  \r\nKari Kuutti and Liam J Bannon. 2014. The turn to practice in HCI: towards a research agenda. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 3543–3552.  \r\nBruno Latour. 2005. Reassembling the social: an introduction to actor-network-theory. Oxford University Press, Oxford ; New York. OCLC: ocm58054359.  \r\nKher Hui Ng, Victoria Shipp, Richard Mortier, Steve Benford, Martin Flintham, and Tom Rodden. 2015. Understanding food consumption lifecycles using wearable cameras. Personal and Ubiquitous Computing 19, 7 (Oct. 2015), 1183–1195. https://doi.org/10.1007/s00779-015-0871-y  \r\nSebastian Prost, Clara Crivellaro, Andy Haddon, and Rob Comber. 2018. Food democracy in the making: Designing with local food networks. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 333.  \r\nAndreas Reckwitz. 2003. Grundelemente einer Theorie sozialer Praktiken/Basic Elements of a Theory of Social Practices. Zeitschrift für Soziologie 32, 4 (2003), 282–301.  \r\nTheodore R Schatzki. 2002. The site of the social: A philosophical account of the constitution of social life and change. Penn State Press.  \r\nTheodore R Schatzki and Theodore R Schatzki. 1996. Social practices: A Wittgensteinian approach to human activity and the social. Cambridge University Press.  \r\nElizabeth Shove, Mika Pantzar, and Matt Watson. 2012. The dynamics of social practice: Everyday life and how it changes. Sage.  \r\nMJ Terpstra, LPA Steenbekkers, NCM De Maertelaere, and S Nijhuis. 2005. Food storage and disposal: consumer practices and knowledge. British Food Journal 107, 7 (2005), 526–533.  \r\nKaisa Torkkeli, Johanna Mäkelä, and Mari Niva. 2018. Elements of practice in the analysis of auto-ethnographical cooking videos. Journal of Consumer Culture(2018), 1469540518764248.  \r\nAlan Warde. 2005. Consumption and theories of practice. Journal of consumer culture 5, 2 (2005), 131–153.  \r\nAlan Warde. 2016. The practice of eating. John Wiley & Sons.  \r\nVolker Wulf, Markus Rohde, Volkmar Pipek, and Gunnar Stevens. 2011. Engaging with practices: design case studies as a research framework in CSCW. In Proceedings of the ACM 2011 conference on Computer supported cooperative work. ACM, 505–512. ',1,'Lawo','Dennis Lawo, Philip Engelbutzeder, Margarita Esau, and Gunnar Stevens','Dennis Lawo *(University Siegen, Germany)*<br>\r\nPhilip Engelbutzeder *(University Siegen, Germany)*<br>\r\nMargarita Esau *(University Siegen, Germany)*<br>\r\nGunnar Stevens *(University Siegen, Germany)*',NULL,0,'10.1145/3363384.3363470','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Foyer',NULL,1,26),(60,'lyle-public-outcomes-of-publicly-funded-socio-technical-projects-reflections-on-empowerment-participation-and-researcher-respons','2019-09-03 08:29:56','2019-11-19 12:39:38','2019-09-03 08:29:56',NULL,1,'published','[]','Public Outcomes of Publicly Funded Socio-Technical Projects: Reflections on Empowerment, Participation, and Researcher Responsibility','In this short essay, we present our reflections on public outcomes of publicly funded socio-technical projects in relevance to discussions on empowerment, participation, and researcher responsibility in the field of Human Computer Interaction (HCI). Our work offers a reflective analysis and raises critical questions for further communal discussion about the life of research projects when the funding ends. When a publicly funded research project for empowering users comes to an end, how do we as HCI researchers measure the social impact of our interventions? What are the public outcomes and what are our responsibilities after we leave the field? To address these questions, first, we introduce two publicly funded socio-technical projects, situate our work with respect to current discourse on empowering users in HCI, present findings and insights based on our analysis of the projects, and conclude with a set of questions that are intended to further communal discussion.','Peter Lyle and Gopinaath Kannabiran. 2019. Public Outcomes of Publicly Funded Socio-Technical Projects: Reflections on Empowerment, Participation, and Researcher Responsibility. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 3 pages. [https://doi.org/10.1145/3363384.3363480](https://doi.org/10.1145/3363384.3363480 \"DOI for the article \'Public Outcomes of Publicly Funded Socio-Technical Projects: Reflections on Empowerment, Participation, and Researcher Responsibility\'\")','1 INTRODUCTION\r\n\r\nWe present our thoughts and contribute to the discourse on the level of publicly visible outcomes (such as documents or ICT systems) of publicly funded socio-technical research projects, with regard to what it means to those a project intends to serve. We do this, referring to work on empowerment within HCI, looking at a specific case of a European funded Participatory Design project called PIE News/Commonfare (hereafter Commonfare), in which Peter (author) was involved as a postdoc design researcher. As both authors here and now, however, the perspective of empowerment is of particular interest as part of our involvement in a different European funded project – Common Interactive Objects (hereafter CIO).\r\n\r\nLife does not begin nor end with project funding and in the case of the Commonfare project, which focuses on precariousness and how it is experienced by people in Europe, these struggles neither begin nor end with the public outcomes of the project (including devlierables, and an online platform at commonfare.net). We use Commonfare as a case study of a project at the end of research funding and the currently ongoing CIO project guides our concerns on empowerment. Both, Commonfare and CIO, are publicly funded socio-technical projects that aim to empower a group of users.\r\n\r\n2 EMPOWERMENT\r\n\r\nTracing back to Scandinavian Participatory Design discourse, empowerment has been and continues to remain a central concern for HCI researchers. Empowering users is a common and important motive for both Commonfare1 and CIO2 projects. With the widespread adoption of ubiquitous computing [9] and technology permeating into all aspects of human life [2], addressing power relations becomes urgent, important, and inevitable. Feminist works in HCI, e.g. [1, 12] alongside other efforts such as Action Research [5] and Designing for Social Justice [3] are a few examples of ongoing efforts that engage with questions concerning empowerment in HCI.\r\n\r\nDrawing upon Foucault\'s notion of power, Kannabiran & Petersen [7] highlight that “the designed system is not a passive sandbox which just permits or restricts something but is rather an active site that enables the various stakeholders to negotiate power and have a conversation” and “is the very site of contestation with inbuilt political stances, beliefs, and prejudices upon which power is constantly performed, contested and negotiated” [7]. A recent literature survey on empowerment in HCI, Schneider and colleagues [10] present a framework that seeks to understand several aspects of empowerment, although the one that interests us most is that of ‘power-over’ and ‘power-to’ relationships. Our intent, and reason for thinking about who is involved and what the output of a project is in terms, relates to these concepts of empowerment.\r\n\r\nThe CIO project is concerned with extending “human control over the technological environment by human beings, both individually and together” with an aim to “empower users to better understand and develop the technologies they use”2. In the context of CIO project, empowerment is framed as offering “new ways for people to construct and configure human physical and virtual environments, together, over time and within communities”2. Therefore, empowerment in the context of this work is concerned with what happens in the research field and lives of participants both during and after research project funding.\r\n\r\n3 COMMONFARE\r\n\r\nCommonfare1 was funded from mid-2016 to mid-2019, and sought to respond to approximately 25% of people living in Europe who are at risk of poverty of material deprivation, often relating to limited employment opportunities, and reducing state welfare provisions. The response took the form of a participatory design process that has involved different demographics and local communities in three pilot countries (Croatia, Italy and the Netherlands), and the development of a web-based platform commonfare.net. We understand participation in this project as including a number of different types of actors: the funding body, the project consortium members (including initially 8, but now 7 organisations: a mix of research, technical and pilot partners), and communities who are the focus of the research.\r\n\r\nThe project and its outcomes are in many ways public, for instance: it is publicly funded; the technology outcome commonfare.net is publicly visible; the software development effort is open source3; much effort has been put into communicating achievements of the project, and related efforts by others to address precariousness in Europe via social media; and project reports and deliverables have been published on the project website. The research outputs of commonfare have strived to be published in a mix of green or gold open access.\r\n\r\nBeyond actually writing about that which the project has done and its methods, Sciannamblo et al. [11] have sought to make public information about the process that led to the project, including a personal account and rationale of assembling the consortium of partners and the construction of the project proposal by Maurizio, a co-author of that paper and coordinator of the project. Other efforts have sought to demystify the internal organisation of the way in which the project has unfolded framed in terms of infrastructuring and organisational configurations between consortium, funding agency and research participation [8].\r\n\r\nWhile the outputs publicly available now speak to work done by different consortium partners during the course of the funded portion of the project, what happens after the funding is finished? What benefit is there to people to interact with or learn from what has happened? A partner organisation was tasked with reporting on the sustainability options for the project beyond the funding term [4], which has now taken the form of the Commonfare Association4. The goals of this Commonfare Association including maintaining both the values of Commonfare and the continuity of commonfare.net, and the relationships that have been forged between different partners and communities. We now try and connect the current and future of Commonfare in terms of Empowerment, to start to unpack what the social intervention has and will mean for those it seeks to empower.\r\n\r\n4 COMMONFARE AND EMPOWERMENT\r\n\r\nHere we present initial thoughts regarding the four aspects of Schneider et al.’s [10] framework on empowerment in HCI, and while we will briefly consider all of these, we will focus more on the concept of power, from which we also look beyond to Hunjan & Pettit [6].\r\n\r\nThe focus of the psychological component relates to the actual effect of empowerment, in particular, for instance, if the process of design and use of a technology serves to focus on improving self-esteem (feeling), teaching skills (knowing) or taking a particular action (doing). Schneider et al. [10] acknowledge that these are interdependent, and in the case of Commonfare, with a focus on fostering autonomy and sharing of experiences and promoting good practices there are elements of at least feeling and doing in its approach.\r\n\r\nThe persistence of empowerment relates to the temporal aspect of an intervention is of particular relevance to our concerns as it relates to an intervention or design process as having an ongoing effect beyond meaningful interaction with the Commonfare platform. Schneider et al. [10] distinguish between transient and persistent empowerment, the difference relating to whether someone is empowered only while engaging with a project, or if it persists beyond. As much of the way Commonfare has been enacted has sought to foster individual and collective autonomy and capabilities of people to confront and respond to their precarious circumstances, the intent is of course that these networks persist, and also that they are not dependent upon (although supported by) the commonfare.net platform.\r\n\r\nThe design mindset is framed in terms of the relationship between the researchers/designers and the people for whom the designed technology ultimately aims to serve. Schneider et al. [10] distinguish between expert and participatory approaches, specifically whether the designer is making the decisions, where some people, often referred to as ‘users’ or ‘subjects’ are the target, but not actively involved in the design process. As a project that takes a participatory design approach, the mindset has that has guided the interactions between the consortium partners, from different target populations and the connections with specific local good practices (e.g. businesses, social entrepreneurs, and activists that respond to issues of precariousness) has been that of including different perspectives.\r\n\r\nFinally, the concept of power as power-to or power-over is presented by Schneider et al. [10] in terms of the relationship between actors and power. Specifically power-to refers to an actors capability, while power-over refers to an actors capability in relation to another actor (i.e. a more hierarchical relationship). For the examples provided by Schneider et al. [10] define an actor as a person or group of people, which for these concepts to be separate seems necessary, as a consideration of resources or technology as an actor in a relationship would almost always entail some level of power-over. While Schneider et al. [10] only make a distinction between two concepts of power as part of their survey of empowerment within HCI, other approaches such as Hunjan & Pettit [6], under the category of ‘expressions of power’ include these plus two additional categories: power-with and power-within. Power-with is about “collective action, the ability to act together”, and is about “bringing together resources and strategies”. Power-within relates to a “sense of self-worth, value, dignity” [6]. A goal of Commonfare is to address issues of value and dignity, and building up people\'s capacities (in an individual and collective sense) to address their circumstances. We are, however, interested in how this actually takes place, both in the sense of the funded period of the project (mid-2016 to mid-2019), and what it means beyond this, for those who executed the project (the consortium), and those subjects who contribute to, and are the target of the design process.\r\n\r\n5 CONCLUSION\r\n\r\nDoes empowerment as a concept and analytical framework to understand the goals of Commonfare provide a meaningful starting point in order to address questions of the efficacy of social good? We have provided a rather rudimentary application of an Empowerment framework to Commonfare, with more of a focus on the concept (or expression) of power, to try and connect with project goals, both within the funded period, and also to the future with regard to the Commonfare Association and CIO project. One aspect lacking in our initial analysis is to engage more with the content produced on the platform, as a way to try and understand if and how people are empowered by and beyond their interactions. This is a future direction of research interest, and one that becomes increasingly relevant as the Commonfare Association becomes active, as at the time of writing this association has only recently come into existence, so it is difficult to say much about how it will fare and the longevity of the project. As researchers who participate in multiple projects of such nature, defining and measuring empowerment in meaningful terms, building infrastructures for fair participation, and professional accountability while receiving public funds are important and serious issues that warrant further communal discussion in HCI.\r\n\r\nACKNOWLEDGMENTS\r\n\r\nThis CIO project has received funding from the European Research Council (ERC) under the European Union\'s Horizon 2020 research and innovation programme (grant agreement No 740548). The Commonfare project has received funding from the European Union\'s Horizon 2020 research and innovation programme (grant agreement No 687922).\r\n\r\nREFERENCES\r\n\r\nShaowen Bardzell. 2010. Feminist HCI: Taking Stock and Outlining an Agenda for Design. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’10). ACM, New York, NY, USA, 1301–1310. https://doi.org/10.1145/1753326.1753521  \r\nSusanne Bødker. 2006. When Second Wave HCI Meets Third Wave Challenges. In Proceedings of the 4th Nordic Conference on Human-computer Interaction: Changing Roles(NordiCHI ’06). ACM, New York, NY, USA, 1–8. https://doi.org/10.1145/1182475.1182476  \r\nSarah Fox, Jill Dimond, Lilly Irani, Tad Hirsch, Michael Muller, and Shaowen Bardzell. 2017. Social Justice and Design: Power and Oppression in Collaborative Systems. In Companion of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing(CSCW ’17 Companion). ACM, New York, NY, USA, 117–122. https://doi.org/10.1145/3022198.3022201  \r\nAndrea Fumagalli, Sandro Gobetti, Cristina Morini, and Rachele Serino. 2017. PIE News - Sustainability and Commonfare Report. Deliverable D5.4 produced for the PIE News project (2017). https://zenodo.org/record/3332718/files/PIE_D5.4_FIN.pdf  \r\nGillian R. Hayes. 2011. The Relationship of Action Research to Human-computer Interaction. ACM Trans. Comput.-Hum. Interact. 18, 3, Article 15 (Aug. 2011), 20 pages. https://doi.org/10.1145/1993060.1993065  \r\nRaji Hunjan and Jethro Pettit. 2011. Power: A practical guide for facilitating social change. Carnegie United Kingdom Trust Dunfermline.  \r\nGopinaath Kannabiran and Marianne Graves Petersen. 2010. Politics at the Interface: A Foucauldian Power Analysis. In Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries(NordiCHI ’10). ACM, New York, NY, USA, 695–698. https://doi.org/10.1145/1868914.1869007  \r\nPeter Lyle, Mariacristina Sciannamblo, and Maurizio Teli. 2018. Fostering Commonfare. Infrastructuring Autonomous Social Collaboration. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 452, 12 pages. https://doi.org/10.1145/3173574.3174026  \r\nYvonne Rogers. 2006. Moving on from Weiser\'s Vision of Calm Computing: Engaging UbiComp Experiences. In UbiComp 2006: Ubiquitous Computing, Paul Dourishand Adrian Friday (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 404–421.  \r\nHanna Schneider, Malin Eiband, Daniel Ullrich, and Andreas Butz. 2018. Empowerment in HCI - A Survey and Framework. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI ’18). ACM, New York, NY, USA, Article 244, 14 pages. https://doi.org/10.1145/3173574.3173818  \r\nMariacristina Sciannamblo, Peter Lyle, and Maurizio Teli. 2018. Fostering Commonfare. Entanglements between Participatory Design and Feminism. In Design Research Society 2018: Catalyst. 458–471. https://doi.org/10.21606/drs.2018.557  \r\nGeeta Shroff and Matthew Kam. 2011. Towards a Design Model for Women\'s Empowerment in the Developing World. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’11). ACM, New York, NY, USA, 2867–2876. https://doi.org/10.1145/1978942.1979368  \r\nFOOTNOTE\r\n\r\n1 http://pieproject.eu/\r\n\r\n2 http://cs.au.dk/research/pages/cio/\r\n\r\n3github.com/Commonfare-net\r\n\r\n4commonfare.net/en/stories/an-end-has-a-start-welcome-to-the-commonfare-association',1,'Lyle','Peter Lyle and Gopinaath Kannabiran','Peter Lyle *(Aarhus University, Denmark)*<br>\r\nGopinaath Kannabiran *(Aarhus University, Denmark)*',NULL,0,'10.1145/3363384.3363480','ACM Digital Library','Browse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,36),(61,'oppermann-beyond-hci-and-cscw-challenges-and-useful-practices-towards-a-human-centered-vision-of-ai-and-ia','2019-09-03 08:29:56','2019-11-19 12:41:01','2019-09-03 08:29:56',NULL,1,'published','[]','Beyond HCI and CSCW: Challenges and Useful Practices Towards a Human-Centred Vision of AI and IA','Over the decades, technologies envisioned by pioneers such as Douglas Engelbart are becoming a reality. AI has become an important driver for technological progress, posing questions for the future of human-computer interaction. Our research group at Fraunhofer FIT looks back on a 51 year long research tradition that started with Engelbart\'s vision and followed through the larger developments of HCI from the introduction of CSCW up to successful projects involving the engineering of large software systems in practice. In this paper, we outline the history of our institute against the background of trends in HCI, working out the cornerstones and “useful practices” from our research tradition towards our vision of the future of a human-centred AI/IA, with the expectation that this analysis may be useful for similar organisations. In doing so, we illustrate tensions between theory and application, humans and technology, and show how keeping those aspects in balance is an important challenge and chance for bringing disruptive emerging technologies successfully into practice.','Leif Oppermann, Alexander Boden, Britta Hofmann, Wolfgang Prinz, and Stefan Decker. 2019. Beyond HCI and CSCW: Challenges and Useful Practices Towards a Human-Centred Vision of AI and IA. In *Proceedings of the Halfway to the Future Symposium 2019 (HTTF 2019), November 19–20, 2019, Nottingham, United Kingdom*. ACM, New York, NY, USA, 5 pages. [https://doi.org/10.1145/3363384.3363481](https://doi.org/10.1145/3363384.3363481 \"DOI for the article \'Beyond HCI and CSCW: Challenges and Useful Practices Towards a Human-Centred Vision of AI and IA\'\")','1 INTRODUCTION\r\n\r\nOver the decades, technologies as envisioned by pioneers such as Engelbart [30] or McCarthy [46] are becoming reality. Computers serve as tools to solve intellectual challenges such as navigating large amounts of data and enabling collaboration across time and space. Arguably, we are close to Engelbart\'s vision of Intelligence Augmentation (IA) or Brooks’ Intelligence Amplification [17]. At the same time, technologies are getting increasingly autonomous. While we have not reached McCarthy\'s goal of Artificial Intelligence (AI) in the sense of human-like machines, computers are acting as (semi-)autonomous AI agents that increasingly overtake specialised tasks that have required human work in the past. AI has become an important driver for technological progress, posing questions for the future of human-computer interaction. Innovations in AI/IA have been supplemented by Mark Weiser\'s vision of Ubiquitous Computing [65]. The Internet of Things connects physical things to virtual representation, providing data for AI applications [5]. Furthermore, as devices are increasingly interconnected, it is not the computer or the interface anymore, but we are confronted with “systems of systems” that work invisibly in the background based on smart services. This has strong implications on the design of software applications [16], making it unclear what the very borders of the system are. With the 3rd wave of HCI [22], computer technology has spread from the office into the everyday lifeworlds of people, with applications ranging from healthcare over public safety to smart homes and personal computing. For HCI, this “context collapse” means that usage contexts are getting blurry [50], and many innovations are now first adopted in the private consumer market (e.g. social media, speech assistants, smart phones), raising new issues for security and privacy of businesses. Furthermore, this results in complex questions about ethical, legal and social implications of technology, such as the role of social media and “fake news” for elections and other democratic processes, but also about the role of humans for “Human-Computer-Interaction”, for instance regarding the balance of automation vs. augmentation of work and decision making for new economies and models of society.\r\n\r\n2 FROM ENGELBART\'S VISION TO PRACTICE: OUR INSTITUTE FROM 1968 TO 2019\r\n\r\nTowards the end of the 1960s it became evident that programmable computers required a manageable, structured software engineering process, requiring a new kind of education. German academia did not have an answer to this at the time [1][4]. To help utilising computers for complex administrative tasks, the German government founded the Big Science national research centre GMD on 23.04.1968 and announced a programme for the creation of “Informatik” degrees at universities by example of the American computer science degrees. Two years after its installation, in 1970, the direction of GMD was changed from a mathematics-driven to a computer science-oriented focus. On 11.07.2001 [3], GMD was merged with the Fraunhofer Society for the Advancement of Applied Research, resulting in a change of the funding model towards a stronger industry focus, as well as the founding of our institute as it is today, the Fraunhofer Institute for Applied Information Technology FIT [2]. In light of the historic developments, research at our site was always concerned with the design and development of large software systems [60]. Examples include the juridical information system “juris” [63], “KOMEX”, one of the first distributed email systems in Europe (presented at Hannover Fair in 1979 [6]), and the micromodels for the German federal training assistance act [20].\r\n\r\n2.1 Towards HCI and the Social Web\r\n\r\nWith ever more complex systems to be used by non-expert users, user-perceived quality of interactive systems gained significant importance [58]. Such software-ergonomic aspects led to the EVADIS guideline [47] or the ErgoNorm method to verify conformity of software to ISO norm 9241-11, the “ergonomic requirements of office work with visual displays“ [28]. In this respect, FIT has been very active in turning methodological know-how into practice, resulting in an accredited course on usability [34]. At least since the 1980s it also became clear that there is more to computers than the programs and the interfaces, leading to the Assisting Computer research program that aimed at turning the computer from a process automation [39] to an assisting tool that can not only support cooperative works processes [41], but act as an assistant in everyday tasks. This assistant computer was first presented at the CeBIT in Hannover in 1992 raising a lot of attention because of its conceptual integration of AI, HCI [62], CSCW [40], and networked information systems components [52]. This research contributed to shift the focus from human factors to human actors [7], as in the “second wave” of HCI [22], and included the social aspects of using computers at work and at home. FIT participated in the field of Computer Supported Collaborative Work (CSCW) from the very beginning, even before the term was coined at the workshop of Greif and Cashman at Endicott House, MA, in 1984 [32]. With the German reunification came the relocation of the government and parts of the ministries from Bonn to Berlin. To support this process, several research projects have been set up, one of which was POLITeam [57]. Its shared workspaces were based on the proprietary LinkWorks software, but later widened to using the world-wide web [11] as an enabling technology for CSCW [10], resulting in the development of the BSCW shared workspace groupware system that was the first fully web-based groupware solution and was awarded the European Software Innovation price in 1996. Based on these technological pillars, many further projects were built over the years that allowed collaboration across organisational boundaries and implemented, for example, domain specific information systems such as the official German energy research portal EnArgus.de that provides public and private access to semantically linked data [49]. Methodologically, the POLITeam project applied an iterative and evolutionary co-creation process within a professional user group, i.e. knowledge workers in a German ministry. Our research adopted the participatory design approach and created new methods such as user advocacy [45] and congruency in use [55] by the cooperative development of conventions for the adoption of groupware in a business environment, thus performing one of the first “CSCW in the wild” projects. For designing new systems, we usually employ a cooperative prototyping approach [23], but also focus on ethnographic methods for informing technology design [24][51]. Since 2011, the department of User Centered Computing (formerly: HCI) grouped the expertise in the institute and applied it systematically to all running projects. In 2012, FIT founded its dependence BeFIT at the University of Siegen to institutionalize a long-standing cooperation in Socio-Informatics [66], esp. in the context of the practice turn in HCI [42].\r\n\r\n2.2 Making a complex world understandable: Linked Data and the Semantic Web\r\n\r\nThe same trajectory that spanned CSCW and HCI also gave birth to Linked Data and the Semantic Web as an evolution of the World Wide Web [11]. Linked Data has the capability to facilitate interoperation of data and knowledge [27] and of collaborative systems and this will play a role for Intelligence Augmentation by integrating knowledge and systems that present and process knowledge [54]. The Semantic Web itself has also another trajectory: some aspects were emerging from the Knowledge Representation field, which is part of AI, such as the Web Ontology Language or FAIR data [13]. Since their inception, Semantic Web Standards have been applied to Open Data portals, Research Data Management, Life Sciences, and more. However, Linked Data is not only relevant to semantically connect different knowledge resources. It is also relevant to connect different information silos and repositories. For the future, we foresee that the trend towards cloud-based centralisation is turning around to a more decentralised approach where data is kept private and only shared on demand and purpose. Technologies that foster this approach like SOLID or IDS as well as blockchain/DLT become more mature. And since they meet the growing user need and awareness for privacy, as well as the regulatory initiatives like the GDPR, a more decentralised, but yet interlinked approach, will become more and more relevant [25].\r\n\r\n2.3 AI and IA at FIT\r\n\r\nSince first being coined as a term by McCarthy in 1955, Artificial Intelligence (AI) grew into popular sub-discipline of computer science that is much being talked about today. After FITs AI division had been spun out into an own institute AIS in 1997 (nowadays IAIS after another merger), our research agenda at the turn of the millennium was henceforth concerned with the transition from basic groupware to the use of computers as a social medium, as well as for augmenting human intellect in the sense of IA. For FIT, this entailed works from document links to people links [36], tapping into topics such as awareness [53], ubiquitous computing, or pervasive games [44], as well as coordination of dispersed collaborators in a variety of application domains [14], and application of novel technologies such as Blockchain [56]. In this respect, Engelbart\'s vision of computers in organisations and supporting groups, as well as Weiser\'s visions of the IoT have always played a pivotal role [32]. While this was all very expensive at its time, integration, miniaturisation and market success in the office and the consumer market led to price drops that allowed for a ubiquity of devices that can be used outside the typical white-collar office settings and allow for, e.g. use for education, entertainment, personal computing, smart cities, or blue-collar work support.\r\n\r\n3 DISCUSSION\r\n\r\nHCI has been subject to several technological trends in the last decades which ranged from the capabilities of IT, the areas of application and research, as well as the role of the human for “human computer interaction”. The future of HCI, it seems, requires new approaches to research and design, posing complex challenges that are not easy to manage or solve. While this has been suggested already over a decade ago [22], it is more than current in the light of recent developments. On the one hand this seems like yesterday\'s news. But on the other hand, it is us as professional practitioners in the field of HCI reflecting in action about our doings and allowing us to cope with the unique, uncertain, and conflicted situations of practice [61]. FIT was born from the software crisis of the late 1960s, and riding through the Internet crash of the 2000s and the financial crisis of 2008. An implicit strategy to withstand those external factors was to develop reusable software components, like the aforementioned micromodels, the BSCW-server [9], a VR/AR-framework [48], or an IoT-framework [29]. But while this is a viable road for scientific work in research projects, experience shows there is a gap to overcome to get research results and prototypes into industrial practice. The market usually does not want to invest in scientific endeavours, but get results that improve the bottom line. Moreover, as soon as something “just works”, it is better placed in and served by industry anyway.\r\n\r\n3.1 Reflection in Action: From Research to Industrial Practice\r\n\r\nWe have always been impressed with “the urgency of doing”, as attributed to Leonardo da Vinci: “Knowing is not enough; we must apply. Being willing is not enough; we must do.” that is also central to Schön\'s thoughts about reflection in action [61]. With respect to our discipline, we see it as a challenge to continue the “doing”-bit when everyone is doing it. As practitioners in our discipline, we must strive to stay relevant with state-of-the-art research that gives value to people outside university [18]. With all the hype that circumvents IT topics, such as the vision of fully intelligent AI systems, there is reason for criticism [37]. Seeing ourselves as toolsmiths [17], we support the human-centred approach of HCI for engineering complex systems, such as AI, and thus favour IA. We believe IA is of great importance for our continued journey into the digital future of our discipline, economy, environment, and society [26]. As part of the Fraunhofer model to leave the “ivory tower”, we had to learn to become approachable to smaller partners from the industry. Part of that idea is to get a step closer to the client, both: thematically, and spatially. In response, we are actively engaged in several competence centres in cooperation with different universities. This is playing back on the original dualism of theoretical knowledge generated and taught at universities, and the more practical knowledge of applied engineering, such as in the context of recent work in engineering information systems [19] and process mining to look into their corresponding business processes [64].\r\n\r\n3.2 Balancing the Waves\r\n\r\nBy looking at our past, we can see a tension between theory and application, humans and technology; while trying to keep the balance when surfing on the waves of IT. This can be achieved by placing emerging technologies in a new context thus achieving disruptive innovations. For us, it started with the concept of the assisting computer [35], followed by the development of BSCW that turned the web from an information system to a cooperation system, and the dawn of mobile, ubiquitous computing. Today\'s challenges are the integration of consumer technologies [38], the convergence of collaborative computing and Mixed Reality [31], the adoption of new concepts for supporting decentralised networked business eco-systems [56], combining user-centred design methods and data analytics to the Industrial Internet of Things [8], opening up data-silos and replacing them with linked data [12], and better representation of linked data, e.g. through anonymisation [33] or through knowledge graphs [15]. This calls, amongst others, for more transparent and “explainable” AI systems and interfaces that support a better collaboration between human actors and IA. Furthermore, on a methodological level, we need approaches that address the increasing complexity of systems of systems, and account for the complex implications of technology projects that are so deeply embedded in the everyday life and touch core aspects of human life, which likely exceeds current models of participatory design methodologies [43]. This all just means that in order to facilitate digital transformation, we must build systems that humans will still be able to master. It would be very helpful if the basic skills required to support this endeavour could be acquired from early on, as once pioneered in the UK with the BBC Micro [59]. Based on our own history we can conclude that the design and development of IT-related processes for public and private bodies has not been done for good twenty years ago, but instead requires our continuous and ongoing efforts. Combining this with the long nose of innovation [21], we can see that there is reason for hope that we can bring more of our collective research into application.\r\n\r\nREFERENCES\r\n\r\n1968. TECHNIK / COMPUTER-KONGRESS: Welt in der Stube. Spiegel Online 33 (Aug. 1968). https://www.spiegel.de/spiegel/print/d-45950214.html  \r\n2000. Fusion GMD/Fraunhofer: Gerät die IT-Grundlagenforschung unter die Räder?Spiegel Online (Feb. 2000). https://www.spiegel.de/netzwelt/web/fusion-gmd-fraunhofer-geraet-die-it-grundlagenforschung-unter-die-raeder-a-66571.html  \r\n2001. Rechtliche Integration der GMD in die Fraunhofer-Gesellschaft abgeschlossen. https://idw-online.de/en/news?id=37409  \r\n2018. Die Geburt der „Informatik“ | HNF Blog. https://blog.hnf.de/die-geburt-der-informatik/  \r\nKevin Ashton and others. 2009. That ‘internet of things’ thing. RFID journal 22, 7 (2009), 97–114.  \r\nRobert Babatz, Manfred Bogen, and Uta Pankoke-Babatz. 1990. Die X.400-Öffnung von KOMEX. In Elektronische Kommunikation — X.400 MHS, Robert Babatz, Manfred Bogen, Uta Pankoke-Babatz, and Harald Schumny (Eds.). Vieweg+Teubner Verlag, Wiesbaden, 95–115. https://doi.org/10.1007/978-3-322-83106-4_9  \r\nLiam Bannon. 1991. From human factors to human actors: the role of psychology and human-computer interaction studies in system design. In Design at Work: Cooperative Design of Computer Systems, Joan Greenbaumand Morten Kyng (Eds.). Lawrence Erlbaum Associates, 25–44.  \r\nChristian Beecks, Alexander Grass, Shreekantha Devasya, Marc Jentsch, Jose Angel Carvajal Soto, Farshid Tavakolizadeh, Anja Linnemann, and Markus Eisenhauer. 2018. Smart Data and the Industrial Internet of Things. In Next Generation Internet of Things: Distributed Intelligence at the Edge and Human Machine-to-Machine Cooperation. River Publishers. https://doi.org/10.13052/rp-9788770220071  \r\nBastian Benrath. 2019. Cloud aus Deutschland: Die Suche nach dem Hyperscaler. FAZ (Oct. 2019). https://www.faz.net/aktuell/wirtschaft/diginomics/cloud-aus-deutschland-die-suche-nach-dem-hyperscaler-16411233.html  \r\nRichard Bentley, Thilo Horstmann, and Jonathan Trevor. 1997. The World Wide Web as Enabling Technology for CSCW: The Case of BSCW. Computer Supported Cooperative Work (CSCW) 6, 2 (June 1997), 111–134. https://doi.org/10.1023/A:1008631823217  \r\nTim Berners-Lee. 2000. Weaving the Web: The Original Design and Ultimate Destiny of the World Wide Web(1 edition ed.). HarperBusiness, San Francisco.  \r\nTim Berners-Lee. 2010. 5 Star Open Data. http://5stardata.info/  \r\nOya Beyan, Andrea Wuchner, Dirk Eisengräber-Pabst, Christoph Quix, Christian Zaschke, and Oliver Schumacher. 2018. Research Data in the Fraunhofer Digital Project. Creating a FAIR Research Data Infrastructure and Culture. In Workshop on Research Objects, RO 2018. Proceedings. Online resource. 8. http://publica.fraunhofer.de/dokumente/N-534423.html  \r\nAlexander Boden, Frank Rosswog, Gunnar Stevens, and Volker Wulf. 2014. Articulation Spaces: Bridging the Gap Between Formal and Informal Coordination. In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing(CSCW ’14). ACM, New York, NY, USA, 1120–1130. https://doi.org/10.1145/2531602.2531621  \r\nPiero Andrea Bonatti, Stefan Decker, Axel Polleres, and Valentina Presutti. 2019. Knowledge Graphs: New Directions for Knowledge Representation on the Semantic Web (Dagstuhl Seminar 18371). Dagstuhl Reports 8, 9 (2019), 29–111. https://doi.org/10.4230/DagRep.8.9.29  \r\nClaus Bossen, Pelle Ehn, Helena Karasti, Carl Di Salvo, Andrew Clement, Volkmar Pipek, and Yvonne Dittrich. 2014. Infrastructuring, Collaboration and Evolving Socio-material Practices of Changing Our World. In Proceedings of the 13th Participatory Design Conference: Short Papers, Industry Cases, Workshop Descriptions, Doctoral Consortium Papers, and Keynote Abstracts - Volume 2(PDC ’14). ACM, New York, NY, USA, 221–222. https://doi.org/10.1145/2662155.2662211 event-place: Windhoek, Namibia.  \r\nFrederick P. Brooks, Jr.1996. The computer scientist as toolsmith II. Commun. ACM 39, 3 (1996), 61–68. https://doi.org/10.1145/227234.227243  \r\nFrederick P. Brooks, Jr.2010. The Design of Design: Essays from a Computer Scientist (1 ed.). Addison-Wesley Professional, Upper Saddle River, NJ.  \r\nHans Ulrich Buhl, Günter Müller, Gilbert Fridgen, and Maximilian Röglinger. 2012. Business and information systems engineering: A complementary approach to information systems-what we can learn from the past and may conclude from present reflection on the future. Journal of the Association for Information Systems 13, 4 (2012), 236.  \r\nDieter Bungers and Hermann Quinke. 1986. A microsimulation model for the German Federal Training Assistance Act-Principles, problems and experiences. In Microanalytic simulation models to support social and financial policy. Number 7 in Information Research and Resource Reports. North Holland, Amsterdam, 171–183.  \r\nBill Buxton. 2014. The Long Nose of Innovation (Revised). https://www.billbuxton.com/01%20The%20Long%20Nose%20of%20Innovation%20Revised.pdf  \r\nSusanne Bødker. 2006. When second wave HCI meets third wave challenges. In Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles. ACM, 1–8.  \r\nSusanne Bødker and Kaj Grønbæk. 1991. Design in Action: From Prototyping by Demonstration to Cooperative Prototyping. In Design at Work: Cooperative Design of Computer Systems, Joan Greenbaumand Morten Kyng (Eds.). Lawrence Erlbaum Associates, 197–218.  \r\nAndy Crabtree. 2003. Designing Collaborative Systems: A Practical Guide to Ethnography. Springer-Verlag, London. https://www.springer.com/gp/book/9781852337186  \r\nAndy Crabtree, Tom Lodge, James Colley, Chris Greenhalgh, Richard Mortier, and Hamed Haddadi. 2016. Enabling the new economic actor: data protection, the digital economy, and the Databox. Personal and Ubiquitous Computing 20, 6 (Nov. 2016), 947–957. https://doi.org/10.1007/s00779-016-0939-3 \r\nStefan Decker. 2019. Artificial Intelligence and Intelligence Augmentation - two sides of the same coin? | LinkedIn. https://www.linkedin.com/pulse/artificial-intelligence-augmentation-two-sides-same-stefan-decker/  \r\nStefan Decker and Manfred Hauswirth. 2008. Enabling networked knowledge. In International Workshop on Cooperative Information Agents. Springer, 1–15.  \r\nWolfgang Dzida, Britta Hofmann, Regine Freitag, Wolfgang Redtenbacher, Robert Baggen, and Thomas Geis. 2001. Gebrauchstauglichkeit von Software: ErgoNorm: Ein Verfahren zur Konformitätsprüfung von Software auf der Grundlage von DIN EN ISO 9241 Teile 10 und 11. Wirtschaftsverlag N. W. Verlag für neue Wissenschaft, Bremerhaven.  \r\nM. Eisenhauer, P. Rosengren, and P. Antolin. 2009. A Development Platform for Integrating Wireless Devices and Sensors into Ambient Intelligence Systems. In 2009 6th IEEE Annual Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks Workshops. 1–3. https://doi.org/10.1109/SAHCNW.2009.5172913  \r\nDouglas Engelbart. 1963. A Conceptual Framework for the Augmentation of Man\'s Intellect. In The Augmentation of Man\'s Intellect by Machine, P.W. Howertonand D.C. Weeks (Eds.). Vistas in Information Handling, Vol. 1. Spartan Books, Washington D.C.  \r\nBarrett Ens, Joel Lanir, Anthony Tang, Scott Bateman, Gun Lee, Thammathip Piumsomboon, and Mark Billinghurst. 2019. Revisiting collaboration through mixed reality: The evolution of groupware. International Journal of Human-Computer Studies 131 (Nov. 2019), 81–98. https://doi.org/10.1016/j.ijhcs.2019.05.011  \r\nIrene Greif (Ed.). 1988. Computer-supported Cooperative Work: A Book of Readings. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.  \r\nBenjamin Heitmann, Felix Hermsen, and Stefan Decker. 2017. k-RDF-Neighbourhood Anonymity: Combining Structural and Attribute-based Anonymisation for Linked Data.. In PrivOn@ ISWC.  \r\nBritta Hofmann. 2017. Entwicklung eines kontextspezifischen Erhebungs-und Vorhersagemodells beruflichen Lerntransfers am Beispiel der Fraunhofer-FIT-Ausbildung zum zertifizierten Usability Engineer. PhD Thesis. Universität zu Köln.  \r\nPeter Hoschka. 1991. Assisting Computer — A New Generation of Support Systems. In Verteilte Künstliche Intelligenz und kooperatives Arbeiten(Informatik-Fachberichte), W. Brauer and D. Hernández (Eds.). Springer Berlin Heidelberg, 219–230.  \r\nPeter Hoschka. 1998. CSCW Research at GMD-FIT: From Basic Groupware to the Social Web. SIGGROUP Bull. 19, 2 (Aug. 1998), 5–9. https://doi.org/10.1145/290575.290576  \r\nArjun Kharpal. 2017. Stephen Hawking says A.I. could be ’worst event in the history of our civilization’. https://www.cnbc.com/2017/11/06/stephen-hawking-ai-could-be-worst-event-in-civilization.html  \r\nSonja Kind, Jan-Peter Ferdinand, Tobias Jetzke, Stephan Richter, and Sebastian Weide. 2019. Virtuelle und erweiterte Realitäten (VAR): Was das ist und was sie uns bringen; TAB-Arbeitsbericht Nr. 180. Technical Report. 117 pages. https://www.tab-beim-bundestag.de/de/aktuelles/20190625.html  \r\nThomas Kreifelts, Elke Hinrichs, Karl-Heinz Klein, Peter Seuffert, and Gerd Woetzel. 1991. Experiences with the Domino Office Procedure System. In Proceedings of the Second European Conference on Computer-Supported Cooperative Work ECSCW ’91, Liam Bannon, Mike Robinson, and Kjeld Schmidt (Eds.). Springer Netherlands, Dordrecht, 117–130. https://doi.org/10.1007/978-94-011-3506-1_9  \r\nThomas Kreifelts, Elke Hinrichs, and Gerd Woetzel. 1993. Sharing to-do lists with a distributed task manager. In Proceedings of the Third European Conference on Computer-Supported Cooperative Work 13–17 September 1993, Milan, Italy ECSCW’93. Springer, 31–46.  \r\nThomas Kreifelts and Wolfgang Prinz. 1993. ASCW: An Assistant for Cooperative Work. In Proceedings of the Conference on Organizational Computing Systems(COCS ’93). ACM, New York, NY, USA, 269–278. https://doi.org/10.1145/168555.168585 event-place: Milpitas, California, USA.  \r\nKari Kuutti and Liam J Bannon. 2014. The turn to practice in HCI: Towards a research agenda. In Proceedings of the 32nd annual ACM conference on Human factors in computing systems. ACM, 3543–3552.  \r\nMichael Liegl, Alexander Boden, Monika Büscher, Rachel Oliphant, and Xaroula Kerasidou. 2016. Designing for ethical innovation: A case study on ELSI co-design in emergency. International Journal of Human-Computer Studies 95 (2016), 80–95.  \r\nIrma Lindt, Jan Ohlenburg, Uta Pankoke-Babatz, Sabiha Ghellal, Leif Oppermann, and Matt Adams. 2005. Designing Cross Media Games. In PerGames Workshop. Munich, Germany.  \r\nPeter Mambrey, Gloria Mark, and Uta Pankoke-Babatz. 1998. User Advocacy in Participatory Design: Designers’ Experiences with a New Communication Channel. Computer Supported Cooperative Work (CSCW) 7, 3 (Sept. 1998), 291–313. https://doi.org/10.1023/A:1008687122083  \r\nJohn McCarthy and Patrick J Hayes. 1981. Some philosophical problems from the standpoint of artificial intelligence. In Readings in artificial intelligence. Elsevier, 431–450.  \r\nB. Murchner, R. Oppermann, M. Paetau, M. Pieper, H. Simm, and I. Stellmacher. 1987. EVADIS — Ein Leitfaden zur softwareergonomischen Evaluation von Dialogschnittstellen. In Software-Ergonomie ’87 Nützen Informationssysteme dem Benutzer?, W. Schönpflug and M. Wittstock (Eds.). Vieweg+Teubner Verlag, Wiesbaden, 307–316. https://doi.org/10.1007/978-3-322-82971-9_25  \r\nJan Ohlenburg, Iris Herbst, Irma Lindt, Thorsten Fröhlich, and Wolfgang Broll. 2004. The MORGAN framework: enabling dynamic multi-user AR and VR projects. In Proceedings of the ACM symposium on Virtual reality software and technology. ACM, 166–169.  \r\nLeif Oppermann, Elke Hinrichs, Ulrich Schade, Thomas Koch, Manuela Rettweiler, Frederike Ohrem, Patrick Plötz, Carsten Beier, and Wolfgang Prinz. 2015. EnArgus: Zentrales Informationssystem Energieforschungsförderung. Cottbus, 1717–1730.  \r\nLeysia Palen. 1999. Social, Individual and Technological Issues for Groupware Calendar Systems. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems(CHI ’99). ACM, New York, NY, USA, 17–24. https://doi.org/10.1145/302979.302982 event-place: Pittsburgh, Pennsylvania, USA.  \r\nRafael Prikladnicki, Alexander Boden, Gabriela Avram, Cleidson R. B. de Souza, and Volker Wulf. 2014. Data collection in global software engineering research: learning from past experience. Empirical Software Engineering 19, 4 (Aug. 2014), 822–856. https://doi.org/10.1007/s10664-012-9240-x  \r\nWolfgang Prinz. 1993. TOSCA Providing organisational information to CSCW applications. In Proceedings of the Third European Conference on Computer-Supported Cooperative Work 13–17 September 1993, Milan, Italy ECSCW’93. Springer, 139–154.  \r\nWolfgang Prinz. 2002. NESSIE: An Awareness Environment for Cooperative Settings. In ECSCW ’99: Proceedings of the Sixth European Conference on Computer Supported Cooperative Work 12–16 September 1999, Copenhagen, Denmark, Suanne Bødker, Morten Kyng, and Kjeld Schmidt (Eds.). Springer Netherlands, Dordrecht, 391–410. https://doi.org/10.1007/0-306-47316-X_21  \r\nWolfgang Prinz, Herman Loh, Marc Pallot, Hans Schaffers, Antonio Skarmeta, and Stefan Decker. 2006. ECOSPACE–towards an integrated collaboration space for eProfessionals. In 2006 International Conference on Collaborative Computing: Networking, Applications and Worksharing. IEEE, 1–7.  \r\nWolfgang Prinz, Gloria Mark, and Uta Pankoke-Babatz. 1998. Designing groupware for congruency in use. In CSCW, Vol. 98. 14–18.  \r\nWolfgang Prinz, Thomas Rose, Thomas Osterland, and Clemens Putschli. 2019. Blockchain - Reliable Transactions. In Digital Transformation, Reimund Neugebauer (Ed.). Springer Vieweg, Berlin, Heidelberg, 301–309. https://doi.org/10.1007/978-3-662-58134-6  \r\nWolfgang Prinz and Anja Syri. 1997. Two complementary tools for the cooperation in a ministerial environment.  \r\nJef Raskin. 2000. The Humane Interface - New Directions for Designing Interactive Systems. Addison-Wesley.  \r\nYvonne Rogers, Venus Shum, Nic Marquardt, Susan Lechelt, Rose Johnson, Howard Baker, and Matt Davies. 2017. From the BBC Micro to Micro:Bit and Beyond: A British Innovation. Interactions 24, 2 (Feb. 2017), 74–77. https://doi.org/10.1145/3029601  \r\nWinston W. Royce. 1970. Managing the Development of Large Software Systems. In IEEE WESCON. 1–9. \r\nDonald S. Schön. 1983. The Reflective Practitioner: How Professionals Think in Action (Paperback edition 1991). Ashgate.  \r\nMichael Spenke and Christian Beilken. 1991. An Overview of GINA — the Generic Interactive Application. In User Interface Management and Design(EurographicSeminars), David A. Duce, M. Rui Gomes, F. Robert A. Hopgood, and John R. Lee (Eds.). Springer Berlin Heidelberg, 273–293.  \r\nSigmar Uhlig. 1974. Das Projekt ”Juristisches Informationssystem (JURIS)” - Stand Der Arbeiten Und Planungen. In GI-BIFOA, Internationale Fachtagung: Informationszentren in Wirtschaft Und Verwaltung. Springer-Verlag, London, UK, UK, 135–149. http://dl.acm.org/citation.cfm?id=646071.677129  \r\nWil M. P. van der Aalst, Jörg Becker, Martin Bichler, Hans Ulrich Buhl, Jens Dibbern, Ulrich Frank, Ulrich Hasenkamp, Armin Heinzl, Oliver Hinz, Kai-Lung Hui, Matthias Jarke, Dimitris Karagiannis, Natalia Kliewer, Wolfgang König, Jan Mendling, Peter Mertens, Matti Rossi, Stefan Voss, Christof Weinhardt, Robert Winter, and Jelena Zdravkovic. 2018. Views on the Past, Present, and Future of Business and Information Systems Engineering. Business & Information Systems Engineering 60, 6 (Dec. 2018), 443–477. https://doi.org/10.1007/s12599-018-0561-1  \r\nMark Weiser. 1991. The Computer for the 21st Century. Scientific American 265, 3 (1991), 66–75. https://dl.acm.org/citation.cfm?id=329126  \r\nVolker Wulf, Volkmar Pipek, Gunnar Stevens, Markus Rohde, David Randall, and Kjeld Schmidt(Eds.). 2018. Socio-Informatics. Oxford University Press, Oxford, New York. ',1,'Oppermann','Leif Oppermann, Alexander Boden, Britta Hofmann, Wolfgang Prinz, and Stefan Decker','Leif Oppermann *(Fraunhofer FIT, Germany)*<br>\r\nAlexander Boden *(Fraunhofer FIT, Germany)*<br>\r\nBritta Hofmann *(Fraunhofer FIT, Germany)*<br>\r\nWolfgang Prinz *(Fraunhofer FIT, Germany)*<br>\r\nStefan Decker *(Fraunhofer FIT, Germany)*',NULL,0,'10.1145/3363384.3363481','ACM Digital Library','Browse the entry in the ACM Digital LibraryBrowse the entry in the ACM Digital LibraryBrowse the entry in the ACM Digital LibraryBrowse the entry in the ACM Digital LibraryBrowse the entry in the ACM Digital Library',1,NULL,0,0,'Osborne Lounge',NULL,1,37),(62,'climb-machine','2019-11-08 17:38:19','2019-11-08 18:12:14','2019-11-08 17:37:06',NULL,1,'published','[]','Climb! Machine','Replay recordings of performances of [Climb!](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/works/climb.aspx \"Learn more about Climb!\") A composition that challeges the player to go on a musical journey, where each performance is different.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',1,NULL,0,0,'Osborne Lounge',NULL,0,0),(63,'carolan-guitar','2019-11-08 18:04:41','2019-11-08 18:12:12','2019-11-08 18:03:06',NULL,1,'published','[]','Carolan Guitar','Come and play with our beautiful [Carolan Guitar](https://www.nottingham.ac.uk/research/groups/mixedrealitylab/works/carolan-guitar.aspx \"Read about the Carolan Guitar\"), an artefact that knows its own history, see how you can interact with the system through [artcodes](https://www.artcodes.co.uk \"Browse the Artcodes community website\") and [muzicodes](http://eprints.nottingham.ac.uk/37081/ \"Read about our muzicodes system\"), and add your own performance to its collection.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Osborne Lounge',NULL,0,0),(64,'future-machine','2019-11-08 18:06:15','2019-11-09 14:38:11','2019-11-08 18:05:01',NULL,1,'published','[]','Future Machine','Future Machine is a mysterious interactive device that responds to global and local environmental change. Developed by artist/researcher [Rachel Jacobs](http://www.i-am-ai.net/racheljacobs/ \"Browse Rachel\'s website\") in collaboration with communities, scientists, researchers, engineers, programmers and makers. It will travel across England for at least the next 3 years and potentially beyond.',NULL,NULL,1,'Jacobs',NULL,'Rachel Jacobs *(Active Ingredient, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Osborne Lounge',NULL,0,0),(65,'vrtefacts','2019-11-08 18:10:29','2019-11-08 18:15:36','2019-11-08 18:08:03',NULL,1,'published','[]','VRtefacts','[VRtefacts](https://vrtefacts.org/ \"Browse the VRtefacts website\") is a museum-focused virtual reality (VR) experience designed to heighten a visitor’s sense of connection and engagement with items from the collection, ending with visitors donating a personal story around that object. It can be reworked in any number of ways to suit different needs.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Syndicate Room 1',NULL,0,0),(66,'augmented-reality-audio','2019-11-08 18:13:18','2019-11-08 18:13:30','2019-11-08 18:12:35',NULL,1,'published','[]','Augmented Reality Audio','A demonstration of how Audio Augmented Reality can be used to attach virtual sound sources to real world physical objects, and how it can be used to curate, and deliver, virtual soundscapes that can help to promote the exploration of museum and gallery collections and associated audio archival material.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Syndicate Room 2',NULL,0,0),(67,'roboclean','2019-11-08 18:14:55','2019-11-08 18:14:55','2019-11-08 18:13:53',NULL,1,'published','[]','RoboClean','Come and have a chat with our robovac and–who knows–it might even talk back at you? ',NULL,NULL,1,'SPB',NULL,'Smart Products Beacon *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Syndicate Room 3',NULL,0,0),(68,'photo-realiser','2019-11-08 18:16:48','2019-11-12 12:38:47','2019-11-08 18:15:44',NULL,1,'draft','[]','Photo Realiser','Explore what it feels like to be a VR timetraveller. Enter a reconstruction of a photograph from the Warsaw ghetto uprising during World War II, and get a sense of what and who was behind the camera and why the photogrph was taken.\r\n\r\n**Please note: the subject matter may be upsetting.**',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0),(69,'corrupt-kitchen','2019-11-08 18:17:30','2019-11-08 18:17:30','2019-11-08 18:17:10',NULL,1,'published','[]','Corrupt Kitchen','Try a game designed to engage players with health and saftey legislation: Try running a busy burger restaurant while making sure to follow all necessary guidelines—balance profit with corruption for fun and education.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0),(70,'can-t-touch-this','2019-11-08 18:19:11','2019-11-08 18:19:11','2019-11-08 18:17:42',NULL,1,'published','[]','Can’t Touch This','Play a VR game that explores how we visually percieve objects, by challenging you to hit some of those objects with swords. ',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0),(71,'bolt-spinner','2019-11-08 18:19:12','2019-11-08 18:19:39','2019-11-08 18:17:43',NULL,1,'published','[]','Bolt Spinner','A simple VR experience that plays with notions of control, sensory misalignment, performance and vertigo play. You are sitting on top of a bolt and unscrew it. What happens when you unscrew it all the way?',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0),(72,'baby-game','2019-11-08 18:19:13','2019-11-08 18:19:40','2019-11-08 18:17:43',NULL,1,'published','[]','Baby Game','An experience that addresses our ability to interact with the environment around us, and how easily this can be interfered with. Also explores the relationship between player and audience in immersive tech experiences—for whom do we make such experiences?',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0),(73,'tightrope','2019-11-08 18:19:05','2019-11-08 18:19:05','2019-11-08 18:17:52',NULL,1,'published','[]','Tightrope','A VR experience that uses sensory misalignment to increase the challenge of walking on a balance beam, using the principle of opposition training to help users develop balancing skills.',NULL,NULL,1,'MRL',NULL,'Mixed Reality Laboratory *(University of Nottingham, UK)*',NULL,0,NULL,'DOI','DOI link label',0,NULL,0,0,'Balmoral Gallery',NULL,0,0);
/*!40000 ALTER TABLE `bolt_programme` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_relations`
--

DROP TABLE IF EXISTS `bolt_relations`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_relations` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `from_contenttype` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `from_id` int(11) NOT NULL,
  `to_contenttype` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `to_id` int(11) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_4C524BC3EA11294378CED90B` (`from_contenttype`,`from_id`),
  KEY `IDX_4C524BC35ACD264530354A65` (`to_contenttype`,`to_id`)
) ENGINE=InnoDB AUTO_INCREMENT=90 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_relations`
--

LOCK TABLES `bolt_relations` WRITE;
/*!40000 ALTER TABLE `bolt_relations` DISABLE KEYS */;
INSERT INTO `bolt_relations` VALUES (1,'papers',1,'sessions',1),(2,'papers',2,'sessions',2),(3,'papers',3,'sessions',3),(4,'papers',4,'sessions',4),(5,'papers',5,'sessions',5),(6,'papers',6,'sessions',6),(8,'programme',1,'sessions',1),(9,'programme',2,'sessions',2),(10,'programme',3,'sessions',3),(14,'programme',6,'sessions',6),(15,'programme',7,'sessions',1),(20,'programme',12,'sessions',6),(23,'programme',8,'sessions',2),(24,'programme',9,'sessions',3),(25,'programme',13,'sessions',2),(26,'programme',14,'sessions',2),(27,'programme',15,'sessions',2),(28,'programme',16,'sessions',2),(29,'programme',17,'sessions',2),(30,'programme',18,'sessions',5),(31,'programme',19,'sessions',5),(32,'programme',20,'sessions',5),(33,'programme',21,'sessions',5),(34,'programme',22,'sessions',3),(35,'programme',23,'sessions',3),(36,'programme',24,'sessions',3),(37,'programme',25,'sessions',3),(38,'programme',26,'sessions',3),(39,'programme',27,'sessions',1),(40,'programme',28,'sessions',1),(41,'programme',29,'sessions',1),(42,'programme',30,'sessions',1),(43,'programme',31,'sessions',1),(44,'programme',32,'sessions',12),(45,'programme',33,'sessions',12),(46,'programme',34,'sessions',12),(47,'programme',35,'sessions',12),(48,'programme',36,'sessions',12),(49,'programme',37,'sessions',6),(50,'programme',38,'sessions',6),(51,'programme',39,'sessions',6),(52,'programme',40,'sessions',6),(53,'programme',41,'sessions',6),(54,'programme',42,'sessions',2),(55,'programme',43,'sessions',5),(56,'programme',44,'sessions',3),(57,'programme',45,'sessions',1),(58,'programme',46,'sessions',12),(59,'programme',47,'sessions',6),(60,'programme',48,'sessions',10),(61,'programme',49,'sessions',10),(62,'programme',50,'sessions',10),(63,'programme',51,'sessions',10),(64,'programme',52,'sessions',10),(65,'programme',53,'sessions',10),(66,'programme',54,'sessions',10),(67,'programme',55,'sessions',10),(68,'programme',56,'sessions',10),(69,'programme',57,'sessions',10),(71,'programme',59,'sessions',10),(72,'programme',60,'sessions',10),(73,'programme',61,'sessions',10),(74,'programme',10,'sessions',12),(75,'programme',11,'sessions',4),(76,'programme',4,'sessions',12),(77,'programme',5,'sessions',4),(78,'programme',62,'sessions',10),(79,'programme',63,'sessions',10),(80,'programme',64,'sessions',10),(81,'programme',65,'sessions',10),(82,'programme',66,'sessions',10),(83,'programme',67,'sessions',10),(84,'programme',68,'sessions',10),(85,'programme',69,'sessions',10),(86,'programme',70,'sessions',10),(87,'programme',71,'sessions',10),(88,'programme',72,'sessions',10),(89,'programme',73,'sessions',10);
/*!40000 ALTER TABLE `bolt_relations` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_sessions`
--

DROP TABLE IF EXISTS `bolt_sessions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_sessions` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `slug` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `datecreated` datetime NOT NULL,
  `datechanged` datetime NOT NULL,
  `datepublish` datetime DEFAULT NULL,
  `datedepublish` datetime DEFAULT NULL,
  `ownerid` int(11) DEFAULT NULL,
  `status` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `templatefields` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `title` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `teaser` longtext COLLATE utf8_unicode_ci,
  `detail` longtext COLLATE utf8_unicode_ci,
  `chair` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `location` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `locationlink` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `starttime` datetime DEFAULT NULL,
  `lengthmins` int(11) NOT NULL DEFAULT '0',
  `image` longtext COLLATE utf8_unicode_ci COMMENT '(DC2Type:json)',
  `imagecaption` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  `template` varchar(256) COLLATE utf8_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `IDX_CCD8372E989D9B62` (`slug`),
  KEY `IDX_CCD8372EAFBA6FD8` (`datecreated`),
  KEY `IDX_CCD8372EBE74E59A` (`datechanged`),
  KEY `IDX_CCD8372EA5131421` (`datepublish`),
  KEY `IDX_CCD8372EB7805520` (`datedepublish`),
  KEY `IDX_CCD8372E7B00651C` (`status`)
) ENGINE=InnoDB AUTO_INCREMENT=19 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_sessions`
--

LOCK TABLES `bolt_sessions` WRITE;
/*!40000 ALTER TABLE `bolt_sessions` DISABLE KEYS */;
INSERT INTO `bolt_sessions` VALUES (1,'ubicomp','2019-02-23 19:23:09','2019-10-23 10:58:28','2019-02-23 19:21:47',NULL,1,'published','[]','Ubiquitous Computing',NULL,NULL,'Barry Brown','The Great Hall',NULL,'2019-11-20 09:00:00',120,NULL,NULL,NULL),(2,'mxr','2019-02-23 19:28:26','2019-10-11 22:25:28','2019-02-23 19:27:05',NULL,1,'published','[]','Mixed Reality',NULL,NULL,'Asreen Rostami','The Great Hall',NULL,'2019-11-19 10:00:00',120,NULL,NULL,NULL),(3,'ai-humans-machines','2019-02-23 19:30:08','2019-10-11 22:25:42','2019-02-23 19:29:25',NULL,1,'published','[]','Artificial Intelligence, Humans, and Machines',NULL,NULL,'Shaun Lawson','The Great Hall',NULL,'2019-11-19 15:30:00',120,NULL,NULL,NULL),(4,'spaces-keynote','2019-02-23 19:32:08','2019-11-15 12:48:29','2019-02-23 19:31:25',NULL,1,'published','[]','Public and Private Spaces','To allow for lunch, this session is split with the keynote before lunch and [all papers and the panel discussion taking place after lunch](/session/spaces \"View details about the papers and panel discussion for this session\").',NULL,'Luigina Ciolfi','The Great Hall',NULL,'2019-11-20 11:30:00',45,NULL,NULL,NULL),(5,'spaces','2019-02-24 20:50:47','2019-11-15 12:48:33','2019-02-24 20:50:35',NULL,1,'published','[]','Public and Private Spaces','The keynote for this session is [before lunch](/session/spaces-keynote \"View details about the keynote\").',NULL,'Luigina Ciolfi','The Great Hall',NULL,'2019-11-20 13:15:00',75,NULL,NULL,NULL),(6,'research-design','2019-02-24 20:51:08','2019-11-14 18:59:26','2019-02-24 20:51:00',NULL,1,'published','[]','New Approaches to Research and Design',NULL,NULL,'Katherine Isbister','The Great Hall',NULL,'2019-11-20 15:00:00',120,NULL,NULL,NULL),(7,'welcome-and-opening-address','2019-06-01 18:25:05','2019-10-29 10:44:04','2019-06-01 18:23:24',NULL,1,'published','[]','Welcome and opening address','In early 2018, thoughts at the Mixed Reality Laboratory at the University of Nottingham turned to the impending 20th anniversary of the lab\'s foundation, in 1999. It was suggested by someone–who will remain nameless–that it would be great if we hosted a small \'celebration\' to mark the occasion. Skip forward in time to November 2019 and we find ourselves hosting an international conference with a full programme featuring 6 keynotes, 42 long and short papers, and a substantial number of attendees. \r\n\r\nHow did this happen? Put simply, Halfway to the Future *grew organically*. The logic of symposium had always been to explore the theme of past, present, and future of HCI and design-led research, with a focus on work that we felt had been deeply formative in shaping the research culture of the Mixed Reality Lab throughout its 20 year existence. It was on this basis that we selected themes and keynotes.\r\n\r\nAs we began to reflect upon the past 20 years, 6 themes emerged. These themes were then anchored around a particular piece of highly influential work. These all turned out to be very broad and formed the basis of 6 sessions. Unlike a typical conference with one or two keynote speakers that are kept separate from the main proceedings, we wanted each session to mix keynotes with peer reviewed long and short papers, and to bring together all participants in each panel to conclude with a discussion.\r\n\r\nLearn more about [our six themes and keynotes](/themes \"Details about the symposium themes and keynotes\").\r\n',NULL,NULL,'The Great Hall',NULL,'2019-11-19 09:30:00',30,NULL,NULL,NULL),(8,'symposium-dinner','2019-06-03 14:01:57','2019-11-19 17:22:46','2019-06-03 13:59:53',NULL,1,'published','[]','Symposium dinner','The symposium dinner will be held at the **Park Plaza Hotel** in Nottingham, after the drinks reception on the first night. The Park Plaza is a five-minute walk from main symposium venue, some of the way down Maid Marian Way.\r\n','The three-course dinner will include a free complimentary glass of Prosecco. Please note that this is a ticketed event—you must have registered and paid for the dinner during online registration. The cost is £36.\r\n\r\nFind the Park Plaza on [Google Maps](https://goo.gl/maps/y1rcpRd91cfphuKRA \"Park Plaza on Google Maps\") or [Apple Maps](https://maps.apple.com/?address=41%20Maid%20Marian%20Way,%20Nottingham,%20NG1%206GD,%20England&auid=12534055754666441526&ll=52.952759,-1.153371&lsp=9902&q=Park%20Plaza&_ext=ChkKBQgEEOEBCgQIBRADCgQIBhALCgQIChAAEiYpKqLLMWB5SkAxZCw2xbGR8r85qHfxjYZ6SkBBfgFrB59U8r9QBA%3D%3D&t=m \"Park Plaza on Apple Maps\").\r\n\r\n## Menu\r\nThe main menu is as follows, which includes options for those on vegetarian (V), vegan (VG), gluten free (GF), and Halal (H) diets.\r\n\r\nA choice of **starter**:<br>\r\n* Atlantic prawn cocktail with a Marie Rose sauce (H,GF)\r\n* Tomato and mozzarella salad with toasted pine nuts (V,H,GF)\r\n* Ham hock terrine (GF)\r\n* Roasted sweet potato soup (VG,H,GF)\r\n\r\nA choice of **main course**:<br>\r\n* Braised beef, dauphinoise potatoes, and seasonal vegetables, served with red wine jus (GF)\r\n* Poached salmon served with hollandaise sauce and new potatoes (H,GF)\r\n* Four cheese tortellini (V,H)\r\n* Aubergine steak with stuffed vegetables (VG,H,GF)\r\n \r\nA choice of **dessert**:<br>\r\n* Eton mess (V,GF)\r\n* Sticky toffee pudding with toffee sauce and ice cream (V,H)\r\n* Dark chocolate tart served with Chantilly ice cream (V,H)\r\n* Strawberry chia seed pudding (VG,H,GF)\r\n\r\nIf you have other dietary requirements, please contact the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\") and we will liaise with the venue.\r\n\r\n## Making your choice\r\n\r\nThose who have registered and paid for the symposium dinner will be sent an email asking them to confirm meal choices closer to the time. The menu is subject to change, although this is highly unlikely.',NULL,'11th floor, Park Plaza Nottingham','https://www.radissonhotels.com/en-us/hotels/park-plaza-nottingham?facilitatorId=PARKPLAZAPPCBMM&cid=a:ps+b:ggl+c:emea+i:brand+e:pph+d:cese+f:en-US+h:gbnottin&gclsrc=aw.ds&&gclid=EAIaIQobChMI_q2vpI-z5AIVVODtCh0MvQEVEAAYASAAEgJhtPD_BwE','2019-11-19 19:00:00',180,'{\"file\":\"2019-05/parkplaza.jpg\",\"alt\":\"The Park Plaza, Nottingham\"}','The Park Plaza, Nottingham',NULL),(9,'welcome-reception','2019-06-07 19:15:25','2019-10-29 08:28:25','2019-06-07 19:14:03',NULL,1,'published','[]','Welcome reception','We are hosting a free **welcome reception** at [Nottingham Contemporary](https://www.nottinghamcontemporary.org/ \"Website for Nottingham Contemporary\") on **Monday 18th November** at **7pm**. This event is open to symposium attendees as well as colleagues from the University of Nottingham, who have sponsored the event, and includes free nibbles and drinks.\r\n\r\n**Attendees must have a ticket for entry (details have been sent to all those who have registered for the symposium).**','Nottingham Contemporary is one of the largest contemporary art galleries in the UK, presenting free exhibitions, special events, and family activities. It is located on the edge of the Lace Market area of Nottingham, near to Nottingham Railway Station and the Broadmarsh Shopping Centre (which is closed for redevelopment). It is a ten-minute walk from the main symposium venue through the centre of Nottingham.\r\n\r\nFind the gallery on [Google Maps](https://goo.gl/maps/G6CgyW1Uuz3XhLGB6 \"Google Maps information for Nottingham Contemporary\") and [Apple Maps](https://maps.apple.com/?address=Weekday%20Cross,%20Nottingham,%20NG1%202GB,%20England&auid=11838304277092172405&ll=52.951105,-1.145893&lsp=9902&q=Nottingham%20Contemporary&_ext=ChoKBQgEEOEBCgQIBRADCgUIBhCFAQoECAoQABIkKR+RPVEyeUpAMV40bGWyc/K/OZ1mY61YekpAQZzdMCmgNvK/&t=m \"Nottingham Contemporary on Apple Maps\").\r\n\r\nThis event has been sponsored by the University of Nottingham [Creative and Digital Interdisciplinary Research Cluster](https://www.nottingham.ac.uk/research/research-areas/creative-and-digital/index.aspx \"Creative and Digital IRC website\"). We are very grateful for their support.',NULL,'Nottingham Contemporary','https://www.nottinghamcontemporary.org','2019-11-18 19:00:00',180,'{\"file\":\"2019-06/nottinghamcontemporary.jpg\",\"alt\":\"Nottingham Contemporary\"}','Nottingham Contemporary',NULL),(10,'posters-and-demos','2019-06-27 12:00:19','2019-11-08 18:27:43','2019-06-27 11:56:57',NULL,1,'published','[]','Posters, demos, and drinks reception','Come and browse the posters and demos on the ground and first floor of the Albert Hall Conference Centre. This will coincide with the first night\'s drinks reception, which will take place after the first day\'s activities.\r\n\r\nThis event is **free for all symposium attendees**.',NULL,NULL,'Foyer, Osborne Lounge, and Balmoral Gallery',NULL,'2019-11-19 17:30:00',90,NULL,NULL,NULL),(11,'registration','2019-06-27 12:50:22','2019-11-17 15:52:26','2019-06-27 12:48:36',NULL,1,'published','[]','Registration','Symposium registration will open from 8.30am in the [Albert Hall Conference Centre](/venue). Read our [travel information](/travel \"Travel information for HttF\") to help with finding the venue.\r\n\r\n**Refreshments and pastries** will be available in the **Osborne Suite**.','The main entrance to the Albert Hall—on North Circus Street—is not accessible by wheelchair due to steps inside the venue. The alternative entrance on the roundabout from Main Marian Way will be open as an accessible entrance. Please email the [Local Organisation Chair](mailto:local@halfwaytothefuture.org \"Local Organisation Chair email\") to make us aware of your accessibility requirements before the symposium.',NULL,'Foyer',NULL,'2019-11-19 08:30:00',60,NULL,NULL,NULL),(12,'arts-design','2019-09-02 13:11:19','2019-11-15 12:47:17','2019-09-02 13:08:05',NULL,1,'published','[]','Arts and Design-led Approaches',NULL,NULL,'Abigail Durrant','The Great Hall',NULL,'2019-11-19 13:00:00',120,NULL,NULL,NULL),(13,'lunch-tuesday','2019-09-02 13:15:58','2019-11-19 11:38:29','2019-09-02 13:14:53',NULL,1,'published','[]','Lunch','We will provide a free buffet lunch for all attendees on the ground floor of the Albert Hall Conference Centre.\r\n\r\nIf you have any dietary requirements, especially if these have changed since you registered, please alert us immediately by emailing the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\").',NULL,NULL,'Osborne Suite',NULL,'2019-11-19 12:00:00',60,NULL,NULL,NULL),(14,'break','2019-09-02 13:17:51','2019-11-19 11:38:40','2019-09-02 13:16:59',NULL,1,'published','[]','Break','There will be a half an hour break with refreshments on the ground floor of the Albert Hall Conference Centre.\r\n\r\nIf you have any dietary requirements, especially if these have changed since you registered, please alert us immediately by emailing the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\").',NULL,NULL,'Osborne Suite',NULL,'2019-11-19 15:00:00',30,NULL,NULL,NULL),(15,'lunch-wednesday','2019-09-02 13:23:30','2019-11-19 11:38:55','2019-09-02 13:23:08',NULL,1,'published','[]','Lunch','We will provide a free buffet lunch for all attendees on the ground floor of the Albert Hall Conference Centre.\r\n\r\nIf you have any dietary requirements, especially if these have changed since you registered, please alert us immediately by emailing the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\").',NULL,NULL,'Osborne Suite',NULL,'2019-11-20 12:15:00',60,NULL,NULL,NULL),(16,'break-2','2019-09-02 13:24:09','2019-11-19 11:40:29','2019-09-02 13:23:47',NULL,1,'published','[]','Break','There will be a half an hour break with refreshments on the ground floor of the Albert Hall Conference Centre.\r\n\r\nIf you have any dietary requirements, especially if these have changed since you registered, please alert us immediately by emailing the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\").',NULL,NULL,'Osborne Suite',NULL,'2019-11-20 11:00:00',30,NULL,NULL,NULL),(17,'break-3','2019-09-02 13:24:46','2019-11-19 11:40:49','2019-09-02 13:24:23',NULL,1,'published','[]','Break','There will be a half an hour break with refreshments on the ground floor of the Albert Hall Conference Centre.\r\n\r\nIf you have any dietary requirements, especially if these have changed since you registered, please alert us immediately by emailing the [Registration Chair](mailto:registration@halfwaytothefuture.org \"Email the Registration Chair\").',NULL,NULL,'Osborne Suite',NULL,'2019-11-20 14:30:00',30,NULL,NULL,NULL),(18,'symposium-closes','2019-09-02 16:50:09','2019-11-20 15:53:46','2019-09-02 16:49:25',NULL,1,'published','[]','Symposium closes','Thank you for attending Halfway to the Future! We look forward to seeing what the next half of the future holds.\r\n\r\nThe chairs will say a few words before closing the symposium.\r\n\r\nJoel E. Fischer, Sarah Martindale, Martin Porcheron, Stuart Reeves, and Jocelyn Spence<br>\r\n*General Chairs, HttF 2019*',NULL,NULL,'The Great Hall',NULL,'2019-11-20 17:00:00',5,NULL,NULL,NULL);
/*!40000 ALTER TABLE `bolt_sessions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_taxonomy`
--

DROP TABLE IF EXISTS `bolt_taxonomy`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_taxonomy` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `content_id` int(11) NOT NULL,
  `contenttype` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `taxonomytype` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `slug` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `name` varchar(64) COLLATE utf8_unicode_ci NOT NULL,
  `sortorder` int(11) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  KEY `IDX_ABAA120084A0A3ED` (`content_id`),
  KEY `IDX_ABAA1200745E1826` (`contenttype`),
  KEY `IDX_ABAA1200FE2A268F` (`taxonomytype`),
  KEY `IDX_ABAA1200989D9B62` (`slug`),
  KEY `IDX_ABAA1200FEA3B3F9` (`sortorder`)
) ENGINE=InnoDB AUTO_INCREMENT=540 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_taxonomy`
--

LOCK TABLES `bolt_taxonomy` WRITE;
/*!40000 ALTER TABLE `bolt_taxonomy` DISABLE KEYS */;
INSERT INTO `bolt_taxonomy` VALUES (3,1,'pages','menu','authors','Author information',0),(4,2,'pages','menu','organisers','Organisers',1),(5,3,'pages','menu','organisers','Organisers',0),(7,4,'pages','menu','programme','Programme',0),(9,6,'pages','menu','programme','Programme',0),(10,5,'pages','menu','attending','Attendee information',0),(11,7,'pages','menu','attending','Attendee information',0),(12,8,'pages','menu','','',0),(13,1,'pages','categories','authors','Author information',0),(14,1,'pages','in_menu','yes','Yes',0),(15,2,'pages','categories','organisers','Organisers',0),(17,2,'pages','in_menu','yes','Yes',0),(18,3,'pages','categories','organisers','Organisers',1),(19,3,'pages','in_menu','yes','Yes',0),(22,5,'pages','categories','attending','Attendee information',0),(23,5,'pages','in_menu','yes','Yes',0),(24,6,'pages','categories','programme','Programme',0),(26,7,'pages','categories','attending','Attendee information',2),(27,7,'pages','in_menu','yes','Yes',0),(29,8,'pages','in_menu','','',0),(30,4,'pages','categories','programme','Programme',1),(32,9,'pages','in_menu','yes','Yes',0),(36,1,'panels','panels','ubicomp','Ubiquitous Computing',0),(37,1,'panels','types','keynote','Keynote',0),(38,2,'panels','panels','mr','Mixed Reality',0),(39,2,'panels','types','keynote','Keynote',0),(44,3,'panels','panels','mr','Mixed Reality',0),(45,3,'panels','types','reflective','Reflective paper',0),(46,4,'panels','panels','mr','Mixed Reality',0),(47,4,'panels','types','prospective','Prospective paper',0),(52,2,'papers','panels','mr','Mixed Reality',0),(53,2,'papers','types','keynote','Keynote',0),(54,3,'papers','panels','aiandhumans','Artificial Intelligence, Humans & Machines',0),(56,4,'papers','panels','artsdesign','Arts & Design-led Approaches',0),(57,4,'papers','types','keynote','Keynote',0),(58,5,'papers','panels','publicprivate','Public & Private Spaces',0),(59,5,'papers','types','keynote','Keynote',0),(60,6,'papers','panels','researchdesign','New Approaches to Research & Design',0),(61,6,'papers','types','keynote','Keynote',0),(62,10,'pages','categories','programme','Programme',0),(67,1,'papers','types','keynote','Keynote',0),(69,1,'papers','panels','ubicomp','Ubiquitous Computing',0),(70,11,'pages','categories','','',0),(71,11,'pages','in_menu','','',0),(75,3,'papers','types','keynote','Keynote',0),(92,12,'pages','categories','authors','Author information',3),(93,12,'pages','in_menu','yes','Yes',0),(94,13,'pages','categories','attending','Attendee information',5),(97,1,'programme','types','theme-setting','Theme-setting',0),(98,2,'programme','types','theme-setting','Theme-setting',0),(99,3,'programme','types','theme-setting','Theme-setting',0),(100,4,'programme','types','theme-setting','Theme-setting',0),(101,5,'programme','types','theme-setting','Theme-setting',0),(102,6,'programme','types','theme-setting','Theme-setting',0),(103,8,'pages','categories','','',0),(105,14,'pages','in_menu','','',0),(106,14,'pages','categories','emails','Emails',1),(108,15,'pages','in_menu','','',0),(109,15,'pages','categories','emails','Emails',0),(110,4,'pages','in_menu','yes','Yes',0),(112,16,'pages','in_menu','no','No',0),(113,17,'pages','categories','authors','Author information',1),(115,16,'pages','categories','emails','Emails',2),(116,17,'pages','in_menu','yes','Yes',0),(117,9,'pages','categories','programme','Programme',1),(118,18,'pages','categories','attending','Attendee information',0),(119,18,'pages','in_menu','no','No',0),(120,19,'pages','categories','attending','Attendee information',0),(122,19,'pages','in_menu','no','No',0),(123,20,'pages','categories','attending','Attendee information',4),(124,20,'pages','in_menu','yes','Yes',0),(127,21,'pages','categories','attending','Attendee information',1),(128,21,'pages','in_menu','yes','Yes',0),(129,13,'pages','in_menu','no','No',0),(132,22,'pages','categories','attending','Attendee information',3),(133,22,'pages','in_menu','yes','Yes',0),(134,23,'pages','categories','attending','Attendee information',2),(135,23,'pages','in_menu','','',0),(140,25,'pages','categories','attending','Attendee information',2),(142,7,'programme','types','keynote','Keynote',0),(143,8,'programme','types','keynote','Keynote',0),(144,9,'programme','types','keynote','Keynote',0),(146,10,'programme','types','keynote','Keynote',0),(147,11,'programme','types','keynote','Keynote',0),(148,12,'programme','types','keynote','Keynote',0),(149,1,'panels','session_types','panel','Paper/panel session',0),(150,6,'panels','session_types','panel','Papers and panel',0),(151,5,'panels','session_types','panel','Papers and panel',0),(152,4,'panels','session_types','panel','Papers and panel',0),(153,3,'panels','session_types','panel','Papers and panel',0),(154,2,'panels','session_types','panel','Papers and panel',0),(156,7,'sessions','session_types','general','General address',0),(166,26,'pages','in_menu','','',0),(167,26,'pages','categories','emails','Emails',3),(168,25,'pages','in_menu','yes','Yes',0),(170,9,'sessions','session_types','event','Event',0),(171,8,'sessions','session_types','event','Event',0),(173,27,'pages','in_menu','','',0),(174,27,'pages','categories','emails','Emails',4),(175,28,'pages','categories','attending','Attendee information',3),(176,28,'pages','in_menu','','',0),(177,10,'sessions','session_types','event','Event',0),(178,11,'sessions','session_types','event','Event',0),(179,29,'pages','categories','programme','Programme',0),(180,29,'pages','in_menu','no','No',0),(181,30,'pages','categories','emails','Emails',5),(182,30,'pages','in_menu','','',0),(185,31,'pages','categories','authors','Author information',2),(186,31,'pages','in_menu','yes','Yes',0),(188,32,'pages','in_menu','yes','Yes',0),(189,32,'pages','categories','','',0),(191,13,'sessions','session_types','break','Break',0),(192,14,'sessions','session_types','break','Break',0),(193,1,'sessions','session_types','general','Session',0),(194,2,'sessions','session_types','general','Session',0),(195,3,'sessions','session_types','general','Session',0),(196,4,'sessions','session_types','general','Session',0),(197,5,'sessions','session_types','general','Session',0),(198,6,'sessions','session_types','general','Session',0),(199,12,'sessions','session_types','general','Session',0),(200,15,'sessions','session_types','break','Break',0),(201,16,'sessions','session_types','break','Break',0),(202,17,'sessions','session_types','break','Break',0),(203,13,'programme','types','reflective','Reflective paper',1),(204,14,'programme','types','reflective','Reflective paper',2),(205,15,'programme','types','prospective','Future-looking paper',3),(206,16,'programme','types','prospective','Future-looking paper',4),(207,17,'programme','types','prospective','Future-looking paper',5),(208,18,'programme','types','reflective','Reflective paper',1),(209,19,'programme','types','reflective','Reflective paper',2),(210,20,'programme','types','reflective','Reflective paper',3),(211,21,'programme','types','prospective','Future-looking paper',4),(212,22,'programme','types','reflective','Reflective paper',1),(213,23,'programme','types','prospective','Future-looking paper',2),(214,24,'programme','types','prospective','Future-looking paper',3),(215,25,'programme','types','prospective','Future-looking paper',4),(216,26,'programme','types','prospective','Future-looking paper',5),(217,27,'programme','types','reflective','Reflective paper',1),(218,28,'programme','types','reflective','Reflective paper',2),(219,29,'programme','types','reflective','Reflective paper',3),(220,30,'programme','types','prospective','Future-looking paper',4),(221,31,'programme','types','prospective','Future-looking paper',5),(222,32,'programme','types','reflective','Reflective paper',1),(223,33,'programme','types','reflective','Reflective paper',2),(224,34,'programme','types','reflective','Reflective paper',3),(225,35,'programme','types','prospective','Future-looking paper',4),(226,36,'programme','types','prospective','Future-looking paper',5),(228,38,'programme','types','reflective','Reflective paper',2),(229,39,'programme','types','reflective','Reflective paper',3),(230,40,'programme','types','reflective','Reflective paper',4),(231,41,'programme','types','prospective','Future-looking paper',5),(232,42,'programme','types','panel','Panel',6),(233,43,'programme','types','panel','Panel',5),(234,44,'programme','types','panel','Panel',6),(235,45,'programme','types','panel','Panel',6),(236,46,'programme','types','panel','Panel',5),(237,47,'programme','types','panel','Panel',6),(238,18,'sessions','session_types','event','Event',0),(239,48,'programme','types','reflective','Reflective paper',0),(240,49,'programme','types','reflective','Reflective paper',1),(241,50,'programme','types','reflective','Reflective paper',2),(242,51,'programme','types','reflective','Reflective paper',3),(243,52,'programme','types','prospective','Future-looking paper',4),(244,53,'programme','types','reflective','Reflective paper',5),(245,54,'programme','types','prospective','Future-looking paper',6),(246,55,'programme','types','prospective','Future-looking paper',7),(247,56,'programme','types','prospective','Future-looking paper',8),(248,57,'programme','types','reflective','Reflective paper',9),(250,59,'programme','types','prospective','Future-looking paper',11),(251,60,'programme','types','prospective','Future-looking paper',12),(252,61,'programme','types','prospective','Future-looking paper',13),(253,33,'pages','categories','emails','Emails',6),(254,33,'pages','in_menu','','',0),(255,10,'pages','in_menu','yes','Yes',0),(256,6,'pages','in_menu','no','No',0),(257,15,'programme','tags','disaster-response','disaster response',0),(258,15,'programme','tags','search-and-rescue','search and rescue',0),(259,15,'programme','tags','augmented-reality','augmented reality',0),(260,15,'programme','tags','crowdsourcing','crowdsourcing',0),(261,15,'programme','tags','volunteers','volunteers',0),(262,15,'programme','tags','drones','drones',0),(263,15,'programme','tags','video-games','video games',0),(264,15,'programme','tags','design-fiction','design fiction',0),(265,39,'programme','tags','post-interaction','post-interaction',0),(266,39,'programme','tags','hci','HCI',0),(267,39,'programme','tags','interaction','interaction',0),(268,39,'programme','tags','immediacy','immediacy',0),(269,39,'programme','tags','intentionality','intentionality',0),(270,39,'programme','tags','instability','instability',0),(271,39,'programme','tags','interaction-effects','interaction effects',0),(272,17,'programme','tags','filmed-vr','filmed VR',0),(273,17,'programme','tags','360-video','360 video',0),(274,17,'programme','tags','virtual-reality','virtual reality',0),(275,17,'programme','tags','computer-science','computer science',0),(276,17,'programme','tags','healthcare','healthcare',0),(277,17,'programme','tags','elderly-care','elderly care',0),(278,17,'programme','tags','phobia-treatment','phobia treatment',0),(279,56,'programme','tags','abstract-space','abstract space',0),(280,56,'programme','tags','artificial-neural-networks','artificial neural networks',0),(281,56,'programme','tags','philosophy-of-information','philosophy of information',0),(282,60,'programme','tags','empowerment','empowerment',0),(283,60,'programme','tags','power','power',0),(284,60,'programme','tags','researcher-responsibility','researcher responsibility',0),(285,2,'programme','tags','performance','performance',0),(286,2,'programme','tags','traversable-interfaces','traversable interfaces',0),(287,2,'programme','tags','mixed-reality','mixed reality',0),(288,4,'programme','tags','interaction-design','interaction design',0),(289,4,'programme','tags','emotion-and-affective-ui','emotion and affective UI',0),(290,4,'programme','tags','design','design',0),(291,4,'programme','tags','theory','theory',0),(292,4,'programme','tags','design-tips-and-tricks','design tips and tricks',0),(293,4,'programme','tags','heuristics','heuristics',0),(294,4,'programme','tags','interpretation','interpretation',0),(295,1,'programme','tags','calm-computing','calm computing',0),(296,1,'programme','tags','weiser','Weiser',0),(297,1,'programme','tags','user-experiences','user experiences',0),(298,1,'programme','tags','engaged-living','engaged living',0),(299,1,'programme','tags','ubi-comp-history','ubi-comp history',0),(300,1,'programme','tags','pervasive-technologies','pervasive technologies',0),(301,1,'programme','tags','proactive-computing','proactive computing',0),(302,5,'programme','tags','task-coordination','task coordination',0),(303,5,'programme','tags','communicative-practices','communicative practices',0),(304,5,'programme','tags','work-practices','work practices',0),(305,5,'programme','tags','ethnography','ethnography',0),(306,5,'programme','tags','cscw','CSCW',0),(307,6,'programme','tags','multiplicity','multiplicity',0),(308,6,'programme','tags','context','context',0),(309,6,'programme','tags','boundaries','boundaries',0),(310,6,'programme','tags','experience','experience',0),(311,6,'programme','tags','participation','participation',0),(312,23,'programme','tags','physical-copresence','physical copresence',0),(313,23,'programme','tags','collective-action','collective action',0),(314,23,'programme','tags','suprahuman-technology','suprahuman technology',0),(315,40,'programme','tags','manifestos','manifestos',0),(316,40,'programme','tags','fourth-wave-hci','fourth-wave HCI',0),(317,40,'programme','tags','games','games',0),(318,40,'programme','tags','tableau-vivant','tableau vivant',0),(319,40,'programme','tags','activism','activism',0),(320,40,'programme','tags','creative-subversion','creative subversion',0),(321,31,'programme','tags','design-fiction','design fiction',0),(322,31,'programme','tags','ubicomp','ubicomp',0),(323,31,'programme','tags','behavioural-psychology','behavioural psychology',0),(324,31,'programme','tags','freedom','freedom',0),(325,16,'programme','tags','augmented-reality','augmented reality',0),(326,16,'programme','tags','mixed-reality','mixed reality',0),(327,16,'programme','tags','virtual-reality','virtual reality',0),(328,16,'programme','tags','sensory-stimulation','sensory stimulation',0),(329,36,'programme','tags','sociomaterial-practice','sociomaterial practice',0),(330,36,'programme','tags','design-representation','design representation',0),(331,36,'programme','tags','design-enactment','design enactment',0),(332,36,'programme','tags','innovation','innovation',0),(333,59,'programme','tags','practice-theory','practice theory',0),(334,59,'programme','tags','third-wave-of-hci','third wave of HCI',0),(335,59,'programme','tags','consumption','consumption',0),(336,59,'programme','tags','food-lifecycle','food lifecycle',0),(337,59,'programme','tags','network-of-practices','network of practices',0),(338,54,'programme','tags','sonic-intervention','sonic intervention',0),(339,54,'programme','tags','auditory-play','auditory play',0),(340,54,'programme','tags','street-art','street art',0),(341,54,'programme','tags','playful-interaction','playful interaction',0),(342,54,'programme','tags','ubiquitous-computing','ubiquitous computing',0),(343,54,'programme','tags','ambient-interface','ambient interface',0),(344,54,'programme','tags','everyday-objects','everyday objects',0),(345,48,'programme','tags','virtual-reality','virtual reality',0),(346,48,'programme','tags','human-robot-interaction','human-robot interaction',0),(347,48,'programme','tags','industrial-robots','industrial robots',0),(348,48,'programme','tags','human-behaviour','human behaviour',0),(349,27,'programme','tags','communal-practices','communal practices',0),(350,27,'programme','tags','household-group-efficacy','household group-efficacy',0),(351,27,'programme','tags','smart-home','smart home',0),(352,28,'programme','tags','human-computer-interaction','human computer interaction',0),(353,28,'programme','tags','human-data-interaction','human data interaction',0),(354,28,'programme','tags','smart-homes','smart homes',0),(355,28,'programme','tags','internet-of-things','internet of things',0),(356,28,'programme','tags','interaction-design-theory','interaction design theory',0),(357,32,'programme','tags','soma-design','soma design',0),(358,32,'programme','tags','pluralism','pluralism',0),(359,32,'programme','tags','dualism','dualism',0),(360,35,'programme','tags','nonconscious','nonconscious',0),(361,35,'programme','tags','tacit-knowledge','tacit knowledge',0),(362,35,'programme','tags','ideomotor','ideomotor',0),(363,35,'programme','tags','co-design','co-design',0),(364,35,'programme','tags','decision-making','decision making',0),(365,35,'programme','tags','paranormal','paranormal',0),(366,35,'programme','tags','automatism','automatism',0),(367,35,'programme','tags','wearable','wearable',0),(368,35,'programme','tags','vr','VR',0),(369,35,'programme','tags','ouija','ouija',0),(370,35,'programme','tags','design-research','design research',0),(371,35,'programme','tags','participatory-design','participatory design',0),(372,35,'programme','tags','creativity','creativity',0),(373,35,'programme','tags','ideation','ideation',0),(374,26,'programme','tags','ethics','ethics',0),(375,26,'programme','tags','algorithms','algorithms',0),(376,26,'programme','tags','artificial-intelligence','artificial intelligence',0),(377,26,'programme','tags','human-rights','human rights',0),(378,26,'programme','tags','policy','policy',0),(379,37,'programme','tags','participatory-design','participatory design',0),(380,37,'programme','tags','responsible-innovation','responsible innovation',0),(381,37,'programme','tags','creative-industries','creative industries',0),(382,37,'programme','tags','data-driven-innovation','data-driven innovation',0),(383,41,'programme','tags','hci','HCI',0),(384,41,'programme','tags','participatory-design','participatory design',0),(385,41,'programme','tags','situated-play-design','situated play design',0),(386,41,'programme','tags','play','play',0),(387,41,'programme','tags','playfulness','playfulness',0),(388,41,'programme','tags','design-methods','design methods',0),(389,41,'programme','tags','research-through-design','research through design',0),(391,34,'programme','tags','design-fiction','design fiction',0),(392,34,'programme','tags','drawing','drawing',0),(393,34,'programme','tags','sketching','sketching',0),(394,34,'programme','tags','comics','comics',0),(395,34,'programme','tags','scenarios','scenarios',0),(396,34,'programme','tags','future','future',0),(397,33,'programme','tags','constructive-design-research','constructive design research',0),(398,33,'programme','tags','graceful-interaction','graceful interaction',0),(399,33,'programme','tags','exercise-intentions','exercise intentions',0),(400,33,'programme','tags','wearable-technology','wearable technology',0),(401,33,'programme','tags','social-support','social support',0),(402,33,'programme','tags','aesthetics-of-interaction','aesthetics of interaction',0),(403,14,'programme','tags','mixed-reality','mixed reality',0),(404,14,'programme','tags','experience-blend','experience blend',0),(405,14,'programme','tags','blend-framework','blend framework',0),(406,14,'programme','tags','hci-in-museums','HCI in museums',0),(407,21,'programme','tags','creativity','creativity',0),(408,21,'programme','tags','design-fiction','design fiction',0),(409,21,'programme','tags','drones','drones',0),(410,21,'programme','tags','ethics','ethics',0),(411,21,'programme','tags','hci','HCI',0),(412,21,'programme','tags','ubicomp','ubicomp',0),(413,21,'programme','tags','gig-economy','gig economy',0),(414,21,'programme','tags','fictional-abstracts','fictional abstracts',0),(415,21,'programme','tags','human-security','human security',0),(416,21,'programme','tags','future-studies','future studies',0),(417,21,'programme','tags','existentialism','existentialism',0),(418,21,'programme','tags','logistics','logistics',0),(419,21,'programme','tags','ai','AI',0),(420,21,'programme','tags','autonomous-vehicles','autonomous vehicles',0),(421,21,'programme','tags','justice','justice',0),(422,21,'programme','tags','pervasive-computing','pervasive computing',0),(424,25,'programme','tags','conversation-analysis','conversation analysis',0),(425,25,'programme','tags','ethnomethodology','ethnomethodology',0),(426,25,'programme','tags','social-interaction','social interaction',0),(427,25,'programme','tags','artificial-agents','artificial agents',0),(428,51,'programme','tags','design','design',0),(429,51,'programme','tags','games','games',0),(430,51,'programme','tags','interaction-design','interaction design',0),(431,51,'programme','tags','gaze-interaction','gaze interaction',0),(433,30,'programme','tags','social-ai','social AI',0),(434,30,'programme','tags','engaging-ubicomp','engaging ubicomp',0),(435,30,'programme','tags','calm-technology','calm technology',0),(436,30,'programme','tags','human-ai-interaction','human-AI interaction',0),(437,53,'programme','tags','ethnography','ethnography',0),(438,53,'programme','tags','urban-interaction-design','urban interaction design',0),(439,53,'programme','tags','place-attachment','place attachment',0),(440,53,'programme','tags','speculative-design','speculative design',0),(441,53,'programme','tags','design-fictions','design fictions',0),(442,53,'programme','tags','emotion','emotion',0),(443,53,'programme','tags','urban-place','urban place',0),(444,53,'programme','tags','smart-city','smart city',0),(445,53,'programme','tags','walking-talking-method','walking & talking method',0),(446,53,'programme','tags','design-techniques','design techniques',0),(447,53,'programme','tags','ambiguity','ambiguity',0),(448,53,'programme','tags','pact-analysis','PACT-analysis',0),(449,53,'programme','tags','scamper','SCAMPER',0),(450,34,'pages','categories','attending','Attendee information',0),(451,34,'pages','in_menu','no','No',0),(452,61,'programme','tags','research-trajectories','research trajectories',0),(453,61,'programme','tags','intelligence-augmentation','intelligence augmentation',0),(454,61,'programme','tags','intelligence-amplification','intelligence amplification',0),(455,55,'programme','tags','artificial-intelligence','artificial intelligence',0),(456,55,'programme','tags','design-fiction','design fiction',0),(457,55,'programme','tags','participatory-design','participatory design',0),(458,55,'programme','tags','machine-teaching','machine teaching',0),(460,49,'programme','tags','interaction','interaction',0),(461,49,'programme','tags','research-through-design','research through design',0),(462,49,'programme','tags','health','health',0),(463,49,'programme','tags','care','care',0),(464,49,'programme','tags','futures','futures',0),(465,49,'programme','tags','speculation','speculation',0),(467,18,'programme','tags','interaction-design','interaction design',0),(468,18,'programme','tags','service-design','service design',0),(469,18,'programme','tags','hci-research','HCI research',0),(470,18,'programme','tags','values','values',0),(471,57,'programme','tags','fnirs','fNIRS',0),(472,57,'programme','tags','mental-workload','mental workload',0),(473,57,'programme','tags','machine-learning','machine learning',0),(474,57,'programme','tags','deep-learning','deep learning',0),(475,13,'programme','tags','mixed-reality','mixed reality',0),(476,13,'programme','tags','ubiquitous-computing','ubiquitous computing',0),(477,13,'programme','tags','functional-fabrication','functional fabrication',0),(478,13,'programme','tags','thin-film-device-engineering','thin film device engineering',0),(479,13,'programme','tags','tangible-design','tangible design',0),(481,19,'programme','tags','patient-empowerment','patient empowerment',0),(482,19,'programme','tags','articulation-work','articulation work',0),(483,19,'programme','tags','coordination-mechanisms','coordination mechanisms',0),(484,19,'programme','tags','visibility','visibility',0),(485,19,'programme','tags','micro-mobility','micro-mobility',0),(486,20,'programme','tags','ethics','ethics',0),(487,20,'programme','tags','ethnography','ethnography',0),(488,20,'programme','tags','object-oriented-ontology','object oriented ontology',0),(489,20,'programme','tags','thing-ethnography','thing ethnography',0),(490,20,'programme','tags','ethnomining','ethnomining',0),(491,20,'programme','tags','surveillance-capitalism','surveillance capitalism',0),(492,20,'programme','tags','biography-of-artefacts','biography of artefacts',0),(493,20,'programme','tags','third-wave-hci','third wave HCI',0),(495,29,'programme','tags','games','games',0),(496,29,'programme','tags','hci','HCI',0),(497,29,'programme','tags','ubiquitous-computing','ubiquitous computing',0),(498,29,'programme','tags','bacteria','bacteria',0),(499,29,'programme','tags','micro-organisms','micro-organisms',0),(500,29,'programme','tags','edutainment','edutainment',0),(501,29,'programme','tags','iot','IoT',0),(502,22,'programme','tags','ethnomethodology','ethnomethodology',0),(503,22,'programme','tags','human-robot-interaction','human-robot interaction',0),(504,22,'programme','tags','responsible-innovation','responsible innovation',0),(505,22,'programme','tags','social-robots','social robots',0),(507,38,'programme','tags','hci-format','HCI-format',0),(508,38,'programme','tags','value-in-experience','value in experience',0),(509,38,'programme','tags','knowledge-contribution','knowledge contribution',0),(510,52,'programme','tags','social-design','social design',0),(511,52,'programme','tags','civic-engagement','civic engagement',0),(512,52,'programme','tags','research-through-design','research-through-design',0),(513,52,'programme','tags','open-source-technology','open source technology',0),(514,50,'programme','tags','interaction-design','interaction design',0),(515,50,'programme','tags','immersive-experience','immersive experience',0),(516,50,'programme','tags','the-immersive-aesthetic','the immersive aesthetic',0),(517,50,'programme','tags','the-sublime','the sublime',0),(518,50,'programme','tags','experience-design','experience design',0),(519,50,'programme','tags','agent-modeling','agent modeling',0),(520,50,'programme','tags','audience-agency','audience agency',0),(521,50,'programme','tags','conceptualizing-audiences','conceptualizing audiences',0),(522,37,'programme','types','prospective','Future-looking paper',1),(524,62,'programme','types','demo','Demo',0),(525,63,'programme','types','demo','Demo',0),(526,64,'programme','types','demo','Demo',0),(527,65,'programme','types','demo','Demo',0),(528,66,'programme','types','demo','Demo',0),(529,67,'programme','types','demo','Demo',0),(530,68,'programme','types','demo','Demo',0),(531,69,'programme','types','demo','Demo',0),(532,70,'programme','types','demo','Demo',0),(533,71,'programme','types','demo','Demo',0),(534,72,'programme','types','demo','Demo',0),(535,73,'programme','types','demo','Demo',0),(536,35,'pages','categories','programme','Programme',0),(537,35,'pages','in_menu','','',0),(538,24,'pages','categories','programme','Programme',4),(539,24,'pages','in_menu','yes','Yes',0);
/*!40000 ALTER TABLE `bolt_taxonomy` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `bolt_users`
--

DROP TABLE IF EXISTS `bolt_users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `bolt_users` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `password` varchar(128) COLLATE utf8_unicode_ci NOT NULL,
  `email` varchar(254) COLLATE utf8_unicode_ci NOT NULL,
  `lastseen` datetime DEFAULT NULL,
  `lastip` varchar(45) COLLATE utf8_unicode_ci DEFAULT NULL,
  `displayname` varchar(32) COLLATE utf8_unicode_ci NOT NULL,
  `stack` longtext COLLATE utf8_unicode_ci NOT NULL COMMENT '(DC2Type:json)',
  `enabled` tinyint(1) NOT NULL DEFAULT '1',
  `shadowpassword` varchar(128) COLLATE utf8_unicode_ci DEFAULT NULL,
  `shadowtoken` varchar(128) COLLATE utf8_unicode_ci DEFAULT NULL,
  `shadowvalidity` datetime DEFAULT NULL,
  `failedlogins` int(11) NOT NULL DEFAULT '0',
  `throttleduntil` datetime DEFAULT NULL,
  `roles` longtext COLLATE utf8_unicode_ci NOT NULL COMMENT '(DC2Type:json)',
  PRIMARY KEY (`id`),
  UNIQUE KEY `UNIQ_5585B54F85E0677` (`username`),
  UNIQUE KEY `UNIQ_5585B54E7927C74` (`email`),
  KEY `IDX_5585B5450F9BB84` (`enabled`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bolt_users`
--

LOCK TABLES `bolt_users` WRITE;
/*!40000 ALTER TABLE `bolt_users` DISABLE KEYS */;
INSERT INTO `bolt_users` VALUES (1,'USERNAMEREMOVED','PASSWORDREMOVED','EMAILREMOVED','2020-01-22 12:45:00','128.243.2.15','Martin Porcheron','[\"files://2020-01/feedback.pdf\",\"files://2019-10/sponsor-microsoft-white.png\",\"files://2019-10/sponsor-microsoft-black.png\",\"files://2019-06/partner-uon-white.png\",\"files://2019-06/partner-uon-black.png\",\"files://2019-06/sponsor-sigchi-white.png\",\"files://2019-06/sponsor-sigchi-black.png\"]',1,NULL,NULL,NULL,0,NULL,'[\"root\",\"everyone\"]'),(2,'USERNAMEREMOVED','PASSWORDREMOVED','EMAILREMOVED','2019-07-29 15:04:40','128.243.2.15','Joel Fischer','[]',1,NULL,NULL,NULL,0,NULL,'[\"editor\",\"everyone\"]'),(3,'USERNAMEREMOVED','PASSWORDREMOVED','EMAILREMOVED','2019-10-11 13:28:23','128.243.2.16','Jocelyn Spence','[]',1,NULL,NULL,NULL,0,NULL,'[\"editor\",\"everyone\"]');
/*!40000 ALTER TABLE `bolt_users` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2020-01-31 19:30:07
